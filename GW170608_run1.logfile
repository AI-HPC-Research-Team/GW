Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170608_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170608_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0001, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW170608_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW170608_sample_prior_basis/
Model directory models/GW170608_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0001
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.1263	Cost: 34.24s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.6519	Cost: 8.44s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.1229	Cost: 13.75s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.4153	Cost: 8.71s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 19.9399	Cost: 8.40s
Train Epoch: 1 	Average Loss: 21.4910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0075

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 9.999999753259892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 19.7500	Cost: 39.44s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.5515	Cost: 14.57s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.1584	Cost: 12.46s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 18.6711	Cost: 11.99s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.0652	Cost: 12.08s
Train Epoch: 2 	Average Loss: 19.0560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0766

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 9.999999013039593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 17.7904	Cost: 49.73s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 17.2947	Cost: 6.13s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 16.6550	Cost: 13.81s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 16.3136	Cost: 8.54s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 15.8011	Cost: 8.52s
Train Epoch: 3 	Average Loss: 16.7189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8545

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 9.999997779339173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 15.9242	Cost: 27.87s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 15.4200	Cost: 11.21s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 15.2373	Cost: 19.45s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 15.2595	Cost: 13.36s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 14.7220	Cost: 12.19s
Train Epoch: 4 	Average Loss: 15.2638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9164

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 9.99999605215876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 14.7698	Cost: 54.40s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 14.6254	Cost: 6.27s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 14.2107	Cost: 14.83s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 14.4416	Cost: 8.74s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 14.1512	Cost: 8.07s
Train Epoch: 5 	Average Loss: 14.4544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1439

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 9.999993831498517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 14.2611	Cost: 29.22s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 14.1751	Cost: 11.34s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 13.8206	Cost: 15.55s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 13.8935	Cost: 12.33s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 13.7157	Cost: 12.06s
Train Epoch: 6 	Average Loss: 13.9790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7930

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 9.999991117358668e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 13.8158	Cost: 35.26s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 13.7918	Cost: 7.67s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 13.4578	Cost: 13.38s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 13.6386	Cost: 8.45s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 13.4195	Cost: 8.87s
Train Epoch: 7 	Average Loss: 13.6555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5561

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 9.99998790973948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 13.5314	Cost: 28.84s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 13.3642	Cost: 7.20s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 13.2599	Cost: 17.06s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 13.2898	Cost: 14.38s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 13.1315	Cost: 12.51s
Train Epoch: 8 	Average Loss: 13.3408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1568

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 9.99998420864127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 13.2160	Cost: 31.98s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 13.0682	Cost: 6.39s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 12.8386	Cost: 14.72s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 12.9870	Cost: 9.99s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 12.7902	Cost: 11.65s
Train Epoch: 9 	Average Loss: 13.0051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8311

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 9.999980014064402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 12.8917	Cost: 35.88s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 12.8421	Cost: 10.30s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 12.5350	Cost: 15.11s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 12.8359	Cost: 12.26s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 12.6651	Cost: 12.04s
Train Epoch: 10 	Average Loss: 12.7761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6871

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 9.999975326009292e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 12.5531	Cost: 40.65s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 12.6462	Cost: 7.94s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 12.3813	Cost: 9.58s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 12.5535	Cost: 7.67s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 12.4982	Cost: 13.38s
Train Epoch: 11 	Average Loss: 12.5833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4601

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 9.999970144476398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 12.4046	Cost: 31.99s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 12.4621	Cost: 10.71s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 12.3343	Cost: 14.08s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 12.4055	Cost: 12.57s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 12.0562	Cost: 12.06s
Train Epoch: 12 	Average Loss: 12.4156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3679

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 9.999964469466236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 12.4542	Cost: 38.98s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 12.2507	Cost: 11.69s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 12.1969	Cost: 7.71s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 12.1785	Cost: 6.13s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 12.1052	Cost: 12.62s
Train Epoch: 13 	Average Loss: 12.2440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1837

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 9.999958300979366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 12.3850	Cost: 32.97s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 12.1855	Cost: 9.00s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 11.9864	Cost: 23.59s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 12.0246	Cost: 12.14s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 12.0203	Cost: 11.82s
Train Epoch: 14 	Average Loss: 12.1295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0842

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 9.999951639016395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 11.9553	Cost: 51.35s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 12.0678	Cost: 11.03s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 11.8608	Cost: 6.10s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 12.0553	Cost: 6.47s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 11.8616	Cost: 12.67s
Train Epoch: 15 	Average Loss: 11.9646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9413

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 9.999944483577981e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 11.9860	Cost: 27.94s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 11.7465	Cost: 7.17s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 11.7042	Cost: 19.98s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 11.7444	Cost: 12.63s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 11.6494	Cost: 12.25s
Train Epoch: 16 	Average Loss: 11.7931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7734

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 9.99993683466483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 11.5938	Cost: 33.05s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 11.7385	Cost: 12.19s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 11.5702	Cost: 8.51s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 11.6372	Cost: 6.55s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 11.5060	Cost: 14.30s
Train Epoch: 17 	Average Loss: 11.6705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5396

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 9.999928692277696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 11.5314	Cost: 32.28s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 11.5775	Cost: 10.37s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 11.4740	Cost: 15.81s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 11.5312	Cost: 12.12s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 11.4111	Cost: 12.07s
Train Epoch: 18 	Average Loss: 11.5341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4855

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 9.999920056417385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 11.4134	Cost: 39.64s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 11.4049	Cost: 6.24s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 11.3203	Cost: 12.64s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 11.2652	Cost: 8.84s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 11.1478	Cost: 11.23s
Train Epoch: 19 	Average Loss: 11.4000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3759

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 9.999910927084749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 11.3284	Cost: 31.33s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 11.2879	Cost: 7.94s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 11.1148	Cost: 15.97s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 11.1649	Cost: 12.09s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 11.0898	Cost: 11.82s
Train Epoch: 20 	Average Loss: 11.2299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2385

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 9.999901304280687e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 11.1095	Cost: 32.13s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 11.1308	Cost: 11.33s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 10.9782	Cost: 10.26s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 11.0776	Cost: 6.06s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 11.0590	Cost: 6.97s
Train Epoch: 21 	Average Loss: 11.1001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0477

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 9.99989118800615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 11.0852	Cost: 27.32s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 11.0377	Cost: 8.99s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 10.9486	Cost: 22.53s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 11.0682	Cost: 13.79s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 10.9786	Cost: 12.92s
Train Epoch: 22 	Average Loss: 10.9950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9016

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 9.999880578262136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 10.9337	Cost: 53.54s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 10.8241	Cost: 6.13s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 10.7199	Cost: 15.29s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 10.8556	Cost: 8.52s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 10.7735	Cost: 8.45s
Train Epoch: 23 	Average Loss: 10.8662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8406

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 9.999869475049693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 10.7128	Cost: 29.15s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 10.6506	Cost: 9.68s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 10.7327	Cost: 18.16s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 10.6197	Cost: 12.58s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 10.6650	Cost: 11.84s
Train Epoch: 24 	Average Loss: 10.7164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6632

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 9.999857878369916e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 10.6051	Cost: 35.63s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 10.5341	Cost: 7.44s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 10.4949	Cost: 13.42s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 10.4662	Cost: 8.44s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 10.6233	Cost: 8.04s
Train Epoch: 25 	Average Loss: 10.6267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6949

Learning rate: 9.99984578822395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 10.5988	Cost: 29.03s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 10.6161	Cost: 9.50s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 10.3140	Cost: 13.78s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 10.3850	Cost: 12.49s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 10.5837	Cost: 12.80s
Train Epoch: 26 	Average Loss: 10.5002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5145

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 9.999833204612988e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 10.4457	Cost: 32.55s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 10.3536	Cost: 11.71s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 10.2856	Cost: 8.91s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 10.3021	Cost: 9.38s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 10.3257	Cost: 10.89s
Train Epoch: 27 	Average Loss: 10.3609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3605

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 9.999820127538271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 10.4496	Cost: 33.49s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 10.3124	Cost: 9.04s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 10.2610	Cost: 15.45s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 10.1480	Cost: 12.61s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 10.2394	Cost: 12.08s
Train Epoch: 28 	Average Loss: 10.2513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2601

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 9.999806557001093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 10.2560	Cost: 35.77s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 10.1860	Cost: 11.95s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 10.0506	Cost: 11.00s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 10.0231	Cost: 6.47s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 10.2045	Cost: 7.95s
Train Epoch: 29 	Average Loss: 10.1596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1727

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 9.99979249300279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 10.1156	Cost: 32.24s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 10.0529	Cost: 9.24s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 9.9726	Cost: 18.69s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 9.9715	Cost: 12.70s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 10.0371	Cost: 12.11s
Train Epoch: 30 	Average Loss: 10.0516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0786

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 9.99977793554475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 9.9411	Cost: 35.81s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 10.0297	Cost: 11.06s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 9.8693	Cost: 9.14s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 9.9080	Cost: 6.34s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 10.0068	Cost: 14.15s
Train Epoch: 31 	Average Loss: 9.9553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9121

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 9.999762884628413e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 9.8805	Cost: 33.54s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 9.8105	Cost: 8.80s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 9.7842	Cost: 22.77s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 9.8144	Cost: 12.20s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 9.7943	Cost: 11.76s
Train Epoch: 32 	Average Loss: 9.8753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9292

Learning rate: 9.999747340255259e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 9.8655	Cost: 45.53s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 9.7781	Cost: 11.70s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 9.7495	Cost: 7.13s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 9.6740	Cost: 6.29s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 9.8150	Cost: 10.87s
Train Epoch: 33 	Average Loss: 9.7773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7935

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 9.999731302426829e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 9.7649	Cost: 29.62s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 9.6485	Cost: 6.61s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 9.6352	Cost: 18.81s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 9.6736	Cost: 14.41s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 9.6543	Cost: 12.31s
Train Epoch: 34 	Average Loss: 9.6964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6368

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 9.999714771144701e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 9.6388	Cost: 33.23s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 9.6500	Cost: 8.24s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 9.5225	Cost: 15.42s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 9.5164	Cost: 8.91s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 9.4917	Cost: 10.46s
Train Epoch: 35 	Average Loss: 9.5806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6007

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 9.999697746410508e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 9.5368	Cost: 34.06s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 9.5361	Cost: 13.46s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 9.3674	Cost: 15.29s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 9.4373	Cost: 12.09s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 9.5428	Cost: 12.03s
Train Epoch: 36 	Average Loss: 9.5151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5309

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 9.99968022822593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 9.4990	Cost: 34.01s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 9.4525	Cost: 6.34s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 9.3540	Cost: 12.99s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 9.4447	Cost: 8.98s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 9.3320	Cost: 9.62s
Train Epoch: 37 	Average Loss: 9.4316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4151

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 9.999662216592697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 9.4585	Cost: 30.26s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 9.3188	Cost: 10.50s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 9.3041	Cost: 20.39s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 9.2323	Cost: 12.06s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 9.2945	Cost: 11.87s
Train Epoch: 38 	Average Loss: 9.3594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3670

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 9.999643711512586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 9.2685	Cost: 28.23s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 9.3391	Cost: 6.36s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 9.1541	Cost: 13.74s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 9.2399	Cost: 8.50s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 9.1293	Cost: 9.30s
Train Epoch: 39 	Average Loss: 9.2801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2818

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 9.999624712987422e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 9.2611	Cost: 29.11s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 9.1805	Cost: 11.87s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 9.1068	Cost: 15.43s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 9.1508	Cost: 12.90s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 9.2509	Cost: 12.18s
Train Epoch: 40 	Average Loss: 9.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2067

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 9.999605221019082e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 9.1250	Cost: 30.68s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 9.1444	Cost: 11.90s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 9.1379	Cost: 8.94s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 9.1481	Cost: 7.86s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 9.0316	Cost: 13.20s
Train Epoch: 41 	Average Loss: 9.1259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0624

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 9.999585235609488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 9.0512	Cost: 31.98s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 8.9697	Cost: 10.14s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 8.8990	Cost: 14.83s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 8.9445	Cost: 12.19s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 8.9296	Cost: 12.06s
Train Epoch: 42 	Average Loss: 9.0398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0600

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 9.999564756760615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 9.0772	Cost: 38.15s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 9.0708	Cost: 11.89s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 9.0144	Cost: 7.26s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 9.1140	Cost: 6.48s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 9.0767	Cost: 10.66s
Train Epoch: 43 	Average Loss: 9.0097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0248

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 9.999543784474483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 9.0587	Cost: 32.94s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 8.9845	Cost: 7.54s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 8.9018	Cost: 18.36s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 8.8417	Cost: 12.20s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 8.9264	Cost: 12.36s
Train Epoch: 44 	Average Loss: 8.9277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9647

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 9.99952231875316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 8.9238	Cost: 32.17s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 8.8188	Cost: 6.33s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 8.7264	Cost: 16.89s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 8.8079	Cost: 9.36s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 8.8908	Cost: 9.20s
Train Epoch: 45 	Average Loss: 8.8472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8659

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 9.999500359598768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 8.7930	Cost: 28.11s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 8.7545	Cost: 14.96s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 8.6430	Cost: 17.92s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 8.8863	Cost: 12.68s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 8.7686	Cost: 12.03s
Train Epoch: 46 	Average Loss: 8.7842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7940

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 9.999477907013472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 8.8112	Cost: 36.79s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 8.7301	Cost: 10.85s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 8.6993	Cost: 11.41s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 8.5955	Cost: 8.61s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 8.6555	Cost: 12.22s
Train Epoch: 47 	Average Loss: 8.7197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7690

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 9.999454960999486e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 8.5417	Cost: 30.62s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 8.5485	Cost: 7.40s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 8.6174	Cost: 16.34s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 8.5800	Cost: 12.34s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 8.6964	Cost: 12.24s
Train Epoch: 48 	Average Loss: 8.6681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6621

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 9.99943152155908e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 8.6640	Cost: 40.40s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 8.6341	Cost: 6.32s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 8.4551	Cost: 15.06s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 8.4419	Cost: 8.64s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 8.6100	Cost: 9.43s
Train Epoch: 49 	Average Loss: 8.6012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5952

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 9.999407588694566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 8.7155	Cost: 28.82s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 8.6980	Cost: 8.50s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 8.3961	Cost: 16.31s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 8.4845	Cost: 12.31s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 8.5771	Cost: 12.37s
Train Epoch: 50 	Average Loss: 8.5664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5563

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 9.999383162408302e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 8.5846	Cost: 36.43s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 8.4760	Cost: 6.22s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 8.3612	Cost: 15.25s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 8.4231	Cost: 9.38s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 8.4451	Cost: 11.94s
Train Epoch: 51 	Average Loss: 8.4989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5479

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 9.999358242702702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 8.4831	Cost: 36.54s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 8.3436	Cost: 15.00s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 8.3642	Cost: 14.55s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 8.3010	Cost: 12.17s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 8.4101	Cost: 11.84s
Train Epoch: 52 	Average Loss: 8.4279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3962

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 9.999332829580225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 8.4617	Cost: 37.51s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 8.1934	Cost: 6.33s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 8.3217	Cost: 13.05s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 8.4849	Cost: 8.59s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 8.3410	Cost: 8.67s
Train Epoch: 53 	Average Loss: 8.3807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4206

Learning rate: 9.99930692304338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 8.4783	Cost: 27.78s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 8.2844	Cost: 8.83s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 8.2616	Cost: 20.93s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 8.2720	Cost: 12.33s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 8.1588	Cost: 11.90s
Train Epoch: 54 	Average Loss: 8.2930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2391

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 9.999280523094723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 8.4213	Cost: 45.52s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 8.2674	Cost: 6.71s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 8.1774	Cost: 12.39s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 8.2295	Cost: 8.75s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 8.1360	Cost: 8.68s
Train Epoch: 55 	Average Loss: 8.2539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2584

Learning rate: 9.999253629736859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 8.3026	Cost: 34.34s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 8.2164	Cost: 11.11s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 8.1864	Cost: 20.96s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 8.2188	Cost: 12.31s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 8.1822	Cost: 11.96s
Train Epoch: 56 	Average Loss: 8.2163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2248

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 9.999226242972442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 8.1156	Cost: 36.95s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 8.0652	Cost: 11.28s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 8.0789	Cost: 10.36s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 8.1414	Cost: 8.45s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 8.1492	Cost: 11.76s
Train Epoch: 57 	Average Loss: 8.1620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1073

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 9.999198362804177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 8.2776	Cost: 31.55s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 8.0843	Cost: 7.36s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 8.0105	Cost: 17.63s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 7.9574	Cost: 12.19s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 8.0296	Cost: 12.19s
Train Epoch: 58 	Average Loss: 8.0924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1292

Learning rate: 9.999169989234814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 8.0541	Cost: 32.60s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 7.9452	Cost: 12.28s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 8.0104	Cost: 10.81s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 8.0473	Cost: 6.19s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 7.9750	Cost: 9.52s
Train Epoch: 59 	Average Loss: 8.0554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0403

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 9.999141122267153e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 7.8952	Cost: 30.07s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 7.8544	Cost: 8.06s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 8.0156	Cost: 16.90s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 7.9549	Cost: 13.10s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 7.8923	Cost: 11.99s
Train Epoch: 60 	Average Loss: 8.0177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9781

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 9.999111761904044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 7.9424	Cost: 34.25s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 7.8552	Cost: 12.59s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 7.9556	Cost: 7.96s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 7.9127	Cost: 6.46s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 7.8808	Cost: 12.78s
Train Epoch: 61 	Average Loss: 7.9620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9766

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 9.999081908148385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 8.0777	Cost: 33.00s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 7.8802	Cost: 10.77s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 7.9414	Cost: 18.93s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 7.8322	Cost: 11.96s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 7.7652	Cost: 11.93s
Train Epoch: 62 	Average Loss: 7.9430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9392

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 9.999051561003123e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 7.9113	Cost: 33.15s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 7.9949	Cost: 10.55s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 7.7447	Cost: 9.16s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 7.8139	Cost: 6.20s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 7.9262	Cost: 13.10s
Train Epoch: 63 	Average Loss: 7.9293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9124

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 9.999020720471253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 7.8101	Cost: 29.21s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 7.8529	Cost: 11.55s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 7.7458	Cost: 14.60s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 7.7987	Cost: 13.98s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 7.7399	Cost: 12.07s
Train Epoch: 64 	Average Loss: 7.8520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8745

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 9.998989386555816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 7.9477	Cost: 47.81s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 7.7580	Cost: 10.74s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 7.7908	Cost: 7.72s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 7.7954	Cost: 6.64s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 7.9170	Cost: 13.80s
Train Epoch: 65 	Average Loss: 7.8245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8467

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 9.998957559259906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 7.8713	Cost: 32.64s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 7.7776	Cost: 7.24s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 7.7857	Cost: 17.26s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 7.7385	Cost: 12.21s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 7.6887	Cost: 12.14s
Train Epoch: 66 	Average Loss: 7.7873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8342

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 9.998925238586665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 7.8647	Cost: 35.02s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 7.7434	Cost: 7.65s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 7.7044	Cost: 13.62s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 7.6278	Cost: 8.51s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 7.7302	Cost: 8.59s
Train Epoch: 67 	Average Loss: 7.7520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7398

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 9.998892424539283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 7.7032	Cost: 27.72s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 7.7341	Cost: 9.04s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 7.7003	Cost: 14.90s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 7.7149	Cost: 12.09s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 7.6314	Cost: 12.60s
Train Epoch: 68 	Average Loss: 7.7051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6877

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 9.998859117121e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 7.6705	Cost: 35.24s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 7.5949	Cost: 9.69s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 7.5753	Cost: 8.93s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 7.6681	Cost: 8.72s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 7.6467	Cost: 15.05s
Train Epoch: 69 	Average Loss: 7.6839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6905

Learning rate: 9.998825316335099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 7.5012	Cost: 36.84s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 7.5695	Cost: 8.34s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 7.6768	Cost: 17.65s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 7.6717	Cost: 12.09s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 7.6110	Cost: 12.08s
Train Epoch: 70 	Average Loss: 7.6613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7238

Learning rate: 9.99879102218492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 7.6786	Cost: 33.83s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 7.4733	Cost: 11.61s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 7.6972	Cost: 6.29s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 7.6551	Cost: 6.88s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 7.5487	Cost: 15.25s
Train Epoch: 71 	Average Loss: 7.6083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5933

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 9.998756234673847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 7.6638	Cost: 30.62s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 7.5724	Cost: 10.51s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 7.4226	Cost: 14.42s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 7.6294	Cost: 13.79s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 7.5892	Cost: 12.08s
Train Epoch: 72 	Average Loss: 7.5758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6036

Learning rate: 9.998720953805312e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 7.5078	Cost: 38.35s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 7.4241	Cost: 12.43s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 7.5988	Cost: 12.09s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 7.5320	Cost: 7.46s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 7.4351	Cost: 6.13s
Train Epoch: 73 	Average Loss: 7.5436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5518

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Learning rate: 9.998685179582798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 7.5712	Cost: 32.49s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 7.3948	Cost: 10.50s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 7.5731	Cost: 20.60s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 7.4149	Cost: 12.36s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 7.3204	Cost: 11.79s
Train Epoch: 74 	Average Loss: 7.5154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5652

Learning rate: 9.998648912009835e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 7.3739	Cost: 31.10s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 7.3855	Cost: 11.72s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 7.5064	Cost: 6.16s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 7.4330	Cost: 6.11s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 7.2873	Cost: 13.94s
Train Epoch: 75 	Average Loss: 7.4689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4524

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 9.998612151090003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 7.5028	Cost: 29.99s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 7.4690	Cost: 10.90s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 7.4180	Cost: 22.21s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 7.3562	Cost: 12.70s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 7.3998	Cost: 11.92s
Train Epoch: 76 	Average Loss: 7.4487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4668

Learning rate: 9.998574896826931e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 7.4738	Cost: 44.25s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 7.4272	Cost: 6.01s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 7.3819	Cost: 15.11s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 7.4121	Cost: 8.60s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 7.3719	Cost: 8.76s
Train Epoch: 77 	Average Loss: 7.4106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4662

Learning rate: 9.998537149224293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 7.4360	Cost: 30.09s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 7.2861	Cost: 6.92s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 7.3899	Cost: 18.45s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 7.3409	Cost: 12.37s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 7.2839	Cost: 12.04s
Train Epoch: 78 	Average Loss: 7.3862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4055

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 9.998498908285819e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 7.4530	Cost: 34.52s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 7.2330	Cost: 7.57s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 7.2651	Cost: 13.68s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 7.3077	Cost: 8.54s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 7.2642	Cost: 9.02s
Train Epoch: 79 	Average Loss: 7.3570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3894

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 9.998460174015279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 7.4370	Cost: 27.46s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 7.3237	Cost: 8.30s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 7.3287	Cost: 15.91s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 7.3058	Cost: 12.07s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 7.2171	Cost: 12.40s
Train Epoch: 80 	Average Loss: 7.3298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3292

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 9.998420946416499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 7.5740	Cost: 33.68s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 7.2921	Cost: 9.23s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 7.2601	Cost: 9.17s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 7.0982	Cost: 8.89s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 7.3292	Cost: 13.49s
Train Epoch: 81 	Average Loss: 7.3011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3699

Learning rate: 9.998381225493349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 7.4121	Cost: 32.02s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 7.1979	Cost: 11.24s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 7.2878	Cost: 17.90s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 7.2555	Cost: 12.38s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 7.2781	Cost: 11.83s
Train Epoch: 82 	Average Loss: 7.2823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3480

Learning rate: 9.998341011249749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 7.3127	Cost: 39.56s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 7.2948	Cost: 11.18s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 7.2803	Cost: 7.97s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 7.1555	Cost: 6.18s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 7.3152	Cost: 13.45s
Train Epoch: 83 	Average Loss: 7.2782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3146

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 9.99830030368967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 7.3634	Cost: 30.05s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 7.0806	Cost: 10.07s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 7.1849	Cost: 18.98s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 7.0763	Cost: 12.53s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 7.1187	Cost: 12.20s
Train Epoch: 84 	Average Loss: 7.2042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2341

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 9.998259102817127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 7.1774	Cost: 41.75s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 7.1771	Cost: 8.37s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 7.1157	Cost: 10.96s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 7.2142	Cost: 8.96s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 7.0841	Cost: 12.23s
Train Epoch: 85 	Average Loss: 7.2000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2359

Learning rate: 9.99821740863619e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 7.0945	Cost: 48.71s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 7.0703	Cost: 12.33s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 7.1555	Cost: 12.26s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 7.2144	Cost: 12.14s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 7.0207	Cost: 11.90s
Train Epoch: 86 	Average Loss: 7.1384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1478

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 9.99817522115097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 7.1024	Cost: 43.46s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 7.1098	Cost: 6.18s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 7.2740	Cost: 13.47s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 7.1056	Cost: 8.55s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 7.0362	Cost: 8.34s
Train Epoch: 87 	Average Loss: 7.1400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1684

Learning rate: 9.998132540365634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 7.2303	Cost: 28.69s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 7.0815	Cost: 7.83s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 7.2147	Cost: 18.65s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 7.1422	Cost: 13.24s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 6.9562	Cost: 12.10s
Train Epoch: 88 	Average Loss: 7.1285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1337

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 9.998089366284391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 7.1606	Cost: 44.85s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 7.0295	Cost: 10.46s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 7.1177	Cost: 10.92s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 7.1466	Cost: 6.13s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 6.9694	Cost: 12.61s
Train Epoch: 89 	Average Loss: 7.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0938

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 9.998045698911504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 7.0008	Cost: 31.41s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 7.0556	Cost: 6.92s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 7.1005	Cost: 17.21s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 6.9708	Cost: 12.67s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 7.0835	Cost: 12.04s
Train Epoch: 90 	Average Loss: 7.0692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0890

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 9.998001538251281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 7.1834	Cost: 43.82s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 7.0987	Cost: 8.97s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 7.0510	Cost: 10.01s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 6.9855	Cost: 8.22s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 6.8907	Cost: 10.42s
Train Epoch: 91 	Average Loss: 7.0359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0682

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 9.997956884308085e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 7.0298	Cost: 27.51s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 7.0267	Cost: 8.66s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 7.0210	Cost: 15.16s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 6.9675	Cost: 11.93s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 6.9683	Cost: 12.49s
Train Epoch: 92 	Average Loss: 7.0238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0626

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 9.99791173708632e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 7.0322	Cost: 32.60s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 6.9554	Cost: 10.31s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 7.0218	Cost: 8.17s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 6.9099	Cost: 10.30s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 6.9625	Cost: 12.70s
Train Epoch: 93 	Average Loss: 6.9945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0467

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 9.997866096590442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 7.1491	Cost: 33.66s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 7.0460	Cost: 8.48s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 6.9780	Cost: 18.36s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 6.8174	Cost: 12.21s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 7.0212	Cost: 11.89s
Train Epoch: 94 	Average Loss: 6.9916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0153

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Learning rate: 9.997819962824954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 6.9836	Cost: 38.75s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 6.9701	Cost: 10.75s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 6.9919	Cost: 6.30s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 6.8311	Cost: 7.14s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 6.8698	Cost: 13.38s
Train Epoch: 95 	Average Loss: 6.9468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9491

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 9.997773335794414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 6.9399	Cost: 33.26s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 6.9564	Cost: 10.27s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 7.0105	Cost: 15.44s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 6.9198	Cost: 12.19s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 6.8607	Cost: 12.02s
Train Epoch: 96 	Average Loss: 6.9493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9360

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 9.99772621550342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 6.9251	Cost: 34.49s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 6.8762	Cost: 9.12s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 6.8922	Cost: 7.88s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 6.8233	Cost: 7.76s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 6.8496	Cost: 14.02s
Train Epoch: 97 	Average Loss: 6.9042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0058

Learning rate: 9.997678601956623e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 6.9233	Cost: 27.05s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 6.8912	Cost: 7.39s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 6.8536	Cost: 21.49s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 6.8210	Cost: 13.78s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 6.8210	Cost: 12.17s
Train Epoch: 98 	Average Loss: 6.8863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9184

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Learning rate: 9.997630495158724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 6.9240	Cost: 32.51s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 6.8984	Cost: 11.85s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 6.8622	Cost: 8.22s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 6.7516	Cost: 6.43s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 6.8028	Cost: 15.42s
Train Epoch: 99 	Average Loss: 6.8613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9305

Learning rate: 9.997581895114468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 6.8852	Cost: 29.27s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 6.8027	Cost: 9.78s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 6.8716	Cost: 17.25s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 6.9701	Cost: 12.41s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 6.7063	Cost: 12.18s
Train Epoch: 100 	Average Loss: 6.8516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8690

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 9.997532801828656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 6.8821	Cost: 36.14s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 6.6689	Cost: 13.44s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 6.7816	Cost: 7.86s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 6.8198	Cost: 6.56s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 6.7423	Cost: 14.06s
Train Epoch: 101 	Average Loss: 6.8149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8800

Learning rate: 9.997483215306129e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 6.8620	Cost: 32.29s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 6.8590	Cost: 7.39s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 6.8271	Cost: 17.57s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 6.7456	Cost: 11.98s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 6.7755	Cost: 11.99s
Train Epoch: 102 	Average Loss: 6.8285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7634

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 9.997433135551784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 6.7611	Cost: 31.47s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 6.7982	Cost: 11.58s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 6.7229	Cost: 7.55s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 6.6986	Cost: 6.60s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 6.6716	Cost: 14.68s
Train Epoch: 103 	Average Loss: 6.7758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8483

Learning rate: 9.99738256257056e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 6.8594	Cost: 34.90s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 6.7729	Cost: 7.67s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 6.7410	Cost: 20.47s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 6.7499	Cost: 12.00s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 6.7273	Cost: 12.19s
Train Epoch: 104 	Average Loss: 6.7846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7599

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 9.997331496367453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 6.7584	Cost: 32.22s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 6.6879	Cost: 11.88s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 6.7941	Cost: 8.19s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 6.6754	Cost: 6.57s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 6.7110	Cost: 12.89s
Train Epoch: 105 	Average Loss: 6.7438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7877

Learning rate: 9.997279936947499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 6.6922	Cost: 32.47s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 6.6850	Cost: 10.72s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 6.7027	Cost: 18.13s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 6.6465	Cost: 12.37s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 6.5864	Cost: 11.99s
Train Epoch: 106 	Average Loss: 6.7204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7333

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 9.997227884315788e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 6.7411	Cost: 39.20s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 6.7159	Cost: 8.89s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 6.6971	Cost: 9.00s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 6.6304	Cost: 8.06s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 6.6480	Cost: 13.13s
Train Epoch: 107 	Average Loss: 6.7391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6953

Saving model as e107_model.pt & e107_waveforms_supplementary.hdf5
Learning rate: 9.997175338477459e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 6.7192	Cost: 32.07s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 6.6825	Cost: 8.33s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 6.6101	Cost: 16.42s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 6.6838	Cost: 12.52s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 6.6478	Cost: 12.14s
Train Epoch: 108 	Average Loss: 6.7075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7057

Learning rate: 9.997122299437696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 6.6787	Cost: 31.92s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 6.6562	Cost: 10.36s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 6.6099	Cost: 12.56s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 6.5559	Cost: 9.79s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 6.6440	Cost: 14.40s
Train Epoch: 109 	Average Loss: 6.6873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7291

Learning rate: 9.997068767201736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 6.6318	Cost: 35.37s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 6.7322	Cost: 10.07s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 6.6643	Cost: 19.19s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 6.5748	Cost: 12.52s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 6.6543	Cost: 11.76s
Train Epoch: 110 	Average Loss: 6.6211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6734

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 9.997014741774862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 6.6159	Cost: 53.15s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 6.6502	Cost: 6.19s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 6.6778	Cost: 14.06s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 6.6897	Cost: 8.55s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 6.6257	Cost: 7.88s
Train Epoch: 111 	Average Loss: 6.6379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6977

Learning rate: 9.996960223162402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 6.6874	Cost: 77.52s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 6.6251	Cost: 20.29s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 6.5929	Cost: 58.25s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 6.5047	Cost: 18.56s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 6.5383	Cost: 37.12s
Train Epoch: 112 	Average Loss: 6.6094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6301

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 9.996905211369744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 6.6983	Cost: 95.55s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 6.6484	Cost: 16.46s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 6.6594	Cost: 38.20s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 6.4816	Cost: 10.62s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 6.5285	Cost: 43.28s
Train Epoch: 113 	Average Loss: 6.6120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6320

Learning rate: 9.996849706402311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 6.6670	Cost: 39.21s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 6.5410	Cost: 14.28s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 6.4974	Cost: 15.09s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 6.4918	Cost: 12.21s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 6.4361	Cost: 9.92s
Train Epoch: 114 	Average Loss: 6.5756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6542

Learning rate: 9.996793708265583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 6.5917	Cost: 28.14s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 6.5624	Cost: 8.99s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 6.5199	Cost: 9.96s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 6.4796	Cost: 8.93s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 6.4723	Cost: 8.40s
Train Epoch: 115 	Average Loss: 6.5632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6354

Learning rate: 9.996737216965088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 6.6261	Cost: 33.99s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 6.5705	Cost: 12.27s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 6.4208	Cost: 14.35s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 6.4684	Cost: 12.36s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 6.4897	Cost: 10.48s
Train Epoch: 116 	Average Loss: 6.5558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5383

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 9.9966802325064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 6.5507	Cost: 31.82s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 6.5754	Cost: 9.21s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 6.5106	Cost: 18.77s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 6.4945	Cost: 9.10s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 6.4129	Cost: 9.03s
Train Epoch: 117 	Average Loss: 6.5284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5019

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 9.996622754895145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 6.4632	Cost: 37.48s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 6.4365	Cost: 7.39s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 6.5246	Cost: 18.31s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 6.4476	Cost: 12.12s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 6.4534	Cost: 12.02s
Train Epoch: 118 	Average Loss: 6.5048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5253

Learning rate: 9.996564784136994e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 6.5068	Cost: 33.70s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 6.4600	Cost: 9.86s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 6.5638	Cost: 11.06s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 6.3992	Cost: 9.18s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 6.4872	Cost: 11.88s
Train Epoch: 119 	Average Loss: 6.4880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5586

Learning rate: 9.99650632023767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 6.5798	Cost: 35.59s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 6.6070	Cost: 11.19s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 6.4497	Cost: 21.94s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 6.3147	Cost: 12.08s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 6.4734	Cost: 11.95s
Train Epoch: 120 	Average Loss: 6.4699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5489

Learning rate: 9.996447363202941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 6.4486	Cost: 38.12s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 6.3722	Cost: 6.47s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 6.3888	Cost: 14.87s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 6.5024	Cost: 8.54s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 6.3846	Cost: 8.94s
Train Epoch: 121 	Average Loss: 6.4735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5446

Learning rate: 9.996387913038628e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 6.4351	Cost: 34.17s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 6.3681	Cost: 11.02s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 6.3475	Cost: 19.26s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 6.4383	Cost: 12.51s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 6.5784	Cost: 12.04s
Train Epoch: 122 	Average Loss: 6.4515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5778

Learning rate: 9.996327969750598e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 6.6383	Cost: 36.62s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 6.4210	Cost: 6.42s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 6.4125	Cost: 14.25s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 6.4658	Cost: 8.56s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 6.3777	Cost: 9.05s
Train Epoch: 123 	Average Loss: 6.4662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5166

Learning rate: 9.996267533344767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 6.6979	Cost: 30.56s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 6.3063	Cost: 8.70s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 6.4197	Cost: 17.41s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 6.4079	Cost: 14.34s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 6.4117	Cost: 12.52s
Train Epoch: 124 	Average Loss: 6.4180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5084

Learning rate: 9.996206603827099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 6.4975	Cost: 38.44s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 6.4552	Cost: 13.88s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 6.3408	Cost: 12.05s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 6.2868	Cost: 6.23s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 6.2819	Cost: 9.63s
Train Epoch: 125 	Average Loss: 6.3846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4067

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 9.99614518120361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 6.3748	Cost: 33.08s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 6.4128	Cost: 8.75s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 6.3245	Cost: 9.95s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 6.4086	Cost: 6.56s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 6.3149	Cost: 18.55s
Train Epoch: 126 	Average Loss: 6.3737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4837

Learning rate: 9.99608326548036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 6.5417	Cost: 46.84s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 6.5310	Cost: 11.91s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 6.3048	Cost: 11.31s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 6.3544	Cost: 6.41s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 6.3307	Cost: 8.69s
Train Epoch: 127 	Average Loss: 6.3816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4381

Learning rate: 9.996020856663458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 6.5058	Cost: 30.42s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 6.4278	Cost: 5.95s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 6.2824	Cost: 15.01s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 6.3719	Cost: 12.45s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 6.3970	Cost: 14.04s
Train Epoch: 128 	Average Loss: 6.3594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4599

Learning rate: 9.995957954759067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 6.3490	Cost: 36.09s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 6.5151	Cost: 12.63s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 6.3339	Cost: 12.31s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 6.2903	Cost: 10.67s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 6.2832	Cost: 7.19s
Train Epoch: 129 	Average Loss: 6.3388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4648

Learning rate: 9.995894559773395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 6.4175	Cost: 35.23s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 6.3130	Cost: 10.86s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 6.3118	Cost: 9.89s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 6.2203	Cost: 8.91s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 6.3310	Cost: 18.73s
Train Epoch: 130 	Average Loss: 6.3429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3666

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 9.995830671712695e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 6.5239	Cost: 39.67s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 6.3551	Cost: 10.83s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 6.3239	Cost: 12.65s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 6.3963	Cost: 11.69s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 6.3810	Cost: 6.25s
Train Epoch: 131 	Average Loss: 6.3253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4084

Learning rate: 9.995766290583277e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 6.3193	Cost: 30.54s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 6.3454	Cost: 9.10s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 6.2718	Cost: 10.92s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 6.2074	Cost: 7.31s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 6.3324	Cost: 11.75s
Train Epoch: 132 	Average Loss: 6.3078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3512

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 9.995701416391493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 6.2999	Cost: 40.89s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 6.3656	Cost: 11.90s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 6.2350	Cost: 12.38s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 6.2141	Cost: 12.18s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 6.3627	Cost: 7.78s
Train Epoch: 133 	Average Loss: 6.2831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3813

Learning rate: 9.995636049143747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 6.4911	Cost: 30.84s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 6.3839	Cost: 10.80s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 6.1868	Cost: 11.86s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 6.2812	Cost: 10.04s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 6.1560	Cost: 8.37s
Train Epoch: 134 	Average Loss: 6.2753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3636

Learning rate: 9.995570188846488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 6.4748	Cost: 35.42s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 6.3367	Cost: 9.47s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 6.1959	Cost: 24.01s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 6.2499	Cost: 12.39s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 6.3103	Cost: 11.87s
Train Epoch: 135 	Average Loss: 6.2707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3676

Learning rate: 9.99550383550622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 6.3231	Cost: 43.37s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 6.2785	Cost: 11.76s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 6.2054	Cost: 7.76s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 6.2762	Cost: 6.46s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 6.1202	Cost: 13.01s
Train Epoch: 136 	Average Loss: 6.2809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3539

Learning rate: 9.995436989129488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 6.4593	Cost: 29.51s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 6.3292	Cost: 6.30s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 6.2142	Cost: 20.98s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 6.1924	Cost: 12.85s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 6.2284	Cost: 12.25s
Train Epoch: 137 	Average Loss: 6.2485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3453

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 9.99536964972289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 6.3294	Cost: 47.30s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 6.2514	Cost: 12.20s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 6.2980	Cost: 9.07s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 6.1096	Cost: 6.19s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 6.0229	Cost: 13.72s
Train Epoch: 138 	Average Loss: 6.2459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2503

Saving model as e138_model.pt & e138_waveforms_supplementary.hdf5
Learning rate: 9.995301817293077e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 6.3704	Cost: 32.21s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 6.1288	Cost: 8.77s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 6.0921	Cost: 15.94s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 6.2098	Cost: 12.23s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 6.1480	Cost: 12.49s
Train Epoch: 139 	Average Loss: 6.2036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2864

Learning rate: 9.995233491846737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 6.2702	Cost: 60.65s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 6.1874	Cost: 10.41s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 6.1930	Cost: 8.65s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 6.1518	Cost: 6.93s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 6.1486	Cost: 12.59s
Train Epoch: 140 	Average Loss: 6.1745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3187

Learning rate: 9.995164673390618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 6.3032	Cost: 29.21s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 6.1562	Cost: 6.74s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 6.1056	Cost: 17.28s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 6.1005	Cost: 11.49s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 6.0334	Cost: 12.87s
Train Epoch: 141 	Average Loss: 6.1776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2274

Saving model as e141_model.pt & e141_waveforms_supplementary.hdf5
Learning rate: 9.995095361931511e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 6.1836	Cost: 60.83s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 6.2066	Cost: 12.82s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 6.0870	Cost: 30.15s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 6.1879	Cost: 12.08s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 6.0999	Cost: 12.66s
Train Epoch: 142 	Average Loss: 6.1976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2624

Learning rate: 9.995025557476254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 6.2638	Cost: 36.95s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 6.1729	Cost: 7.75s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 5.9593	Cost: 16.45s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 6.1778	Cost: 12.14s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 6.0294	Cost: 12.16s
Train Epoch: 143 	Average Loss: 6.1273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2152

Saving model as e143_model.pt & e143_waveforms_supplementary.hdf5
Learning rate: 9.99495526003174e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 6.0905	Cost: 32.17s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 6.1370	Cost: 10.52s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 6.0923	Cost: 10.38s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 6.1260	Cost: 6.80s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 6.0303	Cost: 14.18s
Train Epoch: 144 	Average Loss: 6.1241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1803

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 9.994884469604905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 6.3429	Cost: 32.75s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 6.0927	Cost: 10.17s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 6.1513	Cost: 20.17s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 6.1178	Cost: 12.18s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 5.9675	Cost: 12.00s
Train Epoch: 145 	Average Loss: 6.1306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1699

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 9.994813186202739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 6.1690	Cost: 34.08s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 6.1628	Cost: 8.12s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 6.0294	Cost: 16.33s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 6.0552	Cost: 8.84s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 6.1336	Cost: 11.84s
Train Epoch: 146 	Average Loss: 6.1203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1507

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Learning rate: 9.994741409832273e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 6.1643	Cost: 49.78s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 5.9923	Cost: 11.59s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 6.0620	Cost: 13.04s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 6.0510	Cost: 12.04s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 6.0750	Cost: 11.71s
Train Epoch: 147 	Average Loss: 6.1098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1778

Learning rate: 9.994669140500594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 6.1256	Cost: 33.66s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 6.1439	Cost: 9.52s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 5.9378	Cost: 10.03s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 6.0519	Cost: 7.26s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 5.9944	Cost: 14.65s
Train Epoch: 148 	Average Loss: 6.0888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1102

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 9.994596378214833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 6.1751	Cost: 32.47s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 6.0971	Cost: 10.38s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 5.9614	Cost: 19.29s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 6.1187	Cost: 12.74s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 5.9743	Cost: 11.88s
Train Epoch: 149 	Average Loss: 6.0788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1220

Learning rate: 9.994523122982173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 6.0931	Cost: 34.42s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 6.0487	Cost: 12.42s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 6.0233	Cost: 7.96s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 6.0403	Cost: 6.89s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 5.9036	Cost: 12.73s
Train Epoch: 150 	Average Loss: 6.0543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0515

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Learning rate: 9.994449374809844e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 6.0288	Cost: 38.77s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 5.9694	Cost: 10.66s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 6.0819	Cost: 17.71s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 6.0099	Cost: 12.04s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 6.0304	Cost: 11.95s
Train Epoch: 151 	Average Loss: 6.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1707

Learning rate: 9.994375133705122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 6.1241	Cost: 43.35s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 6.1390	Cost: 10.69s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 5.9668	Cost: 6.89s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 5.9571	Cost: 6.14s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 5.9302	Cost: 13.01s
Train Epoch: 152 	Average Loss: 6.0246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0677

Learning rate: 9.994300399675336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 6.2463	Cost: 31.70s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 6.0630	Cost: 8.45s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 5.9639	Cost: 22.19s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 6.0298	Cost: 12.80s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 5.8402	Cost: 15.20s
Train Epoch: 153 	Average Loss: 6.0182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0190

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Learning rate: 9.994225172727863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 6.0942	Cost: 37.38s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 6.0141	Cost: 9.49s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 5.9210	Cost: 10.42s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 5.9484	Cost: 8.85s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 5.8031	Cost: 13.80s
Train Epoch: 154 	Average Loss: 5.9992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0476

Learning rate: 9.994149452870126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 6.0392	Cost: 30.07s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 5.8425	Cost: 10.89s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 5.9551	Cost: 20.88s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 5.9987	Cost: 12.14s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 5.9663	Cost: 11.90s
Train Epoch: 155 	Average Loss: 5.9842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1378

Learning rate: 9.9940732401096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 6.1294	Cost: 36.20s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 5.9545	Cost: 7.88s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 5.9397	Cost: 12.42s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 6.1020	Cost: 9.00s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 5.8659	Cost: 12.49s
Train Epoch: 156 	Average Loss: 6.0034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9978

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 9.993996534453805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 6.1065	Cost: 41.58s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 5.9484	Cost: 11.86s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 5.9291	Cost: 12.55s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 6.0263	Cost: 12.06s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 5.9306	Cost: 11.92s
Train Epoch: 157 	Average Loss: 5.9841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0724

Learning rate: 9.993919335910311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 6.0500	Cost: 32.23s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 5.9103	Cost: 12.20s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 5.8875	Cost: 9.50s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 6.0483	Cost: 6.11s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 5.9073	Cost: 10.85s
Train Epoch: 158 	Average Loss: 5.9729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0423

Learning rate: 9.993841644486739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 6.0186	Cost: 29.76s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 5.9055	Cost: 9.54s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 5.9072	Cost: 25.58s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 5.9495	Cost: 12.86s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 5.9185	Cost: 12.00s
Train Epoch: 159 	Average Loss: 5.9549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1010

Learning rate: 9.993763460190757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 6.1714	Cost: 49.41s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 5.9573	Cost: 6.24s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 5.8571	Cost: 14.44s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 5.8533	Cost: 8.53s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 5.9769	Cost: 8.66s
Train Epoch: 160 	Average Loss: 5.9488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0418

Learning rate: 9.993684783030081e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 6.0968	Cost: 30.25s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 5.9502	Cost: 7.71s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 5.8619	Cost: 24.76s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 5.9498	Cost: 11.97s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 5.7687	Cost: 12.18s
Train Epoch: 161 	Average Loss: 5.9566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0672

Learning rate: 9.993605613012475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 6.1717	Cost: 43.37s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 5.9350	Cost: 10.15s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 5.8706	Cost: 10.84s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 5.8969	Cost: 6.45s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 5.9388	Cost: 12.05s
Train Epoch: 162 	Average Loss: 5.9283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0165

Learning rate: 9.993525950145754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 5.8960	Cost: 29.91s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 5.9581	Cost: 7.38s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 5.8397	Cost: 22.12s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 5.9432	Cost: 12.47s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 5.8286	Cost: 12.02s
Train Epoch: 163 	Average Loss: 5.9291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0622

Learning rate: 9.993445794437781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 6.0316	Cost: 85.00s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 5.9196	Cost: 14.63s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 5.7855	Cost: 18.41s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 5.8699	Cost: 10.88s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 5.8607	Cost: 24.65s
Train Epoch: 164 	Average Loss: 5.9117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0034

Learning rate: 9.993365145896465e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 6.0262	Cost: 39.32s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 5.9498	Cost: 6.49s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 5.7862	Cost: 17.92s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 5.8780	Cost: 12.11s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 5.7621	Cost: 11.83s
Train Epoch: 165 	Average Loss: 5.8893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9735

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Learning rate: 9.993284004529768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 5.9759	Cost: 30.95s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 6.0114	Cost: 8.37s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 5.8043	Cost: 11.40s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 5.8925	Cost: 6.17s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 5.7087	Cost: 15.74s
Train Epoch: 166 	Average Loss: 5.8805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9731

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Learning rate: 9.993202370345697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 5.9566	Cost: 43.42s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 5.8308	Cost: 13.57s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 5.7291	Cost: 13.48s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 5.8501	Cost: 12.21s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 5.8063	Cost: 11.93s
Train Epoch: 167 	Average Loss: 5.8908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0331

Learning rate: 9.993120243352309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 6.1272	Cost: 44.97s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 5.8926	Cost: 7.53s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 5.8409	Cost: 11.36s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 5.7543	Cost: 8.99s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 5.7880	Cost: 8.88s
Train Epoch: 168 	Average Loss: 5.8727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9734

Learning rate: 9.993037623557708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 6.1665	Cost: 29.12s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 5.8840	Cost: 12.85s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 5.8346	Cost: 17.44s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 5.9119	Cost: 12.33s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 5.7426	Cost: 11.89s
Train Epoch: 169 	Average Loss: 5.8519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0018

Learning rate: 9.992954510970051e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 5.8755	Cost: 39.58s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 5.8122	Cost: 12.50s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 5.7036	Cost: 12.08s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 5.7747	Cost: 10.68s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 5.6777	Cost: 6.10s
Train Epoch: 170 	Average Loss: 5.8368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9722

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 9.99287090559754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 5.9311	Cost: 28.17s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 5.8144	Cost: 6.55s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 5.7027	Cost: 13.77s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 5.7321	Cost: 8.62s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 5.8105	Cost: 7.35s
Train Epoch: 171 	Average Loss: 5.8337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9225

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 9.992786807448426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 6.0631	Cost: 34.68s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 5.7979	Cost: 12.87s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 5.7275	Cost: 14.97s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 5.8091	Cost: 12.89s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 5.8350	Cost: 11.36s
Train Epoch: 172 	Average Loss: 5.8277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8900

Saving model as e172_model.pt & e172_waveforms_supplementary.hdf5
Learning rate: 9.992702216531012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 5.7045	Cost: 34.71s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 5.8288	Cost: 9.62s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 5.7161	Cost: 12.83s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 5.7804	Cost: 8.79s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 5.7131	Cost: 11.46s
Train Epoch: 173 	Average Loss: 5.8028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8681

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 9.992617132853643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 5.8003	Cost: 32.98s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 5.7612	Cost: 10.43s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 5.7065	Cost: 16.83s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 5.8472	Cost: 12.11s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 5.6609	Cost: 12.21s
Train Epoch: 174 	Average Loss: 5.7927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8661

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 9.992531556424718e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 5.7915	Cost: 50.58s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 5.7673	Cost: 7.03s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 5.7227	Cost: 14.26s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 5.8069	Cost: 8.65s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 5.7097	Cost: 8.03s
Train Epoch: 175 	Average Loss: 5.7917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8815

Learning rate: 9.992445487252684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 5.9897	Cost: 29.68s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 5.7205	Cost: 8.50s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 5.6306	Cost: 16.70s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 5.6935	Cost: 11.97s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 5.7741	Cost: 12.00s
Train Epoch: 176 	Average Loss: 5.7826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8703

Learning rate: 9.992358925346033e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 5.9466	Cost: 32.47s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 5.8613	Cost: 10.63s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 5.6388	Cost: 8.92s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 5.7968	Cost: 6.11s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 5.7278	Cost: 13.49s
Train Epoch: 177 	Average Loss: 5.7805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9378

Learning rate: 9.992271870713308e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 5.8553	Cost: 29.79s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 5.8444	Cost: 10.69s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 5.6623	Cost: 21.30s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 5.7508	Cost: 13.13s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 5.7751	Cost: 12.20s
Train Epoch: 178 	Average Loss: 5.7725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8700

Learning rate: 9.992184323363105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 5.9023	Cost: 52.73s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 5.7435	Cost: 6.38s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 5.6381	Cost: 14.37s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 5.7674	Cost: 8.48s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 5.8582	Cost: 8.33s
Train Epoch: 179 	Average Loss: 5.7726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8600

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 9.992096283304062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 5.9649	Cost: 29.72s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 5.8071	Cost: 7.87s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 5.6436	Cost: 17.26s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 5.7175	Cost: 13.15s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 5.6308	Cost: 12.21s
Train Epoch: 180 	Average Loss: 5.7428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8927

Learning rate: 9.992007750544869e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 5.8219	Cost: 45.22s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 5.8431	Cost: 11.72s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 5.7527	Cost: 8.03s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 5.7246	Cost: 6.35s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 5.5761	Cost: 12.28s
Train Epoch: 181 	Average Loss: 5.7631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8615

Learning rate: 9.991918725094262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 5.7630	Cost: 30.69s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 5.7977	Cost: 7.35s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 5.5196	Cost: 17.93s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 5.7210	Cost: 14.60s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 5.6273	Cost: 14.80s
Train Epoch: 182 	Average Loss: 5.7111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8088

Saving model as e182_model.pt & e182_waveforms_supplementary.hdf5
Learning rate: 9.99182920696103e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 5.8655	Cost: 34.51s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 5.7261	Cost: 11.51s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 5.6690	Cost: 10.78s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 5.6456	Cost: 7.74s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 5.6259	Cost: 13.55s
Train Epoch: 183 	Average Loss: 5.7106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8917

Learning rate: 9.991739196154006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 5.7668	Cost: 33.69s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 5.6784	Cost: 9.91s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 5.5798	Cost: 19.08s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 5.7847	Cost: 12.16s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 5.6527	Cost: 12.14s
Train Epoch: 184 	Average Loss: 5.7083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8239

Learning rate: 9.991648692682075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 5.6739	Cost: 42.52s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 5.6930	Cost: 6.18s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 5.6482	Cost: 14.64s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 5.6718	Cost: 8.72s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 5.5676	Cost: 10.49s
Train Epoch: 185 	Average Loss: 5.6956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7691

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 9.991557696554169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 5.7407	Cost: 29.94s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 5.6142	Cost: 10.83s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 5.5298	Cost: 16.10s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 5.6920	Cost: 12.28s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 5.6189	Cost: 12.20s
Train Epoch: 186 	Average Loss: 5.6849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8233

Learning rate: 9.99146620777927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 5.8346	Cost: 32.11s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 5.7453	Cost: 8.82s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 5.5255	Cost: 9.97s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 5.6619	Cost: 6.67s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 5.5764	Cost: 13.89s
Train Epoch: 187 	Average Loss: 5.6757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8022

Learning rate: 9.991374226366404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 5.8849	Cost: 28.86s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 5.6809	Cost: 8.95s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 5.5753	Cost: 23.17s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 5.5863	Cost: 11.61s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 5.5563	Cost: 16.25s
Train Epoch: 188 	Average Loss: 5.6722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7969

Learning rate: 9.991281752324654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 5.6228	Cost: 43.98s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 5.6714	Cost: 11.94s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 5.5850	Cost: 7.76s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 5.6763	Cost: 6.26s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 5.6139	Cost: 13.84s
Train Epoch: 189 	Average Loss: 5.6499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8100

Learning rate: 9.991188785663142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 5.8329	Cost: 30.10s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 5.6033	Cost: 7.85s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 5.5181	Cost: 18.79s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 5.5033	Cost: 12.29s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 5.4792	Cost: 12.10s
Train Epoch: 190 	Average Loss: 5.6367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7474

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 9.991095326391049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 5.8078	Cost: 41.90s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 5.6485	Cost: 12.12s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 5.4944	Cost: 7.20s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 5.6123	Cost: 6.13s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 5.5235	Cost: 13.81s
Train Epoch: 191 	Average Loss: 5.6392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7428

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 9.991001374517595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 5.5974	Cost: 28.76s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 5.6981	Cost: 7.06s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 5.5032	Cost: 18.80s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 5.5352	Cost: 14.68s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 5.5549	Cost: 13.42s
Train Epoch: 192 	Average Loss: 5.6269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7804

Learning rate: 9.990906930052053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 5.8077	Cost: 39.08s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 5.6049	Cost: 13.25s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 5.4470	Cost: 11.48s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 5.5262	Cost: 8.16s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 5.4366	Cost: 10.17s
Train Epoch: 193 	Average Loss: 5.6207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7578

Learning rate: 9.990811993003745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 5.6395	Cost: 35.55s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 5.6438	Cost: 8.58s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 5.5139	Cost: 11.56s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 5.4680	Cost: 7.10s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 5.4486	Cost: 18.58s
Train Epoch: 194 	Average Loss: 5.5960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7096

Saving model as e194_model.pt & e194_waveforms_supplementary.hdf5
Learning rate: 9.990716563382042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 5.7009	Cost: 41.49s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 5.6776	Cost: 13.03s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 5.4848	Cost: 12.55s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 5.5037	Cost: 10.35s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 5.5678	Cost: 6.59s
Train Epoch: 195 	Average Loss: 5.6053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7158

Learning rate: 9.990620641196361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 5.6535	Cost: 35.77s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 5.6651	Cost: 8.05s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 5.4855	Cost: 13.71s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 5.6096	Cost: 8.54s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 5.5448	Cost: 6.67s
Train Epoch: 196 	Average Loss: 5.5846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7539

Learning rate: 9.99052422645617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 5.8026	Cost: 28.93s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 5.5687	Cost: 8.72s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 5.3071	Cost: 17.62s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 5.5043	Cost: 11.75s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 5.4893	Cost: 11.96s
Train Epoch: 197 	Average Loss: 5.5798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7368

Learning rate: 9.990427319170984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 5.6619	Cost: 31.83s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 5.6701	Cost: 12.36s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 5.5069	Cost: 8.12s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 5.5575	Cost: 7.20s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 5.4741	Cost: 13.79s
Train Epoch: 198 	Average Loss: 5.5894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6963

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 9.990329919350368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 5.7309	Cost: 82.12s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 5.7059	Cost: 16.71s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 5.3835	Cost: 29.23s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 5.5468	Cost: 17.34s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 5.5105	Cost: 21.17s
Train Epoch: 199 	Average Loss: 5.5562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7436

Learning rate: 9.990232027003935e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 5.7710	Cost: 29.75s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 5.5643	Cost: 10.13s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 5.4148	Cost: 9.76s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 5.5940	Cost: 8.18s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 5.5536	Cost: 18.83s
Train Epoch: 200 	Average Loss: 5.5703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7112

Learning rate: 9.990133642141346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 5.8491	Cost: 37.96s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 5.6316	Cost: 14.33s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 5.4571	Cost: 12.19s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 5.6109	Cost: 11.80s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 5.4574	Cost: 6.27s
Train Epoch: 201 	Average Loss: 5.5684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6787

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 9.990034764772311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 5.5497	Cost: 28.74s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 5.6284	Cost: 8.77s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 5.4272	Cost: 10.21s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 5.5102	Cost: 9.01s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 5.4821	Cost: 11.88s
Train Epoch: 202 	Average Loss: 5.5322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6898

Learning rate: 9.98993539490659e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 5.7672	Cost: 31.07s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 5.4293	Cost: 13.29s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 5.4313	Cost: 14.69s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 5.5374	Cost: 12.69s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 5.4357	Cost: 9.08s
Train Epoch: 203 	Average Loss: 5.5357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7255

Learning rate: 9.989835532553989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 5.7594	Cost: 33.93s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 5.5667	Cost: 11.43s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 5.3484	Cost: 11.04s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 5.5477	Cost: 9.17s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 5.4042	Cost: 15.76s
Train Epoch: 204 	Average Loss: 5.5278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6944

Learning rate: 9.989735177724366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 5.6777	Cost: 32.87s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 5.5558	Cost: 6.49s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 5.3472	Cost: 20.60s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 5.5117	Cost: 12.06s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 5.3686	Cost: 12.06s
Train Epoch: 205 	Average Loss: 5.4998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6756

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 9.989634330427624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 5.6739	Cost: 34.40s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 5.5113	Cost: 10.46s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 5.4040	Cost: 10.55s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 5.4304	Cost: 6.51s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 5.4328	Cost: 13.46s
Train Epoch: 206 	Average Loss: 5.4942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6414

Saving model as e206_model.pt & e206_waveforms_supplementary.hdf5
Learning rate: 9.989532990673716e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 5.5476	Cost: 31.84s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 5.5114	Cost: 10.06s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 5.4040	Cost: 13.52s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 5.4512	Cost: 13.36s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 5.4438	Cost: 11.84s
Train Epoch: 207 	Average Loss: 5.4967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6326

Saving model as e207_model.pt & e207_waveforms_supplementary.hdf5
Learning rate: 9.989431158472645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 5.6747	Cost: 41.95s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 5.6276	Cost: 11.96s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 5.3877	Cost: 12.07s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 5.4764	Cost: 8.46s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 5.3968	Cost: 6.23s
Train Epoch: 208 	Average Loss: 5.4996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6636

Learning rate: 9.98932883383446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 5.6730	Cost: 29.26s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 5.4771	Cost: 9.04s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 5.2840	Cost: 10.75s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 5.4448	Cost: 8.66s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 5.4657	Cost: 9.38s
Train Epoch: 209 	Average Loss: 5.4958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7167

Learning rate: 9.989226016769262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 5.5858	Cost: 29.11s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 5.4730	Cost: 10.71s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 5.3951	Cost: 15.33s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 5.4389	Cost: 13.64s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 5.4740	Cost: 11.94s
Train Epoch: 210 	Average Loss: 5.4664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6901

Learning rate: 9.989122707287198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 5.7712	Cost: 47.83s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 5.5091	Cost: 11.72s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 5.3983	Cost: 7.54s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 5.3965	Cost: 6.16s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 5.3294	Cost: 11.59s
Train Epoch: 211 	Average Loss: 5.4715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5865

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 9.989018905398462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 5.6262	Cost: 28.79s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 5.5669	Cost: 7.20s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 5.2851	Cost: 18.23s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 5.4014	Cost: 13.59s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 5.3333	Cost: 12.41s
Train Epoch: 212 	Average Loss: 5.4593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6198

Learning rate: 9.9889146111133e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 5.6548	Cost: 35.98s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 5.4641	Cost: 12.21s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 5.3709	Cost: 7.95s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 5.3759	Cost: 7.37s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.2353	Cost: 15.39s
Train Epoch: 213 	Average Loss: 5.4534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5325

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Learning rate: 9.988809824442008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 5.5500	Cost: 28.04s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 5.5589	Cost: 10.22s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 5.3879	Cost: 13.84s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 5.4569	Cost: 12.96s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 5.3172	Cost: 12.01s
Train Epoch: 214 	Average Loss: 5.4206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6107

Learning rate: 9.988704545394925e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 5.5373	Cost: 45.58s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 5.5444	Cost: 11.58s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 5.4262	Cost: 11.11s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 5.3841	Cost: 7.15s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.3823	Cost: 9.18s
Train Epoch: 215 	Average Loss: 5.4503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5858

Learning rate: 9.988598773982444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 5.5966	Cost: 44.40s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 5.5241	Cost: 6.00s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.3580	Cost: 13.03s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 5.3567	Cost: 10.59s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 5.2484	Cost: 16.78s
Train Epoch: 216 	Average Loss: 5.4325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5672

Learning rate: 9.988492510215002e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 5.5179	Cost: 39.81s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 5.4558	Cost: 12.56s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.3261	Cost: 12.24s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 5.3828	Cost: 7.22s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.2635	Cost: 6.38s
Train Epoch: 217 	Average Loss: 5.4067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5244

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 9.988385754103088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 5.4801	Cost: 32.26s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 5.4767	Cost: 8.64s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 5.2594	Cost: 14.20s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 5.3051	Cost: 9.13s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 5.3372	Cost: 16.68s
Train Epoch: 218 	Average Loss: 5.4080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5488

Learning rate: 9.988278505657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 5.4955	Cost: 42.01s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 5.4293	Cost: 12.69s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 5.2419	Cost: 12.26s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 5.3935	Cost: 9.67s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.3065	Cost: 6.36s
Train Epoch: 219 	Average Loss: 5.3879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5208

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 9.988170764888036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 5.4205	Cost: 30.53s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 5.5102	Cost: 9.93s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 5.1697	Cost: 9.21s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 5.3574	Cost: 7.97s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 5.3026	Cost: 13.61s
Train Epoch: 220 	Average Loss: 5.4031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5076

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Learning rate: 9.988062531806117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 5.6623	Cost: 44.27s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 5.3757	Cost: 12.79s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 5.2523	Cost: 12.11s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 5.3031	Cost: 10.52s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.2040	Cost: 6.34s
Train Epoch: 221 	Average Loss: 5.3833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5082

Learning rate: 9.987953806422163e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 5.4533	Cost: 28.65s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 5.4194	Cost: 8.85s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 5.2733	Cost: 10.16s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 5.3516	Cost: 9.44s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.3691	Cost: 8.05s
Train Epoch: 222 	Average Loss: 5.3822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5684

Learning rate: 9.987844588746906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 5.5576	Cost: 32.32s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 5.4490	Cost: 12.23s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 5.2266	Cost: 15.52s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 5.3170	Cost: 12.37s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.1809	Cost: 12.02s
Train Epoch: 223 	Average Loss: 5.3637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5451

Learning rate: 9.987734878791122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 5.4399	Cost: 32.57s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 5.3821	Cost: 13.57s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 5.2138	Cost: 12.95s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 5.4018	Cost: 8.11s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 5.3303	Cost: 13.81s
Train Epoch: 224 	Average Loss: 5.3684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5498

Learning rate: 9.987624676565643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 5.5698	Cost: 33.89s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 5.4166	Cost: 10.40s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 5.2350	Cost: 20.31s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 5.3071	Cost: 11.85s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.2778	Cost: 12.23s
Train Epoch: 225 	Average Loss: 5.3611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5045

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 9.987513982081342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 5.5997	Cost: 41.44s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 5.4523	Cost: 6.80s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 5.1697	Cost: 14.73s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 5.2546	Cost: 8.87s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.2542	Cost: 8.91s
Train Epoch: 226 	Average Loss: 5.3276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4592

Saving model as e226_model.pt & e226_waveforms_supplementary.hdf5
Learning rate: 9.987402795349145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 5.4842	Cost: 30.23s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 5.4083	Cost: 10.42s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 5.2101	Cost: 13.28s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 5.2837	Cost: 11.97s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.2267	Cost: 12.00s
Train Epoch: 227 	Average Loss: 5.3471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5692

Learning rate: 9.987291116380029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 5.4608	Cost: 31.09s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 5.4430	Cost: 11.84s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 5.2173	Cost: 7.10s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 5.2434	Cost: 6.13s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.2774	Cost: 14.91s
Train Epoch: 228 	Average Loss: 5.3178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5369

Learning rate: 9.98717894518501e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 5.3621	Cost: 29.42s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 5.3525	Cost: 11.36s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 5.2369	Cost: 12.67s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 5.3385	Cost: 14.48s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 5.1844	Cost: 12.22s
Train Epoch: 229 	Average Loss: 5.3058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4681

Learning rate: 9.987066281775164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 5.4117	Cost: 49.54s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 5.4227	Cost: 12.12s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 5.1390	Cost: 6.68s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 5.3936	Cost: 6.37s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.2161	Cost: 13.42s
Train Epoch: 230 	Average Loss: 5.3225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5257

Learning rate: 9.98695312616161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 5.5415	Cost: 26.86s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 5.3709	Cost: 9.45s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 5.1678	Cost: 15.95s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 5.2859	Cost: 12.70s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.2674	Cost: 11.89s
Train Epoch: 231 	Average Loss: 5.3100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5023

Learning rate: 9.986839478355513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 5.3926	Cost: 48.96s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 5.3109	Cost: 11.05s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 5.2244	Cost: 8.35s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 5.1672	Cost: 6.45s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.1415	Cost: 12.62s
Train Epoch: 232 	Average Loss: 5.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5073

Learning rate: 9.986725338368092e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 5.4815	Cost: 30.71s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 5.3078	Cost: 12.14s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.1468	Cost: 17.22s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 5.3293	Cost: 12.97s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.1288	Cost: 12.47s
Train Epoch: 233 	Average Loss: 5.2843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4461

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 9.986610706210612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 5.4180	Cost: 57.44s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 5.4210	Cost: 6.04s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 5.0675	Cost: 12.29s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 5.3330	Cost: 8.59s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.2629	Cost: 8.59s
Train Epoch: 234 	Average Loss: 5.2933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4092

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 9.986495581894385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 5.3884	Cost: 31.02s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 5.2877	Cost: 11.49s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 5.1162	Cost: 12.58s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 5.2082	Cost: 12.38s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.2264	Cost: 12.07s
Train Epoch: 235 	Average Loss: 5.2778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5007

Learning rate: 9.986379965430775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 5.4058	Cost: 33.21s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 5.3637	Cost: 8.31s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.1735	Cost: 13.99s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 5.2496	Cost: 8.40s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.1624	Cost: 8.81s
Train Epoch: 236 	Average Loss: 5.2817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4393

Learning rate: 9.986263856831194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 5.3808	Cost: 30.17s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 5.3202	Cost: 10.94s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 5.0931	Cost: 17.22s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 5.1414	Cost: 12.73s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.0668	Cost: 12.49s
Train Epoch: 237 	Average Loss: 5.2249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4304

Learning rate: 9.9861472561071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 5.4675	Cost: 31.98s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 5.2459	Cost: 9.33s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.0927	Cost: 12.53s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 5.1165	Cost: 8.76s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.2597	Cost: 12.27s
Train Epoch: 238 	Average Loss: 5.2458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5033

Learning rate: 9.98603016327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 5.5455	Cost: 48.93s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 5.2322	Cost: 9.41s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 5.0555	Cost: 15.87s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 5.1682	Cost: 12.16s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 4.9869	Cost: 12.05s
Train Epoch: 239 	Average Loss: 5.2245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4192

Learning rate: 9.985912578331452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 5.3105	Cost: 37.68s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 5.3606	Cost: 9.98s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 5.0585	Cost: 9.72s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 5.0305	Cost: 6.82s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.2438	Cost: 14.80s
Train Epoch: 240 	Average Loss: 5.2301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4253

Learning rate: 9.985794501303059e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 5.4927	Cost: 40.08s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 5.3217	Cost: 10.46s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.1836	Cost: 17.45s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 5.1360	Cost: 12.34s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.1766	Cost: 11.84s
Train Epoch: 241 	Average Loss: 5.2347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4497

Learning rate: 9.985675932196479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 5.3029	Cost: 36.02s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 5.2924	Cost: 10.14s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.1303	Cost: 8.51s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 5.1625	Cost: 6.31s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.1063	Cost: 14.40s
Train Epoch: 242 	Average Loss: 5.2069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3663

Saving model as e242_model.pt & e242_waveforms_supplementary.hdf5
Learning rate: 9.985556871023408e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 5.2885	Cost: 35.61s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 5.3366	Cost: 9.26s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.0559	Cost: 20.78s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 5.1288	Cost: 12.19s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.1135	Cost: 11.94s
Train Epoch: 243 	Average Loss: 5.1764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4457

Learning rate: 9.985437317795604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 5.3865	Cost: 28.07s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 5.2471	Cost: 6.36s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.0617	Cost: 14.55s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 5.1578	Cost: 8.61s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.0867	Cost: 8.50s
Train Epoch: 244 	Average Loss: 5.2070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4866

Learning rate: 9.985317272524864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 5.5428	Cost: 32.34s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 5.1843	Cost: 13.25s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.0875	Cost: 19.57s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 5.0907	Cost: 12.55s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 5.1547	Cost: 11.96s
Train Epoch: 245 	Average Loss: 5.1766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4431

Learning rate: 9.985196735223035e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 5.2775	Cost: 39.65s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 5.1448	Cost: 11.96s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 5.1334	Cost: 8.18s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 5.1059	Cost: 6.62s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 5.0645	Cost: 13.34s
Train Epoch: 246 	Average Loss: 5.1787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4202

Learning rate: 9.985075705902012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 5.3891	Cost: 29.54s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 5.2185	Cost: 11.20s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 5.0734	Cost: 20.57s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 5.1690	Cost: 12.25s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 5.1356	Cost: 12.26s
Train Epoch: 247 	Average Loss: 5.1855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3907

Learning rate: 9.984954184573743e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 5.5543	Cost: 54.55s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 5.2340	Cost: 6.48s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 4.9884	Cost: 13.30s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 5.0483	Cost: 8.74s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 5.0313	Cost: 8.38s
Train Epoch: 248 	Average Loss: 5.1520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3669

Learning rate: 9.984832171250219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 5.4567	Cost: 28.58s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 5.1990	Cost: 8.31s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 5.0923	Cost: 16.95s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 5.0392	Cost: 12.39s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 5.1351	Cost: 12.22s
Train Epoch: 249 	Average Loss: 5.1666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4119

Learning rate: 9.984709665943483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 5.5062	Cost: 31.84s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 5.2785	Cost: 11.84s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.0224	Cost: 10.52s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 5.0806	Cost: 6.45s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.0405	Cost: 11.36s
Train Epoch: 250 	Average Loss: 5.1863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3951

Learning rate: 9.98458666866563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 5.4699	Cost: 35.32s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 5.1431	Cost: 6.58s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 4.9127	Cost: 16.45s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 5.0162	Cost: 9.56s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.0132	Cost: 14.67s
Train Epoch: 251 	Average Loss: 5.1404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3560

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 9.984463179428794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 5.2940	Cost: 50.27s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 5.2160	Cost: 9.99s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 5.0076	Cost: 8.02s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 4.9020	Cost: 6.57s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.9994	Cost: 14.56s
Train Epoch: 252 	Average Loss: 5.0977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3463

Saving model as e252_model.pt & e252_waveforms_supplementary.hdf5
Learning rate: 9.984339198245162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 5.2813	Cost: 33.30s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 5.1853	Cost: 10.07s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 4.9715	Cost: 15.28s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 5.0369	Cost: 12.18s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.0928	Cost: 12.26s
Train Epoch: 253 	Average Loss: 5.1207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3439

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 9.984214725126977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 5.4017	Cost: 29.86s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 5.2712	Cost: 11.15s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 4.9157	Cost: 10.06s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 5.0183	Cost: 9.60s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.0259	Cost: 12.08s
Train Epoch: 254 	Average Loss: 5.1180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3688

Learning rate: 9.98408976008652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 5.3877	Cost: 33.78s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 5.1627	Cost: 10.48s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 4.9003	Cost: 18.21s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 5.0197	Cost: 12.52s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.9632	Cost: 11.93s
Train Epoch: 255 	Average Loss: 5.1042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3174

Saving model as e255_model.pt & e255_waveforms_supplementary.hdf5
Learning rate: 9.983964303136122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 5.2801	Cost: 49.08s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 5.1610	Cost: 10.98s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.9451	Cost: 6.94s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 5.1006	Cost: 6.56s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 5.1415	Cost: 13.93s
Train Epoch: 256 	Average Loss: 5.1139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3636

Learning rate: 9.98383835428817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 5.3703	Cost: 30.88s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 5.1923	Cost: 7.95s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 4.9762	Cost: 23.86s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 5.0179	Cost: 12.33s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.9755	Cost: 12.13s
Train Epoch: 257 	Average Loss: 5.1047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2866

Saving model as e257_model.pt & e257_waveforms_supplementary.hdf5
Learning rate: 9.983711913555091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 5.3609	Cost: 50.50s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 5.1601	Cost: 6.99s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.9393	Cost: 14.21s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 5.0749	Cost: 8.64s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.9548	Cost: 9.11s
Train Epoch: 258 	Average Loss: 5.0913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3043

Learning rate: 9.983584980949367e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 5.2106	Cost: 34.57s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 5.2117	Cost: 11.69s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.9901	Cost: 13.06s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 5.0425	Cost: 12.31s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 5.1331	Cost: 12.16s
Train Epoch: 259 	Average Loss: 5.1915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3238

Learning rate: 9.983457556483523e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 5.4948	Cost: 49.03s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 5.1176	Cost: 11.03s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.9699	Cost: 7.42s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 5.0887	Cost: 6.96s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.9169	Cost: 13.65s
Train Epoch: 260 	Average Loss: 5.1221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3461

Learning rate: 9.983329640170136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 5.3403	Cost: 27.07s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 5.1327	Cost: 7.45s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.9778	Cost: 17.70s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 4.9812	Cost: 12.24s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 4.9527	Cost: 12.23s
Train Epoch: 261 	Average Loss: 5.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3382

Learning rate: 9.983201232021833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 5.2756	Cost: 36.55s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 5.1511	Cost: 12.35s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 5.0580	Cost: 8.12s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 4.9091	Cost: 9.14s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.9625	Cost: 12.39s
Train Epoch: 262 	Average Loss: 5.0709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2795

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 9.983072332051286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 5.2626	Cost: 34.61s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 5.1025	Cost: 9.14s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 4.9579	Cost: 16.74s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 5.0303	Cost: 12.08s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 4.9753	Cost: 11.89s
Train Epoch: 263 	Average Loss: 5.0547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2709

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 9.982942940271217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 5.4357	Cost: 38.83s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 5.0347	Cost: 12.52s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 4.9793	Cost: 6.68s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 5.0300	Cost: 6.26s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.8773	Cost: 14.04s
Train Epoch: 264 	Average Loss: 5.0428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2871

Learning rate: 9.982813056694397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 5.1654	Cost: 39.71s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 5.0624	Cost: 7.98s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.9134	Cost: 20.79s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 4.9913	Cost: 12.01s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 4.9226	Cost: 12.03s
Train Epoch: 265 	Average Loss: 5.0126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2678

Saving model as e265_model.pt & e265_waveforms_supplementary.hdf5
Learning rate: 9.982682681333644e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 5.3442	Cost: 85.46s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 5.0972	Cost: 11.02s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 4.8856	Cost: 22.56s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 4.9425	Cost: 10.86s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 4.9242	Cost: 24.72s
Train Epoch: 266 	Average Loss: 5.0279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2992

Learning rate: 9.982551814201825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 5.2183	Cost: 34.95s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 5.0394	Cost: 13.13s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 4.9171	Cost: 13.70s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 5.0565	Cost: 12.29s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 4.8855	Cost: 11.91s
Train Epoch: 267 	Average Loss: 5.0234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3491

Learning rate: 9.982420455311858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 5.3689	Cost: 35.58s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 5.0573	Cost: 11.77s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 4.8600	Cost: 7.96s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 5.0450	Cost: 6.28s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 5.0385	Cost: 12.53s
Train Epoch: 268 	Average Loss: 5.0383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2894

Learning rate: 9.982288604676707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 5.2690	Cost: 31.23s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 4.9792	Cost: 10.16s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 4.9075	Cost: 25.67s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 4.9411	Cost: 13.25s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 4.9499	Cost: 11.93s
Train Epoch: 269 	Average Loss: 5.0195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2776

Learning rate: 9.982156262309383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 5.2806	Cost: 43.81s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 5.1056	Cost: 6.05s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 4.8165	Cost: 15.59s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 4.9328	Cost: 8.45s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 4.8346	Cost: 8.41s
Train Epoch: 270 	Average Loss: 5.0041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2966

Learning rate: 9.98202342822295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 5.3199	Cost: 31.63s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 5.1067	Cost: 7.82s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 4.8654	Cost: 17.40s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 4.9397	Cost: 12.84s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 4.9108	Cost: 11.84s
Train Epoch: 271 	Average Loss: 4.9888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2109

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 9.981890102430519e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 5.1831	Cost: 48.63s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 4.8985	Cost: 6.25s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 4.8953	Cost: 14.87s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 4.8702	Cost: 8.58s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.9026	Cost: 8.86s
Train Epoch: 272 	Average Loss: 4.9583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2666

Learning rate: 9.981756284945245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 5.2770	Cost: 28.42s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 4.9404	Cost: 7.08s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 4.8397	Cost: 17.09s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 4.8936	Cost: 12.10s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.8797	Cost: 12.31s
Train Epoch: 273 	Average Loss: 4.9601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3429

Learning rate: 9.98162197578034e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.2243	Cost: 33.48s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 4.9819	Cost: 8.05s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 4.7435	Cost: 13.26s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 4.8418	Cost: 9.44s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 4.8441	Cost: 13.23s
Train Epoch: 274 	Average Loss: 4.9435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2225

Learning rate: 9.981487174949054e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.2061	Cost: 39.96s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 4.9400	Cost: 10.83s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 4.8090	Cost: 12.79s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 4.9341	Cost: 12.14s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 4.7621	Cost: 12.08s
Train Epoch: 275 	Average Loss: 4.9532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1942

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 9.981351882464696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 5.1219	Cost: 31.95s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 4.9760	Cost: 9.42s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 4.9608	Cost: 10.86s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 4.8788	Cost: 8.85s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 4.7807	Cost: 12.42s
Train Epoch: 276 	Average Loss: 4.9444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1764

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 9.981216098340617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 5.1721	Cost: 29.62s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 4.9214	Cost: 7.93s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 4.8276	Cost: 16.44s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 4.8379	Cost: 12.39s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 4.8558	Cost: 12.40s
Train Epoch: 277 	Average Loss: 4.9314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2487

Learning rate: 9.981079822590219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 5.1792	Cost: 33.34s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 5.0169	Cost: 11.68s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 4.7399	Cost: 7.69s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 4.9071	Cost: 6.55s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 4.8656	Cost: 13.05s
Train Epoch: 278 	Average Loss: 4.9385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1955

Learning rate: 9.980943055226952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.0085	Cost: 29.05s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 4.9316	Cost: 12.10s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.8100	Cost: 20.63s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 4.7923	Cost: 12.54s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 4.8131	Cost: 12.19s
Train Epoch: 279 	Average Loss: 4.9268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1508

Saving model as e279_model.pt & e279_waveforms_supplementary.hdf5
Learning rate: 9.980805796264313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 5.1567	Cost: 45.83s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 4.9213	Cost: 6.15s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 4.8671	Cost: 13.52s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 4.8234	Cost: 8.56s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 4.7086	Cost: 7.91s
Train Epoch: 280 	Average Loss: 4.9200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1706

Learning rate: 9.98066804571585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 5.1868	Cost: 28.46s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 4.9364	Cost: 8.43s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 4.8687	Cost: 21.19s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 4.8569	Cost: 12.74s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 4.9131	Cost: 11.94s
Train Epoch: 281 	Average Loss: 4.9053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2254

Learning rate: 9.980529803595159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 5.2459	Cost: 31.72s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 4.9547	Cost: 10.41s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 4.7081	Cost: 9.24s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 4.8709	Cost: 7.46s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 4.8015	Cost: 12.52s
Train Epoch: 282 	Average Loss: 4.9004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2168

Learning rate: 9.980391069915883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 5.1974	Cost: 27.90s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 4.8937	Cost: 8.85s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 4.7574	Cost: 15.89s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 4.7220	Cost: 13.33s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 4.8027	Cost: 12.57s
Train Epoch: 283 	Average Loss: 4.8792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2086

Learning rate: 9.980251844691714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 5.0310	Cost: 37.30s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 5.0803	Cost: 10.14s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 4.7880	Cost: 11.07s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 4.8754	Cost: 8.52s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 4.8308	Cost: 11.22s
Train Epoch: 284 	Average Loss: 4.8941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1858

Learning rate: 9.980112127936395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 5.1390	Cost: 31.43s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 4.9412	Cost: 8.13s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 4.7899	Cost: 17.69s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 4.8773	Cost: 13.15s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 4.8503	Cost: 12.80s
Train Epoch: 285 	Average Loss: 4.9186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2553

Learning rate: 9.979971919663715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 5.1194	Cost: 40.10s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 4.8996	Cost: 10.98s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 4.7912	Cost: 12.10s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 4.8975	Cost: 12.35s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 4.6981	Cost: 7.59s
Train Epoch: 286 	Average Loss: 4.8709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2458

Learning rate: 9.97983121988751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 5.1433	Cost: 36.17s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 4.9986	Cost: 6.40s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 4.6706	Cost: 14.22s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 4.7379	Cost: 8.75s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 4.8660	Cost: 8.81s
Train Epoch: 287 	Average Loss: 4.8698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2276

Learning rate: 9.97969002862167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 5.2674	Cost: 34.91s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 4.8149	Cost: 8.21s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.6775	Cost: 17.99s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 4.7861	Cost: 12.12s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 4.7754	Cost: 12.12s
Train Epoch: 288 	Average Loss: 4.8609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1550

Learning rate: 9.979548345880126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 5.2247	Cost: 31.15s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 4.8709	Cost: 8.71s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 4.6937	Cost: 9.64s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 4.8552	Cost: 8.34s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 4.7789	Cost: 12.17s
Train Epoch: 289 	Average Loss: 4.8614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1854

Learning rate: 9.979406171676863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 5.2666	Cost: 29.09s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 4.9208	Cost: 10.32s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 4.7338	Cost: 22.04s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 4.6702	Cost: 13.47s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 4.8411	Cost: 12.11s
Train Epoch: 290 	Average Loss: 4.8405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1442

Saving model as e290_model.pt & e290_waveforms_supplementary.hdf5
Learning rate: 9.979263506025915e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 5.1478	Cost: 59.36s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 4.9050	Cost: 7.58s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 4.6845	Cost: 11.56s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 4.8526	Cost: 8.64s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 4.8500	Cost: 8.29s
Train Epoch: 291 	Average Loss: 4.8473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1168

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 9.97912034894136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 5.0580	Cost: 30.99s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 4.8644	Cost: 12.16s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.6405	Cost: 17.05s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 4.6910	Cost: 12.14s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 4.7752	Cost: 12.09s
Train Epoch: 292 	Average Loss: 4.8305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1391

Learning rate: 9.978976700437328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 5.1297	Cost: 38.55s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 4.9204	Cost: 8.24s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 4.7248	Cost: 12.66s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 4.8254	Cost: 9.18s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 4.7654	Cost: 12.03s
Train Epoch: 293 	Average Loss: 4.8301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1186

Learning rate: 9.978832560527998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 5.2052	Cost: 28.15s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 4.7872	Cost: 9.82s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 4.6042	Cost: 17.14s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 4.7165	Cost: 12.13s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 4.6888	Cost: 12.19s
Train Epoch: 294 	Average Loss: 4.8073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1330

Learning rate: 9.978687929227592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 5.1823	Cost: 38.74s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 4.8272	Cost: 12.46s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 4.8062	Cost: 12.11s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 4.8077	Cost: 7.07s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 4.6813	Cost: 10.01s
Train Epoch: 295 	Average Loss: 4.7974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1374

Learning rate: 9.978542806550388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 5.1149	Cost: 46.60s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 4.8824	Cost: 6.76s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 4.6558	Cost: 17.71s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 4.7644	Cost: 12.22s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 4.5935	Cost: 11.93s
Train Epoch: 296 	Average Loss: 4.8009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1454

Learning rate: 9.978397192510708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 5.1199	Cost: 33.23s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 4.7293	Cost: 6.40s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 4.6778	Cost: 14.22s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 4.7585	Cost: 8.91s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 4.6130	Cost: 12.20s
Train Epoch: 297 	Average Loss: 4.7674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1690

Learning rate: 9.978251087122923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 4.9052	Cost: 35.14s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 4.8522	Cost: 13.06s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 4.5626	Cost: 16.22s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 4.7179	Cost: 12.11s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 4.7312	Cost: 11.96s
Train Epoch: 298 	Average Loss: 4.7802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1464

Learning rate: 9.978104490401455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.1257	Cost: 46.30s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 4.8468	Cost: 9.28s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 4.5646	Cost: 7.36s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 4.6914	Cost: 7.92s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 4.5841	Cost: 13.53s
Train Epoch: 299 	Average Loss: 4.7546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1247

Learning rate: 9.977957402360771e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.1240	Cost: 33.19s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 4.8262	Cost: 10.79s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 4.5227	Cost: 20.82s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 4.6707	Cost: 11.91s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 4.6553	Cost: 12.12s
Train Epoch: 300 	Average Loss: 4.7371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1248

Learning rate: 9.977809823015388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 5.1634	Cost: 30.49s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 4.7897	Cost: 6.50s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 4.7094	Cost: 14.18s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 4.6477	Cost: 9.59s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 4.5956	Cost: 12.16s
Train Epoch: 301 	Average Loss: 4.7562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1368

Learning rate: 9.97766175237987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 5.1152	Cost: 27.84s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 4.8049	Cost: 8.82s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 4.5882	Cost: 22.18s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 4.6531	Cost: 14.23s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 4.5975	Cost: 11.97s
Train Epoch: 302 	Average Loss: 4.7345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0895

Saving model as e302_model.pt & e302_waveforms_supplementary.hdf5
Learning rate: 9.977513190468834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 5.0678	Cost: 36.97s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 4.7600	Cost: 13.63s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 4.6916	Cost: 9.53s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 4.6618	Cost: 6.27s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 4.5377	Cost: 14.54s
Train Epoch: 303 	Average Loss: 4.7168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1984

Learning rate: 9.977364137296942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 5.0642	Cost: 31.07s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 4.7904	Cost: 10.29s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 4.5932	Cost: 18.93s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 4.7112	Cost: 12.09s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 4.5386	Cost: 12.14s
Train Epoch: 304 	Average Loss: 4.7088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0234

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Learning rate: 9.977214592878902e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 4.9342	Cost: 38.95s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 4.8484	Cost: 7.16s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 4.5078	Cost: 12.46s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 4.6573	Cost: 8.94s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 4.5645	Cost: 8.68s
Train Epoch: 305 	Average Loss: 4.7075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1160

Learning rate: 9.977064557229477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 5.1413	Cost: 29.37s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 4.7657	Cost: 11.79s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 4.5705	Cost: 18.38s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 4.6826	Cost: 12.25s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 4.5195	Cost: 11.86s
Train Epoch: 306 	Average Loss: 4.7174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0561

Learning rate: 9.976914030363472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 4.9581	Cost: 39.41s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 4.6825	Cost: 8.57s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 4.5602	Cost: 10.89s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 4.6605	Cost: 8.09s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 4.6342	Cost: 9.89s
Train Epoch: 307 	Average Loss: 4.7060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0864

Learning rate: 9.976763012295747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 5.0660	Cost: 30.91s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 4.6883	Cost: 7.07s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 4.5085	Cost: 20.82s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 4.6658	Cost: 13.92s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 4.6119	Cost: 12.56s
Train Epoch: 308 	Average Loss: 4.6801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0943

Learning rate: 9.976611503041203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 5.0172	Cost: 43.07s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 4.7053	Cost: 11.30s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 4.5579	Cost: 8.43s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 4.6461	Cost: 6.10s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 4.5705	Cost: 14.82s
Train Epoch: 309 	Average Loss: 4.6947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0337

Learning rate: 9.976459502614796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 4.9192	Cost: 27.66s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 4.6233	Cost: 8.55s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.5063	Cost: 17.16s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 4.5920	Cost: 11.47s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.5449	Cost: 14.82s
Train Epoch: 310 	Average Loss: 4.6744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0359

Learning rate: 9.976307011031527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 5.1122	Cost: 42.95s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 4.7720	Cost: 13.93s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 4.5187	Cost: 12.12s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 4.5302	Cost: 9.31s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.4985	Cost: 5.89s
Train Epoch: 311 	Average Loss: 4.6572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9904

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 9.976154028306446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 4.9891	Cost: 33.46s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 4.7278	Cost: 8.06s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 4.4043	Cost: 10.41s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 4.4897	Cost: 8.93s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 4.5910	Cost: 8.47s
Train Epoch: 312 	Average Loss: 4.6528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0477

Learning rate: 9.976000554454652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 5.1022	Cost: 33.23s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 4.7396	Cost: 8.42s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 4.5276	Cost: 16.79s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 4.5628	Cost: 11.99s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 4.5455	Cost: 12.36s
Train Epoch: 313 	Average Loss: 4.6534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0120

Learning rate: 9.975846589491293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 4.8698	Cost: 35.50s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 4.6375	Cost: 9.89s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 4.4067	Cost: 9.35s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 4.4901	Cost: 7.06s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 4.4477	Cost: 15.38s
Train Epoch: 314 	Average Loss: 4.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9804

Saving model as e314_model.pt & e314_waveforms_supplementary.hdf5
Learning rate: 9.975692133431563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 5.0353	Cost: 28.77s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 4.7296	Cost: 9.86s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 4.5873	Cost: 21.25s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 4.5594	Cost: 12.24s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 4.5406	Cost: 11.89s
Train Epoch: 315 	Average Loss: 4.6588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0074

Learning rate: 9.975537186290708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 5.0484	Cost: 33.95s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 4.6428	Cost: 13.97s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 4.4561	Cost: 22.18s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 4.5062	Cost: 11.41s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 4.5047	Cost: 28.88s
Train Epoch: 316 	Average Loss: 4.6077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9937

Learning rate: 9.975381748084019e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 4.8421	Cost: 34.63s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 4.6868	Cost: 6.96s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 4.4491	Cost: 16.94s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 4.4767	Cost: 12.33s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 4.3991	Cost: 11.84s
Train Epoch: 317 	Average Loss: 4.6137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9896

Learning rate: 9.975225818826839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 4.9359	Cost: 33.33s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 4.6417	Cost: 11.43s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 4.5134	Cost: 12.08s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 4.5513	Cost: 12.03s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 4.4090	Cost: 8.03s
Train Epoch: 318 	Average Loss: 4.5926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0008

Learning rate: 9.975069398534559e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 5.0782	Cost: 29.28s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 4.6413	Cost: 9.97s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 4.4656	Cost: 15.91s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 4.5345	Cost: 7.04s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 4.4974	Cost: 12.38s
Train Epoch: 319 	Average Loss: 4.6089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9878

Learning rate: 9.974912487222611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 5.0632	Cost: 36.35s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 4.6030	Cost: 12.96s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 4.4358	Cost: 13.75s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 4.5474	Cost: 12.03s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 4.4155	Cost: 11.95s
Train Epoch: 320 	Average Loss: 4.5725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0008

Learning rate: 9.974755084906488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 5.0965	Cost: 33.77s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 4.6495	Cost: 6.51s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.4215	Cost: 14.22s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 4.5013	Cost: 8.71s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 4.4757	Cost: 9.66s
Train Epoch: 321 	Average Loss: 4.5813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8952

Saving model as e321_model.pt & e321_waveforms_supplementary.hdf5
Learning rate: 9.974597191601719e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 5.0422	Cost: 32.41s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 4.5392	Cost: 13.10s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.5038	Cost: 18.30s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 4.5452	Cost: 11.90s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 4.5009	Cost: 11.89s
Train Epoch: 322 	Average Loss: 4.5704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9396

Learning rate: 9.974438807323893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 4.9006	Cost: 30.51s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 4.6042	Cost: 6.65s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.4463	Cost: 12.12s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 4.6076	Cost: 9.06s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.5529	Cost: 9.41s
Train Epoch: 323 	Average Loss: 4.5496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9861

Learning rate: 9.97427993208864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 4.9148	Cost: 28.27s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 4.6518	Cost: 6.73s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.2592	Cost: 22.80s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 4.4168	Cost: 13.95s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.4160	Cost: 12.14s
Train Epoch: 324 	Average Loss: 4.5242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9478

Learning rate: 9.97412056591164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 4.9001	Cost: 34.83s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 4.6618	Cost: 14.11s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.3753	Cost: 9.58s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 4.5348	Cost: 8.21s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.4334	Cost: 10.84s
Train Epoch: 325 	Average Loss: 4.5359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9515

Learning rate: 9.973960708808621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 5.1297	Cost: 33.49s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 4.6432	Cost: 6.70s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.4233	Cost: 18.65s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 4.5441	Cost: 12.59s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 4.4287	Cost: 12.00s
Train Epoch: 326 	Average Loss: 4.5429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9458

Learning rate: 9.97380036079536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 5.0746	Cost: 44.01s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 4.6264	Cost: 11.03s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 4.3792	Cost: 7.60s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 4.4562	Cost: 6.35s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 4.3955	Cost: 14.67s
Train Epoch: 327 	Average Loss: 4.5230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9317

Learning rate: 9.973639521887684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 4.9609	Cost: 33.58s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 4.5263	Cost: 6.94s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.3750	Cost: 18.38s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 4.5208	Cost: 12.19s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.4228	Cost: 11.94s
Train Epoch: 328 	Average Loss: 4.5191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8997

Learning rate: 9.973478192101466e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 4.9458	Cost: 33.04s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 4.6114	Cost: 12.50s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.3290	Cost: 8.82s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 4.4346	Cost: 8.45s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.4466	Cost: 17.49s
Train Epoch: 329 	Average Loss: 4.4997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8539

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Learning rate: 9.973316371452633e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 4.8499	Cost: 33.52s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 4.4994	Cost: 9.19s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.3759	Cost: 25.09s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 4.3859	Cost: 11.87s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.3498	Cost: 11.94s
Train Epoch: 330 	Average Loss: 4.4825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9528

Learning rate: 9.97315405995715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 4.8225	Cost: 42.79s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 4.5648	Cost: 7.13s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.3878	Cost: 12.23s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 4.3807	Cost: 8.66s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.4249	Cost: 9.16s
Train Epoch: 331 	Average Loss: 4.4770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9030

Learning rate: 9.97299125763104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 4.8862	Cost: 30.07s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 4.3891	Cost: 10.07s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.3413	Cost: 19.14s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 4.4170	Cost: 12.00s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 4.3076	Cost: 12.10s
Train Epoch: 332 	Average Loss: 4.4763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8999

Learning rate: 9.972827964490369e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 4.8390	Cost: 40.55s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 4.5179	Cost: 12.21s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.3217	Cost: 8.00s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 4.3979	Cost: 6.42s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.2658	Cost: 13.41s
Train Epoch: 333 	Average Loss: 4.4573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8732

Learning rate: 9.972664180551254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 4.8670	Cost: 31.05s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 4.4880	Cost: 10.79s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.3206	Cost: 22.14s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 4.5317	Cost: 12.16s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.3910	Cost: 11.83s
Train Epoch: 334 	Average Loss: 4.4624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8823

Learning rate: 9.972499905829862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 5.0216	Cost: 47.36s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 4.5138	Cost: 10.87s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.2664	Cost: 9.60s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 4.3944	Cost: 6.23s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 4.2456	Cost: 9.31s
Train Epoch: 335 	Average Loss: 4.4469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8957

Learning rate: 9.972335140342403e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 4.8900	Cost: 29.50s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 4.4594	Cost: 8.92s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.2260	Cost: 11.96s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 4.3137	Cost: 8.48s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 4.2942	Cost: 20.17s
Train Epoch: 336 	Average Loss: 4.4309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8582

Learning rate: 9.972169884105142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 4.8122	Cost: 37.62s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 4.5327	Cost: 12.25s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.3341	Cost: 12.19s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 4.2969	Cost: 12.29s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 4.2886	Cost: 6.35s
Train Epoch: 337 	Average Loss: 4.4184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9116

Learning rate: 9.972004137134385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 4.8081	Cost: 30.72s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 4.4944	Cost: 8.85s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.2583	Cost: 10.25s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 4.3109	Cost: 8.66s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 4.1561	Cost: 9.27s
Train Epoch: 338 	Average Loss: 4.3988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8107

Saving model as e338_model.pt & e338_waveforms_supplementary.hdf5
Learning rate: 9.971837899446494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 4.7280	Cost: 33.00s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 4.4158	Cost: 14.67s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.3292	Cost: 14.31s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 4.2891	Cost: 12.23s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 4.2884	Cost: 6.96s
Train Epoch: 339 	Average Loss: 4.3887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8316

Learning rate: 9.971671171057876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 4.8738	Cost: 40.85s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 4.4936	Cost: 8.95s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.2989	Cost: 10.76s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 4.3688	Cost: 8.57s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 4.2539	Cost: 7.46s
Train Epoch: 340 	Average Loss: 4.4075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8048

Saving model as e340_model.pt & e340_waveforms_supplementary.hdf5
Learning rate: 9.971503951984984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 4.7381	Cost: 32.79s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 4.3905	Cost: 6.91s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.1627	Cost: 18.15s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 4.3411	Cost: 12.13s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 4.3161	Cost: 11.92s
Train Epoch: 341 	Average Loss: 4.3799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8214

Learning rate: 9.971336242244322e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 4.7568	Cost: 33.65s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 4.3900	Cost: 10.80s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 4.1993	Cost: 7.46s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 4.4106	Cost: 7.02s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 4.1910	Cost: 14.84s
Train Epoch: 342 	Average Loss: 4.4022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8115

Learning rate: 9.971168041852446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 4.8329	Cost: 34.74s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 4.4445	Cost: 11.31s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.2921	Cost: 20.11s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 4.2987	Cost: 11.93s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 4.1449	Cost: 11.95s
Train Epoch: 343 	Average Loss: 4.3620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7937

Saving model as e343_model.pt & e343_waveforms_supplementary.hdf5
Learning rate: 9.970999350825954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 4.7163	Cost: 39.76s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 4.3531	Cost: 6.20s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 4.2895	Cost: 12.88s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 4.2981	Cost: 9.08s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 4.2903	Cost: 8.89s
Train Epoch: 344 	Average Loss: 4.3885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8312

Learning rate: 9.970830169181494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 4.8016	Cost: 40.61s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 4.3877	Cost: 12.86s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 4.2095	Cost: 12.40s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 4.3074	Cost: 12.03s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 4.2922	Cost: 11.98s
Train Epoch: 345 	Average Loss: 4.3659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8107

Learning rate: 9.970660496935765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 4.8296	Cost: 31.59s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 4.4017	Cost: 10.34s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 4.1284	Cost: 6.22s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 4.2850	Cost: 6.37s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 4.1857	Cost: 15.79s
Train Epoch: 346 	Average Loss: 4.3595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7549

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Learning rate: 9.970490334105514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 4.6857	Cost: 27.52s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 4.4272	Cost: 10.76s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 4.1941	Cost: 20.44s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 4.1651	Cost: 13.70s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 4.2591	Cost: 11.83s
Train Epoch: 347 	Average Loss: 4.3396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7950

Learning rate: 9.970319680707532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 4.9383	Cost: 59.85s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 4.3067	Cost: 6.09s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 4.1522	Cost: 13.48s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 4.3668	Cost: 8.52s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 4.0969	Cost: 7.67s
Train Epoch: 348 	Average Loss: 4.3324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7366

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 9.970148536758666e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 4.7579	Cost: 27.90s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 4.3471	Cost: 9.31s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 4.2110	Cost: 16.40s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 4.1514	Cost: 12.65s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 4.2095	Cost: 12.07s
Train Epoch: 349 	Average Loss: 4.2987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7905

Learning rate: 9.969976902275804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 4.6834	Cost: 37.49s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 4.3825	Cost: 11.89s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 4.2198	Cost: 7.06s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 4.2597	Cost: 6.19s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 4.2479	Cost: 13.20s
Train Epoch: 350 	Average Loss: 4.3207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7561

Learning rate: 9.969804777275889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 4.7817	Cost: 26.88s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 4.2243	Cost: 6.44s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.2213	Cost: 25.16s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 4.1400	Cost: 14.20s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 4.1429	Cost: 12.21s
Train Epoch: 351 	Average Loss: 4.3050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7278

Saving model as e351_model.pt & e351_waveforms_supplementary.hdf5
Learning rate: 9.969632161775905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 4.7397	Cost: 33.32s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 4.1617	Cost: 11.44s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 4.0308	Cost: 9.98s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 4.2181	Cost: 9.39s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 4.1211	Cost: 11.04s
Train Epoch: 352 	Average Loss: 4.2592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6890

Saving model as e352_model.pt & e352_waveforms_supplementary.hdf5
Learning rate: 9.969459055792892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 4.5579	Cost: 34.44s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 4.3317	Cost: 9.25s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 4.1607	Cost: 19.32s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 4.2388	Cost: 12.70s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 4.1342	Cost: 11.71s
Train Epoch: 353 	Average Loss: 4.2913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7342

Learning rate: 9.969285459343932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 4.6904	Cost: 32.96s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 4.2940	Cost: 10.59s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 4.1362	Cost: 8.52s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 4.1570	Cost: 8.33s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 4.0707	Cost: 12.86s
Train Epoch: 354 	Average Loss: 4.2745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7401

Learning rate: 9.96911137244616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 4.7203	Cost: 35.18s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 4.3414	Cost: 7.11s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 4.1462	Cost: 20.56s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 4.1817	Cost: 12.30s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 4.2022	Cost: 12.03s
Train Epoch: 355 	Average Loss: 4.2752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7832

Learning rate: 9.968936795116758e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 4.8020	Cost: 33.95s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 4.3660	Cost: 11.56s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 4.0952	Cost: 8.16s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 4.1811	Cost: 7.19s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 4.1814	Cost: 15.03s
Train Epoch: 356 	Average Loss: 4.2616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7445

Learning rate: 9.968761727372955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 4.7149	Cost: 34.25s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 4.2575	Cost: 7.93s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 4.1740	Cost: 19.36s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 4.2539	Cost: 12.32s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 4.1488	Cost: 12.16s
Train Epoch: 357 	Average Loss: 4.2639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7356

Learning rate: 9.96858616923203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 4.6892	Cost: 46.65s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 4.2795	Cost: 12.17s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 4.0933	Cost: 7.39s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 4.0793	Cost: 6.33s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 4.1181	Cost: 11.34s
Train Epoch: 358 	Average Loss: 4.2234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7665

Learning rate: 9.96841012071131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 4.7303	Cost: 27.03s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 4.3603	Cost: 10.55s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 4.1542	Cost: 26.12s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 4.0746	Cost: 13.54s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 4.1592	Cost: 12.18s
Train Epoch: 359 	Average Loss: 4.2362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6812

Saving model as e359_model.pt & e359_waveforms_supplementary.hdf5
Learning rate: 9.968233581828168e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 4.7504	Cost: 40.24s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 4.3048	Cost: 9.80s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 4.0324	Cost: 10.01s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 4.0410	Cost: 7.42s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 4.0149	Cost: 12.66s
Train Epoch: 360 	Average Loss: 4.1986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6667

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Learning rate: 9.968056552600032e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 4.6863	Cost: 36.26s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 4.2784	Cost: 11.06s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 4.0915	Cost: 14.83s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 4.2616	Cost: 11.53s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 4.0908	Cost: 12.17s
Train Epoch: 361 	Average Loss: 4.1946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6248

Saving model as e361_model.pt & e361_waveforms_supplementary.hdf5
Learning rate: 9.967879033044371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 4.6817	Cost: 49.18s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 4.1886	Cost: 6.25s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 3.9926	Cost: 13.27s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 4.1742	Cost: 8.49s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 3.9629	Cost: 8.36s
Train Epoch: 362 	Average Loss: 4.1873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6434

Learning rate: 9.967701023178707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 4.6032	Cost: 28.24s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 4.2588	Cost: 6.84s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 4.1330	Cost: 17.22s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 4.1865	Cost: 12.52s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 4.1160	Cost: 12.35s
Train Epoch: 363 	Average Loss: 4.2065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6927

Learning rate: 9.967522523020609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 4.6209	Cost: 33.61s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 4.2688	Cost: 11.40s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.9927	Cost: 10.40s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 4.1645	Cost: 8.30s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 4.0409	Cost: 15.18s
Train Epoch: 364 	Average Loss: 4.1693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6607

Learning rate: 9.967343532587693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 4.7085	Cost: 32.32s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 4.1618	Cost: 10.98s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 3.9818	Cost: 18.60s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 4.1185	Cost: 12.05s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 4.0753	Cost: 11.83s
Train Epoch: 365 	Average Loss: 4.1767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6746

Learning rate: 9.967164051897624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 4.6678	Cost: 45.90s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 4.2069	Cost: 8.08s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 4.0276	Cost: 11.43s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 4.1210	Cost: 9.10s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 4.0169	Cost: 11.93s
Train Epoch: 366 	Average Loss: 4.1477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6735

Learning rate: 9.966984080968118e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 4.6142	Cost: 35.24s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 4.1924	Cost: 7.31s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.9851	Cost: 16.54s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 4.0492	Cost: 12.41s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 4.1016	Cost: 11.70s
Train Epoch: 367 	Average Loss: 4.1672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6952

Learning rate: 9.966803619816938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 4.6944	Cost: 31.88s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 4.1837	Cost: 11.23s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 3.9533	Cost: 9.62s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 4.1755	Cost: 6.06s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 4.0397	Cost: 9.40s
Train Epoch: 368 	Average Loss: 4.1504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6608

Learning rate: 9.966622668461892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 4.6758	Cost: 32.01s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 4.1727	Cost: 10.75s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 4.0712	Cost: 18.82s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 4.0423	Cost: 12.19s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 4.0021	Cost: 12.17s
Train Epoch: 369 	Average Loss: 4.1211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5804

Saving model as e369_model.pt & e369_waveforms_supplementary.hdf5
Learning rate: 9.96644122692084e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 4.5892	Cost: 39.87s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 4.0677	Cost: 8.97s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.9454	Cost: 10.32s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 4.1587	Cost: 8.37s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.8449	Cost: 10.54s
Train Epoch: 370 	Average Loss: 4.0903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6607

Learning rate: 9.966259295211689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 4.4159	Cost: 27.24s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 4.2158	Cost: 7.46s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.9844	Cost: 23.65s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 4.1394	Cost: 12.07s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 4.0034	Cost: 11.69s
Train Epoch: 371 	Average Loss: 4.1300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5737

Saving model as e371_model.pt & e371_waveforms_supplementary.hdf5
Learning rate: 9.966076873352397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 4.5407	Cost: 43.35s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 4.2240	Cost: 11.59s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 4.0285	Cost: 8.39s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 4.0656	Cost: 6.31s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 4.0181	Cost: 12.27s
Train Epoch: 372 	Average Loss: 4.1191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6222

Learning rate: 9.965893961360968e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 4.7202	Cost: 30.78s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 4.1434	Cost: 10.65s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.9379	Cost: 24.13s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 4.0462	Cost: 12.44s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 4.0116	Cost: 12.04s
Train Epoch: 373 	Average Loss: 4.1186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6241

Learning rate: 9.965710559255453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 4.4838	Cost: 51.96s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 4.2165	Cost: 8.22s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.9766	Cost: 12.09s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 3.9668	Cost: 8.54s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.9297	Cost: 8.69s
Train Epoch: 374 	Average Loss: 4.0582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6235

Learning rate: 9.965526667053955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 4.6955	Cost: 30.07s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 4.1857	Cost: 7.10s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.9409	Cost: 18.11s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 4.0671	Cost: 12.23s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.9180	Cost: 11.81s
Train Epoch: 375 	Average Loss: 4.0929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6131

Learning rate: 9.965342284774624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 4.6361	Cost: 32.71s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 4.1910	Cost: 12.34s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.9811	Cost: 8.46s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 4.0270	Cost: 6.37s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.8387	Cost: 12.91s
Train Epoch: 376 	Average Loss: 4.0878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5581

Saving model as e376_model.pt & e376_waveforms_supplementary.hdf5
Learning rate: 9.965157412435655e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 4.5274	Cost: 30.44s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 4.0658	Cost: 8.03s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.9247	Cost: 16.82s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 3.9445	Cost: 11.88s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.8312	Cost: 12.89s
Train Epoch: 377 	Average Loss: 4.0491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5619

Learning rate: 9.964972050055294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 4.4934	Cost: 35.12s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 4.0727	Cost: 9.24s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.9791	Cost: 10.60s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 4.0139	Cost: 8.92s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 3.9093	Cost: 14.87s
Train Epoch: 378 	Average Loss: 4.0585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6236

Learning rate: 9.964786197651839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 4.6881	Cost: 41.58s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 3.9730	Cost: 7.00s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.8301	Cost: 18.67s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 3.9593	Cost: 12.29s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 3.8767	Cost: 12.10s
Train Epoch: 379 	Average Loss: 4.0155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5652

Learning rate: 9.96459985524363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 4.4756	Cost: 34.70s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 3.9629	Cost: 11.78s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 3.9201	Cost: 12.15s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 3.9557	Cost: 8.98s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 3.8177	Cost: 6.27s
Train Epoch: 380 	Average Loss: 3.9971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5584

Learning rate: 9.96441302284906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 4.4112	Cost: 30.06s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 4.0989	Cost: 8.73s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.8060	Cost: 10.23s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 4.0280	Cost: 7.24s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.8765	Cost: 17.30s
Train Epoch: 381 	Average Loss: 3.9963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5367

Saving model as e381_model.pt & e381_waveforms_supplementary.hdf5
Learning rate: 9.964225700486566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 4.6282	Cost: 38.84s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 4.0331	Cost: 14.35s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.7930	Cost: 12.26s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 3.9044	Cost: 12.08s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 3.9734	Cost: 8.00s
Train Epoch: 382 	Average Loss: 4.0042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5522

Learning rate: 9.96403788817464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 4.6262	Cost: 29.38s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 3.9836	Cost: 9.31s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.8887	Cost: 11.14s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 4.0037	Cost: 8.57s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 3.9681	Cost: 8.75s
Train Epoch: 383 	Average Loss: 3.9931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5919

Learning rate: 9.963849585931816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 4.4348	Cost: 29.52s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 4.1081	Cost: 9.43s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.9264	Cost: 23.37s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 4.1269	Cost: 12.16s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 3.7909	Cost: 11.84s
Train Epoch: 384 	Average Loss: 4.0401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5665

Learning rate: 9.963660793776678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 4.5690	Cost: 55.42s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 4.0584	Cost: 6.45s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.9005	Cost: 12.67s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 4.0813	Cost: 8.74s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 3.9032	Cost: 8.52s
Train Epoch: 385 	Average Loss: 4.0202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5384

Learning rate: 9.963471511727859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 4.3782	Cost: 27.11s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 3.9402	Cost: 8.77s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 3.7921	Cost: 16.23s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 3.8867	Cost: 12.76s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 3.7662	Cost: 12.16s
Train Epoch: 386 	Average Loss: 3.9638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5324

Saving model as e386_model.pt & e386_waveforms_supplementary.hdf5
Learning rate: 9.963281739804043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 4.5163	Cost: 32.74s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 3.9467	Cost: 8.16s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.7634	Cost: 13.15s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 3.8453	Cost: 8.71s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 3.7648	Cost: 10.48s
Train Epoch: 387 	Average Loss: 3.9703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5035

Saving model as e387_model.pt & e387_waveforms_supplementary.hdf5
Learning rate: 9.963091478023956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 4.5052	Cost: 28.32s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 4.0793	Cost: 9.69s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 3.6941	Cost: 15.61s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 3.8543	Cost: 13.11s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 3.8671	Cost: 12.18s
Train Epoch: 388 	Average Loss: 3.9395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5525

Learning rate: 9.962900726406379e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 4.5396	Cost: 45.14s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 3.9827	Cost: 11.79s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 3.7526	Cost: 9.14s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 3.9558	Cost: 6.47s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 3.7928	Cost: 14.39s
Train Epoch: 389 	Average Loss: 3.9637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5524

Learning rate: 9.962709484970139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 4.4156	Cost: 29.86s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 3.9766	Cost: 7.13s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 3.7197	Cost: 17.53s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 3.9551	Cost: 12.16s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 3.7486	Cost: 11.86s
Train Epoch: 390 	Average Loss: 3.9507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5218

Learning rate: 9.962517753734109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 4.3493	Cost: 31.33s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 3.9539	Cost: 12.50s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 3.8539	Cost: 11.46s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 3.8084	Cost: 6.31s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 3.8413	Cost: 7.92s
Train Epoch: 391 	Average Loss: 3.9271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5274

Learning rate: 9.962325532717212e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 4.4344	Cost: 37.89s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 3.8174	Cost: 10.04s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 3.6736	Cost: 20.11s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 3.9064	Cost: 11.92s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 3.8159	Cost: 11.82s
Train Epoch: 392 	Average Loss: 3.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5609

Learning rate: 9.96213282193842e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 4.4786	Cost: 43.11s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 3.9294	Cost: 7.25s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 3.7659	Cost: 12.18s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 3.8060	Cost: 8.66s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 3.7381	Cost: 8.12s
Train Epoch: 393 	Average Loss: 3.9015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5018

Saving model as e393_model.pt & e393_waveforms_supplementary.hdf5
Learning rate: 9.961939621416751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 4.3357	Cost: 31.53s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 3.9210	Cost: 11.53s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 3.7468	Cost: 17.77s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 3.8504	Cost: 12.24s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 3.7154	Cost: 11.97s
Train Epoch: 394 	Average Loss: 3.8843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4963

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Learning rate: 9.961745931171276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 4.5975	Cost: 30.86s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 3.8562	Cost: 6.33s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 3.7134	Cost: 14.22s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 3.7825	Cost: 8.62s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 3.6846	Cost: 8.55s
Train Epoch: 395 	Average Loss: 3.8500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4204

Saving model as e395_model.pt & e395_waveforms_supplementary.hdf5
Learning rate: 9.96155175122111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 4.3855	Cost: 27.71s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 3.9717	Cost: 7.00s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 3.6524	Cost: 17.94s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 3.7818	Cost: 13.26s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 3.7439	Cost: 13.08s
Train Epoch: 396 	Average Loss: 3.8774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4847

Learning rate: 9.96135708158542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 4.4849	Cost: 38.03s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 3.8880	Cost: 13.05s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 3.6942	Cost: 12.22s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 3.8518	Cost: 8.53s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 3.6753	Cost: 6.29s
Train Epoch: 397 	Average Loss: 3.8447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4537

Learning rate: 9.961161922283415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 4.5685	Cost: 34.48s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 3.7847	Cost: 8.89s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 3.7723	Cost: 10.80s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 3.7751	Cost: 8.73s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 3.7436	Cost: 9.04s
Train Epoch: 398 	Average Loss: 3.8382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4258

Learning rate: 9.960966273334359e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 4.3946	Cost: 32.38s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 3.9656	Cost: 13.31s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 3.7966	Cost: 17.76s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 3.7677	Cost: 12.22s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 3.6681	Cost: 12.02s
Train Epoch: 399 	Average Loss: 3.8338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3927

Saving model as e399_model.pt & e399_waveforms_supplementary.hdf5
Learning rate: 9.960770134757561e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 4.3484	Cost: 54.36s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 3.8536	Cost: 8.73s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 3.6766	Cost: 8.83s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 3.7160	Cost: 8.88s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 3.6659	Cost: 8.78s
Train Epoch: 400 	Average Loss: 3.8162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4019

Learning rate: 9.96057350657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 4.3347	Cost: 29.38s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 3.9154	Cost: 8.72s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 3.6742	Cost: 16.33s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 3.6437	Cost: 12.31s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 3.6288	Cost: 12.18s
Train Epoch: 401 	Average Loss: 3.8008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4285

Learning rate: 9.960376388798222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 4.3352	Cost: 33.14s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 3.9084	Cost: 11.94s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 3.7431	Cost: 7.77s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 3.7076	Cost: 6.46s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 3.6816	Cost: 14.92s
Train Epoch: 402 	Average Loss: 3.8232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3862

Saving model as e402_model.pt & e402_waveforms_supplementary.hdf5
Learning rate: 9.960178781454541e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 4.3623	Cost: 30.05s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 3.7987	Cost: 7.18s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 3.6490	Cost: 25.88s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 3.7774	Cost: 12.18s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 3.6967	Cost: 12.11s
Train Epoch: 403 	Average Loss: 3.7887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4192

Learning rate: 9.959980684560841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 4.3790	Cost: 35.73s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 3.8088	Cost: 11.91s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 3.7659	Cost: 10.78s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 3.6990	Cost: 7.41s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 3.7249	Cost: 13.41s
Train Epoch: 404 	Average Loss: 3.8124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4663

Learning rate: 9.959782098136674e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 4.4763	Cost: 38.98s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 3.8352	Cost: 6.65s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 3.5510	Cost: 18.00s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 3.6938	Cost: 12.23s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 3.6026	Cost: 11.83s
Train Epoch: 405 	Average Loss: 3.7753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3045

Saving model as e405_model.pt & e405_waveforms_supplementary.hdf5
Learning rate: 9.959583022201639e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 4.3849	Cost: 30.07s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 3.6551	Cost: 11.13s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 3.5768	Cost: 8.30s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 3.5938	Cost: 6.40s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 3.5776	Cost: 14.80s
Train Epoch: 406 	Average Loss: 3.7563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3929

Learning rate: 9.959383456775382e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 4.1759	Cost: 42.56s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 4.0531	Cost: 10.78s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 3.6503	Cost: 15.47s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 3.7917	Cost: 11.86s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 3.7499	Cost: 11.98s
Train Epoch: 407 	Average Loss: 3.8476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4578

Learning rate: 9.959183401877603e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 4.2703	Cost: 36.41s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 3.8358	Cost: 6.53s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 3.6128	Cost: 14.09s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 3.7310	Cost: 8.96s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 3.6321	Cost: 11.57s
Train Epoch: 408 	Average Loss: 3.7694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3390

Learning rate: 9.958982857528043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 4.2374	Cost: 30.62s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 3.7007	Cost: 9.33s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 3.6612	Cost: 16.47s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 3.6480	Cost: 13.48s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 3.6300	Cost: 11.95s
Train Epoch: 409 	Average Loss: 3.7390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3559

Learning rate: 9.958781823746497e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 4.4591	Cost: 39.30s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 3.7164	Cost: 12.44s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 3.6258	Cost: 8.50s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 3.7345	Cost: 6.17s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 3.6069	Cost: 15.30s
Train Epoch: 410 	Average Loss: 3.7704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3363

Learning rate: 9.958580300552807e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 4.3201	Cost: 28.73s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 3.7367	Cost: 10.45s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 3.6160	Cost: 24.76s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 3.7047	Cost: 12.29s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 3.6503	Cost: 11.95s
Train Epoch: 411 	Average Loss: 3.7530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3530

Learning rate: 9.95837828796686e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 4.2689	Cost: 57.13s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 3.7235	Cost: 6.01s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 3.6548	Cost: 14.02s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 3.5261	Cost: 8.58s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 3.5424	Cost: 8.66s
Train Epoch: 412 	Average Loss: 3.7261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3782

Learning rate: 9.958175786008596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 4.3075	Cost: 27.56s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 3.7666	Cost: 7.28s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 3.5352	Cost: 17.17s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 3.5836	Cost: 12.61s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 3.5363	Cost: 12.75s
Train Epoch: 413 	Average Loss: 3.6962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3395

Learning rate: 9.957972794698001e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 4.2710	Cost: 42.62s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 3.6848	Cost: 11.26s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 3.4966	Cost: 9.49s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 3.6299	Cost: 6.27s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 3.5232	Cost: 15.08s
Train Epoch: 414 	Average Loss: 3.6992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3370

Learning rate: 9.957769314055109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 4.2036	Cost: 30.90s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 3.6446	Cost: 6.68s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 3.5477	Cost: 16.40s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 3.6297	Cost: 12.60s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 3.3788	Cost: 12.27s
Train Epoch: 415 	Average Loss: 3.6545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3088

Learning rate: 9.957565344100001e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 4.3262	Cost: 56.34s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 3.7261	Cost: 8.49s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 3.5533	Cost: 10.68s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 3.5277	Cost: 8.90s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 3.6703	Cost: 10.47s
Train Epoch: 416 	Average Loss: 3.6898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3075

Learning rate: 9.95736088485281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 4.3650	Cost: 28.49s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 3.7885	Cost: 6.65s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 3.5074	Cost: 17.48s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 3.5701	Cost: 13.02s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 3.5445	Cost: 12.50s
Train Epoch: 417 	Average Loss: 3.6605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3172

Learning rate: 9.957155936333717e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 4.2352	Cost: 34.07s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 3.7018	Cost: 12.74s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 3.4769	Cost: 10.04s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 3.5672	Cost: 9.38s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 3.5214	Cost: 13.77s
Train Epoch: 418 	Average Loss: 3.6523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2596

Saving model as e418_model.pt & e418_waveforms_supplementary.hdf5
Learning rate: 9.956950498562945e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 4.2604	Cost: 33.99s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 3.6954	Cost: 10.04s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 3.5771	Cost: 13.88s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 3.6002	Cost: 12.03s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 3.3814	Cost: 12.12s
Train Epoch: 419 	Average Loss: 3.6265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3338

Learning rate: 9.956744571560774e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 4.3714	Cost: 37.21s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 3.6237	Cost: 12.37s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 3.4955	Cost: 8.91s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 3.5931	Cost: 6.44s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 3.5017	Cost: 10.71s
Train Epoch: 420 	Average Loss: 3.6325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3208

Learning rate: 9.956538155347526e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 4.4476	Cost: 33.61s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 3.6451	Cost: 6.21s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 3.3904	Cost: 15.24s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 3.4916	Cost: 12.37s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 3.5154	Cost: 14.42s
Train Epoch: 421 	Average Loss: 3.6258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3609

Learning rate: 9.956331249943575e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 4.3753	Cost: 30.52s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 3.7229	Cost: 12.28s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 3.5654	Cost: 12.20s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 3.5149	Cost: 7.39s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 3.3707	Cost: 8.85s
Train Epoch: 422 	Average Loss: 3.6345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3080

Learning rate: 9.956123855369338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 4.2791	Cost: 35.29s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 3.5573	Cost: 9.39s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 3.4959	Cost: 19.68s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 3.5739	Cost: 12.04s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 3.4378	Cost: 11.98s
Train Epoch: 423 	Average Loss: 3.6035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2804

Learning rate: 9.95591597164529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 4.3233	Cost: 40.65s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 3.5225	Cost: 11.90s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 3.4172	Cost: 9.39s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 3.5318	Cost: 6.30s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 3.4777	Cost: 10.94s
Train Epoch: 424 	Average Loss: 3.6082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3431

Learning rate: 9.955707598791946e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 4.2145	Cost: 28.35s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 3.6015	Cost: 7.68s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 3.3991	Cost: 16.28s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 3.5716	Cost: 11.61s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 3.4265	Cost: 13.22s
Train Epoch: 425 	Average Loss: 3.5981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1615

Saving model as e425_model.pt & e425_waveforms_supplementary.hdf5
Learning rate: 9.955498736829867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 4.2553	Cost: 39.07s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 3.5060	Cost: 12.35s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 3.4381	Cost: 8.56s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 3.5392	Cost: 6.26s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 3.4086	Cost: 12.64s
Train Epoch: 426 	Average Loss: 3.5536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2334

Learning rate: 9.955289385779672e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 4.0353	Cost: 38.02s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 3.5949	Cost: 9.99s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 3.4665	Cost: 22.24s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 3.3385	Cost: 12.16s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 3.4286	Cost: 12.19s
Train Epoch: 427 	Average Loss: 3.5699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3048

Learning rate: 9.955079545662022e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 4.3039	Cost: 57.08s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 3.5799	Cost: 6.31s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 3.3639	Cost: 13.06s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 3.4449	Cost: 8.84s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 3.3452	Cost: 8.40s
Train Epoch: 428 	Average Loss: 3.5385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2260

Learning rate: 9.954869216497627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 4.2462	Cost: 28.60s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 3.6337	Cost: 8.63s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 3.3915	Cost: 21.12s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 3.4167	Cost: 12.30s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 3.3825	Cost: 11.85s
Train Epoch: 429 	Average Loss: 3.5275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1716

Learning rate: 9.954658398307247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 4.1360	Cost: 42.57s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 3.5035	Cost: 6.38s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 3.3174	Cost: 14.01s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 3.4414	Cost: 8.37s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 3.3931	Cost: 8.71s
Train Epoch: 430 	Average Loss: 3.5153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2472

Learning rate: 9.954447091111686e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 4.2857	Cost: 29.21s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 3.7275	Cost: 9.18s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 3.3972	Cost: 20.33s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 3.5073	Cost: 13.18s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 3.4798	Cost: 12.20s
Train Epoch: 431 	Average Loss: 3.5970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2859

Learning rate: 9.954235294931802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 4.3167	Cost: 33.17s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 3.5796	Cost: 14.43s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 3.3357	Cost: 11.09s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 3.5053	Cost: 7.83s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 3.3313	Cost: 15.61s
Train Epoch: 432 	Average Loss: 3.5262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1610

Saving model as e432_model.pt & e432_waveforms_supplementary.hdf5
Learning rate: 9.954023009788497e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 4.1517	Cost: 38.61s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 3.4839	Cost: 7.67s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 3.2904	Cost: 17.36s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 3.4112	Cost: 11.98s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 3.3473	Cost: 12.11s
Train Epoch: 433 	Average Loss: 3.5042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1871

Learning rate: 9.953810235702723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 4.2488	Cost: 32.11s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 3.5014	Cost: 11.80s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 3.2633	Cost: 8.02s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 3.6143	Cost: 6.44s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 3.2098	Cost: 16.07s
Train Epoch: 434 	Average Loss: 3.4848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2203

Learning rate: 9.95359697269548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 4.2697	Cost: 29.03s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 3.6049	Cost: 9.13s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 3.3143	Cost: 21.76s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 3.3846	Cost: 12.20s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 3.3562	Cost: 12.22s
Train Epoch: 435 	Average Loss: 3.5051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2486

Learning rate: 9.953383220787815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 4.1522	Cost: 37.11s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 3.4558	Cost: 11.14s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 3.3699	Cost: 9.49s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 3.3749	Cost: 6.46s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 3.3392	Cost: 16.39s
Train Epoch: 436 	Average Loss: 3.4611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1981

Learning rate: 9.953168980000828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 4.1660	Cost: 45.55s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 3.4755	Cost: 6.62s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 3.3080	Cost: 17.34s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 3.4981	Cost: 12.07s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 3.2879	Cost: 11.88s
Train Epoch: 437 	Average Loss: 3.4813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1616

Learning rate: 9.95295425035566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 4.0687	Cost: 30.61s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 3.5124	Cost: 8.87s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 3.2722	Cost: 10.03s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 3.4794	Cost: 7.58s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 3.2469	Cost: 14.56s
Train Epoch: 438 	Average Loss: 3.4454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2473

Learning rate: 9.952739031873505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 4.1116	Cost: 35.69s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 3.3745	Cost: 13.24s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 3.2771	Cost: 16.99s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 3.2960	Cost: 12.26s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 3.3125	Cost: 11.44s
Train Epoch: 439 	Average Loss: 3.4274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0720

Saving model as e439_model.pt & e439_waveforms_supplementary.hdf5
Learning rate: 9.952523324575606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 4.0756	Cost: 33.43s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 3.4756	Cost: 7.18s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 3.2374	Cost: 13.76s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 3.3398	Cost: 8.73s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 3.2675	Cost: 8.43s
Train Epoch: 440 	Average Loss: 3.4061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1651

Learning rate: 9.952307128483249e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 4.2222	Cost: 34.70s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 3.4716	Cost: 10.16s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 3.2683	Cost: 20.70s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 3.2555	Cost: 12.31s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 3.2368	Cost: 11.91s
Train Epoch: 441 	Average Loss: 3.4157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1790

Learning rate: 9.952090443617776e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 4.1394	Cost: 35.16s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 3.4041	Cost: 10.83s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 3.2344	Cost: 8.91s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 3.2625	Cost: 6.16s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 3.4040	Cost: 12.41s
Train Epoch: 442 	Average Loss: 3.4104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2712

Learning rate: 9.95187327000057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 4.2436	Cost: 29.23s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 3.6073	Cost: 9.34s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 3.2042	Cost: 25.82s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 3.2676	Cost: 14.09s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 3.1204	Cost: 12.08s
Train Epoch: 443 	Average Loss: 3.4477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1899

Learning rate: 9.951655607653065e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 4.0963	Cost: 50.67s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 3.5174	Cost: 6.25s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 3.2254	Cost: 14.53s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 3.3534	Cost: 8.67s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 3.1600	Cost: 8.75s
Train Epoch: 444 	Average Loss: 3.4202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1583

Learning rate: 9.951437456596745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 4.1237	Cost: 31.32s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 3.4563	Cost: 7.16s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 3.2931	Cost: 18.34s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 3.3392	Cost: 12.45s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 3.1477	Cost: 11.91s
Train Epoch: 445 	Average Loss: 3.4079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1206

Learning rate: 9.951218816853138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 4.2113	Cost: 38.25s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 3.5003	Cost: 11.37s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 3.2046	Cost: 7.40s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 3.3063	Cost: 6.37s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 3.1752	Cost: 13.63s
Train Epoch: 446 	Average Loss: 3.3815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1078

Learning rate: 9.950999688443825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 4.1027	Cost: 26.46s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 3.3513	Cost: 8.96s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 3.1621	Cost: 15.30s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 3.4311	Cost: 12.21s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 3.1435	Cost: 13.11s
Train Epoch: 447 	Average Loss: 3.3981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0623

Saving model as e447_model.pt & e447_waveforms_supplementary.hdf5
Learning rate: 9.950780071390434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 3.9968	Cost: 32.92s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 3.5107	Cost: 9.37s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 3.1614	Cost: 12.39s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 3.2997	Cost: 9.28s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 3.1216	Cost: 12.69s
Train Epoch: 448 	Average Loss: 3.3786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1693

Learning rate: 9.95055996571464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 4.1811	Cost: 32.62s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 3.3904	Cost: 13.13s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 3.2137	Cost: 13.57s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 3.2852	Cost: 12.24s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 3.1236	Cost: 12.05s
Train Epoch: 449 	Average Loss: 3.3581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1573

Learning rate: 9.950339371438165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 4.0537	Cost: 39.23s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 3.4499	Cost: 12.11s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 3.1183	Cost: 7.14s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 3.3007	Cost: 6.17s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 3.1212	Cost: 13.68s
Train Epoch: 450 	Average Loss: 3.3441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2004

Learning rate: 9.950118288582781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 4.1024	Cost: 32.63s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 3.6066	Cost: 7.79s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 3.3462	Cost: 16.99s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 3.4896	Cost: 12.28s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 3.2859	Cost: 12.16s
Train Epoch: 451 	Average Loss: 3.5083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1696

Learning rate: 9.949896717170309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 4.1063	Cost: 34.07s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 3.3953	Cost: 8.27s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 3.2077	Cost: 11.60s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 3.1651	Cost: 8.72s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 3.1198	Cost: 13.29s
Train Epoch: 452 	Average Loss: 3.3818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0950

Learning rate: 9.949674657222618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 4.0271	Cost: 27.50s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 3.4083	Cost: 8.98s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 3.2519	Cost: 24.49s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 3.2383	Cost: 12.91s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 3.2905	Cost: 11.85s
Train Epoch: 453 	Average Loss: 3.3646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1399

Learning rate: 9.949452108761622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 4.2486	Cost: 58.13s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 3.4901	Cost: 10.69s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 3.2414	Cost: 6.59s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 3.2716	Cost: 6.36s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 3.1115	Cost: 14.05s
Train Epoch: 454 	Average Loss: 3.3474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0847

Learning rate: 9.949229071809287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 4.0983	Cost: 27.73s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 3.2055	Cost: 10.11s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 3.0952	Cost: 22.46s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 3.1617	Cost: 12.32s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 3.0063	Cost: 12.18s
Train Epoch: 455 	Average Loss: 3.2967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0593

Saving model as e455_model.pt & e455_waveforms_supplementary.hdf5
Learning rate: 9.949005546387625e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 4.0290	Cost: 39.47s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 3.3341	Cost: 10.66s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 3.1677	Cost: 7.83s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 3.1137	Cost: 6.52s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 3.1037	Cost: 14.10s
Train Epoch: 456 	Average Loss: 3.2639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1028

Learning rate: 9.9487815325187e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 4.1522	Cost: 26.83s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 3.2371	Cost: 8.72s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 3.1067	Cost: 15.95s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 3.1326	Cost: 12.14s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 3.1460	Cost: 12.42s
Train Epoch: 457 	Average Loss: 3.2682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0270

Saving model as e457_model.pt & e457_waveforms_supplementary.hdf5
Learning rate: 9.948557030224616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 3.9103	Cost: 51.94s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 3.2877	Cost: 8.87s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 3.0353	Cost: 10.16s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 3.1398	Cost: 8.01s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 3.0490	Cost: 11.88s
Train Epoch: 458 	Average Loss: 3.2553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0181

Saving model as e458_model.pt & e458_waveforms_supplementary.hdf5
Learning rate: 9.948332039527536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 4.1780	Cost: 29.10s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 3.1834	Cost: 8.39s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 2.9886	Cost: 16.50s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 3.3403	Cost: 12.07s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 3.1022	Cost: 12.41s
Train Epoch: 459 	Average Loss: 3.2713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0659

Learning rate: 9.948106560449663e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 4.1416	Cost: 34.52s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 3.3744	Cost: 10.83s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 3.0403	Cost: 8.89s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 3.1264	Cost: 6.34s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 3.2006	Cost: 18.15s
Train Epoch: 460 	Average Loss: 3.2683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0337

Learning rate: 9.947880593013248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 4.0773	Cost: 38.83s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 3.2751	Cost: 11.11s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 3.1201	Cost: 13.59s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 3.2286	Cost: 12.08s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 3.0437	Cost: 11.88s
Train Epoch: 461 	Average Loss: 3.2596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0287

Learning rate: 9.9476541372406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 4.0625	Cost: 34.49s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 3.2801	Cost: 12.53s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 3.1344	Cost: 7.95s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 3.2657	Cost: 6.44s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 3.1158	Cost: 14.00s
Train Epoch: 462 	Average Loss: 3.2880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0431

Learning rate: 9.947427193154066e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 4.1068	Cost: 31.05s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 3.2476	Cost: 6.73s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 3.0871	Cost: 18.22s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 3.1036	Cost: 12.63s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 3.0503	Cost: 12.05s
Train Epoch: 463 	Average Loss: 3.2353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0527

Learning rate: 9.947199760776042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 3.8716	Cost: 33.45s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 3.0333	Cost: 10.23s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 3.0415	Cost: 9.80s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 3.1811	Cost: 6.36s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 3.0628	Cost: 16.95s
Train Epoch: 464 	Average Loss: 3.1896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9912

Saving model as e464_model.pt & e464_waveforms_supplementary.hdf5
Learning rate: 9.946971840128976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 3.9692	Cost: 35.27s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 3.2469	Cost: 11.03s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 3.0301	Cost: 20.06s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 3.0237	Cost: 12.24s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 2.9556	Cost: 12.07s
Train Epoch: 465 	Average Loss: 3.1975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0105

Learning rate: 9.946743431235365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 4.0398	Cost: 43.24s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 3.2173	Cost: 6.27s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 3.0380	Cost: 14.22s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 3.0484	Cost: 8.64s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 3.0498	Cost: 8.74s
Train Epoch: 466 	Average Loss: 3.1853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9348

Saving model as e466_model.pt & e466_waveforms_supplementary.hdf5
Learning rate: 9.94651453411775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 3.9145	Cost: 35.67s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 3.1629	Cost: 14.68s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 3.0365	Cost: 15.34s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 3.1121	Cost: 12.20s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 2.9500	Cost: 12.02s
Train Epoch: 467 	Average Loss: 3.1540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9993

Learning rate: 9.946285148798723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 3.8665	Cost: 37.43s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 3.0925	Cost: 11.40s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 3.0061	Cost: 8.02s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 3.0359	Cost: 6.29s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 3.0581	Cost: 13.08s
Train Epoch: 468 	Average Loss: 3.1411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9363

Learning rate: 9.946055275300923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 3.7200	Cost: 33.34s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 3.1811	Cost: 7.74s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 2.8727	Cost: 19.55s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 3.0237	Cost: 12.35s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 2.9637	Cost: 12.08s
Train Epoch: 469 	Average Loss: 3.1112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0023

Learning rate: 9.945824913647039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 3.9311	Cost: 46.33s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 3.2120	Cost: 5.99s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 2.9708	Cost: 13.78s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 3.1026	Cost: 8.54s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 2.9242	Cost: 8.33s
Train Epoch: 470 	Average Loss: 3.1409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9513

Learning rate: 9.945594063859803e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 4.0322	Cost: 30.13s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 3.0973	Cost: 8.45s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 2.9048	Cost: 16.88s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 3.0453	Cost: 13.67s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 2.9367	Cost: 13.17s
Train Epoch: 471 	Average Loss: 3.1113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9247

Saving model as e471_model.pt & e471_waveforms_supplementary.hdf5
Learning rate: 9.945362725962006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 3.7484	Cost: 33.33s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 3.1084	Cost: 11.10s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 2.9659	Cost: 9.72s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 3.0378	Cost: 8.90s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 2.9668	Cost: 12.47s
Train Epoch: 472 	Average Loss: 3.1130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9424

Learning rate: 9.945130899976472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 3.7881	Cost: 33.83s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 3.0954	Cost: 8.83s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 3.0200	Cost: 17.46s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 2.9285	Cost: 12.02s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 2.9451	Cost: 11.97s
Train Epoch: 473 	Average Loss: 3.0955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9391

Learning rate: 9.944898585926086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 3.9436	Cost: 37.78s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 3.3006	Cost: 12.14s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 3.0536	Cost: 6.78s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 3.1493	Cost: 6.23s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 2.8666	Cost: 14.84s
Train Epoch: 474 	Average Loss: 3.2309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9682

Learning rate: 9.944665783833775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 3.9341	Cost: 31.54s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 3.0890	Cost: 7.14s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 2.8585	Cost: 17.54s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 3.0359	Cost: 12.31s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 2.7966	Cost: 12.21s
Train Epoch: 475 	Average Loss: 3.0871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9347

Learning rate: 9.944432493722518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 3.7510	Cost: 33.62s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 3.0978	Cost: 9.39s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 2.8916	Cost: 17.00s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 3.0123	Cost: 8.93s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 2.8758	Cost: 12.58s
Train Epoch: 476 	Average Loss: 3.0709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9328

Learning rate: 9.944198715615337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 3.9328	Cost: 32.52s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 3.1589	Cost: 10.64s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 3.0637	Cost: 24.14s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 2.9443	Cost: 12.02s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 3.0111	Cost: 11.85s
Train Epoch: 477 	Average Loss: 3.0852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9140

Saving model as e477_model.pt & e477_waveforms_supplementary.hdf5
Learning rate: 9.943964449535306e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 3.9798	Cost: 49.90s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 3.0380	Cost: 7.14s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 2.8445	Cost: 12.30s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 2.9951	Cost: 8.67s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 2.8822	Cost: 7.37s
Train Epoch: 478 	Average Loss: 3.0565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8875

Saving model as e478_model.pt & e478_waveforms_supplementary.hdf5
Learning rate: 9.943729695505547e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 3.7512	Cost: 28.06s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 3.0594	Cost: 10.90s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 2.9188	Cost: 21.89s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 3.0666	Cost: 12.33s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 2.9027	Cost: 12.13s
Train Epoch: 479 	Average Loss: 3.0643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9645

Learning rate: 9.943494453549226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 3.7281	Cost: 40.54s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 3.1173	Cost: 7.85s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 2.9377	Cost: 11.22s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 3.0758	Cost: 9.70s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 2.9357	Cost: 12.14s
Train Epoch: 480 	Average Loss: 3.1335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9790

Learning rate: 9.943258723689565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 4.0178	Cost: 30.59s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 3.1678	Cost: 10.26s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 2.9520	Cost: 20.85s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 2.9200	Cost: 12.91s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 2.7454	Cost: 11.77s
Train Epoch: 481 	Average Loss: 3.0617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9431

Learning rate: 9.943022505949827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 3.9927	Cost: 57.76s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 3.0724	Cost: 6.26s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 2.8857	Cost: 13.66s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 3.0085	Cost: 8.64s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 2.7897	Cost: 9.18s
Train Epoch: 482 	Average Loss: 3.0741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9367

Learning rate: 9.942785800353326e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 4.0614	Cost: 29.94s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 3.0611	Cost: 7.99s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 2.8776	Cost: 17.17s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 2.8941	Cost: 12.25s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 3.0136	Cost: 12.07s
Train Epoch: 483 	Average Loss: 3.0459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0032

Learning rate: 9.942548606923424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 3.8722	Cost: 34.56s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 3.0509	Cost: 10.85s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 2.9547	Cost: 9.07s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 3.0288	Cost: 7.20s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 2.8399	Cost: 15.37s
Train Epoch: 484 	Average Loss: 3.1000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8757

Saving model as e484_model.pt & e484_waveforms_supplementary.hdf5
Learning rate: 9.942310925683532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 3.9450	Cost: 28.21s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 3.1082	Cost: 10.86s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 2.8275	Cost: 19.44s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 2.9478	Cost: 12.07s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 2.9634	Cost: 11.85s
Train Epoch: 485 	Average Loss: 3.0372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9157

Learning rate: 9.942072756657107e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 3.9898	Cost: 42.02s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 2.8672	Cost: 12.36s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 2.7937	Cost: 9.46s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 2.8578	Cost: 7.12s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 2.8166	Cost: 11.95s
Train Epoch: 486 	Average Loss: 2.9621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8129

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Learning rate: 9.941834099867654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 3.7755	Cost: 36.59s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 2.9880	Cost: 6.74s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 2.7788	Cost: 17.14s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 2.8714	Cost: 12.25s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 2.7415	Cost: 11.88s
Train Epoch: 487 	Average Loss: 2.9564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7924

Saving model as e487_model.pt & e487_waveforms_supplementary.hdf5
Learning rate: 9.941594955338732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 3.7609	Cost: 31.62s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 3.0360	Cost: 10.64s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 2.7572	Cost: 9.00s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 2.8998	Cost: 6.74s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 2.7063	Cost: 14.23s
Train Epoch: 488 	Average Loss: 2.9398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8174

Learning rate: 9.941355323093938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 4.0063	Cost: 39.02s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 2.8841	Cost: 13.28s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 2.8775	Cost: 14.76s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 2.8718	Cost: 11.82s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 2.6917	Cost: 11.93s
Train Epoch: 489 	Average Loss: 2.9417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8122

Learning rate: 9.941115203156927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 3.8123	Cost: 54.85s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 3.0240	Cost: 7.66s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 2.7426	Cost: 10.41s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 2.8364	Cost: 9.57s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 2.7448	Cost: 15.03s
Train Epoch: 490 	Average Loss: 2.9526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7967

Learning rate: 9.940874595551397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 3.8265	Cost: 32.37s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 2.8595	Cost: 11.47s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 2.8351	Cost: 18.91s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 2.7949	Cost: 12.27s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 2.7640	Cost: 11.99s
Train Epoch: 491 	Average Loss: 2.9376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7889

Saving model as e491_model.pt & e491_waveforms_supplementary.hdf5
Learning rate: 9.940633500301093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 3.7845	Cost: 29.81s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 3.0466	Cost: 8.70s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 2.6624	Cost: 11.50s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 2.8766	Cost: 9.71s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 2.7347	Cost: 12.13s
Train Epoch: 492 	Average Loss: 2.9098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7966

Learning rate: 9.940391917429813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 3.7676	Cost: 28.36s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 2.8471	Cost: 10.07s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 2.7136	Cost: 21.95s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 2.8157	Cost: 12.88s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 2.6417	Cost: 11.99s
Train Epoch: 493 	Average Loss: 2.9026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7796

Saving model as e493_model.pt & e493_waveforms_supplementary.hdf5
Learning rate: 9.9401498469614e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 3.7322	Cost: 56.06s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 2.8760	Cost: 6.24s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 2.7973	Cost: 13.41s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 2.8254	Cost: 8.39s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 2.8004	Cost: 7.76s
Train Epoch: 494 	Average Loss: 2.8785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8430

Learning rate: 9.93990728891974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 3.7180	Cost: 29.09s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 2.9383	Cost: 10.38s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 2.9325	Cost: 18.39s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 2.7786	Cost: 12.31s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 2.7776	Cost: 12.02s
Train Epoch: 495 	Average Loss: 2.9336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8400

Learning rate: 9.939664243328781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 3.6430	Cost: 40.46s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 2.9221	Cost: 12.16s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 2.7659	Cost: 7.25s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 2.6894	Cost: 6.67s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 2.7016	Cost: 12.95s
Train Epoch: 496 	Average Loss: 2.8710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7835

Learning rate: 9.939420710212505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 3.6417	Cost: 29.55s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 2.8457	Cost: 6.47s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 2.7592	Cost: 18.71s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 2.8276	Cost: 13.80s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 2.6058	Cost: 12.37s
Train Epoch: 497 	Average Loss: 2.8598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7508

Saving model as e497_model.pt & e497_waveforms_supplementary.hdf5
Learning rate: 9.939176689594949e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 3.8358	Cost: 33.96s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 2.8150	Cost: 8.58s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 2.7725	Cost: 14.41s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 2.7227	Cost: 8.53s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 2.6392	Cost: 11.80s
Train Epoch: 498 	Average Loss: 2.8467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7287

Saving model as e498_model.pt & e498_waveforms_supplementary.hdf5
Learning rate: 9.938932181500198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 3.6330	Cost: 29.77s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 2.9177	Cost: 8.99s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 2.7009	Cost: 15.69s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 2.7328	Cost: 12.20s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 2.5116	Cost: 12.12s
Train Epoch: 499 	Average Loss: 2.8074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7290

Learning rate: 9.938687185952383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 3.7561	Cost: 47.79s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 2.8621	Cost: 10.65s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 2.6770	Cost: 8.57s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 2.8054	Cost: 7.35s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 2.6449	Cost: 14.23s
Train Epoch: 500 	Average Loss: 2.8270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7278

Saving model as e500_model.pt & e500_waveforms_supplementary.hdf5
Learning rate: 9.938441702975683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 3.5459	Cost: 29.99s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 2.7662	Cost: 8.02s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 2.6569	Cost: 16.94s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 2.7587	Cost: 12.01s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 2.5511	Cost: 12.18s
Train Epoch: 501 	Average Loss: 2.8036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7797

Learning rate: 9.938195732594328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 3.6620	Cost: 32.35s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 2.8499	Cost: 11.97s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 2.6735	Cost: 7.22s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 2.8086	Cost: 8.75s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 2.6999	Cost: 13.04s
Train Epoch: 502 	Average Loss: 2.8592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6831

Saving model as e502_model.pt & e502_waveforms_supplementary.hdf5
Learning rate: 9.937949274832593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 3.6239	Cost: 35.68s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 2.7525	Cost: 7.76s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 2.5429	Cost: 18.42s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 2.6973	Cost: 12.39s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 2.5526	Cost: 11.99s
Train Epoch: 503 	Average Loss: 2.8191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7517

Learning rate: 9.937702329714805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 3.7443	Cost: 37.49s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 2.8418	Cost: 10.56s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 2.6339	Cost: 7.71s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 2.7064	Cost: 6.34s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 2.7558	Cost: 13.63s
Train Epoch: 504 	Average Loss: 2.8038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7045

Learning rate: 9.937454897265332e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 3.6740	Cost: 34.81s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 2.8953	Cost: 10.18s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 2.6909	Cost: 14.34s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 2.7200	Cost: 12.32s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 2.6766	Cost: 11.97s
Train Epoch: 505 	Average Loss: 2.8032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7618

Learning rate: 9.937206977508597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 3.7670	Cost: 31.53s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 2.8270	Cost: 12.17s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 2.6623	Cost: 7.19s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 2.6460	Cost: 7.39s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 2.4973	Cost: 13.76s
Train Epoch: 506 	Average Loss: 2.8065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6281

Saving model as e506_model.pt & e506_waveforms_supplementary.hdf5
Learning rate: 9.936958570469071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 3.5200	Cost: 31.03s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 2.7366	Cost: 10.31s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 2.7343	Cost: 24.68s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 2.7528	Cost: 12.37s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 2.6566	Cost: 11.79s
Train Epoch: 507 	Average Loss: 2.7498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7431

Learning rate: 9.936709676171268e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 3.6914	Cost: 51.11s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 2.7714	Cost: 6.39s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 2.6142	Cost: 13.99s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 2.8286	Cost: 8.54s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 2.4915	Cost: 7.42s
Train Epoch: 508 	Average Loss: 2.7854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6445

Learning rate: 9.936460294639754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 3.8322	Cost: 27.40s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 2.6645	Cost: 8.58s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 2.6188	Cost: 18.34s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 2.6390	Cost: 12.37s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 2.5918	Cost: 12.01s
Train Epoch: 509 	Average Loss: 2.7433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6897

Learning rate: 9.93621042589914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 3.6380	Cost: 39.31s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 2.7083	Cost: 12.05s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 2.5972	Cost: 7.13s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 2.6858	Cost: 6.17s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 2.4960	Cost: 14.42s
Train Epoch: 510 	Average Loss: 2.7223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6309

Learning rate: 9.935960069974091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 3.6672	Cost: 27.37s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 2.8270	Cost: 8.79s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 2.6310	Cost: 23.36s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 2.5662	Cost: 13.44s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 2.5363	Cost: 13.10s
Train Epoch: 511 	Average Loss: 2.7109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6842

Learning rate: 9.935709226889313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 3.5491	Cost: 51.53s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 2.7519	Cost: 7.18s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 2.4291	Cost: 13.34s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 2.5983	Cost: 8.53s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 2.3793	Cost: 8.85s
Train Epoch: 512 	Average Loss: 2.6772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5784

Saving model as e512_model.pt & e512_waveforms_supplementary.hdf5
Learning rate: 9.935457896669563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 3.5726	Cost: 29.71s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 2.7983	Cost: 8.00s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 2.6680	Cost: 16.97s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 2.6805	Cost: 12.25s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 2.6525	Cost: 12.29s
Train Epoch: 513 	Average Loss: 2.7550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7176

Learning rate: 9.935206079339646e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 3.8298	Cost: 37.40s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 2.6703	Cost: 12.08s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 2.6804	Cost: 9.71s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 2.6103	Cost: 8.69s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 2.4313	Cost: 18.33s
Train Epoch: 514 	Average Loss: 2.7174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6692

Learning rate: 9.934953774924418e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 3.6974	Cost: 36.11s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 2.6476	Cost: 8.66s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 2.4976	Cost: 20.61s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 2.4671	Cost: 11.97s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 2.4726	Cost: 11.98s
Train Epoch: 515 	Average Loss: 2.6801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6051

Learning rate: 9.93470098344878e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 3.5611	Cost: 41.33s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 2.6558	Cost: 6.34s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 2.5102	Cost: 15.04s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 2.5931	Cost: 8.78s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 2.5322	Cost: 11.99s
Train Epoch: 516 	Average Loss: 2.6635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6549

Learning rate: 9.934447704937678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 3.5710	Cost: 32.28s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 2.5845	Cost: 6.89s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 2.4914	Cost: 18.42s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 2.5565	Cost: 12.16s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 2.3893	Cost: 11.82s
Train Epoch: 517 	Average Loss: 2.6526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6297

Learning rate: 9.934193939416114e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 3.5215	Cost: 29.35s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 2.6507	Cost: 9.40s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 2.4140	Cost: 9.87s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 2.4252	Cost: 7.38s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 2.5294	Cost: 11.83s
Train Epoch: 518 	Average Loss: 2.6645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6618

Learning rate: 9.933939686909132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 3.2978	Cost: 33.34s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 2.6577	Cost: 11.40s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 2.5428	Cost: 23.71s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 2.7016	Cost: 12.21s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 2.5610	Cost: 12.11s
Train Epoch: 519 	Average Loss: 2.6696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7012

Learning rate: 9.933684947441824e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 3.6200	Cost: 37.89s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 2.7394	Cost: 8.18s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 2.4602	Cost: 13.22s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 2.6365	Cost: 8.56s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 2.4864	Cost: 9.99s
Train Epoch: 520 	Average Loss: 2.6712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6455

Learning rate: 9.933429721039335e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 3.6628	Cost: 35.74s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 2.7426	Cost: 10.01s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 2.6957	Cost: 15.57s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 2.6137	Cost: 12.62s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 2.5382	Cost: 11.99s
Train Epoch: 521 	Average Loss: 2.7085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6875

Learning rate: 9.933174007726853e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 3.6224	Cost: 51.06s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 2.5819	Cost: 8.00s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 2.4852	Cost: 9.51s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 2.5727	Cost: 8.01s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 2.3910	Cost: 11.83s
Train Epoch: 522 	Average Loss: 2.6340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5985

Learning rate: 9.932917807529615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 3.6959	Cost: 28.15s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 2.5689	Cost: 6.86s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 2.4360	Cost: 19.97s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 2.5021	Cost: 13.53s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 2.4594	Cost: 12.17s
Train Epoch: 523 	Average Loss: 2.6048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5069

Saving model as e523_model.pt & e523_waveforms_supplementary.hdf5
Learning rate: 9.93266112047291e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 3.6809	Cost: 34.47s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 2.5681	Cost: 12.57s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 2.4378	Cost: 9.08s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 2.4529	Cost: 7.71s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 2.2868	Cost: 13.44s
Train Epoch: 524 	Average Loss: 2.5646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6119

Learning rate: 9.932403946582067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 3.5379	Cost: 29.95s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 2.5031	Cost: 8.69s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 2.3520	Cost: 17.05s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 2.4739	Cost: 12.22s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 2.4606	Cost: 12.16s
Train Epoch: 525 	Average Loss: 2.5734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6702

Learning rate: 9.932146285882473e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 3.7150	Cost: 45.73s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 2.5859	Cost: 12.34s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 2.4283	Cost: 10.50s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 2.4566	Cost: 6.71s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 2.3115	Cost: 7.82s
Train Epoch: 526 	Average Loss: 2.6189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5539

Learning rate: 9.931888138399556e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 3.6445	Cost: 34.35s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 2.5454	Cost: 8.70s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 2.3897	Cost: 9.35s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 2.6070	Cost: 6.88s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 2.3431	Cost: 15.20s
Train Epoch: 527 	Average Loss: 2.6166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5976

Learning rate: 9.931629504158793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 3.5921	Cost: 30.92s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 2.6047	Cost: 12.84s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 2.3705	Cost: 12.13s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 2.3962	Cost: 12.12s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 2.3305	Cost: 10.53s
Train Epoch: 528 	Average Loss: 2.5276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5909

Learning rate: 9.931370383185712e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 3.6909	Cost: 32.27s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 2.4860	Cost: 8.09s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 2.3745	Cost: 10.70s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 2.3952	Cost: 10.46s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 2.3389	Cost: 9.61s
Train Epoch: 529 	Average Loss: 2.5576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4748

Saving model as e529_model.pt & e529_waveforms_supplementary.hdf5
Learning rate: 9.931110775505886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 3.4382	Cost: 39.30s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 2.5153	Cost: 14.21s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 2.3904	Cost: 12.87s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 2.4459	Cost: 11.87s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 2.4753	Cost: 11.57s
Train Epoch: 530 	Average Loss: 2.5679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6180

Learning rate: 9.93085068114494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 3.6514	Cost: 33.27s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 2.6690	Cost: 10.97s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 2.3844	Cost: 7.85s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 2.4158	Cost: 6.27s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 2.3018	Cost: 13.12s
Train Epoch: 531 	Average Loss: 2.5695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5070

Learning rate: 9.930590100128539e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 3.4313	Cost: 34.18s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 2.4145	Cost: 11.02s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 2.3911	Cost: 19.57s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 2.3988	Cost: 12.29s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 2.4211	Cost: 11.87s
Train Epoch: 532 	Average Loss: 2.4868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5387

Learning rate: 9.930329032482406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 3.4714	Cost: 36.14s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 2.5003	Cost: 10.64s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 2.3448	Cost: 9.11s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 2.4961	Cost: 6.22s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 2.3223	Cost: 11.97s
Train Epoch: 533 	Average Loss: 2.4955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5404

Learning rate: 9.930067478232305e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 3.4793	Cost: 29.61s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 2.5209	Cost: 10.65s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 2.3377	Cost: 24.92s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 2.4120	Cost: 13.27s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 2.3375	Cost: 12.01s
Train Epoch: 534 	Average Loss: 2.4867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5214

Learning rate: 9.929805437404053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 3.7502	Cost: 52.54s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 2.5509	Cost: 6.34s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 2.4479	Cost: 14.45s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 2.4170	Cost: 8.45s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 2.2801	Cost: 6.54s
Train Epoch: 535 	Average Loss: 2.5007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5893

Learning rate: 9.92954291002351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 3.6342	Cost: 37.46s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 2.5779	Cost: 12.97s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 2.3144	Cost: 15.43s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 2.4327	Cost: 12.35s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 2.4669	Cost: 12.26s
Train Epoch: 536 	Average Loss: 2.5660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6923

Learning rate: 9.929279896116587e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 3.6580	Cost: 41.16s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 2.4947	Cost: 6.34s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 2.3797	Cost: 14.31s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 2.3915	Cost: 8.64s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 2.3616	Cost: 9.25s
Train Epoch: 537 	Average Loss: 2.5281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5352

Learning rate: 9.929016395709243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 3.4784	Cost: 25.29s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 2.4274	Cost: 6.81s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 2.3283	Cost: 16.14s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 2.4026	Cost: 12.33s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 2.2027	Cost: 12.99s
Train Epoch: 538 	Average Loss: 2.4751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5958

Learning rate: 9.928752408827483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 3.5337	Cost: 36.17s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 2.5522	Cost: 12.81s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 2.1556	Cost: 12.93s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 2.4891	Cost: 8.27s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 2.2591	Cost: 6.78s
Train Epoch: 539 	Average Loss: 2.4673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5705

Learning rate: 9.928487935497362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 3.5397	Cost: 34.51s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 2.4456	Cost: 8.86s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 2.2535	Cost: 9.76s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 2.2535	Cost: 6.91s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 2.2493	Cost: 19.30s
Train Epoch: 540 	Average Loss: 2.4407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5805

Learning rate: 9.928222975744984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 3.5265	Cost: 48.10s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 2.4465	Cost: 12.19s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 2.2517	Cost: 12.38s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 2.2574	Cost: 7.82s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 2.2695	Cost: 6.18s
Train Epoch: 541 	Average Loss: 2.4447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4859

Learning rate: 9.927957529596498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 3.4866	Cost: 29.83s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 2.4810	Cost: 9.23s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 2.3637	Cost: 11.93s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 2.3372	Cost: 8.30s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 2.2875	Cost: 8.27s
Train Epoch: 542 	Average Loss: 2.4426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4964

Learning rate: 9.927691597078101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 3.5777	Cost: 28.77s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 2.4703	Cost: 8.30s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 2.2821	Cost: 17.69s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 2.2914	Cost: 11.99s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 2.1189	Cost: 11.91s
Train Epoch: 543 	Average Loss: 2.4215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4444

Saving model as e543_model.pt & e543_waveforms_supplementary.hdf5
Learning rate: 9.927425178216043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 3.4334	Cost: 29.64s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 2.4290	Cost: 6.30s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 2.1407	Cost: 13.74s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 2.3327	Cost: 9.08s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 2.2033	Cost: 11.77s
Train Epoch: 544 	Average Loss: 2.3766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4328

Saving model as e544_model.pt & e544_waveforms_supplementary.hdf5
Learning rate: 9.927158273036618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 3.4022	Cost: 36.91s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 2.4370	Cost: 14.74s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 2.1854	Cost: 13.04s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 2.2519	Cost: 12.15s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 2.0796	Cost: 11.83s
Train Epoch: 545 	Average Loss: 2.3441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4084

Saving model as e545_model.pt & e545_waveforms_supplementary.hdf5
Learning rate: 9.926890881566166e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 3.3917	Cost: 32.52s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 2.3729	Cost: 8.16s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 2.2792	Cost: 13.40s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 2.2381	Cost: 8.68s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 2.2633	Cost: 8.48s
Train Epoch: 546 	Average Loss: 2.4058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5045

Learning rate: 9.926623003831078e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 3.5216	Cost: 30.59s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 2.5453	Cost: 12.13s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 2.2790	Cost: 12.40s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 2.3841	Cost: 13.43s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 2.0788	Cost: 12.06s
Train Epoch: 547 	Average Loss: 2.4142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4387

Learning rate: 9.926354639857796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 3.4380	Cost: 39.42s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 2.3264	Cost: 12.27s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 2.2161	Cost: 10.14s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 2.1197	Cost: 6.03s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 2.1908	Cost: 8.16s
Train Epoch: 548 	Average Loss: 2.3263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4624

Learning rate: 9.926085789672802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 3.3646	Cost: 29.39s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 2.4894	Cost: 7.59s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 2.1677	Cost: 12.61s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 2.2231	Cost: 11.12s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 1.9913	Cost: 21.23s
Train Epoch: 549 	Average Loss: 2.3287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4575

Learning rate: 9.92581645330263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 3.3025	Cost: 39.64s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 2.3596	Cost: 14.44s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 2.2026	Cost: 12.24s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 2.1549	Cost: 10.61s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 2.1095	Cost: 6.16s
Train Epoch: 550 	Average Loss: 2.3282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4713

Learning rate: 9.925546630773865e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 3.4618	Cost: 32.78s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 2.4061	Cost: 9.27s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 2.2195	Cost: 10.84s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 2.2711	Cost: 8.61s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 2.1899	Cost: 6.62s
Train Epoch: 551 	Average Loss: 2.3019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4677

Learning rate: 9.925276322113137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 3.2709	Cost: 32.15s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 2.3537	Cost: 12.73s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 2.1429	Cost: 15.05s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 2.1716	Cost: 12.50s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 2.1901	Cost: 12.20s
Train Epoch: 552 	Average Loss: 2.3050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4462

Learning rate: 9.925005527347125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 3.2713	Cost: 45.86s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 2.2579	Cost: 7.29s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 2.1861	Cost: 11.87s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 2.1206	Cost: 8.76s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 2.0602	Cost: 9.55s
Train Epoch: 553 	Average Loss: 2.2633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3795

Saving model as e553_model.pt & e553_waveforms_supplementary.hdf5
Learning rate: 9.924734246502554e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 3.3567	Cost: 27.65s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 2.2668	Cost: 6.73s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 2.1570	Cost: 17.07s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 2.0986	Cost: 12.63s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 2.0392	Cost: 12.33s
Train Epoch: 554 	Average Loss: 2.2606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4339

Learning rate: 9.9244624796062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 3.3380	Cost: 33.99s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 2.3382	Cost: 10.90s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 2.1590	Cost: 11.18s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 2.1279	Cost: 8.65s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 2.1262	Cost: 12.70s
Train Epoch: 555 	Average Loss: 2.2747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3777

Saving model as e555_model.pt & e555_waveforms_supplementary.hdf5
Learning rate: 9.924190226684883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 3.4277	Cost: 35.35s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 2.4554	Cost: 9.96s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 2.1902	Cost: 13.94s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 2.3010	Cost: 12.07s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 2.1510	Cost: 12.23s
Train Epoch: 556 	Average Loss: 2.3319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4307

Learning rate: 9.923917487765477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 3.3509	Cost: 41.11s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 2.3117	Cost: 9.05s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 2.2318	Cost: 8.83s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 2.0896	Cost: 7.81s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 2.1285	Cost: 12.96s
Train Epoch: 557 	Average Loss: 2.2942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4626

Learning rate: 9.923644262874898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 3.4093	Cost: 34.76s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 2.3885	Cost: 6.79s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 2.0667	Cost: 17.74s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 2.1127	Cost: 12.40s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 2.0939	Cost: 11.90s
Train Epoch: 558 	Average Loss: 2.3347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5020

Learning rate: 9.92337055204011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 3.4962	Cost: 30.45s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 2.3526	Cost: 12.38s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 2.1377	Cost: 7.16s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 2.2435	Cost: 6.74s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 2.0717	Cost: 12.59s
Train Epoch: 559 	Average Loss: 2.2798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3936

Learning rate: 9.92309635528813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 3.3822	Cost: 33.23s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 2.3541	Cost: 11.23s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 2.0099	Cost: 16.70s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 2.1044	Cost: 12.53s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 2.0649	Cost: 11.99s
Train Epoch: 560 	Average Loss: 2.2051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3403

Saving model as e560_model.pt & e560_waveforms_supplementary.hdf5
Learning rate: 9.92282167264602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 3.3971	Cost: 32.16s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 2.1424	Cost: 12.60s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 2.0351	Cost: 11.97s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 2.1808	Cost: 6.19s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 2.0256	Cost: 9.97s
Train Epoch: 561 	Average Loss: 2.1964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4517

Learning rate: 9.92254650414089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 3.2952	Cost: 31.39s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 2.3384	Cost: 9.83s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 2.2357	Cost: 13.43s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 2.2136	Cost: 13.96s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 2.1362	Cost: 12.11s
Train Epoch: 562 	Average Loss: 2.2952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3987

Learning rate: 9.922270849799896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 3.4048	Cost: 39.92s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 2.3207	Cost: 12.43s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 2.1539	Cost: 12.07s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 2.1109	Cost: 8.03s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 2.1180	Cost: 6.21s
Train Epoch: 563 	Average Loss: 2.2388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3361

Saving model as e563_model.pt & e563_waveforms_supplementary.hdf5
Learning rate: 9.921994709650246e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 3.2642	Cost: 30.57s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 2.1394	Cost: 6.65s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 2.1719	Cost: 15.43s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 2.0722	Cost: 10.78s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 2.1152	Cost: 20.04s
Train Epoch: 564 	Average Loss: 2.2117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3120

Saving model as e564_model.pt & e564_waveforms_supplementary.hdf5
Learning rate: 9.921718083719194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 3.1253	Cost: 43.84s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 2.3336	Cost: 12.92s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 2.1843	Cost: 12.12s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 2.1051	Cost: 6.32s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 1.9296	Cost: 6.75s
Train Epoch: 565 	Average Loss: 2.1963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3544

Learning rate: 9.921440972034041e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 3.3104	Cost: 37.20s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 2.3239	Cost: 6.11s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 2.2603	Cost: 16.11s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 2.1002	Cost: 11.94s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 1.9704	Cost: 12.22s
Train Epoch: 566 	Average Loss: 2.2351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2959

Saving model as e566_model.pt & e566_waveforms_supplementary.hdf5
Learning rate: 9.921163374622138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 3.2641	Cost: 46.91s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 2.2962	Cost: 8.68s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 1.9756	Cost: 10.36s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 2.0273	Cost: 6.22s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 1.9217	Cost: 13.90s
Train Epoch: 567 	Average Loss: 2.1504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2049

Saving model as e567_model.pt & e567_waveforms_supplementary.hdf5
Learning rate: 9.920885291510881e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 3.2838	Cost: 26.99s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 2.1530	Cost: 6.59s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 2.2534	Cost: 13.97s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 2.2813	Cost: 11.87s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 2.0530	Cost: 15.01s
Train Epoch: 568 	Average Loss: 2.2688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4645

Learning rate: 9.920606722727717e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 3.3752	Cost: 33.58s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 2.5105	Cost: 12.89s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 2.2097	Cost: 12.59s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 2.2319	Cost: 6.68s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 2.0329	Cost: 7.59s
Train Epoch: 569 	Average Loss: 2.3249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3213

Learning rate: 9.920327668300141e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 3.2697	Cost: 29.92s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 2.2699	Cost: 8.14s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 2.2285	Cost: 21.50s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 2.3506	Cost: 12.53s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 2.1475	Cost: 12.06s
Train Epoch: 570 	Average Loss: 2.3325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5081

Learning rate: 9.920048128255691e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 3.6616	Cost: 43.95s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 2.3525	Cost: 11.88s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 2.0898	Cost: 7.40s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 2.1394	Cost: 6.69s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 1.8192	Cost: 15.25s
Train Epoch: 571 	Average Loss: 2.2465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2446

Learning rate: 9.91976810262196e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 3.3565	Cost: 28.57s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 2.2530	Cost: 7.31s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 1.9515	Cost: 17.25s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 1.9351	Cost: 12.12s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 1.8960	Cost: 12.07s
Train Epoch: 572 	Average Loss: 2.1404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2510

Learning rate: 9.919487591426583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 3.3554	Cost: 31.64s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 2.2078	Cost: 12.17s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 1.8761	Cost: 11.98s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 1.8796	Cost: 6.44s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 1.9041	Cost: 8.03s
Train Epoch: 573 	Average Loss: 2.0687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3313

Learning rate: 9.919206594697245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 3.5478	Cost: 33.89s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 2.1726	Cost: 12.37s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 2.0021	Cost: 19.68s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 1.7730	Cost: 12.43s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 1.8468	Cost: 11.84s
Train Epoch: 574 	Average Loss: 2.0534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2855

Learning rate: 9.918925112461682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 3.2157	Cost: 34.45s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 2.0389	Cost: 6.92s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 2.1036	Cost: 14.66s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 2.0276	Cost: 8.52s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 1.9047	Cost: 8.67s
Train Epoch: 575 	Average Loss: 2.1105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2662

Learning rate: 9.918643144747673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 3.1998	Cost: 29.01s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 2.1227	Cost: 6.76s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 2.0317	Cost: 18.49s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 1.9130	Cost: 12.78s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 1.8964	Cost: 12.04s
Train Epoch: 576 	Average Loss: 2.0851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1892

Saving model as e576_model.pt & e576_waveforms_supplementary.hdf5
Learning rate: 9.918360691583047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 3.1706	Cost: 42.86s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 2.0488	Cost: 10.60s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 1.8117	Cost: 7.05s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 1.9018	Cost: 7.00s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 1.9340	Cost: 13.19s
Train Epoch: 577 	Average Loss: 2.0294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2374

Learning rate: 9.918077752995681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 3.0452	Cost: 31.72s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 2.0635	Cost: 6.75s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 1.8885	Cost: 18.82s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 1.9382	Cost: 14.07s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 1.7957	Cost: 12.30s
Train Epoch: 578 	Average Loss: 2.0310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2970

Learning rate: 9.917794329013504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 3.1686	Cost: 34.10s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 2.1502	Cost: 10.23s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 1.9836	Cost: 14.44s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 2.1927	Cost: 8.92s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 2.0604	Cost: 14.81s
Train Epoch: 579 	Average Loss: 2.1755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4139

Learning rate: 9.917510419664483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 3.1464	Cost: 35.09s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 2.3054	Cost: 10.50s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 2.1333	Cost: 17.15s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 1.9563	Cost: 12.04s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 1.8720	Cost: 11.89s
Train Epoch: 580 	Average Loss: 2.1617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3273

Learning rate: 9.91722602497664e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 3.2380	Cost: 33.06s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 2.2029	Cost: 12.57s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 1.9925	Cost: 7.71s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 1.9651	Cost: 6.43s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 1.8352	Cost: 14.53s
Train Epoch: 581 	Average Loss: 2.0886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2313

Learning rate: 9.916941144978047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 3.3370	Cost: 34.37s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 2.0623	Cost: 8.05s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 1.9314	Cost: 16.33s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 1.8742	Cost: 12.26s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 1.7910	Cost: 12.12s
Train Epoch: 582 	Average Loss: 2.0170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1889

Saving model as e582_model.pt & e582_waveforms_supplementary.hdf5
Learning rate: 9.916655779696818e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 3.0993	Cost: 31.26s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 2.0114	Cost: 12.55s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 1.8451	Cost: 8.93s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 1.9424	Cost: 9.05s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 1.7949	Cost: 16.33s
Train Epoch: 583 	Average Loss: 1.9894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2100

Learning rate: 9.916369929161117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 3.2566	Cost: 31.17s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 2.0260	Cost: 8.73s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 1.8389	Cost: 17.26s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 1.9800	Cost: 12.45s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 1.7326	Cost: 15.15s
Train Epoch: 584 	Average Loss: 1.9708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2449

Learning rate: 9.916083593399158e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 3.2523	Cost: 57.73s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 1.9825	Cost: 9.86s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 1.7352	Cost: 6.82s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 1.7625	Cost: 6.69s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 1.6962	Cost: 14.38s
Train Epoch: 585 	Average Loss: 1.9865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1745

Saving model as e585_model.pt & e585_waveforms_supplementary.hdf5
Learning rate: 9.9157967724392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 3.2134	Cost: 33.96s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 1.9261	Cost: 9.98s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 1.9134	Cost: 16.20s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 2.0402	Cost: 12.72s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 1.8351	Cost: 12.03s
Train Epoch: 586 	Average Loss: 2.0051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2279

Learning rate: 9.915509466309551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 3.1280	Cost: 39.06s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 2.0259	Cost: 7.94s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 1.9081	Cost: 11.37s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 1.7523	Cost: 8.68s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 1.6893	Cost: 12.29s
Train Epoch: 587 	Average Loss: 1.9704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1534

Saving model as e587_model.pt & e587_waveforms_supplementary.hdf5
Learning rate: 9.915221675038568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 2.9635	Cost: 31.38s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 1.8514	Cost: 11.54s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 1.7632	Cost: 19.90s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 1.7421	Cost: 12.27s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 1.7245	Cost: 11.95s
Train Epoch: 588 	Average Loss: 1.9249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1688

Learning rate: 9.914933398654654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 3.1145	Cost: 43.47s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 2.0183	Cost: 12.18s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 1.9750	Cost: 9.00s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 1.7942	Cost: 6.28s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 1.7082	Cost: 10.35s
Train Epoch: 589 	Average Loss: 1.9544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1044

Saving model as e589_model.pt & e589_waveforms_supplementary.hdf5
Learning rate: 9.914644637186261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 3.0116	Cost: 30.04s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 1.8387	Cost: 8.65s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 1.7573	Cost: 10.63s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 1.7379	Cost: 7.93s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 1.6579	Cost: 19.48s
Train Epoch: 590 	Average Loss: 1.9070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0459

Saving model as e590_model.pt & e590_waveforms_supplementary.hdf5
Learning rate: 9.914355390661888e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 2.8535	Cost: 38.46s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 1.8952	Cost: 12.43s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 1.7495	Cost: 10.91s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 1.8902	Cost: 6.24s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 1.7610	Cost: 11.27s
Train Epoch: 591 	Average Loss: 1.9091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1266

Learning rate: 9.914065659110084e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 3.1805	Cost: 28.11s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 2.0313	Cost: 7.06s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 1.7984	Cost: 17.25s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 1.8821	Cost: 10.41s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 1.7163	Cost: 13.97s
Train Epoch: 592 	Average Loss: 1.9456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1332

Learning rate: 9.913775442559442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 3.2098	Cost: 36.57s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 1.9172	Cost: 12.88s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 1.6110	Cost: 12.37s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 1.7440	Cost: 6.89s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 1.6399	Cost: 7.06s
Train Epoch: 593 	Average Loss: 1.8696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0792

Learning rate: 9.913484741038609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 3.2074	Cost: 33.34s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 2.0037	Cost: 8.90s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 1.7453	Cost: 10.30s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 1.8391	Cost: 7.25s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 1.6691	Cost: 9.01s
Train Epoch: 594 	Average Loss: 1.9077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1512

Learning rate: 9.913193554576272e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 3.2303	Cost: 32.58s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 1.8254	Cost: 7.67s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 1.7022	Cost: 17.42s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 1.6815	Cost: 12.61s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 1.6681	Cost: 11.87s
Train Epoch: 595 	Average Loss: 1.8336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0774

Learning rate: 9.912901883201172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 2.9885	Cost: 29.82s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 1.8573	Cost: 6.25s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 1.5771	Cost: 14.38s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 1.7117	Cost: 9.26s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 1.6567	Cost: 9.91s
Train Epoch: 596 	Average Loss: 1.8277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0779

Learning rate: 9.912609726942096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 3.0530	Cost: 31.98s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 1.8117	Cost: 11.28s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 1.6209	Cost: 15.56s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 1.8748	Cost: 12.77s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 1.7194	Cost: 11.93s
Train Epoch: 597 	Average Loss: 1.8701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1230

Learning rate: 9.912317085827877e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 2.9940	Cost: 36.77s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 1.7930	Cost: 12.32s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 1.7120	Cost: 10.88s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 1.6253	Cost: 6.17s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 1.5583	Cost: 9.45s
Train Epoch: 598 	Average Loss: 1.8127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0970

Learning rate: 9.9120239598874e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 3.1103	Cost: 39.60s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 1.7681	Cost: 7.57s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 1.6420	Cost: 18.00s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 1.6587	Cost: 12.36s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 1.4987	Cost: 12.00s
Train Epoch: 599 	Average Loss: 1.7819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1250

Learning rate: 9.911730349149594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 3.0156	Cost: 35.75s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 1.9668	Cost: 11.07s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 1.5852	Cost: 10.47s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 1.6993	Cost: 6.27s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 1.4950	Cost: 10.73s
Train Epoch: 600 	Average Loss: 1.8012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0941

Learning rate: 9.911436253643436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 3.0775	Cost: 30.67s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 2.0006	Cost: 10.04s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 1.8910	Cost: 17.80s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 1.8541	Cost: 12.40s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 1.7578	Cost: 12.17s
Train Epoch: 601 	Average Loss: 1.9314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1952

Learning rate: 9.911141673397953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 2.9056	Cost: 41.88s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 1.9105	Cost: 11.92s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 1.7387	Cost: 9.23s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 1.7476	Cost: 6.42s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 1.6028	Cost: 12.11s
Train Epoch: 602 	Average Loss: 1.8457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0818

Learning rate: 9.91084660844222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 3.0375	Cost: 33.05s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 1.7667	Cost: 8.37s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 1.6344	Cost: 17.97s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 1.6010	Cost: 12.36s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 1.4560	Cost: 12.17s
Train Epoch: 603 	Average Loss: 1.7596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0307

Saving model as e603_model.pt & e603_waveforms_supplementary.hdf5
Learning rate: 9.910551058805357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 2.8083	Cost: 33.22s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 1.8468	Cost: 13.11s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 1.6055	Cost: 12.12s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 1.5440	Cost: 7.45s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 1.5814	Cost: 5.87s
Train Epoch: 604 	Average Loss: 1.7541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0727

Learning rate: 9.910255024516536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 3.1902	Cost: 29.44s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 1.8468	Cost: 8.38s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 1.5403	Cost: 21.11s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 1.5982	Cost: 14.85s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 1.5076	Cost: 12.72s
Train Epoch: 605 	Average Loss: 1.7384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0773

Learning rate: 9.909958505604974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 2.9268	Cost: 52.59s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 1.7628	Cost: 10.69s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 1.6999	Cost: 7.44s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 1.5187	Cost: 6.35s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 1.5406	Cost: 13.22s
Train Epoch: 606 	Average Loss: 1.7365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9922

Saving model as e606_model.pt & e606_waveforms_supplementary.hdf5
Learning rate: 9.909661502099934e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 2.9000	Cost: 29.69s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 1.5734	Cost: 9.60s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 1.5010	Cost: 18.05s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 1.5250	Cost: 12.10s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 1.4877	Cost: 12.08s
Train Epoch: 607 	Average Loss: 1.6673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0222

Learning rate: 9.90936401403073e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 2.7027	Cost: 36.48s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 1.7819	Cost: 12.01s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 1.6436	Cost: 7.46s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 1.6648	Cost: 6.34s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 1.7335	Cost: 13.17s
Train Epoch: 608 	Average Loss: 1.7761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0893

Learning rate: 9.909066041426725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 3.1261	Cost: 27.87s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 1.7536	Cost: 7.34s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 1.5434	Cost: 19.25s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 1.7134	Cost: 14.20s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 1.5085	Cost: 12.62s
Train Epoch: 609 	Average Loss: 1.7648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0932

Learning rate: 9.908767584317324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 2.9539	Cost: 35.62s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 1.7901	Cost: 8.72s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 1.5986	Cost: 12.09s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 1.5389	Cost: 8.27s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 1.3772	Cost: 11.77s
Train Epoch: 610 	Average Loss: 1.7141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0164

Learning rate: 9.908468642731985e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 2.8507	Cost: 28.20s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 1.6790	Cost: 9.34s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 1.5372	Cost: 24.04s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 1.5750	Cost: 13.56s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 1.4990	Cost: 12.45s
Train Epoch: 611 	Average Loss: 1.7092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0523

Learning rate: 9.908169216700214e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 3.0555	Cost: 53.88s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 1.5985	Cost: 10.49s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 1.4578	Cost: 9.06s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 1.5222	Cost: 6.08s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 1.5242	Cost: 12.68s
Train Epoch: 612 	Average Loss: 1.6552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9861

Saving model as e612_model.pt & e612_waveforms_supplementary.hdf5
Learning rate: 9.907869306251562e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 2.7532	Cost: 30.72s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 1.7032	Cost: 10.16s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 1.4141	Cost: 19.42s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 1.4575	Cost: 12.60s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 1.5948	Cost: 12.15s
Train Epoch: 613 	Average Loss: 1.6532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9775

Saving model as e613_model.pt & e613_waveforms_supplementary.hdf5
Learning rate: 9.907568911415629e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 2.9903	Cost: 45.29s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 1.6933	Cost: 7.12s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 1.5347	Cost: 13.70s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 1.5562	Cost: 8.55s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 1.7006	Cost: 9.04s
Train Epoch: 614 	Average Loss: 1.7287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1356

Learning rate: 9.907268032222063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 3.0479	Cost: 31.98s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 1.7272	Cost: 9.28s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 1.4863	Cost: 13.48s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 1.4865	Cost: 12.82s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 1.5021	Cost: 12.16s
Train Epoch: 615 	Average Loss: 1.7010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0423

Learning rate: 9.906966668700558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 3.0589	Cost: 46.01s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 1.9338	Cost: 12.16s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 1.3988	Cost: 12.35s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 1.5973	Cost: 6.79s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 1.4909	Cost: 5.96s
Train Epoch: 616 	Average Loss: 1.6719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9932

Learning rate: 9.90666482088086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 3.2188	Cost: 29.08s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 1.7130	Cost: 8.09s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 1.4231	Cost: 9.86s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 1.5911	Cost: 7.39s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 1.5690	Cost: 21.35s
Train Epoch: 617 	Average Loss: 1.6528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9794

Learning rate: 9.906362488792757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 2.9138	Cost: 34.35s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 1.6234	Cost: 14.12s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 1.5930	Cost: 11.78s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 1.4640	Cost: 6.16s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 1.4320	Cost: 10.27s
Train Epoch: 618 	Average Loss: 1.6583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0125

Learning rate: 9.906059672466091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 2.8661	Cost: 30.42s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 1.8317	Cost: 7.85s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 1.6527	Cost: 16.35s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 1.7245	Cost: 12.80s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 1.3885	Cost: 11.86s
Train Epoch: 619 	Average Loss: 1.7336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0720

Learning rate: 9.905756371930748e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 3.1874	Cost: 38.77s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 1.8250	Cost: 12.78s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 1.5908	Cost: 11.40s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 1.5046	Cost: 6.72s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 1.5261	Cost: 6.35s
Train Epoch: 620 	Average Loss: 1.6709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9827

Learning rate: 9.905452587216662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 2.7247	Cost: 36.90s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 1.6176	Cost: 9.12s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 1.5119	Cost: 16.44s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 1.4655	Cost: 12.21s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 1.3900	Cost: 12.08s
Train Epoch: 621 	Average Loss: 1.6068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9032

Saving model as e621_model.pt & e621_waveforms_supplementary.hdf5
Learning rate: 9.905148318353815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 2.9886	Cost: 33.92s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 1.5228	Cost: 10.91s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 1.3079	Cost: 8.97s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 1.3976	Cost: 7.11s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 1.2945	Cost: 11.91s
Train Epoch: 622 	Average Loss: 1.5498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8512

Saving model as e622_model.pt & e622_waveforms_supplementary.hdf5
Learning rate: 9.904843565372238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 2.8789	Cost: 30.12s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 1.5448	Cost: 9.94s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 1.4420	Cost: 18.14s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 1.3476	Cost: 12.76s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 1.3574	Cost: 12.28s
Train Epoch: 623 	Average Loss: 1.5505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9670

Learning rate: 9.904538328302008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 3.0290	Cost: 41.39s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 1.4347	Cost: 11.70s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 1.4103	Cost: 9.00s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 1.4271	Cost: 6.25s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 1.2629	Cost: 11.35s
Train Epoch: 624 	Average Loss: 1.5310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9426

Learning rate: 9.904232607173254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 2.8653	Cost: 30.48s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 1.5238	Cost: 7.19s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 1.3756	Cost: 17.63s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 1.3723	Cost: 13.20s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 1.3722	Cost: 12.10s
Train Epoch: 625 	Average Loss: 1.5327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8693

Learning rate: 9.903926402016143e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 2.8911	Cost: 45.12s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 1.4431	Cost: 10.63s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 1.3854	Cost: 9.09s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 1.3276	Cost: 6.53s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 1.4052	Cost: 11.55s
Train Epoch: 626 	Average Loss: 1.5016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9074

Learning rate: 9.903619712860903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 2.8250	Cost: 28.78s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 1.5644	Cost: 6.88s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 1.3630	Cost: 17.56s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 1.3910	Cost: 14.96s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 1.2347	Cost: 12.91s
Train Epoch: 627 	Average Loss: 1.5459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8810

Learning rate: 9.903312539737797e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 2.6917	Cost: 37.08s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 1.6453	Cost: 12.22s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 1.3377	Cost: 10.64s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 1.3298	Cost: 6.44s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 1.2964	Cost: 12.25s
Train Epoch: 628 	Average Loss: 1.5429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9077

Learning rate: 9.903004882677146e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 2.6846	Cost: 28.64s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 1.5208	Cost: 8.28s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 1.4375	Cost: 17.55s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 1.4630	Cost: 12.76s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 1.3406	Cost: 11.98s
Train Epoch: 629 	Average Loss: 1.5972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9295

Learning rate: 9.902696741709314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 2.6711	Cost: 38.06s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 1.6615	Cost: 12.73s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 1.4383	Cost: 13.27s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 1.3250	Cost: 8.94s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 1.4116	Cost: 6.20s
Train Epoch: 630 	Average Loss: 1.6293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9073

Learning rate: 9.902388116864713e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 2.8006	Cost: 46.45s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 1.5980	Cost: 6.32s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 1.2703	Cost: 13.92s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 1.4427	Cost: 12.16s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 1.2917	Cost: 12.09s
Train Epoch: 631 	Average Loss: 1.5570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9249

Learning rate: 9.902079008173801e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 2.9143	Cost: 41.14s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 1.5995	Cost: 12.01s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 1.5001	Cost: 12.11s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 1.4429	Cost: 6.67s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 1.3685	Cost: 6.09s
Train Epoch: 632 	Average Loss: 1.5988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9481

Learning rate: 9.90176941566709e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 2.9600	Cost: 30.85s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 1.4456	Cost: 8.92s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 1.3013	Cost: 12.11s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 1.3377	Cost: 9.33s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 1.2923	Cost: 18.63s
Train Epoch: 633 	Average Loss: 1.5320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9044

Learning rate: 9.90145933937513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 3.0472	Cost: 35.45s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 1.3758	Cost: 11.82s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 1.3485	Cost: 13.06s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 1.4092	Cost: 11.93s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 1.3190	Cost: 9.48s
Train Epoch: 634 	Average Loss: 1.5001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8354

Saving model as e634_model.pt & e634_waveforms_supplementary.hdf5
Learning rate: 9.901148779328529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 2.7056	Cost: 28.79s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 1.4031	Cost: 8.42s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 1.3337	Cost: 13.81s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 1.2454	Cost: 9.38s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 1.2239	Cost: 10.90s
Train Epoch: 635 	Average Loss: 1.4312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7806

Saving model as e635_model.pt & e635_waveforms_supplementary.hdf5
Learning rate: 9.900837735557936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 2.6153	Cost: 46.08s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 1.3468	Cost: 12.54s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 1.2175	Cost: 12.18s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 1.1696	Cost: 12.10s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 1.1615	Cost: 8.21s
Train Epoch: 636 	Average Loss: 1.3765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8868

Learning rate: 9.90052620809405e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 2.7926	Cost: 54.18s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 1.3180	Cost: 7.41s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 1.2537	Cost: 11.90s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 1.3537	Cost: 8.53s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 1.2219	Cost: 7.91s
Train Epoch: 637 	Average Loss: 1.4140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7805

Saving model as e637_model.pt & e637_waveforms_supplementary.hdf5
Learning rate: 9.900214196967617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 3.0263	Cost: 29.73s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 1.2861	Cost: 8.75s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 1.1729	Cost: 17.43s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 1.2603	Cost: 13.50s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 1.2769	Cost: 12.13s
Train Epoch: 638 	Average Loss: 1.4033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7945

Learning rate: 9.899901702209434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 2.7219	Cost: 35.83s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 1.4468	Cost: 12.57s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 1.2763	Cost: 9.58s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 1.2972	Cost: 6.27s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 1.1912	Cost: 13.25s
Train Epoch: 639 	Average Loss: 1.4660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7279

Saving model as e639_model.pt & e639_waveforms_supplementary.hdf5
Learning rate: 9.899588723850338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 2.6559	Cost: 32.86s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 1.3422	Cost: 10.44s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 1.2300	Cost: 14.46s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 1.2439	Cost: 11.79s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 1.2098	Cost: 12.28s
Train Epoch: 640 	Average Loss: 1.3939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8805

Learning rate: 9.899275261921224e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 2.9273	Cost: 53.29s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 1.4104	Cost: 6.48s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 1.3098	Cost: 14.51s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 1.3178	Cost: 8.47s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 1.0900	Cost: 8.51s
Train Epoch: 641 	Average Loss: 1.4181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7658

Learning rate: 9.898961316453026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 2.3712	Cost: 29.97s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 1.4118	Cost: 8.52s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 1.3876	Cost: 15.69s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 1.5124	Cost: 12.19s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 1.2472	Cost: 12.45s
Train Epoch: 642 	Average Loss: 1.4319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8183

Learning rate: 9.898646887476729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 2.8028	Cost: 33.20s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 1.4463	Cost: 10.58s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 1.2416	Cost: 10.03s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 1.3015	Cost: 8.31s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 1.0948	Cost: 10.85s
Train Epoch: 643 	Average Loss: 1.3737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7589

Learning rate: 9.898331975023371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 2.7902	Cost: 36.82s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 1.4179	Cost: 10.39s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 1.2361	Cost: 14.41s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 1.1497	Cost: 12.66s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 1.1224	Cost: 11.71s
Train Epoch: 644 	Average Loss: 1.3834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7158

Saving model as e644_model.pt & e644_waveforms_supplementary.hdf5
Learning rate: 9.898016579124025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 2.6478	Cost: 43.00s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 1.3423	Cost: 11.60s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 1.1209	Cost: 8.39s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 1.0951	Cost: 6.23s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 1.1307	Cost: 13.00s
Train Epoch: 645 	Average Loss: 1.3401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8325

Learning rate: 9.897700699809825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 2.8695	Cost: 29.46s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 1.4600	Cost: 8.05s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 1.2828	Cost: 20.73s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 1.1966	Cost: 12.23s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 1.1069	Cost: 12.18s
Train Epoch: 646 	Average Loss: 1.4145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7662

Learning rate: 9.897384337111944e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 2.8675	Cost: 33.60s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 1.2719	Cost: 12.05s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 1.1495	Cost: 9.32s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 1.2182	Cost: 7.30s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 1.0429	Cost: 12.17s
Train Epoch: 647 	Average Loss: 1.3147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7281

Learning rate: 9.897067491061608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 2.7045	Cost: 27.60s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 1.1855	Cost: 8.45s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 1.2465	Cost: 21.44s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 1.2419	Cost: 13.67s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 1.1556	Cost: 12.55s
Train Epoch: 648 	Average Loss: 1.3440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6909

Saving model as e648_model.pt & e648_waveforms_supplementary.hdf5
Learning rate: 9.896750161690087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 2.5224	Cost: 52.50s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 1.2207	Cost: 9.17s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 1.1398	Cost: 8.50s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 0.9533	Cost: 7.43s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 1.1021	Cost: 13.64s
Train Epoch: 649 	Average Loss: 1.2544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6722

Saving model as e649_model.pt & e649_waveforms_supplementary.hdf5
Learning rate: 9.8964323490287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 2.5069	Cost: 30.05s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 1.3428	Cost: 11.09s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 1.0952	Cost: 18.85s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 1.0990	Cost: 12.91s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 1.1209	Cost: 12.06s
Train Epoch: 650 	Average Loss: 1.2978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7296

Learning rate: 9.896114053108814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 2.6283	Cost: 47.41s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 1.1233	Cost: 8.93s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 1.0860	Cost: 10.50s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 1.0621	Cost: 7.59s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 1.0208	Cost: 12.52s
Train Epoch: 651 	Average Loss: 1.2863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6412

Saving model as e651_model.pt & e651_waveforms_supplementary.hdf5
Learning rate: 9.895795273961846e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 2.6023	Cost: 34.78s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 1.1918	Cost: 10.72s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 1.1260	Cost: 15.25s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 1.1463	Cost: 12.46s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 0.9994	Cost: 12.17s
Train Epoch: 652 	Average Loss: 1.2329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6282

Saving model as e652_model.pt & e652_waveforms_supplementary.hdf5
Learning rate: 9.895476011619254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 2.4054	Cost: 48.62s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 1.3110	Cost: 6.24s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 1.0990	Cost: 14.59s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 1.0547	Cost: 8.47s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 0.9981	Cost: 7.62s
Train Epoch: 653 	Average Loss: 1.2344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6656

Learning rate: 9.89515626611255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 2.6577	Cost: 27.19s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 1.1942	Cost: 8.36s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 1.0557	Cost: 15.58s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 1.0907	Cost: 12.19s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 0.9486	Cost: 12.47s
Train Epoch: 654 	Average Loss: 1.2143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5793

Saving model as e654_model.pt & e654_waveforms_supplementary.hdf5
Learning rate: 9.894836037473293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 2.4716	Cost: 32.80s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 1.2112	Cost: 8.31s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 0.9695	Cost: 17.00s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 0.9877	Cost: 8.83s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 0.9541	Cost: 12.01s
Train Epoch: 655 	Average Loss: 1.2118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6099

Learning rate: 9.894515325733087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 2.5869	Cost: 34.68s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 1.1745	Cost: 9.91s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 1.1125	Cost: 14.91s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 0.9826	Cost: 12.03s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 0.9679	Cost: 12.17s
Train Epoch: 656 	Average Loss: 1.2228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6380

Learning rate: 9.894194130923585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 2.6524	Cost: 42.95s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 1.1590	Cost: 8.80s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 1.0602	Cost: 10.47s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 1.2405	Cost: 6.26s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 0.9574	Cost: 13.29s
Train Epoch: 657 	Average Loss: 1.1950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6022

Learning rate: 9.893872453076489e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 2.2367	Cost: 34.22s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 1.2505	Cost: 6.89s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 0.9697	Cost: 18.41s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 1.0659	Cost: 12.14s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 1.0848	Cost: 12.27s
Train Epoch: 658 	Average Loss: 1.2016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5710

Saving model as e658_model.pt & e658_waveforms_supplementary.hdf5
Learning rate: 9.893550292223543e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 2.5967	Cost: 34.26s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 1.1452	Cost: 11.16s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 1.0283	Cost: 6.60s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 1.0295	Cost: 8.19s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 0.8650	Cost: 14.04s
Train Epoch: 659 	Average Loss: 1.1787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6350

Learning rate: 9.893227648396548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 2.5035	Cost: 53.87s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 1.1356	Cost: 12.31s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 1.1456	Cost: 12.11s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 1.1341	Cost: 12.11s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 1.1556	Cost: 10.42s
Train Epoch: 660 	Average Loss: 1.2781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7042

Learning rate: 9.892904521627345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 2.5317	Cost: 29.41s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 1.1620	Cost: 9.67s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 1.1581	Cost: 11.20s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 1.1033	Cost: 8.94s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 0.8507	Cost: 10.25s
Train Epoch: 661 	Average Loss: 1.2024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6334

Learning rate: 9.892580911947826e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 2.6214	Cost: 39.61s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 1.0749	Cost: 13.13s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 0.9957	Cost: 13.58s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 0.9862	Cost: 12.25s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 0.9091	Cost: 11.91s
Train Epoch: 662 	Average Loss: 1.1253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5164

Saving model as e662_model.pt & e662_waveforms_supplementary.hdf5
Learning rate: 9.892256819389932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 2.5833	Cost: 34.19s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 1.0072	Cost: 7.52s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 1.0427	Cost: 13.93s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 1.0985	Cost: 8.47s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 0.9655	Cost: 8.91s
Train Epoch: 663 	Average Loss: 1.1508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6350

Learning rate: 9.891932243985645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 2.7536	Cost: 35.74s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 1.2731	Cost: 10.02s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 1.0355	Cost: 17.37s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 1.0817	Cost: 12.28s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 0.9181	Cost: 11.93s
Train Epoch: 664 	Average Loss: 1.1341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6372

Learning rate: 9.891607185767004e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 2.5451	Cost: 49.10s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 1.1344	Cost: 7.29s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 0.9586	Cost: 10.90s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 1.0115	Cost: 8.86s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 0.9079	Cost: 8.67s
Train Epoch: 665 	Average Loss: 1.1465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5929

Learning rate: 9.891281644766087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 2.6101	Cost: 27.23s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 1.1466	Cost: 6.72s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 0.8421	Cost: 14.54s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 0.9689	Cost: 12.88s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 0.8148	Cost: 14.55s
Train Epoch: 666 	Average Loss: 1.1355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6096

Learning rate: 9.890955621015026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 2.6036	Cost: 36.79s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 0.9623	Cost: 13.81s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 0.9641	Cost: 10.99s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 0.9889	Cost: 6.64s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 0.8320	Cost: 13.80s
Train Epoch: 667 	Average Loss: 1.0555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4909

Saving model as e667_model.pt & e667_waveforms_supplementary.hdf5
Learning rate: 9.890629114545997e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 2.4241	Cost: 33.94s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 1.0501	Cost: 8.32s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 0.8169	Cost: 16.76s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 0.8813	Cost: 12.02s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 0.8224	Cost: 12.26s
Train Epoch: 668 	Average Loss: 0.9988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5400

Learning rate: 9.890302125391226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 2.3814	Cost: 37.01s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 1.0889	Cost: 12.40s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 0.9859	Cost: 8.24s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 0.9091	Cost: 7.02s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 0.8300	Cost: 11.83s
Train Epoch: 669 	Average Loss: 1.0786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5211

Learning rate: 9.889974653582986e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 2.5580	Cost: 35.16s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 1.1866	Cost: 6.50s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 0.9329	Cost: 18.19s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 0.8041	Cost: 11.89s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 0.8456	Cost: 11.89s
Train Epoch: 670 	Average Loss: 1.0570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4932

Learning rate: 9.889646699153596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 2.5043	Cost: 31.01s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 0.9253	Cost: 12.15s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 0.8702	Cost: 10.25s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 0.8577	Cost: 6.28s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 0.9199	Cost: 8.91s
Train Epoch: 671 	Average Loss: 1.0193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4781

Saving model as e671_model.pt & e671_waveforms_supplementary.hdf5
Learning rate: 9.889318262135424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 2.3779	Cost: 41.38s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 0.9466	Cost: 7.83s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 0.9046	Cost: 17.04s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 0.8510	Cost: 12.00s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 0.7405	Cost: 12.08s
Train Epoch: 672 	Average Loss: 1.0207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7044

Learning rate: 9.888989342560885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 2.6880	Cost: 39.25s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 1.4269	Cost: 12.01s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 1.1912	Cost: 11.39s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 1.2535	Cost: 6.33s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 1.1288	Cost: 8.83s
Train Epoch: 673 	Average Loss: 1.4178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7588

Learning rate: 9.888659940462443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 2.6208	Cost: 33.32s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 1.1434	Cost: 8.48s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 1.0305	Cost: 16.65s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 0.9737	Cost: 12.81s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 0.8885	Cost: 12.09s
Train Epoch: 674 	Average Loss: 1.1669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4806

Learning rate: 9.88833005587261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 2.3913	Cost: 31.03s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 0.9576	Cost: 12.39s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 0.7654	Cost: 11.22s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 0.7520	Cost: 8.24s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 0.6228	Cost: 11.00s
Train Epoch: 675 	Average Loss: 0.9857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5278

Learning rate: 9.887999688823941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 2.5274	Cost: 36.22s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 0.9016	Cost: 11.40s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 0.8641	Cost: 8.13s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 0.7944	Cost: 6.84s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 0.7656	Cost: 19.29s
Train Epoch: 676 	Average Loss: 0.9709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5386

Learning rate: 9.887668839349044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 2.7181	Cost: 55.98s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 0.9873	Cost: 11.67s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 0.8701	Cost: 8.61s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 0.8513	Cost: 6.21s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 0.8573	Cost: 10.64s
Train Epoch: 677 	Average Loss: 1.0323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5156

Learning rate: 9.887337507480573e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 2.4378	Cost: 27.77s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 0.9578	Cost: 9.45s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 0.7615	Cost: 15.20s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 0.8270	Cost: 14.59s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 0.6302	Cost: 13.15s
Train Epoch: 678 	Average Loss: 0.9882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4150

Saving model as e678_model.pt & e678_waveforms_supplementary.hdf5
Learning rate: 9.887005693251226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 2.5640	Cost: 49.91s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 1.0027	Cost: 12.17s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 0.8205	Cost: 8.45s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 0.8471	Cost: 6.07s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 0.6376	Cost: 11.69s
Train Epoch: 679 	Average Loss: 0.9573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5725

Learning rate: 9.886673396693755e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 2.3726	Cost: 31.54s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 1.0062	Cost: 6.64s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 0.9694	Cost: 18.48s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 0.8734	Cost: 12.39s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 0.7235	Cost: 12.16s
Train Epoch: 680 	Average Loss: 0.9784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4792

Learning rate: 9.886340617840956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 2.4797	Cost: 41.29s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 1.0258	Cost: 11.72s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 0.8584	Cost: 6.96s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 0.8080	Cost: 6.19s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 0.7381	Cost: 13.35s
Train Epoch: 681 	Average Loss: 0.9822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4245

Learning rate: 9.886007356725671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 2.4122	Cost: 29.82s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 0.8985	Cost: 6.18s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 0.7944	Cost: 20.75s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 0.6988	Cost: 14.15s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 0.7762	Cost: 12.25s
Train Epoch: 682 	Average Loss: 0.9496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6031

Learning rate: 9.885673613380794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 2.3732	Cost: 38.41s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 1.1056	Cost: 12.00s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 0.8003	Cost: 9.37s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 0.8773	Cost: 9.48s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 0.7225	Cost: 11.03s
Train Epoch: 683 	Average Loss: 1.0380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5060

Learning rate: 9.885339387839263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 2.6056	Cost: 33.28s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 1.0267	Cost: 8.42s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 0.9770	Cost: 13.58s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 0.8627	Cost: 7.61s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 0.6863	Cost: 19.30s
Train Epoch: 684 	Average Loss: 1.0436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4074

Saving model as e684_model.pt & e684_waveforms_supplementary.hdf5
Learning rate: 9.885004680134064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 2.1927	Cost: 37.59s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 0.8959	Cost: 11.83s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 0.7983	Cost: 7.65s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 0.6750	Cost: 6.12s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 0.4895	Cost: 13.88s
Train Epoch: 685 	Average Loss: 0.8640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3719

Saving model as e685_model.pt & e685_waveforms_supplementary.hdf5
Learning rate: 9.884669490298232e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 2.4163	Cost: 31.60s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 0.7755	Cost: 8.70s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 0.8123	Cost: 16.18s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 0.6223	Cost: 11.95s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 0.5111	Cost: 12.18s
Train Epoch: 686 	Average Loss: 0.8833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3957

Learning rate: 9.884333818364849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 2.3015	Cost: 32.43s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 0.9527	Cost: 9.32s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 0.7147	Cost: 9.64s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 0.7010	Cost: 8.69s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 0.5069	Cost: 11.56s
Train Epoch: 687 	Average Loss: 0.8670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3155

Saving model as e687_model.pt & e687_waveforms_supplementary.hdf5
Learning rate: 9.883997664367044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 2.5245	Cost: 28.40s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 0.7886	Cost: 10.59s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 0.6637	Cost: 21.37s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 0.4885	Cost: 13.12s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 0.4711	Cost: 11.98s
Train Epoch: 688 	Average Loss: 0.7807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3034

Saving model as e688_model.pt & e688_waveforms_supplementary.hdf5
Learning rate: 9.883661028337996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 2.1842	Cost: 50.83s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 0.8374	Cost: 6.25s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 0.6143	Cost: 14.36s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 0.6384	Cost: 8.60s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 0.5212	Cost: 8.45s
Train Epoch: 689 	Average Loss: 0.7559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2911

Saving model as e689_model.pt & e689_waveforms_supplementary.hdf5
Learning rate: 9.883323910310927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 2.2560	Cost: 28.57s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 0.6499	Cost: 8.19s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 0.5517	Cost: 19.91s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 0.6782	Cost: 12.16s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 0.6526	Cost: 11.95s
Train Epoch: 690 	Average Loss: 0.7783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2737

Saving model as e690_model.pt & e690_waveforms_supplementary.hdf5
Learning rate: 9.88298631031911e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 2.2674	Cost: 41.64s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 0.7890	Cost: 6.85s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 0.6417	Cost: 11.67s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 0.5534	Cost: 8.69s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 0.5372	Cost: 9.17s
Train Epoch: 691 	Average Loss: 0.7346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2973

Learning rate: 9.882648228395867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 2.5019	Cost: 29.08s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 0.6328	Cost: 10.16s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 0.6969	Cost: 22.83s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 0.6527	Cost: 13.34s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 0.5918	Cost: 12.21s
Train Epoch: 692 	Average Loss: 0.8071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3627

Learning rate: 9.882309664574563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 2.4027	Cost: 48.36s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 0.7394	Cost: 11.74s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 0.6455	Cost: 8.85s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 0.6853	Cost: 6.16s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 0.4644	Cost: 12.64s
Train Epoch: 693 	Average Loss: 0.7877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2947

Learning rate: 9.881970618888613e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 2.2036	Cost: 32.58s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 0.6957	Cost: 7.32s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 0.5620	Cost: 17.30s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 0.5793	Cost: 12.46s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 0.5130	Cost: 12.19s
Train Epoch: 694 	Average Loss: 0.6717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3213

Learning rate: 9.88163109137148e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 2.0736	Cost: 34.34s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 0.7235	Cost: 11.85s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 0.5476	Cost: 7.85s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 0.6050	Cost: 6.64s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 0.5597	Cost: 13.20s
Train Epoch: 695 	Average Loss: 0.7730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2770

Learning rate: 9.881291082056673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 2.4274	Cost: 30.75s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 0.7092	Cost: 8.25s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 0.6423	Cost: 16.99s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 0.6153	Cost: 13.56s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 0.5469	Cost: 12.49s
Train Epoch: 696 	Average Loss: 0.7617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3323

Learning rate: 9.880950590977753e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 2.1812	Cost: 32.96s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 0.9168	Cost: 12.48s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 0.6084	Cost: 9.71s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 0.6293	Cost: 8.75s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 0.4345	Cost: 13.35s
Train Epoch: 697 	Average Loss: 0.7415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2192

Saving model as e697_model.pt & e697_waveforms_supplementary.hdf5
Learning rate: 9.88060961816832e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 2.2503	Cost: 50.12s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 0.6604	Cost: 13.31s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 0.5617	Cost: 12.14s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 0.5544	Cost: 12.01s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 0.3894	Cost: 11.05s
Train Epoch: 698 	Average Loss: 0.7154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2583

Learning rate: 9.88026816366203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 2.2858	Cost: 33.21s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 0.6142	Cost: 6.74s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 0.5159	Cost: 14.15s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 0.4700	Cost: 8.85s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 0.2781	Cost: 8.87s
Train Epoch: 699 	Average Loss: 0.6873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2597

Learning rate: 9.879926227492583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 2.0369	Cost: 33.94s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 0.5959	Cost: 14.54s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 0.3349	Cost: 12.91s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 0.4209	Cost: 12.00s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 0.3323	Cost: 11.78s
Train Epoch: 700 	Average Loss: 0.6387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2648

Learning rate: 9.879583809693725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 2.2818	Cost: 37.95s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 0.6823	Cost: 6.50s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 0.5958	Cost: 13.63s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 0.6963	Cost: 8.84s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 0.3822	Cost: 9.43s
Train Epoch: 701 	Average Loss: 0.7042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2550

Learning rate: 9.879240910299253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 2.3284	Cost: 30.00s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 0.7038	Cost: 14.63s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 0.4903	Cost: 16.21s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 0.5625	Cost: 12.71s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 0.5104	Cost: 11.30s
Train Epoch: 702 	Average Loss: 0.6927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3458

Learning rate: 9.87889752934301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 2.4399	Cost: 29.88s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 0.7438	Cost: 10.28s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 0.6435	Cost: 12.35s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 0.6325	Cost: 9.33s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 0.5922	Cost: 11.86s
Train Epoch: 703 	Average Loss: 0.7961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4110

Learning rate: 9.878553666858885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 2.4095	Cost: 42.12s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 0.6323	Cost: 9.99s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 0.5551	Cost: 14.33s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 0.4341	Cost: 12.37s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 0.4425	Cost: 11.81s
Train Epoch: 704 	Average Loss: 0.6953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1835

Saving model as e704_model.pt & e704_waveforms_supplementary.hdf5
Learning rate: 9.878209322880817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 2.2173	Cost: 39.19s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 0.6595	Cost: 9.68s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 0.5712	Cost: 7.98s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 0.6144	Cost: 6.83s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 0.2594	Cost: 14.04s
Train Epoch: 705 	Average Loss: 0.6517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2133

Learning rate: 9.87786449744279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 1.9951	Cost: 31.69s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 0.5414	Cost: 9.95s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 0.5142	Cost: 17.38s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 0.5548	Cost: 12.55s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 0.3906	Cost: 12.19s
Train Epoch: 706 	Average Loss: 0.6410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2306

Learning rate: 9.87751919057884e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 2.4460	Cost: 46.07s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 0.5879	Cost: 10.59s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 0.4826	Cost: 6.50s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 0.5261	Cost: 6.86s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 0.3350	Cost: 14.32s
Train Epoch: 707 	Average Loss: 0.6061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1097

Saving model as e707_model.pt & e707_waveforms_supplementary.hdf5
Learning rate: 9.877173402323044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 2.0916	Cost: 34.65s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 0.3899	Cost: 13.02s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 0.4613	Cost: 14.83s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 0.4802	Cost: 11.93s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 0.3679	Cost: 11.82s
Train Epoch: 708 	Average Loss: 0.5785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2029

Learning rate: 9.876827132709531e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 2.1538	Cost: 57.28s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 0.5615	Cost: 7.98s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 0.4219	Cost: 10.44s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 0.5097	Cost: 8.92s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 0.2148	Cost: 8.95s
Train Epoch: 709 	Average Loss: 0.5876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1486

Learning rate: 9.876480381772478e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 2.0772	Cost: 29.65s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 0.5802	Cost: 8.52s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 0.5920	Cost: 18.32s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 0.4889	Cost: 13.73s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 0.3654	Cost: 12.30s
Train Epoch: 710 	Average Loss: 0.6202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1890

Learning rate: 9.876133149546104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 2.1343	Cost: 39.68s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 0.4815	Cost: 12.30s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 0.5578	Cost: 12.21s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 0.4065	Cost: 6.24s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 0.2909	Cost: 6.22s
Train Epoch: 711 	Average Loss: 0.5274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1027

Saving model as e711_model.pt & e711_waveforms_supplementary.hdf5
Learning rate: 9.875785436064683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 1.9162	Cost: 27.51s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 0.6545	Cost: 6.83s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 0.6107	Cost: 24.06s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 0.5249	Cost: 13.13s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 0.3034	Cost: 12.24s
Train Epoch: 712 	Average Loss: 0.6151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1374

Learning rate: 9.875437241362533e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 2.2254	Cost: 47.00s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 0.5883	Cost: 11.66s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 0.4247	Cost: 8.92s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 0.4540	Cost: 6.13s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 0.3593	Cost: 12.07s
Train Epoch: 713 	Average Loss: 0.5518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1901

Learning rate: 9.875088565474018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 2.2015	Cost: 34.51s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 0.5012	Cost: 6.49s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 0.3766	Cost: 16.26s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 0.3420	Cost: 12.06s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 0.1727	Cost: 12.09s
Train Epoch: 714 	Average Loss: 0.5052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1055

Learning rate: 9.874739408433551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 2.1616	Cost: 36.05s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 0.4233	Cost: 12.21s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 0.2088	Cost: 11.27s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 0.3358	Cost: 6.20s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 0.2518	Cost: 11.36s
Train Epoch: 715 	Average Loss: 0.4734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0660

Saving model as e715_model.pt & e715_waveforms_supplementary.hdf5
Learning rate: 9.874389770275595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 2.0917	Cost: 30.66s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 0.4696	Cost: 8.59s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 0.2396	Cost: 18.22s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 0.2447	Cost: 11.82s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 0.2193	Cost: 12.02s
Train Epoch: 716 	Average Loss: 0.4525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1278

Learning rate: 9.874039651034654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 2.0764	Cost: 41.24s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 0.4134	Cost: 12.44s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 0.3743	Cost: 7.91s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 0.4849	Cost: 6.28s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 0.2217	Cost: 14.80s
Train Epoch: 717 	Average Loss: 0.4562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0922

Learning rate: 9.873689050745284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 1.8506	Cost: 34.06s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 0.4169	Cost: 6.47s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 0.2358	Cost: 17.93s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 0.2172	Cost: 12.02s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 0.2471	Cost: 11.83s
Train Epoch: 718 	Average Loss: 0.4337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1411

Learning rate: 9.873337969442089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 2.1304	Cost: 31.00s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 0.5528	Cost: 12.30s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 0.2713	Cost: 12.11s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 0.3286	Cost: 6.87s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 0.1221	Cost: 6.23s
Train Epoch: 719 	Average Loss: 0.4900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1176

Learning rate: 9.87298640715972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 2.0340	Cost: 30.87s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 0.2944	Cost: 10.25s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 0.4713	Cost: 20.45s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 0.4507	Cost: 12.81s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 0.3828	Cost: 11.89s
Train Epoch: 720 	Average Loss: 0.5494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1658

Learning rate: 9.872634363932875e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 2.0704	Cost: 38.79s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 0.4168	Cost: 12.40s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 0.4303	Cost: 10.18s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 0.3963	Cost: 6.06s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 0.2683	Cost: 10.29s
Train Epoch: 721 	Average Loss: 0.5312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1113

Learning rate: 9.872281839796297e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 2.0049	Cost: 32.04s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 0.6692	Cost: 10.23s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 0.4328	Cost: 23.08s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 0.6050	Cost: 12.37s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 0.4474	Cost: 11.78s
Train Epoch: 722 	Average Loss: 0.6353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2870

Learning rate: 9.87192883478478e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 2.2477	Cost: 30.59s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 0.6825	Cost: 12.58s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 0.3722	Cost: 7.49s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 0.5462	Cost: 6.59s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 0.2467	Cost: 10.75s
Train Epoch: 723 	Average Loss: 0.6401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0737

Learning rate: 9.871575348933164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 1.9684	Cost: 26.53s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 0.5621	Cost: 10.04s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 0.3761	Cost: 22.27s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 0.5301	Cost: 14.25s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 0.1883	Cost: 12.14s
Train Epoch: 724 	Average Loss: 0.5441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1080

Learning rate: 9.871221382276338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 2.2792	Cost: 48.70s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 0.5057	Cost: 10.80s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 0.3181	Cost: 8.67s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 0.3220	Cost: 7.23s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 0.1461	Cost: 12.54s
Train Epoch: 725 	Average Loss: 0.4607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9984

Saving model as e725_model.pt & e725_waveforms_supplementary.hdf5
Learning rate: 9.870866934849235e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 2.0871	Cost: 28.98s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 0.5724	Cost: 6.98s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 0.2334	Cost: 19.78s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 0.4085	Cost: 12.47s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 0.3069	Cost: 11.77s
Train Epoch: 726 	Average Loss: 0.4677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0621

Learning rate: 9.870512006686839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 1.9448	Cost: 40.35s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 0.3170	Cost: 7.64s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 0.3047	Cost: 13.20s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 0.3549	Cost: 8.63s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 0.2788	Cost: 8.48s
Train Epoch: 727 	Average Loss: 0.4436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0949

Learning rate: 9.870156597824179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 1.9506	Cost: 28.62s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 0.2192	Cost: 6.79s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 0.1328	Cost: 17.49s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 0.3164	Cost: 15.35s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 0.0862	Cost: 12.63s
Train Epoch: 728 	Average Loss: 0.3617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9359

Saving model as e728_model.pt & e728_waveforms_supplementary.hdf5
Learning rate: 9.869800708296334e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 1.8721	Cost: 33.76s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 0.2915	Cost: 6.68s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 0.1557	Cost: 16.41s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 0.2215	Cost: 9.17s
Train Epoch: 729 [81920/90000 (91%)]	Loss: -0.0468	Cost: 12.05s
Train Epoch: 729 	Average Loss: 0.2692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8686

Saving model as e729_model.pt & e729_waveforms_supplementary.hdf5
Learning rate: 9.869444338138427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 2.1294	Cost: 38.35s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 0.2032	Cost: 9.99s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 0.1307	Cost: 16.28s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 0.2393	Cost: 12.18s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 0.0569	Cost: 12.03s
Train Epoch: 730 	Average Loss: 0.2364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8916

Learning rate: 9.869087487385631e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 1.9495	Cost: 36.13s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 0.2910	Cost: 7.55s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 0.0834	Cost: 11.84s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 0.1960	Cost: 9.13s
Train Epoch: 731 [81920/90000 (91%)]	Loss: -0.0285	Cost: 11.49s
Train Epoch: 731 	Average Loss: 0.2732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0326

Learning rate: 9.868730156073167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 1.8503	Cost: 29.89s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 0.3516	Cost: 10.68s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 0.2702	Cost: 19.83s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 0.1548	Cost: 12.24s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 0.0196	Cost: 12.22s
Train Epoch: 732 	Average Loss: 0.2594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8521

Saving model as e732_model.pt & e732_waveforms_supplementary.hdf5
Learning rate: 9.8683723442363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 1.8485	Cost: 46.35s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 0.1811	Cost: 6.27s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 0.1367	Cost: 14.46s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 0.1080	Cost: 8.71s
Train Epoch: 733 [81920/90000 (91%)]	Loss: -0.0122	Cost: 9.31s
Train Epoch: 733 	Average Loss: 0.2773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9415

Learning rate: 9.868014051910347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 1.8505	Cost: 29.56s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 0.1884	Cost: 11.82s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 0.2693	Cost: 17.57s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 0.2512	Cost: 13.36s
Train Epoch: 734 [81920/90000 (91%)]	Loss: -0.0721	Cost: 12.17s
Train Epoch: 734 	Average Loss: 0.3062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0399

Learning rate: 9.86765527913067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 1.7423	Cost: 59.45s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 0.3358	Cost: 6.34s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 0.1668	Cost: 13.45s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 0.1460	Cost: 8.69s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 0.0786	Cost: 9.02s
Train Epoch: 735 	Average Loss: 0.3127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9759

Learning rate: 9.867296025932675e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 1.9547	Cost: 28.69s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 0.2962	Cost: 8.85s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 0.2007	Cost: 16.18s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 0.1414	Cost: 12.66s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 0.0944	Cost: 12.37s
Train Epoch: 736 	Average Loss: 0.2852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9332

Learning rate: 9.866936292351822e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 1.6813	Cost: 38.54s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 0.2436	Cost: 11.29s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 0.1991	Cost: 8.11s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 0.0654	Cost: 6.44s
Train Epoch: 737 [81920/90000 (91%)]	Loss: -0.0429	Cost: 15.00s
Train Epoch: 737 	Average Loss: 0.2408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9796

Learning rate: 9.866576078423615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 1.9606	Cost: 27.60s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 0.0349	Cost: 9.97s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 0.0836	Cost: 18.25s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 0.0232	Cost: 12.16s
Train Epoch: 738 [81920/90000 (91%)]	Loss: -0.0854	Cost: 12.39s
Train Epoch: 738 	Average Loss: 0.1825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9162

Learning rate: 9.866215384183606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 1.7888	Cost: 42.88s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 0.1504	Cost: 11.85s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 0.0015	Cost: 10.46s
Train Epoch: 739 [61440/90000 (68%)]	Loss: -0.0010	Cost: 6.50s
Train Epoch: 739 [81920/90000 (91%)]	Loss: -0.1623	Cost: 13.31s
Train Epoch: 739 	Average Loss: 0.1276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8532

Learning rate: 9.865854209667392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 1.5858	Cost: 38.13s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 0.1514	Cost: 6.76s
Train Epoch: 740 [40960/90000 (45%)]	Loss: -0.0619	Cost: 17.21s
Train Epoch: 740 [61440/90000 (68%)]	Loss: -0.0274	Cost: 12.25s
Train Epoch: 740 [81920/90000 (91%)]	Loss: -0.0708	Cost: 12.12s
Train Epoch: 740 	Average Loss: 0.1286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8802

Learning rate: 9.865492554910621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 1.8433	Cost: 31.15s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 0.0979	Cost: 11.36s
Train Epoch: 741 [40960/90000 (45%)]	Loss: -0.0067	Cost: 8.40s
Train Epoch: 741 [61440/90000 (68%)]	Loss: -0.0034	Cost: 6.64s
Train Epoch: 741 [81920/90000 (91%)]	Loss: -0.1474	Cost: 14.91s
Train Epoch: 741 	Average Loss: 0.1459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9720

Learning rate: 9.865130419948984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 1.8942	Cost: 31.80s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 0.1565	Cost: 6.81s
Train Epoch: 742 [40960/90000 (45%)]	Loss: -0.0030	Cost: 20.01s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 0.1004	Cost: 12.69s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 0.0291	Cost: 11.91s
Train Epoch: 742 	Average Loss: 0.2125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8521

Learning rate: 9.864767804818229e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 1.8245	Cost: 33.12s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 0.2416	Cost: 11.36s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 0.1105	Cost: 10.32s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 0.0417	Cost: 8.61s
Train Epoch: 743 [81920/90000 (91%)]	Loss: -0.0418	Cost: 14.59s
Train Epoch: 743 	Average Loss: 0.2514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9709

Learning rate: 9.864404709554137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 1.8904	Cost: 50.11s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 0.2046	Cost: 6.61s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 0.1361	Cost: 18.04s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 0.2332	Cost: 12.26s
Train Epoch: 744 [81920/90000 (91%)]	Loss: -0.0182	Cost: 11.86s
Train Epoch: 744 	Average Loss: 0.3031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0004

Learning rate: 9.864041134192549e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 2.0908	Cost: 34.26s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 0.3801	Cost: 12.04s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 0.2190	Cost: 6.51s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 0.1429	Cost: 6.38s
Train Epoch: 745 [81920/90000 (91%)]	Loss: -0.0253	Cost: 14.87s
Train Epoch: 745 	Average Loss: 0.3372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9405

Learning rate: 9.863677078769347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 1.9051	Cost: 31.72s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 0.2154	Cost: 14.26s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 0.0859	Cost: 17.86s
Train Epoch: 746 [61440/90000 (68%)]	Loss: -0.1029	Cost: 12.33s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 0.0199	Cost: 11.95s
Train Epoch: 746 	Average Loss: 0.2284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9061

Learning rate: 9.863312543320462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 1.7043	Cost: 34.53s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 0.1734	Cost: 9.11s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 0.0505	Cost: 11.40s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 0.0388	Cost: 8.88s
Train Epoch: 747 [81920/90000 (91%)]	Loss: -0.0229	Cost: 9.15s
Train Epoch: 747 	Average Loss: 0.2191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8239

Saving model as e747_model.pt & e747_waveforms_supplementary.hdf5
Learning rate: 9.862947527881872e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 1.7797	Cost: 35.92s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 0.3232	Cost: 13.11s
Train Epoch: 748 [40960/90000 (45%)]	Loss: -0.1849	Cost: 17.26s
Train Epoch: 748 [61440/90000 (68%)]	Loss: -0.1614	Cost: 12.02s
Train Epoch: 748 [81920/90000 (91%)]	Loss: -0.0465	Cost: 12.19s
Train Epoch: 748 	Average Loss: 0.1183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7808

Saving model as e748_model.pt & e748_waveforms_supplementary.hdf5
Learning rate: 9.862582032489604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 1.6279	Cost: 40.65s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 0.0129	Cost: 10.27s
Train Epoch: 749 [40960/90000 (45%)]	Loss: -0.1488	Cost: 6.37s
Train Epoch: 749 [61440/90000 (68%)]	Loss: -0.2718	Cost: 6.39s
Train Epoch: 749 [81920/90000 (91%)]	Loss: -0.1743	Cost: 12.92s
Train Epoch: 749 	Average Loss: 0.0400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8220

Learning rate: 9.862216057179729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 1.6213	Cost: 28.19s
Train Epoch: 750 [20480/90000 (23%)]	Loss: -0.1012	Cost: 7.29s
Train Epoch: 750 [40960/90000 (45%)]	Loss: -0.0766	Cost: 18.59s
Train Epoch: 750 [61440/90000 (68%)]	Loss: -0.2252	Cost: 14.54s
Train Epoch: 750 [81920/90000 (91%)]	Loss: -0.1588	Cost: 13.13s
Train Epoch: 750 	Average Loss: 0.0244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8689

Learning rate: 9.861849601988368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 1.8100	Cost: 39.93s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 0.1472	Cost: 12.03s
Train Epoch: 751 [40960/90000 (45%)]	Loss: -0.0132	Cost: 11.17s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 0.0360	Cost: 6.42s
Train Epoch: 751 [81920/90000 (91%)]	Loss: -0.2188	Cost: 12.64s
Train Epoch: 751 	Average Loss: 0.1590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9412

Learning rate: 9.86148266695169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 2.0890	Cost: 35.79s
Train Epoch: 752 [20480/90000 (23%)]	Loss: -0.0219	Cost: 7.21s
Train Epoch: 752 [40960/90000 (45%)]	Loss: -0.1916	Cost: 17.05s
Train Epoch: 752 [61440/90000 (68%)]	Loss: -0.1257	Cost: 12.38s
Train Epoch: 752 [81920/90000 (91%)]	Loss: -0.2003	Cost: 12.35s
Train Epoch: 752 	Average Loss: 0.0919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8579

Learning rate: 9.861115252105906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 1.5526	Cost: 43.05s
Train Epoch: 753 [20480/90000 (23%)]	Loss: -0.0360	Cost: 12.20s
Train Epoch: 753 [40960/90000 (45%)]	Loss: -0.2762	Cost: 8.07s
Train Epoch: 753 [61440/90000 (68%)]	Loss: -0.0950	Cost: 6.42s
Train Epoch: 753 [81920/90000 (91%)]	Loss: -0.2251	Cost: 12.86s
Train Epoch: 753 	Average Loss: 0.0574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8397

Learning rate: 9.860747357487283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 1.6109	Cost: 27.74s
Train Epoch: 754 [20480/90000 (23%)]	Loss: -0.1007	Cost: 6.03s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 0.0035	Cost: 17.28s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 0.0037	Cost: 12.52s
Train Epoch: 754 [81920/90000 (91%)]	Loss: -0.1739	Cost: 12.19s
Train Epoch: 754 	Average Loss: 0.1136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8848

Learning rate: 9.860378983132128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 1.6752	Cost: 35.41s
Train Epoch: 755 [20480/90000 (23%)]	Loss: -0.0399	Cost: 11.88s
Train Epoch: 755 [40960/90000 (45%)]	Loss: -0.1210	Cost: 10.49s
Train Epoch: 755 [61440/90000 (68%)]	Loss: -0.1217	Cost: 7.93s
Train Epoch: 755 [81920/90000 (91%)]	Loss: -0.1184	Cost: 8.55s
Train Epoch: 755 	Average Loss: 0.0483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7248

Saving model as e755_model.pt & e755_waveforms_supplementary.hdf5
Learning rate: 9.860010129076798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 1.5962	Cost: 36.91s
Train Epoch: 756 [20480/90000 (23%)]	Loss: -0.0674	Cost: 7.26s
Train Epoch: 756 [40960/90000 (45%)]	Loss: -0.2442	Cost: 15.27s
Train Epoch: 756 [61440/90000 (68%)]	Loss: -0.0485	Cost: 12.02s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 0.0645	Cost: 12.97s
Train Epoch: 756 	Average Loss: 0.0571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8629

Learning rate: 9.8596407953577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 2.0381	Cost: 41.37s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 0.0306	Cost: 12.04s
Train Epoch: 757 [40960/90000 (45%)]	Loss: -0.0016	Cost: 8.46s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 0.0133	Cost: 6.27s
Train Epoch: 757 [81920/90000 (91%)]	Loss: -0.0771	Cost: 12.03s
Train Epoch: 757 	Average Loss: 0.1393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8405

Learning rate: 9.859270982011284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 1.7178	Cost: 34.91s
Train Epoch: 758 [20480/90000 (23%)]	Loss: -0.0435	Cost: 10.27s
Train Epoch: 758 [40960/90000 (45%)]	Loss: -0.1445	Cost: 20.01s
Train Epoch: 758 [61440/90000 (68%)]	Loss: -0.0871	Cost: 12.27s
Train Epoch: 758 [81920/90000 (91%)]	Loss: -0.1323	Cost: 11.82s
Train Epoch: 758 	Average Loss: 0.0834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8183

Learning rate: 9.858900689074049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 1.8892	Cost: 37.89s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 0.0684	Cost: 11.62s
Train Epoch: 759 [40960/90000 (45%)]	Loss: -0.1706	Cost: 7.49s
Train Epoch: 759 [61440/90000 (68%)]	Loss: -0.1834	Cost: 6.25s
Train Epoch: 759 [81920/90000 (91%)]	Loss: -0.2627	Cost: 13.33s
Train Epoch: 759 	Average Loss: 0.0341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7338

Learning rate: 9.85852991658254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 1.4781	Cost: 33.17s
Train Epoch: 760 [20480/90000 (23%)]	Loss: -0.0424	Cost: 11.20s
Train Epoch: 760 [40960/90000 (45%)]	Loss: -0.2669	Cost: 15.59s
Train Epoch: 760 [61440/90000 (68%)]	Loss: -0.1735	Cost: 12.25s
Train Epoch: 760 [81920/90000 (91%)]	Loss: -0.2658	Cost: 12.01s
Train Epoch: 760 	Average Loss: -0.0212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7338

Learning rate: 9.858158664573355e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 1.5388	Cost: 32.92s
Train Epoch: 761 [20480/90000 (23%)]	Loss: -0.1072	Cost: 10.84s
Train Epoch: 761 [40960/90000 (45%)]	Loss: -0.2737	Cost: 6.17s
Train Epoch: 761 [61440/90000 (68%)]	Loss: -0.1707	Cost: 6.12s
Train Epoch: 761 [81920/90000 (91%)]	Loss: -0.3333	Cost: 13.44s
Train Epoch: 761 	Average Loss: -0.0279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7424

Learning rate: 9.857786933083131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 1.8380	Cost: 27.45s
Train Epoch: 762 [20480/90000 (23%)]	Loss: -0.1962	Cost: 10.70s
Train Epoch: 762 [40960/90000 (45%)]	Loss: -0.3237	Cost: 22.97s
Train Epoch: 762 [61440/90000 (68%)]	Loss: -0.2948	Cost: 13.41s
Train Epoch: 762 [81920/90000 (91%)]	Loss: -0.3273	Cost: 11.96s
Train Epoch: 762 	Average Loss: -0.0618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7967

Learning rate: 9.85741472214856e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 1.8314	Cost: 47.63s
Train Epoch: 763 [20480/90000 (23%)]	Loss: -0.0620	Cost: 10.67s
Train Epoch: 763 [40960/90000 (45%)]	Loss: -0.3207	Cost: 8.00s
Train Epoch: 763 [61440/90000 (68%)]	Loss: -0.2722	Cost: 6.85s
Train Epoch: 763 [81920/90000 (91%)]	Loss: -0.4387	Cost: 12.07s
Train Epoch: 763 	Average Loss: -0.1116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7545

Learning rate: 9.857042031806373e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 1.7986	Cost: 31.79s
Train Epoch: 764 [20480/90000 (23%)]	Loss: -0.2494	Cost: 6.77s
Train Epoch: 764 [40960/90000 (45%)]	Loss: -0.1532	Cost: 19.40s
Train Epoch: 764 [61440/90000 (68%)]	Loss: -0.3639	Cost: 12.42s
Train Epoch: 764 [81920/90000 (91%)]	Loss: -0.3503	Cost: 12.12s
Train Epoch: 764 	Average Loss: -0.1167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6718

Saving model as e764_model.pt & e764_waveforms_supplementary.hdf5
Learning rate: 9.856668862093358e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 1.6597	Cost: 43.84s
Train Epoch: 765 [20480/90000 (23%)]	Loss: -0.0796	Cost: 6.45s
Train Epoch: 765 [40960/90000 (45%)]	Loss: -0.2809	Cost: 14.20s
Train Epoch: 765 [61440/90000 (68%)]	Loss: -0.3346	Cost: 8.53s
Train Epoch: 765 [81920/90000 (91%)]	Loss: -0.3879	Cost: 8.69s
Train Epoch: 765 	Average Loss: -0.1592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5826

Saving model as e765_model.pt & e765_waveforms_supplementary.hdf5
Learning rate: 9.856295213046343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 1.8732	Cost: 30.15s
Train Epoch: 766 [20480/90000 (23%)]	Loss: -0.1926	Cost: 9.01s
Train Epoch: 766 [40960/90000 (45%)]	Loss: -0.4580	Cost: 17.17s
Train Epoch: 766 [61440/90000 (68%)]	Loss: -0.4480	Cost: 13.61s
Train Epoch: 766 [81920/90000 (91%)]	Loss: -0.4884	Cost: 12.28s
Train Epoch: 766 	Average Loss: -0.2093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6452

Learning rate: 9.855921084702205e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 1.5660	Cost: 34.42s
Train Epoch: 767 [20480/90000 (23%)]	Loss: -0.1625	Cost: 11.46s
Train Epoch: 767 [40960/90000 (45%)]	Loss: -0.3061	Cost: 11.95s
Train Epoch: 767 [61440/90000 (68%)]	Loss: -0.3297	Cost: 8.72s
Train Epoch: 767 [81920/90000 (91%)]	Loss: -0.4101	Cost: 15.17s
Train Epoch: 767 	Average Loss: -0.1660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5819

Saving model as e767_model.pt & e767_waveforms_supplementary.hdf5
Learning rate: 9.85554647709787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 1.6814	Cost: 30.82s
Train Epoch: 768 [20480/90000 (23%)]	Loss: -0.2143	Cost: 9.02s
Train Epoch: 768 [40960/90000 (45%)]	Loss: -0.5470	Cost: 15.45s
Train Epoch: 768 [61440/90000 (68%)]	Loss: -0.4059	Cost: 12.40s
Train Epoch: 768 [81920/90000 (91%)]	Loss: -0.6124	Cost: 12.24s
Train Epoch: 768 	Average Loss: -0.2167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5393

Saving model as e768_model.pt & e768_waveforms_supplementary.hdf5
Learning rate: 9.85517139027031e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 1.2265	Cost: 38.60s
Train Epoch: 769 [20480/90000 (23%)]	Loss: -0.3554	Cost: 7.46s
Train Epoch: 769 [40960/90000 (45%)]	Loss: -0.4228	Cost: 14.70s
Train Epoch: 769 [61440/90000 (68%)]	Loss: -0.3119	Cost: 8.71s
Train Epoch: 769 [81920/90000 (91%)]	Loss: -0.4097	Cost: 10.67s
Train Epoch: 769 	Average Loss: -0.2391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6489

Learning rate: 9.854795824256546e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 1.6021	Cost: 28.97s
Train Epoch: 770 [20480/90000 (23%)]	Loss: -0.2661	Cost: 8.42s
Train Epoch: 770 [40960/90000 (45%)]	Loss: -0.3316	Cost: 16.44s
Train Epoch: 770 [61440/90000 (68%)]	Loss: -0.4066	Cost: 12.29s
Train Epoch: 770 [81920/90000 (91%)]	Loss: -0.3878	Cost: 12.47s
Train Epoch: 770 	Average Loss: -0.1904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6243

Learning rate: 9.854419779093642e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 1.6131	Cost: 32.69s
Train Epoch: 771 [20480/90000 (23%)]	Loss: -0.2468	Cost: 11.92s
Train Epoch: 771 [40960/90000 (45%)]	Loss: -0.4410	Cost: 8.73s
Train Epoch: 771 [61440/90000 (68%)]	Loss: -0.3873	Cost: 8.22s
Train Epoch: 771 [81920/90000 (91%)]	Loss: -0.2086	Cost: 13.31s
Train Epoch: 771 	Average Loss: -0.1841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6956

Learning rate: 9.854043254818714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 1.5133	Cost: 40.96s
Train Epoch: 772 [20480/90000 (23%)]	Loss: -0.2003	Cost: 7.05s
Train Epoch: 772 [40960/90000 (45%)]	Loss: -0.3944	Cost: 18.34s
Train Epoch: 772 [61440/90000 (68%)]	Loss: -0.1527	Cost: 11.88s
Train Epoch: 772 [81920/90000 (91%)]	Loss: -0.3529	Cost: 12.00s
Train Epoch: 772 	Average Loss: -0.0457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6501

Learning rate: 9.853666251468923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 1.6221	Cost: 39.00s
Train Epoch: 773 [20480/90000 (23%)]	Loss: -0.1848	Cost: 11.45s
Train Epoch: 773 [40960/90000 (45%)]	Loss: -0.1311	Cost: 8.69s
Train Epoch: 773 [61440/90000 (68%)]	Loss: -0.4774	Cost: 6.42s
Train Epoch: 773 [81920/90000 (91%)]	Loss: -0.5137	Cost: 14.43s
Train Epoch: 773 	Average Loss: -0.1646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4607

Saving model as e773_model.pt & e773_waveforms_supplementary.hdf5
Learning rate: 9.853288769081479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 1.6853	Cost: 32.19s
Train Epoch: 774 [20480/90000 (23%)]	Loss: -0.3701	Cost: 6.67s
Train Epoch: 774 [40960/90000 (45%)]	Loss: -0.4509	Cost: 20.61s
Train Epoch: 774 [61440/90000 (68%)]	Loss: -0.4547	Cost: 12.41s
Train Epoch: 774 [81920/90000 (91%)]	Loss: -0.4797	Cost: 12.00s
Train Epoch: 774 	Average Loss: -0.2865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5525

Learning rate: 9.852910807693636e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 1.4472	Cost: 30.47s
Train Epoch: 775 [20480/90000 (23%)]	Loss: -0.5270	Cost: 8.77s
Train Epoch: 775 [40960/90000 (45%)]	Loss: -0.5425	Cost: 13.81s
Train Epoch: 775 [61440/90000 (68%)]	Loss: -0.5055	Cost: 9.32s
Train Epoch: 775 [81920/90000 (91%)]	Loss: -0.5575	Cost: 11.76s
Train Epoch: 775 	Average Loss: -0.2872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6154

Learning rate: 9.8525323673427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 1.6152	Cost: 36.76s
Train Epoch: 776 [20480/90000 (23%)]	Loss: -0.3401	Cost: 11.64s
Train Epoch: 776 [40960/90000 (45%)]	Loss: -0.4507	Cost: 16.56s
Train Epoch: 776 [61440/90000 (68%)]	Loss: -0.3833	Cost: 12.12s
Train Epoch: 776 [81920/90000 (91%)]	Loss: -0.5051	Cost: 11.90s
Train Epoch: 776 	Average Loss: -0.2593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4614

Learning rate: 9.85215344806602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 1.7471	Cost: 54.94s
Train Epoch: 777 [20480/90000 (23%)]	Loss: -0.4494	Cost: 6.34s
Train Epoch: 777 [40960/90000 (45%)]	Loss: -0.5388	Cost: 13.93s
Train Epoch: 777 [61440/90000 (68%)]	Loss: -0.5757	Cost: 8.59s
Train Epoch: 777 [81920/90000 (91%)]	Loss: -0.4711	Cost: 8.59s
Train Epoch: 777 	Average Loss: -0.3027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5704

Learning rate: 9.851774049900992e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 1.5083	Cost: 29.22s
Train Epoch: 778 [20480/90000 (23%)]	Loss: -0.3580	Cost: 11.13s
Train Epoch: 778 [40960/90000 (45%)]	Loss: -0.2083	Cost: 18.95s
Train Epoch: 778 [61440/90000 (68%)]	Loss: -0.4820	Cost: 13.76s
Train Epoch: 778 [81920/90000 (91%)]	Loss: -0.5571	Cost: 11.97s
Train Epoch: 778 	Average Loss: -0.2593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5796

Learning rate: 9.851394172885063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 1.7245	Cost: 48.26s
Train Epoch: 779 [20480/90000 (23%)]	Loss: -0.3964	Cost: 10.53s
Train Epoch: 779 [40960/90000 (45%)]	Loss: -0.3963	Cost: 8.73s
Train Epoch: 779 [61440/90000 (68%)]	Loss: -0.3734	Cost: 7.49s
Train Epoch: 779 [81920/90000 (91%)]	Loss: -0.5142	Cost: 11.68s
Train Epoch: 779 	Average Loss: -0.2678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5961

Learning rate: 9.851013817055725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 1.5658	Cost: 31.70s
Train Epoch: 780 [20480/90000 (23%)]	Loss: -0.3194	Cost: 9.24s
Train Epoch: 780 [40960/90000 (45%)]	Loss: -0.5256	Cost: 18.93s
Train Epoch: 780 [61440/90000 (68%)]	Loss: -0.5170	Cost: 13.39s
Train Epoch: 780 [81920/90000 (91%)]	Loss: -0.6000	Cost: 12.11s
Train Epoch: 780 	Average Loss: -0.3096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4427

Saving model as e780_model.pt & e780_waveforms_supplementary.hdf5
Learning rate: 9.850632982450517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 1.3918	Cost: 50.91s
Train Epoch: 781 [20480/90000 (23%)]	Loss: -0.3432	Cost: 10.40s
Train Epoch: 781 [40960/90000 (45%)]	Loss: -0.2277	Cost: 6.41s
Train Epoch: 781 [61440/90000 (68%)]	Loss: -0.2903	Cost: 6.47s
Train Epoch: 781 [81920/90000 (91%)]	Loss: -0.5021	Cost: 12.46s
Train Epoch: 781 	Average Loss: -0.2481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4915

Learning rate: 9.850251669107029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 1.6274	Cost: 28.90s
Train Epoch: 782 [20480/90000 (23%)]	Loss: -0.2937	Cost: 7.17s
Train Epoch: 782 [40960/90000 (45%)]	Loss: -0.1193	Cost: 18.04s
Train Epoch: 782 [61440/90000 (68%)]	Loss: -0.2357	Cost: 13.01s
Train Epoch: 782 [81920/90000 (91%)]	Loss: -0.4344	Cost: 12.35s
Train Epoch: 782 	Average Loss: -0.1563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5579

Learning rate: 9.84986987706289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 1.4987	Cost: 34.47s
Train Epoch: 783 [20480/90000 (23%)]	Loss: -0.2419	Cost: 11.76s
Train Epoch: 783 [40960/90000 (45%)]	Loss: -0.3196	Cost: 8.59s
Train Epoch: 783 [61440/90000 (68%)]	Loss: -0.2706	Cost: 7.48s
Train Epoch: 783 [81920/90000 (91%)]	Loss: -0.3891	Cost: 13.77s
Train Epoch: 783 	Average Loss: -0.1506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5881

Learning rate: 9.849487606355786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 1.4017	Cost: 29.43s
Train Epoch: 784 [20480/90000 (23%)]	Loss: -0.3176	Cost: 10.47s
Train Epoch: 784 [40960/90000 (45%)]	Loss: -0.3713	Cost: 21.14s
Train Epoch: 784 [61440/90000 (68%)]	Loss: -0.5855	Cost: 11.98s
Train Epoch: 784 [81920/90000 (91%)]	Loss: -0.5762	Cost: 11.88s
Train Epoch: 784 	Average Loss: -0.2772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4291

Saving model as e784_model.pt & e784_waveforms_supplementary.hdf5
Learning rate: 9.849104857023443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 1.2706	Cost: 42.35s
Train Epoch: 785 [20480/90000 (23%)]	Loss: -0.3461	Cost: 10.20s
Train Epoch: 785 [40960/90000 (45%)]	Loss: -0.3539	Cost: 8.87s
Train Epoch: 785 [61440/90000 (68%)]	Loss: -0.5243	Cost: 7.31s
Train Epoch: 785 [81920/90000 (91%)]	Loss: -0.5411	Cost: 13.92s
Train Epoch: 785 	Average Loss: -0.3392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3692

Saving model as e785_model.pt & e785_waveforms_supplementary.hdf5
Learning rate: 9.848721629103637e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 1.3648	Cost: 31.98s
Train Epoch: 786 [20480/90000 (23%)]	Loss: -0.4529	Cost: 7.40s
Train Epoch: 786 [40960/90000 (45%)]	Loss: -0.5921	Cost: 17.85s
Train Epoch: 786 [61440/90000 (68%)]	Loss: -0.6629	Cost: 12.04s
Train Epoch: 786 [81920/90000 (91%)]	Loss: -0.9131	Cost: 11.83s
Train Epoch: 786 	Average Loss: -0.4762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3504

Saving model as e786_model.pt & e786_waveforms_supplementary.hdf5
Learning rate: 9.848337922634192e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 1.1821	Cost: 31.57s
Train Epoch: 787 [20480/90000 (23%)]	Loss: -0.6221	Cost: 11.68s
Train Epoch: 787 [40960/90000 (45%)]	Loss: -0.6238	Cost: 6.29s
Train Epoch: 787 [61440/90000 (68%)]	Loss: -0.7137	Cost: 6.84s
Train Epoch: 787 [81920/90000 (91%)]	Loss: -0.7872	Cost: 14.68s
Train Epoch: 787 	Average Loss: -0.5236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3956

Learning rate: 9.847953737652978e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 1.1724	Cost: 34.25s
Train Epoch: 788 [20480/90000 (23%)]	Loss: -0.5566	Cost: 11.77s
Train Epoch: 788 [40960/90000 (45%)]	Loss: -0.6596	Cost: 16.55s
Train Epoch: 788 [61440/90000 (68%)]	Loss: -0.6592	Cost: 12.40s
Train Epoch: 788 [81920/90000 (91%)]	Loss: -0.7135	Cost: 12.03s
Train Epoch: 788 	Average Loss: -0.5264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3271

Saving model as e788_model.pt & e788_waveforms_supplementary.hdf5
Learning rate: 9.847569074197914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 1.1177	Cost: 41.95s
Train Epoch: 789 [20480/90000 (23%)]	Loss: -0.5924	Cost: 7.94s
Train Epoch: 789 [40960/90000 (45%)]	Loss: -0.6802	Cost: 10.30s
Train Epoch: 789 [61440/90000 (68%)]	Loss: -0.6159	Cost: 8.75s
Train Epoch: 789 [81920/90000 (91%)]	Loss: -0.7845	Cost: 9.27s
Train Epoch: 789 	Average Loss: -0.5213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2029

Saving model as e789_model.pt & e789_waveforms_supplementary.hdf5
Learning rate: 9.847183932306961e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 1.2959	Cost: 29.62s
Train Epoch: 790 [20480/90000 (23%)]	Loss: -0.5636	Cost: 9.60s
Train Epoch: 790 [40960/90000 (45%)]	Loss: -0.7287	Cost: 21.81s
Train Epoch: 790 [61440/90000 (68%)]	Loss: -0.7789	Cost: 12.20s
Train Epoch: 790 [81920/90000 (91%)]	Loss: -0.8151	Cost: 11.82s
Train Epoch: 790 	Average Loss: -0.5587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2482

Learning rate: 9.846798312018134e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 1.3328	Cost: 40.15s
Train Epoch: 791 [20480/90000 (23%)]	Loss: -0.7509	Cost: 6.28s
Train Epoch: 791 [40960/90000 (45%)]	Loss: -0.7543	Cost: 14.19s
Train Epoch: 791 [61440/90000 (68%)]	Loss: -0.8147	Cost: 8.52s
Train Epoch: 791 [81920/90000 (91%)]	Loss: -0.7133	Cost: 8.87s
Train Epoch: 791 	Average Loss: -0.5779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3652

Learning rate: 9.846412213369493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 1.0881	Cost: 28.37s
Train Epoch: 792 [20480/90000 (23%)]	Loss: -0.5825	Cost: 6.81s
Train Epoch: 792 [40960/90000 (45%)]	Loss: -0.7358	Cost: 21.62s
Train Epoch: 792 [61440/90000 (68%)]	Loss: -0.6768	Cost: 13.27s
Train Epoch: 792 [81920/90000 (91%)]	Loss: -0.7358	Cost: 12.23s
Train Epoch: 792 	Average Loss: -0.5033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3436

Learning rate: 9.84602563639914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 1.1278	Cost: 36.63s
Train Epoch: 793 [20480/90000 (23%)]	Loss: -0.6321	Cost: 10.76s
Train Epoch: 793 [40960/90000 (45%)]	Loss: -0.5753	Cost: 10.23s
Train Epoch: 793 [61440/90000 (68%)]	Loss: -0.8249	Cost: 9.03s
Train Epoch: 793 [81920/90000 (91%)]	Loss: -0.8105	Cost: 11.84s
Train Epoch: 793 	Average Loss: -0.5353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3005

Learning rate: 9.845638581145233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 1.4210	Cost: 37.47s
Train Epoch: 794 [20480/90000 (23%)]	Loss: -0.4889	Cost: 8.25s
Train Epoch: 794 [40960/90000 (45%)]	Loss: -0.7067	Cost: 16.16s
Train Epoch: 794 [61440/90000 (68%)]	Loss: -0.7647	Cost: 11.99s
Train Epoch: 794 [81920/90000 (91%)]	Loss: -0.8592	Cost: 12.22s
Train Epoch: 794 	Average Loss: -0.5364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3377

Learning rate: 9.845251047645971e-05
