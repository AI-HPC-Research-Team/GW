Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170608_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170608_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0001, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW170608_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW170608_sample_prior_basis/
Model directory models/GW170608_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0001
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.1263	Cost: 34.24s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.6519	Cost: 8.44s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.1229	Cost: 13.75s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.4153	Cost: 8.71s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 19.9399	Cost: 8.40s
Train Epoch: 1 	Average Loss: 21.4910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0075

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 9.999999753259892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 19.7500	Cost: 39.44s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.5515	Cost: 14.57s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.1584	Cost: 12.46s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 18.6711	Cost: 11.99s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.0652	Cost: 12.08s
Train Epoch: 2 	Average Loss: 19.0560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0766

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 9.999999013039593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 17.7904	Cost: 49.73s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 17.2947	Cost: 6.13s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 16.6550	Cost: 13.81s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 16.3136	Cost: 8.54s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 15.8011	Cost: 8.52s
Train Epoch: 3 	Average Loss: 16.7189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8545

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 9.999997779339173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 15.9242	Cost: 27.87s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 15.4200	Cost: 11.21s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 15.2373	Cost: 19.45s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 15.2595	Cost: 13.36s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 14.7220	Cost: 12.19s
Train Epoch: 4 	Average Loss: 15.2638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9164

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 9.99999605215876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 14.7698	Cost: 54.40s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 14.6254	Cost: 6.27s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 14.2107	Cost: 14.83s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 14.4416	Cost: 8.74s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 14.1512	Cost: 8.07s
Train Epoch: 5 	Average Loss: 14.4544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1439

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 9.999993831498517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 14.2611	Cost: 29.22s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 14.1751	Cost: 11.34s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 13.8206	Cost: 15.55s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 13.8935	Cost: 12.33s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 13.7157	Cost: 12.06s
Train Epoch: 6 	Average Loss: 13.9790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7930

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 9.999991117358668e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 13.8158	Cost: 35.26s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 13.7918	Cost: 7.67s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 13.4578	Cost: 13.38s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 13.6386	Cost: 8.45s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 13.4195	Cost: 8.87s
Train Epoch: 7 	Average Loss: 13.6555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5561

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 9.99998790973948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 13.5314	Cost: 28.84s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 13.3642	Cost: 7.20s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 13.2599	Cost: 17.06s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 13.2898	Cost: 14.38s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 13.1315	Cost: 12.51s
Train Epoch: 8 	Average Loss: 13.3408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1568

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 9.99998420864127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 13.2160	Cost: 31.98s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 13.0682	Cost: 6.39s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 12.8386	Cost: 14.72s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 12.9870	Cost: 9.99s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 12.7902	Cost: 11.65s
Train Epoch: 9 	Average Loss: 13.0051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8311

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 9.999980014064402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 12.8917	Cost: 35.88s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 12.8421	Cost: 10.30s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 12.5350	Cost: 15.11s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 12.8359	Cost: 12.26s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 12.6651	Cost: 12.04s
Train Epoch: 10 	Average Loss: 12.7761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6871

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 9.999975326009292e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 12.5531	Cost: 40.65s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 12.6462	Cost: 7.94s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 12.3813	Cost: 9.58s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 12.5535	Cost: 7.67s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 12.4982	Cost: 13.38s
Train Epoch: 11 	Average Loss: 12.5833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4601

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 9.999970144476398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 12.4046	Cost: 31.99s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 12.4621	Cost: 10.71s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 12.3343	Cost: 14.08s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 12.4055	Cost: 12.57s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 12.0562	Cost: 12.06s
Train Epoch: 12 	Average Loss: 12.4156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3679

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 9.999964469466236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 12.4542	Cost: 38.98s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 12.2507	Cost: 11.69s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 12.1969	Cost: 7.71s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 12.1785	Cost: 6.13s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 12.1052	Cost: 12.62s
Train Epoch: 13 	Average Loss: 12.2440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1837

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 9.999958300979366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 12.3850	Cost: 32.97s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 12.1855	Cost: 9.00s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 11.9864	Cost: 23.59s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 12.0246	Cost: 12.14s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 12.0203	Cost: 11.82s
Train Epoch: 14 	Average Loss: 12.1295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0842

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 9.999951639016395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 11.9553	Cost: 51.35s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 12.0678	Cost: 11.03s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 11.8608	Cost: 6.10s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 12.0553	Cost: 6.47s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 11.8616	Cost: 12.67s
Train Epoch: 15 	Average Loss: 11.9646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9413

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 9.999944483577981e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 11.9860	Cost: 27.94s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 11.7465	Cost: 7.17s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 11.7042	Cost: 19.98s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 11.7444	Cost: 12.63s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 11.6494	Cost: 12.25s
Train Epoch: 16 	Average Loss: 11.7931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7734

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 9.99993683466483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 11.5938	Cost: 33.05s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 11.7385	Cost: 12.19s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 11.5702	Cost: 8.51s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 11.6372	Cost: 6.55s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 11.5060	Cost: 14.30s
Train Epoch: 17 	Average Loss: 11.6705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5396

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 9.999928692277696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 11.5314	Cost: 32.28s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 11.5775	Cost: 10.37s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 11.4740	Cost: 15.81s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 11.5312	Cost: 12.12s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 11.4111	Cost: 12.07s
Train Epoch: 18 	Average Loss: 11.5341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4855

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 9.999920056417385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 11.4134	Cost: 39.64s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 11.4049	Cost: 6.24s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 11.3203	Cost: 12.64s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 11.2652	Cost: 8.84s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 11.1478	Cost: 11.23s
Train Epoch: 19 	Average Loss: 11.4000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3759

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 9.999910927084749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 11.3284	Cost: 31.33s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 11.2879	Cost: 7.94s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 11.1148	Cost: 15.97s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 11.1649	Cost: 12.09s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 11.0898	Cost: 11.82s
Train Epoch: 20 	Average Loss: 11.2299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2385

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 9.999901304280687e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 11.1095	Cost: 32.13s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 11.1308	Cost: 11.33s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 10.9782	Cost: 10.26s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 11.0776	Cost: 6.06s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 11.0590	Cost: 6.97s
Train Epoch: 21 	Average Loss: 11.1001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0477

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 9.99989118800615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 11.0852	Cost: 27.32s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 11.0377	Cost: 8.99s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 10.9486	Cost: 22.53s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 11.0682	Cost: 13.79s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 10.9786	Cost: 12.92s
Train Epoch: 22 	Average Loss: 10.9950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9016

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 9.999880578262136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 10.9337	Cost: 53.54s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 10.8241	Cost: 6.13s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 10.7199	Cost: 15.29s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 10.8556	Cost: 8.52s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 10.7735	Cost: 8.45s
Train Epoch: 23 	Average Loss: 10.8662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8406

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 9.999869475049693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 10.7128	Cost: 29.15s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 10.6506	Cost: 9.68s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 10.7327	Cost: 18.16s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 10.6197	Cost: 12.58s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 10.6650	Cost: 11.84s
Train Epoch: 24 	Average Loss: 10.7164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6632

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 9.999857878369916e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 10.6051	Cost: 35.63s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 10.5341	Cost: 7.44s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 10.4949	Cost: 13.42s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 10.4662	Cost: 8.44s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 10.6233	Cost: 8.04s
Train Epoch: 25 	Average Loss: 10.6267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6949

Learning rate: 9.99984578822395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 10.5988	Cost: 29.03s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 10.6161	Cost: 9.50s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 10.3140	Cost: 13.78s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 10.3850	Cost: 12.49s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 10.5837	Cost: 12.80s
Train Epoch: 26 	Average Loss: 10.5002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5145

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 9.999833204612988e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 10.4457	Cost: 32.55s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 10.3536	Cost: 11.71s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 10.2856	Cost: 8.91s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 10.3021	Cost: 9.38s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 10.3257	Cost: 10.89s
Train Epoch: 27 	Average Loss: 10.3609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3605

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 9.999820127538271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 10.4496	Cost: 33.49s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 10.3124	Cost: 9.04s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 10.2610	Cost: 15.45s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 10.1480	Cost: 12.61s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 10.2394	Cost: 12.08s
Train Epoch: 28 	Average Loss: 10.2513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2601

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 9.999806557001093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 10.2560	Cost: 35.77s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 10.1860	Cost: 11.95s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 10.0506	Cost: 11.00s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 10.0231	Cost: 6.47s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 10.2045	Cost: 7.95s
Train Epoch: 29 	Average Loss: 10.1596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1727

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 9.99979249300279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 10.1156	Cost: 32.24s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 10.0529	Cost: 9.24s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 9.9726	Cost: 18.69s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 9.9715	Cost: 12.70s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 10.0371	Cost: 12.11s
Train Epoch: 30 	Average Loss: 10.0516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0786

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 9.99977793554475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 9.9411	Cost: 35.81s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 10.0297	Cost: 11.06s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 9.8693	Cost: 9.14s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 9.9080	Cost: 6.34s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 10.0068	Cost: 14.15s
Train Epoch: 31 	Average Loss: 9.9553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9121

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 9.999762884628413e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 9.8805	Cost: 33.54s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 9.8105	Cost: 8.80s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 9.7842	Cost: 22.77s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 9.8144	Cost: 12.20s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 9.7943	Cost: 11.76s
Train Epoch: 32 	Average Loss: 9.8753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9292

Learning rate: 9.999747340255259e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 9.8655	Cost: 45.53s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 9.7781	Cost: 11.70s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 9.7495	Cost: 7.13s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 9.6740	Cost: 6.29s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 9.8150	Cost: 10.87s
Train Epoch: 33 	Average Loss: 9.7773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7935

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 9.999731302426829e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 9.7649	Cost: 29.62s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 9.6485	Cost: 6.61s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 9.6352	Cost: 18.81s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 9.6736	Cost: 14.41s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 9.6543	Cost: 12.31s
Train Epoch: 34 	Average Loss: 9.6964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6368

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 9.999714771144701e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 9.6388	Cost: 33.23s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 9.6500	Cost: 8.24s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 9.5225	Cost: 15.42s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 9.5164	Cost: 8.91s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 9.4917	Cost: 10.46s
Train Epoch: 35 	Average Loss: 9.5806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6007

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 9.999697746410508e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 9.5368	Cost: 34.06s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 9.5361	Cost: 13.46s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 9.3674	Cost: 15.29s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 9.4373	Cost: 12.09s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 9.5428	Cost: 12.03s
Train Epoch: 36 	Average Loss: 9.5151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5309

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 9.99968022822593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 9.4990	Cost: 34.01s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 9.4525	Cost: 6.34s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 9.3540	Cost: 12.99s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 9.4447	Cost: 8.98s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 9.3320	Cost: 9.62s
Train Epoch: 37 	Average Loss: 9.4316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4151

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 9.999662216592697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 9.4585	Cost: 30.26s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 9.3188	Cost: 10.50s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 9.3041	Cost: 20.39s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 9.2323	Cost: 12.06s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 9.2945	Cost: 11.87s
Train Epoch: 38 	Average Loss: 9.3594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3670

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 9.999643711512586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 9.2685	Cost: 28.23s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 9.3391	Cost: 6.36s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 9.1541	Cost: 13.74s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 9.2399	Cost: 8.50s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 9.1293	Cost: 9.30s
Train Epoch: 39 	Average Loss: 9.2801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2818

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 9.999624712987422e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 9.2611	Cost: 29.11s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 9.1805	Cost: 11.87s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 9.1068	Cost: 15.43s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 9.1508	Cost: 12.90s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 9.2509	Cost: 12.18s
Train Epoch: 40 	Average Loss: 9.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2067

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 9.999605221019082e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 9.1250	Cost: 30.68s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 9.1444	Cost: 11.90s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 9.1379	Cost: 8.94s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 9.1481	Cost: 7.86s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 9.0316	Cost: 13.20s
Train Epoch: 41 	Average Loss: 9.1259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0624

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 9.999585235609488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 9.0512	Cost: 31.98s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 8.9697	Cost: 10.14s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 8.8990	Cost: 14.83s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 8.9445	Cost: 12.19s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 8.9296	Cost: 12.06s
Train Epoch: 42 	Average Loss: 9.0398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0600

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 9.999564756760615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 9.0772	Cost: 38.15s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 9.0708	Cost: 11.89s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 9.0144	Cost: 7.26s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 9.1140	Cost: 6.48s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 9.0767	Cost: 10.66s
Train Epoch: 43 	Average Loss: 9.0097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0248

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 9.999543784474483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 9.0587	Cost: 32.94s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 8.9845	Cost: 7.54s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 8.9018	Cost: 18.36s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 8.8417	Cost: 12.20s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 8.9264	Cost: 12.36s
Train Epoch: 44 	Average Loss: 8.9277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9647

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 9.99952231875316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 8.9238	Cost: 32.17s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 8.8188	Cost: 6.33s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 8.7264	Cost: 16.89s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 8.8079	Cost: 9.36s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 8.8908	Cost: 9.20s
Train Epoch: 45 	Average Loss: 8.8472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8659

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 9.999500359598768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 8.7930	Cost: 28.11s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 8.7545	Cost: 14.96s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 8.6430	Cost: 17.92s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 8.8863	Cost: 12.68s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 8.7686	Cost: 12.03s
Train Epoch: 46 	Average Loss: 8.7842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7940

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 9.999477907013472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 8.8112	Cost: 36.79s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 8.7301	Cost: 10.85s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 8.6993	Cost: 11.41s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 8.5955	Cost: 8.61s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 8.6555	Cost: 12.22s
Train Epoch: 47 	Average Loss: 8.7197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7690

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 9.999454960999486e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 8.5417	Cost: 30.62s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 8.5485	Cost: 7.40s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 8.6174	Cost: 16.34s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 8.5800	Cost: 12.34s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 8.6964	Cost: 12.24s
Train Epoch: 48 	Average Loss: 8.6681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6621

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 9.99943152155908e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 8.6640	Cost: 40.40s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 8.6341	Cost: 6.32s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 8.4551	Cost: 15.06s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 8.4419	Cost: 8.64s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 8.6100	Cost: 9.43s
Train Epoch: 49 	Average Loss: 8.6012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5952

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 9.999407588694566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 8.7155	Cost: 28.82s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 8.6980	Cost: 8.50s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 8.3961	Cost: 16.31s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 8.4845	Cost: 12.31s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 8.5771	Cost: 12.37s
Train Epoch: 50 	Average Loss: 8.5664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5563

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 9.999383162408302e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 8.5846	Cost: 36.43s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 8.4760	Cost: 6.22s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 8.3612	Cost: 15.25s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 8.4231	Cost: 9.38s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 8.4451	Cost: 11.94s
Train Epoch: 51 	Average Loss: 8.4989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5479

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 9.999358242702702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 8.4831	Cost: 36.54s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 8.3436	Cost: 15.00s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 8.3642	Cost: 14.55s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 8.3010	Cost: 12.17s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 8.4101	Cost: 11.84s
Train Epoch: 52 	Average Loss: 8.4279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3962

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 9.999332829580225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 8.4617	Cost: 37.51s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 8.1934	Cost: 6.33s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 8.3217	Cost: 13.05s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 8.4849	Cost: 8.59s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 8.3410	Cost: 8.67s
Train Epoch: 53 	Average Loss: 8.3807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4206

Learning rate: 9.99930692304338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 8.4783	Cost: 27.78s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 8.2844	Cost: 8.83s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 8.2616	Cost: 20.93s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 8.2720	Cost: 12.33s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 8.1588	Cost: 11.90s
Train Epoch: 54 	Average Loss: 8.2930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2391

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 9.999280523094723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 8.4213	Cost: 45.52s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 8.2674	Cost: 6.71s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 8.1774	Cost: 12.39s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 8.2295	Cost: 8.75s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 8.1360	Cost: 8.68s
Train Epoch: 55 	Average Loss: 8.2539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2584

Learning rate: 9.999253629736859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 8.3026	Cost: 34.34s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 8.2164	Cost: 11.11s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 8.1864	Cost: 20.96s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 8.2188	Cost: 12.31s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 8.1822	Cost: 11.96s
Train Epoch: 56 	Average Loss: 8.2163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2248

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 9.999226242972442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 8.1156	Cost: 36.95s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 8.0652	Cost: 11.28s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 8.0789	Cost: 10.36s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 8.1414	Cost: 8.45s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 8.1492	Cost: 11.76s
Train Epoch: 57 	Average Loss: 8.1620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1073

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 9.999198362804177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 8.2776	Cost: 31.55s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 8.0843	Cost: 7.36s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 8.0105	Cost: 17.63s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 7.9574	Cost: 12.19s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 8.0296	Cost: 12.19s
Train Epoch: 58 	Average Loss: 8.0924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1292

Learning rate: 9.999169989234814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 8.0541	Cost: 32.60s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 7.9452	Cost: 12.28s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 8.0104	Cost: 10.81s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 8.0473	Cost: 6.19s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 7.9750	Cost: 9.52s
Train Epoch: 59 	Average Loss: 8.0554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0403

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 9.999141122267153e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 7.8952	Cost: 30.07s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 7.8544	Cost: 8.06s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 8.0156	Cost: 16.90s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 7.9549	Cost: 13.10s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 7.8923	Cost: 11.99s
Train Epoch: 60 	Average Loss: 8.0177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9781

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 9.999111761904044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 7.9424	Cost: 34.25s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 7.8552	Cost: 12.59s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 7.9556	Cost: 7.96s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 7.9127	Cost: 6.46s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 7.8808	Cost: 12.78s
Train Epoch: 61 	Average Loss: 7.9620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9766

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 9.999081908148385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 8.0777	Cost: 33.00s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 7.8802	Cost: 10.77s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 7.9414	Cost: 18.93s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 7.8322	Cost: 11.96s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 7.7652	Cost: 11.93s
Train Epoch: 62 	Average Loss: 7.9430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9392

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 9.999051561003123e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 7.9113	Cost: 33.15s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 7.9949	Cost: 10.55s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 7.7447	Cost: 9.16s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 7.8139	Cost: 6.20s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 7.9262	Cost: 13.10s
Train Epoch: 63 	Average Loss: 7.9293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9124

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 9.999020720471253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 7.8101	Cost: 29.21s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 7.8529	Cost: 11.55s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 7.7458	Cost: 14.60s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 7.7987	Cost: 13.98s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 7.7399	Cost: 12.07s
Train Epoch: 64 	Average Loss: 7.8520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8745

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 9.998989386555816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 7.9477	Cost: 47.81s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 7.7580	Cost: 10.74s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 7.7908	Cost: 7.72s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 7.7954	Cost: 6.64s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 7.9170	Cost: 13.80s
Train Epoch: 65 	Average Loss: 7.8245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8467

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 9.998957559259906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 7.8713	Cost: 32.64s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 7.7776	Cost: 7.24s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 7.7857	Cost: 17.26s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 7.7385	Cost: 12.21s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 7.6887	Cost: 12.14s
Train Epoch: 66 	Average Loss: 7.7873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8342

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 9.998925238586665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 7.8647	Cost: 35.02s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 7.7434	Cost: 7.65s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 7.7044	Cost: 13.62s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 7.6278	Cost: 8.51s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 7.7302	Cost: 8.59s
Train Epoch: 67 	Average Loss: 7.7520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7398

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 9.998892424539283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 7.7032	Cost: 27.72s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 7.7341	Cost: 9.04s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 7.7003	Cost: 14.90s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 7.7149	Cost: 12.09s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 7.6314	Cost: 12.60s
Train Epoch: 68 	Average Loss: 7.7051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6877

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 9.998859117121e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 7.6705	Cost: 35.24s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 7.5949	Cost: 9.69s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 7.5753	Cost: 8.93s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 7.6681	Cost: 8.72s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 7.6467	Cost: 15.05s
Train Epoch: 69 	Average Loss: 7.6839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6905

Learning rate: 9.998825316335099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 7.5012	Cost: 36.84s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 7.5695	Cost: 8.34s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 7.6768	Cost: 17.65s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 7.6717	Cost: 12.09s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 7.6110	Cost: 12.08s
Train Epoch: 70 	Average Loss: 7.6613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7238

Learning rate: 9.99879102218492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 7.6786	Cost: 33.83s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 7.4733	Cost: 11.61s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 7.6972	Cost: 6.29s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 7.6551	Cost: 6.88s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 7.5487	Cost: 15.25s
Train Epoch: 71 	Average Loss: 7.6083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5933

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 9.998756234673847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 7.6638	Cost: 30.62s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 7.5724	Cost: 10.51s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 7.4226	Cost: 14.42s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 7.6294	Cost: 13.79s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 7.5892	Cost: 12.08s
Train Epoch: 72 	Average Loss: 7.5758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6036

Learning rate: 9.998720953805312e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 7.5078	Cost: 38.35s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 7.4241	Cost: 12.43s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 7.5988	Cost: 12.09s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 7.5320	Cost: 7.46s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 7.4351	Cost: 6.13s
Train Epoch: 73 	Average Loss: 7.5436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5518

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Learning rate: 9.998685179582798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 7.5712	Cost: 32.49s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 7.3948	Cost: 10.50s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 7.5731	Cost: 20.60s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 7.4149	Cost: 12.36s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 7.3204	Cost: 11.79s
Train Epoch: 74 	Average Loss: 7.5154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5652

Learning rate: 9.998648912009835e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 7.3739	Cost: 31.10s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 7.3855	Cost: 11.72s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 7.5064	Cost: 6.16s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 7.4330	Cost: 6.11s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 7.2873	Cost: 13.94s
Train Epoch: 75 	Average Loss: 7.4689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4524

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 9.998612151090003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 7.5028	Cost: 29.99s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 7.4690	Cost: 10.90s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 7.4180	Cost: 22.21s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 7.3562	Cost: 12.70s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 7.3998	Cost: 11.92s
Train Epoch: 76 	Average Loss: 7.4487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4668

Learning rate: 9.998574896826931e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 7.4738	Cost: 44.25s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 7.4272	Cost: 6.01s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 7.3819	Cost: 15.11s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 7.4121	Cost: 8.60s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 7.3719	Cost: 8.76s
Train Epoch: 77 	Average Loss: 7.4106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4662

Learning rate: 9.998537149224293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 7.4360	Cost: 30.09s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 7.2861	Cost: 6.92s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 7.3899	Cost: 18.45s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 7.3409	Cost: 12.37s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 7.2839	Cost: 12.04s
Train Epoch: 78 	Average Loss: 7.3862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4055

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 9.998498908285819e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 7.4530	Cost: 34.52s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 7.2330	Cost: 7.57s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 7.2651	Cost: 13.68s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 7.3077	Cost: 8.54s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 7.2642	Cost: 9.02s
Train Epoch: 79 	Average Loss: 7.3570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3894

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 9.998460174015279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 7.4370	Cost: 27.46s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 7.3237	Cost: 8.30s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 7.3287	Cost: 15.91s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 7.3058	Cost: 12.07s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 7.2171	Cost: 12.40s
Train Epoch: 80 	Average Loss: 7.3298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3292

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 9.998420946416499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 7.5740	Cost: 33.68s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 7.2921	Cost: 9.23s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 7.2601	Cost: 9.17s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 7.0982	Cost: 8.89s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 7.3292	Cost: 13.49s
Train Epoch: 81 	Average Loss: 7.3011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3699

Learning rate: 9.998381225493349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 7.4121	Cost: 32.02s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 7.1979	Cost: 11.24s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 7.2878	Cost: 17.90s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 7.2555	Cost: 12.38s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 7.2781	Cost: 11.83s
Train Epoch: 82 	Average Loss: 7.2823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3480

Learning rate: 9.998341011249749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 7.3127	Cost: 39.56s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 7.2948	Cost: 11.18s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 7.2803	Cost: 7.97s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 7.1555	Cost: 6.18s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 7.3152	Cost: 13.45s
Train Epoch: 83 	Average Loss: 7.2782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3146

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 9.99830030368967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 7.3634	Cost: 30.05s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 7.0806	Cost: 10.07s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 7.1849	Cost: 18.98s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 7.0763	Cost: 12.53s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 7.1187	Cost: 12.20s
Train Epoch: 84 	Average Loss: 7.2042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2341

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 9.998259102817127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 7.1774	Cost: 41.75s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 7.1771	Cost: 8.37s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 7.1157	Cost: 10.96s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 7.2142	Cost: 8.96s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 7.0841	Cost: 12.23s
Train Epoch: 85 	Average Loss: 7.2000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2359

Learning rate: 9.99821740863619e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 7.0945	Cost: 48.71s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 7.0703	Cost: 12.33s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 7.1555	Cost: 12.26s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 7.2144	Cost: 12.14s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 7.0207	Cost: 11.90s
Train Epoch: 86 	Average Loss: 7.1384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1478

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 9.99817522115097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 7.1024	Cost: 43.46s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 7.1098	Cost: 6.18s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 7.2740	Cost: 13.47s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 7.1056	Cost: 8.55s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 7.0362	Cost: 8.34s
Train Epoch: 87 	Average Loss: 7.1400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1684

Learning rate: 9.998132540365634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 7.2303	Cost: 28.69s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 7.0815	Cost: 7.83s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 7.2147	Cost: 18.65s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 7.1422	Cost: 13.24s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 6.9562	Cost: 12.10s
Train Epoch: 88 	Average Loss: 7.1285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1337

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 9.998089366284391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 7.1606	Cost: 44.85s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 7.0295	Cost: 10.46s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 7.1177	Cost: 10.92s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 7.1466	Cost: 6.13s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 6.9694	Cost: 12.61s
Train Epoch: 89 	Average Loss: 7.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0938

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 9.998045698911504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 7.0008	Cost: 31.41s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 7.0556	Cost: 6.92s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 7.1005	Cost: 17.21s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 6.9708	Cost: 12.67s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 7.0835	Cost: 12.04s
Train Epoch: 90 	Average Loss: 7.0692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0890

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 9.998001538251281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 7.1834	Cost: 43.82s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 7.0987	Cost: 8.97s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 7.0510	Cost: 10.01s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 6.9855	Cost: 8.22s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 6.8907	Cost: 10.42s
Train Epoch: 91 	Average Loss: 7.0359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0682

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 9.997956884308085e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 7.0298	Cost: 27.51s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 7.0267	Cost: 8.66s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 7.0210	Cost: 15.16s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 6.9675	Cost: 11.93s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 6.9683	Cost: 12.49s
Train Epoch: 92 	Average Loss: 7.0238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0626

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 9.99791173708632e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 7.0322	Cost: 32.60s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 6.9554	Cost: 10.31s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 7.0218	Cost: 8.17s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 6.9099	Cost: 10.30s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 6.9625	Cost: 12.70s
Train Epoch: 93 	Average Loss: 6.9945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0467

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 9.997866096590442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 7.1491	Cost: 33.66s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 7.0460	Cost: 8.48s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 6.9780	Cost: 18.36s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 6.8174	Cost: 12.21s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 7.0212	Cost: 11.89s
Train Epoch: 94 	Average Loss: 6.9916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0153

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Learning rate: 9.997819962824954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 6.9836	Cost: 38.75s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 6.9701	Cost: 10.75s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 6.9919	Cost: 6.30s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 6.8311	Cost: 7.14s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 6.8698	Cost: 13.38s
Train Epoch: 95 	Average Loss: 6.9468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9491

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 9.997773335794414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 6.9399	Cost: 33.26s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 6.9564	Cost: 10.27s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 7.0105	Cost: 15.44s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 6.9198	Cost: 12.19s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 6.8607	Cost: 12.02s
Train Epoch: 96 	Average Loss: 6.9493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9360

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 9.99772621550342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 6.9251	Cost: 34.49s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 6.8762	Cost: 9.12s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 6.8922	Cost: 7.88s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 6.8233	Cost: 7.76s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 6.8496	Cost: 14.02s
Train Epoch: 97 	Average Loss: 6.9042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0058

Learning rate: 9.997678601956623e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 6.9233	Cost: 27.05s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 6.8912	Cost: 7.39s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 6.8536	Cost: 21.49s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 6.8210	Cost: 13.78s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 6.8210	Cost: 12.17s
Train Epoch: 98 	Average Loss: 6.8863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9184

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Learning rate: 9.997630495158724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 6.9240	Cost: 32.51s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 6.8984	Cost: 11.85s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 6.8622	Cost: 8.22s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 6.7516	Cost: 6.43s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 6.8028	Cost: 15.42s
Train Epoch: 99 	Average Loss: 6.8613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9305

Learning rate: 9.997581895114468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 6.8852	Cost: 29.27s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 6.8027	Cost: 9.78s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 6.8716	Cost: 17.25s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 6.9701	Cost: 12.41s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 6.7063	Cost: 12.18s
Train Epoch: 100 	Average Loss: 6.8516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8690

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 9.997532801828656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 6.8821	Cost: 36.14s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 6.6689	Cost: 13.44s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 6.7816	Cost: 7.86s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 6.8198	Cost: 6.56s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 6.7423	Cost: 14.06s
Train Epoch: 101 	Average Loss: 6.8149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8800

Learning rate: 9.997483215306129e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 6.8620	Cost: 32.29s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 6.8590	Cost: 7.39s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 6.8271	Cost: 17.57s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 6.7456	Cost: 11.98s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 6.7755	Cost: 11.99s
Train Epoch: 102 	Average Loss: 6.8285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7634

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 9.997433135551784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 6.7611	Cost: 31.47s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 6.7982	Cost: 11.58s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 6.7229	Cost: 7.55s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 6.6986	Cost: 6.60s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 6.6716	Cost: 14.68s
Train Epoch: 103 	Average Loss: 6.7758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8483

Learning rate: 9.99738256257056e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 6.8594	Cost: 34.90s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 6.7729	Cost: 7.67s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 6.7410	Cost: 20.47s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 6.7499	Cost: 12.00s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 6.7273	Cost: 12.19s
Train Epoch: 104 	Average Loss: 6.7846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7599

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 9.997331496367453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 6.7584	Cost: 32.22s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 6.6879	Cost: 11.88s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 6.7941	Cost: 8.19s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 6.6754	Cost: 6.57s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 6.7110	Cost: 12.89s
Train Epoch: 105 	Average Loss: 6.7438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7877

Learning rate: 9.997279936947499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 6.6922	Cost: 32.47s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 6.6850	Cost: 10.72s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 6.7027	Cost: 18.13s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 6.6465	Cost: 12.37s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 6.5864	Cost: 11.99s
Train Epoch: 106 	Average Loss: 6.7204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7333

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 9.997227884315788e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 6.7411	Cost: 39.20s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 6.7159	Cost: 8.89s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 6.6971	Cost: 9.00s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 6.6304	Cost: 8.06s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 6.6480	Cost: 13.13s
Train Epoch: 107 	Average Loss: 6.7391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6953

Saving model as e107_model.pt & e107_waveforms_supplementary.hdf5
Learning rate: 9.997175338477459e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 6.7192	Cost: 32.07s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 6.6825	Cost: 8.33s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 6.6101	Cost: 16.42s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 6.6838	Cost: 12.52s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 6.6478	Cost: 12.14s
Train Epoch: 108 	Average Loss: 6.7075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7057

Learning rate: 9.997122299437696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 6.6787	Cost: 31.92s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 6.6562	Cost: 10.36s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 6.6099	Cost: 12.56s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 6.5559	Cost: 9.79s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 6.6440	Cost: 14.40s
Train Epoch: 109 	Average Loss: 6.6873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7291

Learning rate: 9.997068767201736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 6.6318	Cost: 35.37s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 6.7322	Cost: 10.07s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 6.6643	Cost: 19.19s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 6.5748	Cost: 12.52s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 6.6543	Cost: 11.76s
Train Epoch: 110 	Average Loss: 6.6211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6734

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 9.997014741774862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 6.6159	Cost: 53.15s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 6.6502	Cost: 6.19s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 6.6778	Cost: 14.06s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 6.6897	Cost: 8.55s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 6.6257	Cost: 7.88s
Train Epoch: 111 	Average Loss: 6.6379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6977

Learning rate: 9.996960223162402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 6.6874	Cost: 77.52s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 6.6251	Cost: 20.29s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 6.5929	Cost: 58.25s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 6.5047	Cost: 18.56s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 6.5383	Cost: 37.12s
Train Epoch: 112 	Average Loss: 6.6094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6301

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 9.996905211369744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 6.6983	Cost: 95.55s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 6.6484	Cost: 16.46s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 6.6594	Cost: 38.20s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 6.4816	Cost: 10.62s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 6.5285	Cost: 43.28s
Train Epoch: 113 	Average Loss: 6.6120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6320

Learning rate: 9.996849706402311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 6.6670	Cost: 39.21s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 6.5410	Cost: 14.28s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 6.4974	Cost: 15.09s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 6.4918	Cost: 12.21s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 6.4361	Cost: 9.92s
Train Epoch: 114 	Average Loss: 6.5756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6542

Learning rate: 9.996793708265583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 6.5917	Cost: 28.14s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 6.5624	Cost: 8.99s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 6.5199	Cost: 9.96s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 6.4796	Cost: 8.93s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 6.4723	Cost: 8.40s
Train Epoch: 115 	Average Loss: 6.5632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6354

Learning rate: 9.996737216965088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 6.6261	Cost: 33.99s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 6.5705	Cost: 12.27s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 6.4208	Cost: 14.35s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 6.4684	Cost: 12.36s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 6.4897	Cost: 10.48s
Train Epoch: 116 	Average Loss: 6.5558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5383

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 9.9966802325064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 6.5507	Cost: 31.82s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 6.5754	Cost: 9.21s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 6.5106	Cost: 18.77s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 6.4945	Cost: 9.10s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 6.4129	Cost: 9.03s
Train Epoch: 117 	Average Loss: 6.5284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5019

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 9.996622754895145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 6.4632	Cost: 37.48s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 6.4365	Cost: 7.39s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 6.5246	Cost: 18.31s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 6.4476	Cost: 12.12s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 6.4534	Cost: 12.02s
Train Epoch: 118 	Average Loss: 6.5048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5253

Learning rate: 9.996564784136994e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 6.5068	Cost: 33.70s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 6.4600	Cost: 9.86s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 6.5638	Cost: 11.06s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 6.3992	Cost: 9.18s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 6.4872	Cost: 11.88s
Train Epoch: 119 	Average Loss: 6.4880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5586

Learning rate: 9.99650632023767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 6.5798	Cost: 35.59s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 6.6070	Cost: 11.19s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 6.4497	Cost: 21.94s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 6.3147	Cost: 12.08s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 6.4734	Cost: 11.95s
Train Epoch: 120 	Average Loss: 6.4699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5489

Learning rate: 9.996447363202941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 6.4486	Cost: 38.12s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 6.3722	Cost: 6.47s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 6.3888	Cost: 14.87s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 6.5024	Cost: 8.54s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 6.3846	Cost: 8.94s
Train Epoch: 121 	Average Loss: 6.4735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5446

Learning rate: 9.996387913038628e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 6.4351	Cost: 34.17s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 6.3681	Cost: 11.02s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 6.3475	Cost: 19.26s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 6.4383	Cost: 12.51s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 6.5784	Cost: 12.04s
Train Epoch: 122 	Average Loss: 6.4515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5778

Learning rate: 9.996327969750598e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 6.6383	Cost: 36.62s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 6.4210	Cost: 6.42s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 6.4125	Cost: 14.25s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 6.4658	Cost: 8.56s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 6.3777	Cost: 9.05s
Train Epoch: 123 	Average Loss: 6.4662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5166

Learning rate: 9.996267533344767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 6.6979	Cost: 30.56s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 6.3063	Cost: 8.70s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 6.4197	Cost: 17.41s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 6.4079	Cost: 14.34s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 6.4117	Cost: 12.52s
Train Epoch: 124 	Average Loss: 6.4180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5084

Learning rate: 9.996206603827099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 6.4975	Cost: 38.44s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 6.4552	Cost: 13.88s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 6.3408	Cost: 12.05s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 6.2868	Cost: 6.23s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 6.2819	Cost: 9.63s
Train Epoch: 125 	Average Loss: 6.3846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4067

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 9.99614518120361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 6.3748	Cost: 33.08s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 6.4128	Cost: 8.75s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 6.3245	Cost: 9.95s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 6.4086	Cost: 6.56s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 6.3149	Cost: 18.55s
Train Epoch: 126 	Average Loss: 6.3737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4837

Learning rate: 9.99608326548036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 6.5417	Cost: 46.84s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 6.5310	Cost: 11.91s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 6.3048	Cost: 11.31s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 6.3544	Cost: 6.41s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 6.3307	Cost: 8.69s
Train Epoch: 127 	Average Loss: 6.3816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4381

Learning rate: 9.996020856663458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 6.5058	Cost: 30.42s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 6.4278	Cost: 5.95s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 6.2824	Cost: 15.01s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 6.3719	Cost: 12.45s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 6.3970	Cost: 14.04s
Train Epoch: 128 	Average Loss: 6.3594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4599

Learning rate: 9.995957954759067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 6.3490	Cost: 36.09s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 6.5151	Cost: 12.63s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 6.3339	Cost: 12.31s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 6.2903	Cost: 10.67s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 6.2832	Cost: 7.19s
Train Epoch: 129 	Average Loss: 6.3388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4648

Learning rate: 9.995894559773395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 6.4175	Cost: 35.23s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 6.3130	Cost: 10.86s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 6.3118	Cost: 9.89s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 6.2203	Cost: 8.91s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 6.3310	Cost: 18.73s
Train Epoch: 130 	Average Loss: 6.3429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3666

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 9.995830671712695e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 6.5239	Cost: 39.67s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 6.3551	Cost: 10.83s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 6.3239	Cost: 12.65s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 6.3963	Cost: 11.69s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 6.3810	Cost: 6.25s
Train Epoch: 131 	Average Loss: 6.3253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4084

Learning rate: 9.995766290583277e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 6.3193	Cost: 30.54s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 6.3454	Cost: 9.10s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 6.2718	Cost: 10.92s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 6.2074	Cost: 7.31s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 6.3324	Cost: 11.75s
Train Epoch: 132 	Average Loss: 6.3078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3512

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 9.995701416391493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 6.2999	Cost: 40.89s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 6.3656	Cost: 11.90s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 6.2350	Cost: 12.38s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 6.2141	Cost: 12.18s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 6.3627	Cost: 7.78s
Train Epoch: 133 	Average Loss: 6.2831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3813

Learning rate: 9.995636049143747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 6.4911	Cost: 30.84s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 6.3839	Cost: 10.80s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 6.1868	Cost: 11.86s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 6.2812	Cost: 10.04s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 6.1560	Cost: 8.37s
Train Epoch: 134 	Average Loss: 6.2753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3636

Learning rate: 9.995570188846488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 6.4748	Cost: 35.42s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 6.3367	Cost: 9.47s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 6.1959	Cost: 24.01s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 6.2499	Cost: 12.39s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 6.3103	Cost: 11.87s
Train Epoch: 135 	Average Loss: 6.2707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3676

Learning rate: 9.99550383550622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 6.3231	Cost: 43.37s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 6.2785	Cost: 11.76s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 6.2054	Cost: 7.76s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 6.2762	Cost: 6.46s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 6.1202	Cost: 13.01s
Train Epoch: 136 	Average Loss: 6.2809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3539

Learning rate: 9.995436989129488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 6.4593	Cost: 29.51s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 6.3292	Cost: 6.30s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 6.2142	Cost: 20.98s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 6.1924	Cost: 12.85s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 6.2284	Cost: 12.25s
Train Epoch: 137 	Average Loss: 6.2485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3453

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 9.99536964972289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 6.3294	Cost: 47.30s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 6.2514	Cost: 12.20s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 6.2980	Cost: 9.07s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 6.1096	Cost: 6.19s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 6.0229	Cost: 13.72s
Train Epoch: 138 	Average Loss: 6.2459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2503

Saving model as e138_model.pt & e138_waveforms_supplementary.hdf5
Learning rate: 9.995301817293077e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 6.3704	Cost: 32.21s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 6.1288	Cost: 8.77s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 6.0921	Cost: 15.94s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 6.2098	Cost: 12.23s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 6.1480	Cost: 12.49s
Train Epoch: 139 	Average Loss: 6.2036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2864

Learning rate: 9.995233491846737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 6.2702	Cost: 60.65s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 6.1874	Cost: 10.41s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 6.1930	Cost: 8.65s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 6.1518	Cost: 6.93s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 6.1486	Cost: 12.59s
Train Epoch: 140 	Average Loss: 6.1745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3187

Learning rate: 9.995164673390618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 6.3032	Cost: 29.21s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 6.1562	Cost: 6.74s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 6.1056	Cost: 17.28s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 6.1005	Cost: 11.49s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 6.0334	Cost: 12.87s
Train Epoch: 141 	Average Loss: 6.1776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2274

Saving model as e141_model.pt & e141_waveforms_supplementary.hdf5
Learning rate: 9.995095361931511e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 6.1836	Cost: 60.83s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 6.2066	Cost: 12.82s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 6.0870	Cost: 30.15s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 6.1879	Cost: 12.08s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 6.0999	Cost: 12.66s
Train Epoch: 142 	Average Loss: 6.1976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2624

Learning rate: 9.995025557476254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 6.2638	Cost: 36.95s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 6.1729	Cost: 7.75s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 5.9593	Cost: 16.45s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 6.1778	Cost: 12.14s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 6.0294	Cost: 12.16s
Train Epoch: 143 	Average Loss: 6.1273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2152

Saving model as e143_model.pt & e143_waveforms_supplementary.hdf5
Learning rate: 9.99495526003174e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 6.0905	Cost: 32.17s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 6.1370	Cost: 10.52s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 6.0923	Cost: 10.38s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 6.1260	Cost: 6.80s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 6.0303	Cost: 14.18s
Train Epoch: 144 	Average Loss: 6.1241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1803

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 9.994884469604905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 6.3429	Cost: 32.75s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 6.0927	Cost: 10.17s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 6.1513	Cost: 20.17s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 6.1178	Cost: 12.18s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 5.9675	Cost: 12.00s
Train Epoch: 145 	Average Loss: 6.1306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1699

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 9.994813186202739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 6.1690	Cost: 34.08s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 6.1628	Cost: 8.12s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 6.0294	Cost: 16.33s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 6.0552	Cost: 8.84s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 6.1336	Cost: 11.84s
Train Epoch: 146 	Average Loss: 6.1203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1507

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Learning rate: 9.994741409832273e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 6.1643	Cost: 49.78s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 5.9923	Cost: 11.59s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 6.0620	Cost: 13.04s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 6.0510	Cost: 12.04s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 6.0750	Cost: 11.71s
Train Epoch: 147 	Average Loss: 6.1098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1778

Learning rate: 9.994669140500594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 6.1256	Cost: 33.66s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 6.1439	Cost: 9.52s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 5.9378	Cost: 10.03s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 6.0519	Cost: 7.26s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 5.9944	Cost: 14.65s
Train Epoch: 148 	Average Loss: 6.0888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1102

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 9.994596378214833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 6.1751	Cost: 32.47s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 6.0971	Cost: 10.38s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 5.9614	Cost: 19.29s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 6.1187	Cost: 12.74s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 5.9743	Cost: 11.88s
Train Epoch: 149 	Average Loss: 6.0788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1220

Learning rate: 9.994523122982173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 6.0931	Cost: 34.42s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 6.0487	Cost: 12.42s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 6.0233	Cost: 7.96s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 6.0403	Cost: 6.89s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 5.9036	Cost: 12.73s
Train Epoch: 150 	Average Loss: 6.0543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0515

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Learning rate: 9.994449374809844e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 6.0288	Cost: 38.77s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 5.9694	Cost: 10.66s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 6.0819	Cost: 17.71s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 6.0099	Cost: 12.04s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 6.0304	Cost: 11.95s
Train Epoch: 151 	Average Loss: 6.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1707

Learning rate: 9.994375133705122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 6.1241	Cost: 43.35s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 6.1390	Cost: 10.69s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 5.9668	Cost: 6.89s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 5.9571	Cost: 6.14s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 5.9302	Cost: 13.01s
Train Epoch: 152 	Average Loss: 6.0246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0677

Learning rate: 9.994300399675336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 6.2463	Cost: 31.70s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 6.0630	Cost: 8.45s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 5.9639	Cost: 22.19s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 6.0298	Cost: 12.80s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 5.8402	Cost: 15.20s
Train Epoch: 153 	Average Loss: 6.0182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0190

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Learning rate: 9.994225172727863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 6.0942	Cost: 37.38s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 6.0141	Cost: 9.49s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 5.9210	Cost: 10.42s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 5.9484	Cost: 8.85s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 5.8031	Cost: 13.80s
Train Epoch: 154 	Average Loss: 5.9992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0476

Learning rate: 9.994149452870126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 6.0392	Cost: 30.07s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 5.8425	Cost: 10.89s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 5.9551	Cost: 20.88s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 5.9987	Cost: 12.14s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 5.9663	Cost: 11.90s
Train Epoch: 155 	Average Loss: 5.9842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1378

Learning rate: 9.9940732401096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 6.1294	Cost: 36.20s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 5.9545	Cost: 7.88s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 5.9397	Cost: 12.42s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 6.1020	Cost: 9.00s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 5.8659	Cost: 12.49s
Train Epoch: 156 	Average Loss: 6.0034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9978

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 9.993996534453805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 6.1065	Cost: 41.58s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 5.9484	Cost: 11.86s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 5.9291	Cost: 12.55s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 6.0263	Cost: 12.06s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 5.9306	Cost: 11.92s
Train Epoch: 157 	Average Loss: 5.9841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0724

Learning rate: 9.993919335910311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 6.0500	Cost: 32.23s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 5.9103	Cost: 12.20s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 5.8875	Cost: 9.50s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 6.0483	Cost: 6.11s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 5.9073	Cost: 10.85s
Train Epoch: 158 	Average Loss: 5.9729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0423

Learning rate: 9.993841644486739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 6.0186	Cost: 29.76s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 5.9055	Cost: 9.54s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 5.9072	Cost: 25.58s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 5.9495	Cost: 12.86s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 5.9185	Cost: 12.00s
Train Epoch: 159 	Average Loss: 5.9549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1010

Learning rate: 9.993763460190757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 6.1714	Cost: 49.41s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 5.9573	Cost: 6.24s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 5.8571	Cost: 14.44s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 5.8533	Cost: 8.53s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 5.9769	Cost: 8.66s
Train Epoch: 160 	Average Loss: 5.9488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0418

Learning rate: 9.993684783030081e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 6.0968	Cost: 30.25s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 5.9502	Cost: 7.71s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 5.8619	Cost: 24.76s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 5.9498	Cost: 11.97s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 5.7687	Cost: 12.18s
Train Epoch: 161 	Average Loss: 5.9566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0672

Learning rate: 9.993605613012475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 6.1717	Cost: 43.37s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 5.9350	Cost: 10.15s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 5.8706	Cost: 10.84s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 5.8969	Cost: 6.45s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 5.9388	Cost: 12.05s
Train Epoch: 162 	Average Loss: 5.9283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0165

Learning rate: 9.993525950145754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 5.8960	Cost: 29.91s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 5.9581	Cost: 7.38s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 5.8397	Cost: 22.12s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 5.9432	Cost: 12.47s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 5.8286	Cost: 12.02s
Train Epoch: 163 	Average Loss: 5.9291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0622

Learning rate: 9.993445794437781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 6.0316	Cost: 85.00s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 5.9196	Cost: 14.63s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 5.7855	Cost: 18.41s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 5.8699	Cost: 10.88s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 5.8607	Cost: 24.65s
Train Epoch: 164 	Average Loss: 5.9117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0034

Learning rate: 9.993365145896465e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 6.0262	Cost: 39.32s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 5.9498	Cost: 6.49s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 5.7862	Cost: 17.92s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 5.8780	Cost: 12.11s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 5.7621	Cost: 11.83s
Train Epoch: 165 	Average Loss: 5.8893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9735

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Learning rate: 9.993284004529768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 5.9759	Cost: 30.95s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 6.0114	Cost: 8.37s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 5.8043	Cost: 11.40s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 5.8925	Cost: 6.17s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 5.7087	Cost: 15.74s
Train Epoch: 166 	Average Loss: 5.8805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9731

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Learning rate: 9.993202370345697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 5.9566	Cost: 43.42s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 5.8308	Cost: 13.57s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 5.7291	Cost: 13.48s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 5.8501	Cost: 12.21s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 5.8063	Cost: 11.93s
Train Epoch: 167 	Average Loss: 5.8908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0331

Learning rate: 9.993120243352309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 6.1272	Cost: 44.97s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 5.8926	Cost: 7.53s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 5.8409	Cost: 11.36s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 5.7543	Cost: 8.99s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 5.7880	Cost: 8.88s
Train Epoch: 168 	Average Loss: 5.8727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9734

Learning rate: 9.993037623557708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 6.1665	Cost: 29.12s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 5.8840	Cost: 12.85s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 5.8346	Cost: 17.44s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 5.9119	Cost: 12.33s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 5.7426	Cost: 11.89s
Train Epoch: 169 	Average Loss: 5.8519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0018

Learning rate: 9.992954510970051e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 5.8755	Cost: 39.58s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 5.8122	Cost: 12.50s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 5.7036	Cost: 12.08s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 5.7747	Cost: 10.68s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 5.6777	Cost: 6.10s
Train Epoch: 170 	Average Loss: 5.8368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9722

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 9.99287090559754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 5.9311	Cost: 28.17s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 5.8144	Cost: 6.55s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 5.7027	Cost: 13.77s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 5.7321	Cost: 8.62s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 5.8105	Cost: 7.35s
Train Epoch: 171 	Average Loss: 5.8337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9225

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 9.992786807448426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 6.0631	Cost: 34.68s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 5.7979	Cost: 12.87s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 5.7275	Cost: 14.97s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 5.8091	Cost: 12.89s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 5.8350	Cost: 11.36s
Train Epoch: 172 	Average Loss: 5.8277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8900

Saving model as e172_model.pt & e172_waveforms_supplementary.hdf5
Learning rate: 9.992702216531012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 5.7045	Cost: 34.71s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 5.8288	Cost: 9.62s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 5.7161	Cost: 12.83s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 5.7804	Cost: 8.79s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 5.7131	Cost: 11.46s
Train Epoch: 173 	Average Loss: 5.8028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8681

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 9.992617132853643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 5.8003	Cost: 32.98s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 5.7612	Cost: 10.43s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 5.7065	Cost: 16.83s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 5.8472	Cost: 12.11s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 5.6609	Cost: 12.21s
Train Epoch: 174 	Average Loss: 5.7927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8661

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 9.992531556424718e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 5.7915	Cost: 50.58s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 5.7673	Cost: 7.03s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 5.7227	Cost: 14.26s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 5.8069	Cost: 8.65s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 5.7097	Cost: 8.03s
Train Epoch: 175 	Average Loss: 5.7917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8815

Learning rate: 9.992445487252684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 5.9897	Cost: 29.68s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 5.7205	Cost: 8.50s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 5.6306	Cost: 16.70s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 5.6935	Cost: 11.97s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 5.7741	Cost: 12.00s
Train Epoch: 176 	Average Loss: 5.7826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8703

Learning rate: 9.992358925346033e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 5.9466	Cost: 32.47s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 5.8613	Cost: 10.63s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 5.6388	Cost: 8.92s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 5.7968	Cost: 6.11s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 5.7278	Cost: 13.49s
Train Epoch: 177 	Average Loss: 5.7805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9378

Learning rate: 9.992271870713308e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 5.8553	Cost: 29.79s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 5.8444	Cost: 10.69s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 5.6623	Cost: 21.30s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 5.7508	Cost: 13.13s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 5.7751	Cost: 12.20s
Train Epoch: 178 	Average Loss: 5.7725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8700

Learning rate: 9.992184323363105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 5.9023	Cost: 52.73s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 5.7435	Cost: 6.38s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 5.6381	Cost: 14.37s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 5.7674	Cost: 8.48s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 5.8582	Cost: 8.33s
Train Epoch: 179 	Average Loss: 5.7726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8600

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 9.992096283304062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 5.9649	Cost: 29.72s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 5.8071	Cost: 7.87s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 5.6436	Cost: 17.26s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 5.7175	Cost: 13.15s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 5.6308	Cost: 12.21s
Train Epoch: 180 	Average Loss: 5.7428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8927

Learning rate: 9.992007750544869e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 5.8219	Cost: 45.22s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 5.8431	Cost: 11.72s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 5.7527	Cost: 8.03s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 5.7246	Cost: 6.35s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 5.5761	Cost: 12.28s
Train Epoch: 181 	Average Loss: 5.7631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8615

Learning rate: 9.991918725094262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 5.7630	Cost: 30.69s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 5.7977	Cost: 7.35s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 5.5196	Cost: 17.93s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 5.7210	Cost: 14.60s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 5.6273	Cost: 14.80s
Train Epoch: 182 	Average Loss: 5.7111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8088

Saving model as e182_model.pt & e182_waveforms_supplementary.hdf5
Learning rate: 9.99182920696103e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 5.8655	Cost: 34.51s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 5.7261	Cost: 11.51s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 5.6690	Cost: 10.78s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 5.6456	Cost: 7.74s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 5.6259	Cost: 13.55s
Train Epoch: 183 	Average Loss: 5.7106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8917

Learning rate: 9.991739196154006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 5.7668	Cost: 33.69s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 5.6784	Cost: 9.91s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 5.5798	Cost: 19.08s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 5.7847	Cost: 12.16s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 5.6527	Cost: 12.14s
Train Epoch: 184 	Average Loss: 5.7083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8239

Learning rate: 9.991648692682075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 5.6739	Cost: 42.52s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 5.6930	Cost: 6.18s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 5.6482	Cost: 14.64s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 5.6718	Cost: 8.72s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 5.5676	Cost: 10.49s
Train Epoch: 185 	Average Loss: 5.6956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7691

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 9.991557696554169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 5.7407	Cost: 29.94s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 5.6142	Cost: 10.83s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 5.5298	Cost: 16.10s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 5.6920	Cost: 12.28s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 5.6189	Cost: 12.20s
Train Epoch: 186 	Average Loss: 5.6849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8233

Learning rate: 9.99146620777927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 5.8346	Cost: 32.11s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 5.7453	Cost: 8.82s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 5.5255	Cost: 9.97s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 5.6619	Cost: 6.67s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 5.5764	Cost: 13.89s
Train Epoch: 187 	Average Loss: 5.6757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8022

Learning rate: 9.991374226366404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 5.8849	Cost: 28.86s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 5.6809	Cost: 8.95s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 5.5753	Cost: 23.17s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 5.5863	Cost: 11.61s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 5.5563	Cost: 16.25s
Train Epoch: 188 	Average Loss: 5.6722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7969

Learning rate: 9.991281752324654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 5.6228	Cost: 43.98s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 5.6714	Cost: 11.94s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 5.5850	Cost: 7.76s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 5.6763	Cost: 6.26s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 5.6139	Cost: 13.84s
Train Epoch: 189 	Average Loss: 5.6499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8100

Learning rate: 9.991188785663142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 5.8329	Cost: 30.10s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 5.6033	Cost: 7.85s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 5.5181	Cost: 18.79s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 5.5033	Cost: 12.29s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 5.4792	Cost: 12.10s
Train Epoch: 190 	Average Loss: 5.6367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7474

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 9.991095326391049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 5.8078	Cost: 41.90s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 5.6485	Cost: 12.12s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 5.4944	Cost: 7.20s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 5.6123	Cost: 6.13s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 5.5235	Cost: 13.81s
Train Epoch: 191 	Average Loss: 5.6392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7428

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 9.991001374517595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 5.5974	Cost: 28.76s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 5.6981	Cost: 7.06s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 5.5032	Cost: 18.80s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 5.5352	Cost: 14.68s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 5.5549	Cost: 13.42s
Train Epoch: 192 	Average Loss: 5.6269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7804

Learning rate: 9.990906930052053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 5.8077	Cost: 39.08s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 5.6049	Cost: 13.25s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 5.4470	Cost: 11.48s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 5.5262	Cost: 8.16s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 5.4366	Cost: 10.17s
Train Epoch: 193 	Average Loss: 5.6207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7578

Learning rate: 9.990811993003745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 5.6395	Cost: 35.55s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 5.6438	Cost: 8.58s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 5.5139	Cost: 11.56s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 5.4680	Cost: 7.10s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 5.4486	Cost: 18.58s
Train Epoch: 194 	Average Loss: 5.5960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7096

Saving model as e194_model.pt & e194_waveforms_supplementary.hdf5
Learning rate: 9.990716563382042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 5.7009	Cost: 41.49s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 5.6776	Cost: 13.03s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 5.4848	Cost: 12.55s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 5.5037	Cost: 10.35s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 5.5678	Cost: 6.59s
Train Epoch: 195 	Average Loss: 5.6053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7158

Learning rate: 9.990620641196361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 5.6535	Cost: 35.77s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 5.6651	Cost: 8.05s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 5.4855	Cost: 13.71s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 5.6096	Cost: 8.54s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 5.5448	Cost: 6.67s
Train Epoch: 196 	Average Loss: 5.5846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7539

Learning rate: 9.99052422645617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 5.8026	Cost: 28.93s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 5.5687	Cost: 8.72s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 5.3071	Cost: 17.62s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 5.5043	Cost: 11.75s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 5.4893	Cost: 11.96s
Train Epoch: 197 	Average Loss: 5.5798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7368

Learning rate: 9.990427319170984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 5.6619	Cost: 31.83s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 5.6701	Cost: 12.36s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 5.5069	Cost: 8.12s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 5.5575	Cost: 7.20s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 5.4741	Cost: 13.79s
Train Epoch: 198 	Average Loss: 5.5894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6963

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 9.990329919350368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 5.7309	Cost: 82.12s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 5.7059	Cost: 16.71s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 5.3835	Cost: 29.23s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 5.5468	Cost: 17.34s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 5.5105	Cost: 21.17s
Train Epoch: 199 	Average Loss: 5.5562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7436

Learning rate: 9.990232027003935e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 5.7710	Cost: 29.75s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 5.5643	Cost: 10.13s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 5.4148	Cost: 9.76s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 5.5940	Cost: 8.18s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 5.5536	Cost: 18.83s
Train Epoch: 200 	Average Loss: 5.5703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7112

Learning rate: 9.990133642141346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 5.8491	Cost: 37.96s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 5.6316	Cost: 14.33s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 5.4571	Cost: 12.19s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 5.6109	Cost: 11.80s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 5.4574	Cost: 6.27s
Train Epoch: 201 	Average Loss: 5.5684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6787

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 9.990034764772311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 5.5497	Cost: 28.74s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 5.6284	Cost: 8.77s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 5.4272	Cost: 10.21s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 5.5102	Cost: 9.01s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 5.4821	Cost: 11.88s
Train Epoch: 202 	Average Loss: 5.5322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6898

Learning rate: 9.98993539490659e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 5.7672	Cost: 31.07s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 5.4293	Cost: 13.29s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 5.4313	Cost: 14.69s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 5.5374	Cost: 12.69s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 5.4357	Cost: 9.08s
Train Epoch: 203 	Average Loss: 5.5357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7255

Learning rate: 9.989835532553989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 5.7594	Cost: 33.93s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 5.5667	Cost: 11.43s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 5.3484	Cost: 11.04s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 5.5477	Cost: 9.17s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 5.4042	Cost: 15.76s
Train Epoch: 204 	Average Loss: 5.5278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6944

Learning rate: 9.989735177724366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 5.6777	Cost: 32.87s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 5.5558	Cost: 6.49s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 5.3472	Cost: 20.60s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 5.5117	Cost: 12.06s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 5.3686	Cost: 12.06s
Train Epoch: 205 	Average Loss: 5.4998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6756

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 9.989634330427624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 5.6739	Cost: 34.40s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 5.5113	Cost: 10.46s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 5.4040	Cost: 10.55s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 5.4304	Cost: 6.51s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 5.4328	Cost: 13.46s
Train Epoch: 206 	Average Loss: 5.4942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6414

Saving model as e206_model.pt & e206_waveforms_supplementary.hdf5
Learning rate: 9.989532990673716e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 5.5476	Cost: 31.84s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 5.5114	Cost: 10.06s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 5.4040	Cost: 13.52s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 5.4512	Cost: 13.36s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 5.4438	Cost: 11.84s
Train Epoch: 207 	Average Loss: 5.4967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6326

Saving model as e207_model.pt & e207_waveforms_supplementary.hdf5
Learning rate: 9.989431158472645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 5.6747	Cost: 41.95s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 5.6276	Cost: 11.96s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 5.3877	Cost: 12.07s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 5.4764	Cost: 8.46s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 5.3968	Cost: 6.23s
Train Epoch: 208 	Average Loss: 5.4996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6636

Learning rate: 9.98932883383446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 5.6730	Cost: 29.26s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 5.4771	Cost: 9.04s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 5.2840	Cost: 10.75s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 5.4448	Cost: 8.66s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 5.4657	Cost: 9.38s
Train Epoch: 209 	Average Loss: 5.4958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7167

Learning rate: 9.989226016769262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 5.5858	Cost: 29.11s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 5.4730	Cost: 10.71s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 5.3951	Cost: 15.33s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 5.4389	Cost: 13.64s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 5.4740	Cost: 11.94s
Train Epoch: 210 	Average Loss: 5.4664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6901

Learning rate: 9.989122707287198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 5.7712	Cost: 47.83s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 5.5091	Cost: 11.72s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 5.3983	Cost: 7.54s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 5.3965	Cost: 6.16s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 5.3294	Cost: 11.59s
Train Epoch: 211 	Average Loss: 5.4715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5865

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 9.989018905398462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 5.6262	Cost: 28.79s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 5.5669	Cost: 7.20s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 5.2851	Cost: 18.23s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 5.4014	Cost: 13.59s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 5.3333	Cost: 12.41s
Train Epoch: 212 	Average Loss: 5.4593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6198

Learning rate: 9.9889146111133e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 5.6548	Cost: 35.98s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 5.4641	Cost: 12.21s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 5.3709	Cost: 7.95s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 5.3759	Cost: 7.37s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.2353	Cost: 15.39s
Train Epoch: 213 	Average Loss: 5.4534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5325

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Learning rate: 9.988809824442008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 5.5500	Cost: 28.04s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 5.5589	Cost: 10.22s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 5.3879	Cost: 13.84s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 5.4569	Cost: 12.96s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 5.3172	Cost: 12.01s
Train Epoch: 214 	Average Loss: 5.4206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6107

Learning rate: 9.988704545394925e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 5.5373	Cost: 45.58s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 5.5444	Cost: 11.58s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 5.4262	Cost: 11.11s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 5.3841	Cost: 7.15s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.3823	Cost: 9.18s
Train Epoch: 215 	Average Loss: 5.4503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5858

Learning rate: 9.988598773982444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 5.5966	Cost: 44.40s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 5.5241	Cost: 6.00s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.3580	Cost: 13.03s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 5.3567	Cost: 10.59s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 5.2484	Cost: 16.78s
Train Epoch: 216 	Average Loss: 5.4325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5672

Learning rate: 9.988492510215002e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 5.5179	Cost: 39.81s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 5.4558	Cost: 12.56s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.3261	Cost: 12.24s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 5.3828	Cost: 7.22s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.2635	Cost: 6.38s
Train Epoch: 217 	Average Loss: 5.4067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5244

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 9.988385754103088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 5.4801	Cost: 32.26s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 5.4767	Cost: 8.64s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 5.2594	Cost: 14.20s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 5.3051	Cost: 9.13s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 5.3372	Cost: 16.68s
Train Epoch: 218 	Average Loss: 5.4080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5488

Learning rate: 9.988278505657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 5.4955	Cost: 42.01s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 5.4293	Cost: 12.69s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 5.2419	Cost: 12.26s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 5.3935	Cost: 9.67s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.3065	Cost: 6.36s
Train Epoch: 219 	Average Loss: 5.3879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5208

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 9.988170764888036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 5.4205	Cost: 30.53s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 5.5102	Cost: 9.93s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 5.1697	Cost: 9.21s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 5.3574	Cost: 7.97s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 5.3026	Cost: 13.61s
Train Epoch: 220 	Average Loss: 5.4031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5076

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Learning rate: 9.988062531806117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 5.6623	Cost: 44.27s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 5.3757	Cost: 12.79s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 5.2523	Cost: 12.11s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 5.3031	Cost: 10.52s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.2040	Cost: 6.34s
Train Epoch: 221 	Average Loss: 5.3833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5082

Learning rate: 9.987953806422163e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 5.4533	Cost: 28.65s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 5.4194	Cost: 8.85s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 5.2733	Cost: 10.16s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 5.3516	Cost: 9.44s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.3691	Cost: 8.05s
Train Epoch: 222 	Average Loss: 5.3822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5684

Learning rate: 9.987844588746906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 5.5576	Cost: 32.32s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 5.4490	Cost: 12.23s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 5.2266	Cost: 15.52s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 5.3170	Cost: 12.37s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.1809	Cost: 12.02s
Train Epoch: 223 	Average Loss: 5.3637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5451

Learning rate: 9.987734878791122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 5.4399	Cost: 32.57s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 5.3821	Cost: 13.57s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 5.2138	Cost: 12.95s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 5.4018	Cost: 8.11s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 5.3303	Cost: 13.81s
Train Epoch: 224 	Average Loss: 5.3684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5498

Learning rate: 9.987624676565643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 5.5698	Cost: 33.89s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 5.4166	Cost: 10.40s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 5.2350	Cost: 20.31s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 5.3071	Cost: 11.85s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.2778	Cost: 12.23s
Train Epoch: 225 	Average Loss: 5.3611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5045

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 9.987513982081342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 5.5997	Cost: 41.44s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 5.4523	Cost: 6.80s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 5.1697	Cost: 14.73s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 5.2546	Cost: 8.87s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.2542	Cost: 8.91s
Train Epoch: 226 	Average Loss: 5.3276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4592

Saving model as e226_model.pt & e226_waveforms_supplementary.hdf5
Learning rate: 9.987402795349145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 5.4842	Cost: 30.23s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 5.4083	Cost: 10.42s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 5.2101	Cost: 13.28s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 5.2837	Cost: 11.97s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.2267	Cost: 12.00s
Train Epoch: 227 	Average Loss: 5.3471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5692

Learning rate: 9.987291116380029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 5.4608	Cost: 31.09s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 5.4430	Cost: 11.84s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 5.2173	Cost: 7.10s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 5.2434	Cost: 6.13s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.2774	Cost: 14.91s
Train Epoch: 228 	Average Loss: 5.3178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5369

Learning rate: 9.98717894518501e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 5.3621	Cost: 29.42s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 5.3525	Cost: 11.36s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 5.2369	Cost: 12.67s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 5.3385	Cost: 14.48s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 5.1844	Cost: 12.22s
Train Epoch: 229 	Average Loss: 5.3058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4681

Learning rate: 9.987066281775164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 5.4117	Cost: 49.54s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 5.4227	Cost: 12.12s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 5.1390	Cost: 6.68s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 5.3936	Cost: 6.37s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.2161	Cost: 13.42s
Train Epoch: 230 	Average Loss: 5.3225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5257

Learning rate: 9.98695312616161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 5.5415	Cost: 26.86s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 5.3709	Cost: 9.45s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 5.1678	Cost: 15.95s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 5.2859	Cost: 12.70s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.2674	Cost: 11.89s
Train Epoch: 231 	Average Loss: 5.3100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5023

Learning rate: 9.986839478355513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 5.3926	Cost: 48.96s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 5.3109	Cost: 11.05s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 5.2244	Cost: 8.35s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 5.1672	Cost: 6.45s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.1415	Cost: 12.62s
Train Epoch: 232 	Average Loss: 5.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5073

Learning rate: 9.986725338368092e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 5.4815	Cost: 30.71s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 5.3078	Cost: 12.14s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.1468	Cost: 17.22s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 5.3293	Cost: 12.97s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.1288	Cost: 12.47s
Train Epoch: 233 	Average Loss: 5.2843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4461

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 9.986610706210612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 5.4180	Cost: 57.44s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 5.4210	Cost: 6.04s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 5.0675	Cost: 12.29s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 5.3330	Cost: 8.59s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.2629	Cost: 8.59s
Train Epoch: 234 	Average Loss: 5.2933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4092

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 9.986495581894385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 5.3884	Cost: 31.02s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 5.2877	Cost: 11.49s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 5.1162	Cost: 12.58s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 5.2082	Cost: 12.38s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.2264	Cost: 12.07s
Train Epoch: 235 	Average Loss: 5.2778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5007

Learning rate: 9.986379965430775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 5.4058	Cost: 33.21s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 5.3637	Cost: 8.31s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.1735	Cost: 13.99s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 5.2496	Cost: 8.40s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.1624	Cost: 8.81s
Train Epoch: 236 	Average Loss: 5.2817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4393

Learning rate: 9.986263856831194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 5.3808	Cost: 30.17s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 5.3202	Cost: 10.94s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 5.0931	Cost: 17.22s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 5.1414	Cost: 12.73s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.0668	Cost: 12.49s
Train Epoch: 237 	Average Loss: 5.2249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4304

Learning rate: 9.9861472561071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 5.4675	Cost: 31.98s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 5.2459	Cost: 9.33s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.0927	Cost: 12.53s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 5.1165	Cost: 8.76s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.2597	Cost: 12.27s
Train Epoch: 238 	Average Loss: 5.2458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5033

Learning rate: 9.98603016327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 5.5455	Cost: 48.93s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 5.2322	Cost: 9.41s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 5.0555	Cost: 15.87s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 5.1682	Cost: 12.16s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 4.9869	Cost: 12.05s
Train Epoch: 239 	Average Loss: 5.2245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4192

Learning rate: 9.985912578331452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 5.3105	Cost: 37.68s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 5.3606	Cost: 9.98s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 5.0585	Cost: 9.72s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 5.0305	Cost: 6.82s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.2438	Cost: 14.80s
Train Epoch: 240 	Average Loss: 5.2301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4253

Learning rate: 9.985794501303059e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 5.4927	Cost: 40.08s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 5.3217	Cost: 10.46s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.1836	Cost: 17.45s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 5.1360	Cost: 12.34s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.1766	Cost: 11.84s
Train Epoch: 241 	Average Loss: 5.2347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4497

Learning rate: 9.985675932196479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 5.3029	Cost: 36.02s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 5.2924	Cost: 10.14s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.1303	Cost: 8.51s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 5.1625	Cost: 6.31s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.1063	Cost: 14.40s
Train Epoch: 242 	Average Loss: 5.2069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3663

Saving model as e242_model.pt & e242_waveforms_supplementary.hdf5
Learning rate: 9.985556871023408e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 5.2885	Cost: 35.61s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 5.3366	Cost: 9.26s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.0559	Cost: 20.78s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 5.1288	Cost: 12.19s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.1135	Cost: 11.94s
Train Epoch: 243 	Average Loss: 5.1764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4457

Learning rate: 9.985437317795604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 5.3865	Cost: 28.07s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 5.2471	Cost: 6.36s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.0617	Cost: 14.55s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 5.1578	Cost: 8.61s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.0867	Cost: 8.50s
Train Epoch: 244 	Average Loss: 5.2070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4866

Learning rate: 9.985317272524864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 5.5428	Cost: 32.34s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 5.1843	Cost: 13.25s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.0875	Cost: 19.57s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 5.0907	Cost: 12.55s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 5.1547	Cost: 11.96s
Train Epoch: 245 	Average Loss: 5.1766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4431

Learning rate: 9.985196735223035e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 5.2775	Cost: 39.65s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 5.1448	Cost: 11.96s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 5.1334	Cost: 8.18s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 5.1059	Cost: 6.62s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 5.0645	Cost: 13.34s
Train Epoch: 246 	Average Loss: 5.1787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4202

Learning rate: 9.985075705902012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 5.3891	Cost: 29.54s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 5.2185	Cost: 11.20s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 5.0734	Cost: 20.57s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 5.1690	Cost: 12.25s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 5.1356	Cost: 12.26s
Train Epoch: 247 	Average Loss: 5.1855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3907

Learning rate: 9.984954184573743e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 5.5543	Cost: 54.55s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 5.2340	Cost: 6.48s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 4.9884	Cost: 13.30s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 5.0483	Cost: 8.74s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 5.0313	Cost: 8.38s
Train Epoch: 248 	Average Loss: 5.1520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3669

Learning rate: 9.984832171250219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 5.4567	Cost: 28.58s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 5.1990	Cost: 8.31s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 5.0923	Cost: 16.95s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 5.0392	Cost: 12.39s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 5.1351	Cost: 12.22s
Train Epoch: 249 	Average Loss: 5.1666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4119

Learning rate: 9.984709665943483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 5.5062	Cost: 31.84s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 5.2785	Cost: 11.84s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.0224	Cost: 10.52s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 5.0806	Cost: 6.45s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.0405	Cost: 11.36s
Train Epoch: 250 	Average Loss: 5.1863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3951

Learning rate: 9.98458666866563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 5.4699	Cost: 35.32s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 5.1431	Cost: 6.58s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 4.9127	Cost: 16.45s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 5.0162	Cost: 9.56s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.0132	Cost: 14.67s
Train Epoch: 251 	Average Loss: 5.1404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3560

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 9.984463179428794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 5.2940	Cost: 50.27s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 5.2160	Cost: 9.99s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 5.0076	Cost: 8.02s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 4.9020	Cost: 6.57s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.9994	Cost: 14.56s
Train Epoch: 252 	Average Loss: 5.0977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3463

Saving model as e252_model.pt & e252_waveforms_supplementary.hdf5
Learning rate: 9.984339198245162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 5.2813	Cost: 33.30s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 5.1853	Cost: 10.07s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 4.9715	Cost: 15.28s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 5.0369	Cost: 12.18s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.0928	Cost: 12.26s
Train Epoch: 253 	Average Loss: 5.1207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3439

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 9.984214725126977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 5.4017	Cost: 29.86s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 5.2712	Cost: 11.15s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 4.9157	Cost: 10.06s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 5.0183	Cost: 9.60s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.0259	Cost: 12.08s
Train Epoch: 254 	Average Loss: 5.1180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3688

Learning rate: 9.98408976008652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 5.3877	Cost: 33.78s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 5.1627	Cost: 10.48s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 4.9003	Cost: 18.21s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 5.0197	Cost: 12.52s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.9632	Cost: 11.93s
Train Epoch: 255 	Average Loss: 5.1042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3174

Saving model as e255_model.pt & e255_waveforms_supplementary.hdf5
Learning rate: 9.983964303136122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 5.2801	Cost: 49.08s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 5.1610	Cost: 10.98s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.9451	Cost: 6.94s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 5.1006	Cost: 6.56s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 5.1415	Cost: 13.93s
Train Epoch: 256 	Average Loss: 5.1139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3636

Learning rate: 9.98383835428817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 5.3703	Cost: 30.88s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 5.1923	Cost: 7.95s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 4.9762	Cost: 23.86s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 5.0179	Cost: 12.33s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.9755	Cost: 12.13s
Train Epoch: 257 	Average Loss: 5.1047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2866

Saving model as e257_model.pt & e257_waveforms_supplementary.hdf5
Learning rate: 9.983711913555091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 5.3609	Cost: 50.50s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 5.1601	Cost: 6.99s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.9393	Cost: 14.21s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 5.0749	Cost: 8.64s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.9548	Cost: 9.11s
Train Epoch: 258 	Average Loss: 5.0913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3043

Learning rate: 9.983584980949367e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 5.2106	Cost: 34.57s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 5.2117	Cost: 11.69s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.9901	Cost: 13.06s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 5.0425	Cost: 12.31s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 5.1331	Cost: 12.16s
Train Epoch: 259 	Average Loss: 5.1915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3238

Learning rate: 9.983457556483523e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 5.4948	Cost: 49.03s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 5.1176	Cost: 11.03s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.9699	Cost: 7.42s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 5.0887	Cost: 6.96s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.9169	Cost: 13.65s
Train Epoch: 260 	Average Loss: 5.1221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3461

Learning rate: 9.983329640170136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 5.3403	Cost: 27.07s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 5.1327	Cost: 7.45s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.9778	Cost: 17.70s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 4.9812	Cost: 12.24s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 4.9527	Cost: 12.23s
Train Epoch: 261 	Average Loss: 5.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3382

Learning rate: 9.983201232021833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 5.2756	Cost: 36.55s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 5.1511	Cost: 12.35s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 5.0580	Cost: 8.12s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 4.9091	Cost: 9.14s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.9625	Cost: 12.39s
Train Epoch: 262 	Average Loss: 5.0709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2795

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 9.983072332051286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 5.2626	Cost: 34.61s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 5.1025	Cost: 9.14s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 4.9579	Cost: 16.74s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 5.0303	Cost: 12.08s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 4.9753	Cost: 11.89s
Train Epoch: 263 	Average Loss: 5.0547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2709

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 9.982942940271217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 5.4357	Cost: 38.83s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 5.0347	Cost: 12.52s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 4.9793	Cost: 6.68s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 5.0300	Cost: 6.26s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.8773	Cost: 14.04s
Train Epoch: 264 	Average Loss: 5.0428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2871

Learning rate: 9.982813056694397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 5.1654	Cost: 39.71s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 5.0624	Cost: 7.98s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.9134	Cost: 20.79s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 4.9913	Cost: 12.01s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 4.9226	Cost: 12.03s
Train Epoch: 265 	Average Loss: 5.0126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2678

Saving model as e265_model.pt & e265_waveforms_supplementary.hdf5
Learning rate: 9.982682681333644e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 5.3442	Cost: 85.46s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 5.0972	Cost: 11.02s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 4.8856	Cost: 22.56s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 4.9425	Cost: 10.86s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 4.9242	Cost: 24.72s
Train Epoch: 266 	Average Loss: 5.0279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2992

Learning rate: 9.982551814201825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 5.2183	Cost: 34.95s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 5.0394	Cost: 13.13s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 4.9171	Cost: 13.70s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 5.0565	Cost: 12.29s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 4.8855	Cost: 11.91s
Train Epoch: 267 	Average Loss: 5.0234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3491

Learning rate: 9.982420455311858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 5.3689	Cost: 35.58s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 5.0573	Cost: 11.77s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 4.8600	Cost: 7.96s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 5.0450	Cost: 6.28s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 5.0385	Cost: 12.53s
Train Epoch: 268 	Average Loss: 5.0383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2894

Learning rate: 9.982288604676707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 5.2690	Cost: 31.23s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 4.9792	Cost: 10.16s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 4.9075	Cost: 25.67s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 4.9411	Cost: 13.25s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 4.9499	Cost: 11.93s
Train Epoch: 269 	Average Loss: 5.0195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2776

Learning rate: 9.982156262309383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 5.2806	Cost: 43.81s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 5.1056	Cost: 6.05s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 4.8165	Cost: 15.59s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 4.9328	Cost: 8.45s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 4.8346	Cost: 8.41s
Train Epoch: 270 	Average Loss: 5.0041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2966

Learning rate: 9.98202342822295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 5.3199	Cost: 31.63s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 5.1067	Cost: 7.82s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 4.8654	Cost: 17.40s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 4.9397	Cost: 12.84s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 4.9108	Cost: 11.84s
Train Epoch: 271 	Average Loss: 4.9888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2109

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 9.981890102430519e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 5.1831	Cost: 48.63s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 4.8985	Cost: 6.25s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 4.8953	Cost: 14.87s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 4.8702	Cost: 8.58s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.9026	Cost: 8.86s
Train Epoch: 272 	Average Loss: 4.9583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2666

Learning rate: 9.981756284945245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 5.2770	Cost: 28.42s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 4.9404	Cost: 7.08s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 4.8397	Cost: 17.09s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 4.8936	Cost: 12.10s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.8797	Cost: 12.31s
Train Epoch: 273 	Average Loss: 4.9601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3429

Learning rate: 9.98162197578034e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.2243	Cost: 33.48s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 4.9819	Cost: 8.05s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 4.7435	Cost: 13.26s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 4.8418	Cost: 9.44s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 4.8441	Cost: 13.23s
Train Epoch: 274 	Average Loss: 4.9435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2225

Learning rate: 9.981487174949054e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.2061	Cost: 39.96s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 4.9400	Cost: 10.83s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 4.8090	Cost: 12.79s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 4.9341	Cost: 12.14s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 4.7621	Cost: 12.08s
Train Epoch: 275 	Average Loss: 4.9532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1942

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 9.981351882464696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 5.1219	Cost: 31.95s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 4.9760	Cost: 9.42s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 4.9608	Cost: 10.86s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 4.8788	Cost: 8.85s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 4.7807	Cost: 12.42s
Train Epoch: 276 	Average Loss: 4.9444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1764

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 9.981216098340617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 5.1721	Cost: 29.62s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 4.9214	Cost: 7.93s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 4.8276	Cost: 16.44s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 4.8379	Cost: 12.39s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 4.8558	Cost: 12.40s
Train Epoch: 277 	Average Loss: 4.9314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2487

Learning rate: 9.981079822590219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 5.1792	Cost: 33.34s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 5.0169	Cost: 11.68s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 4.7399	Cost: 7.69s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 4.9071	Cost: 6.55s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 4.8656	Cost: 13.05s
Train Epoch: 278 	Average Loss: 4.9385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1955

Learning rate: 9.980943055226952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.0085	Cost: 29.05s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 4.9316	Cost: 12.10s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.8100	Cost: 20.63s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 4.7923	Cost: 12.54s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 4.8131	Cost: 12.19s
Train Epoch: 279 	Average Loss: 4.9268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1508

Saving model as e279_model.pt & e279_waveforms_supplementary.hdf5
Learning rate: 9.980805796264313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 5.1567	Cost: 45.83s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 4.9213	Cost: 6.15s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 4.8671	Cost: 13.52s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 4.8234	Cost: 8.56s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 4.7086	Cost: 7.91s
Train Epoch: 280 	Average Loss: 4.9200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1706

Learning rate: 9.98066804571585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 5.1868	Cost: 28.46s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 4.9364	Cost: 8.43s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 4.8687	Cost: 21.19s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 4.8569	Cost: 12.74s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 4.9131	Cost: 11.94s
Train Epoch: 281 	Average Loss: 4.9053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2254

Learning rate: 9.980529803595159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 5.2459	Cost: 31.72s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 4.9547	Cost: 10.41s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 4.7081	Cost: 9.24s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 4.8709	Cost: 7.46s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 4.8015	Cost: 12.52s
Train Epoch: 282 	Average Loss: 4.9004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2168

Learning rate: 9.980391069915883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 5.1974	Cost: 27.90s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 4.8937	Cost: 8.85s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 4.7574	Cost: 15.89s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 4.7220	Cost: 13.33s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 4.8027	Cost: 12.57s
Train Epoch: 283 	Average Loss: 4.8792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2086

Learning rate: 9.980251844691714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 5.0310	Cost: 37.30s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 5.0803	Cost: 10.14s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 4.7880	Cost: 11.07s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 4.8754	Cost: 8.52s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 4.8308	Cost: 11.22s
Train Epoch: 284 	Average Loss: 4.8941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1858

Learning rate: 9.980112127936395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 5.1390	Cost: 31.43s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 4.9412	Cost: 8.13s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 4.7899	Cost: 17.69s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 4.8773	Cost: 13.15s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 4.8503	Cost: 12.80s
Train Epoch: 285 	Average Loss: 4.9186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2553

Learning rate: 9.979971919663715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 5.1194	Cost: 40.10s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 4.8996	Cost: 10.98s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 4.7912	Cost: 12.10s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 4.8975	Cost: 12.35s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 4.6981	Cost: 7.59s
Train Epoch: 286 	Average Loss: 4.8709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2458

Learning rate: 9.97983121988751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 5.1433	Cost: 36.17s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 4.9986	Cost: 6.40s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 4.6706	Cost: 14.22s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 4.7379	Cost: 8.75s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 4.8660	Cost: 8.81s
Train Epoch: 287 	Average Loss: 4.8698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2276

Learning rate: 9.97969002862167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 5.2674	Cost: 34.91s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 4.8149	Cost: 8.21s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.6775	Cost: 17.99s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 4.7861	Cost: 12.12s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 4.7754	Cost: 12.12s
Train Epoch: 288 	Average Loss: 4.8609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1550

Learning rate: 9.979548345880126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 5.2247	Cost: 31.15s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 4.8709	Cost: 8.71s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 4.6937	Cost: 9.64s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 4.8552	Cost: 8.34s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 4.7789	Cost: 12.17s
Train Epoch: 289 	Average Loss: 4.8614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1854

Learning rate: 9.979406171676863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 5.2666	Cost: 29.09s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 4.9208	Cost: 10.32s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 4.7338	Cost: 22.04s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 4.6702	Cost: 13.47s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 4.8411	Cost: 12.11s
Train Epoch: 290 	Average Loss: 4.8405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1442

Saving model as e290_model.pt & e290_waveforms_supplementary.hdf5
Learning rate: 9.979263506025915e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 5.1478	Cost: 59.36s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 4.9050	Cost: 7.58s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 4.6845	Cost: 11.56s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 4.8526	Cost: 8.64s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 4.8500	Cost: 8.29s
Train Epoch: 291 	Average Loss: 4.8473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1168

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 9.97912034894136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 5.0580	Cost: 30.99s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 4.8644	Cost: 12.16s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.6405	Cost: 17.05s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 4.6910	Cost: 12.14s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 4.7752	Cost: 12.09s
Train Epoch: 292 	Average Loss: 4.8305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1391

Learning rate: 9.978976700437328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 5.1297	Cost: 38.55s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 4.9204	Cost: 8.24s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 4.7248	Cost: 12.66s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 4.8254	Cost: 9.18s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 4.7654	Cost: 12.03s
Train Epoch: 293 	Average Loss: 4.8301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1186

Learning rate: 9.978832560527998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 5.2052	Cost: 28.15s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 4.7872	Cost: 9.82s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 4.6042	Cost: 17.14s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 4.7165	Cost: 12.13s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 4.6888	Cost: 12.19s
Train Epoch: 294 	Average Loss: 4.8073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1330

Learning rate: 9.978687929227592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 5.1823	Cost: 38.74s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 4.8272	Cost: 12.46s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 4.8062	Cost: 12.11s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 4.8077	Cost: 7.07s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 4.6813	Cost: 10.01s
Train Epoch: 295 	Average Loss: 4.7974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1374

Learning rate: 9.978542806550388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 5.1149	Cost: 46.60s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 4.8824	Cost: 6.76s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 4.6558	Cost: 17.71s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 4.7644	Cost: 12.22s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 4.5935	Cost: 11.93s
Train Epoch: 296 	Average Loss: 4.8009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1454

Learning rate: 9.978397192510708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 5.1199	Cost: 33.23s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 4.7293	Cost: 6.40s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 4.6778	Cost: 14.22s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 4.7585	Cost: 8.91s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 4.6130	Cost: 12.20s
Train Epoch: 297 	Average Loss: 4.7674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1690

Learning rate: 9.978251087122923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 4.9052	Cost: 35.14s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 4.8522	Cost: 13.06s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 4.5626	Cost: 16.22s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 4.7179	Cost: 12.11s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 4.7312	Cost: 11.96s
Train Epoch: 298 	Average Loss: 4.7802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1464

Learning rate: 9.978104490401455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.1257	Cost: 46.30s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 4.8468	Cost: 9.28s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 4.5646	Cost: 7.36s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 4.6914	Cost: 7.92s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 4.5841	Cost: 13.53s
Train Epoch: 299 	Average Loss: 4.7546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1247

Learning rate: 9.977957402360771e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.1240	Cost: 33.19s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 4.8262	Cost: 10.79s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 4.5227	Cost: 20.82s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 4.6707	Cost: 11.91s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 4.6553	Cost: 12.12s
Train Epoch: 300 	Average Loss: 4.7371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1248

Learning rate: 9.977809823015388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 5.1634	Cost: 30.49s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 4.7897	Cost: 6.50s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 4.7094	Cost: 14.18s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 4.6477	Cost: 9.59s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 4.5956	Cost: 12.16s
Train Epoch: 301 	Average Loss: 4.7562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1368

Learning rate: 9.97766175237987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 5.1152	Cost: 27.84s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 4.8049	Cost: 8.82s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 4.5882	Cost: 22.18s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 4.6531	Cost: 14.23s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 4.5975	Cost: 11.97s
Train Epoch: 302 	Average Loss: 4.7345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0895

Saving model as e302_model.pt & e302_waveforms_supplementary.hdf5
Learning rate: 9.977513190468834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 5.0678	Cost: 36.97s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 4.7600	Cost: 13.63s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 4.6916	Cost: 9.53s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 4.6618	Cost: 6.27s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 4.5377	Cost: 14.54s
Train Epoch: 303 	Average Loss: 4.7168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1984

Learning rate: 9.977364137296942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 5.0642	Cost: 31.07s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 4.7904	Cost: 10.29s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 4.5932	Cost: 18.93s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 4.7112	Cost: 12.09s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 4.5386	Cost: 12.14s
Train Epoch: 304 	Average Loss: 4.7088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0234

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Learning rate: 9.977214592878902e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 4.9342	Cost: 38.95s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 4.8484	Cost: 7.16s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 4.5078	Cost: 12.46s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 4.6573	Cost: 8.94s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 4.5645	Cost: 8.68s
Train Epoch: 305 	Average Loss: 4.7075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1160

Learning rate: 9.977064557229477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 5.1413	Cost: 29.37s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 4.7657	Cost: 11.79s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 4.5705	Cost: 18.38s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 4.6826	Cost: 12.25s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 4.5195	Cost: 11.86s
Train Epoch: 306 	Average Loss: 4.7174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0561

Learning rate: 9.976914030363472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 4.9581	Cost: 39.41s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 4.6825	Cost: 8.57s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 4.5602	Cost: 10.89s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 4.6605	Cost: 8.09s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 4.6342	Cost: 9.89s
Train Epoch: 307 	Average Loss: 4.7060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0864

Learning rate: 9.976763012295747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 5.0660	Cost: 30.91s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 4.6883	Cost: 7.07s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 4.5085	Cost: 20.82s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 4.6658	Cost: 13.92s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 4.6119	Cost: 12.56s
Train Epoch: 308 	Average Loss: 4.6801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0943

Learning rate: 9.976611503041203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 5.0172	Cost: 43.07s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 4.7053	Cost: 11.30s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 4.5579	Cost: 8.43s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 4.6461	Cost: 6.10s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 4.5705	Cost: 14.82s
Train Epoch: 309 	Average Loss: 4.6947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0337

Learning rate: 9.976459502614796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 4.9192	Cost: 27.66s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 4.6233	Cost: 8.55s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.5063	Cost: 17.16s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 4.5920	Cost: 11.47s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.5449	Cost: 14.82s
Train Epoch: 310 	Average Loss: 4.6744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0359

Learning rate: 9.976307011031527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 5.1122	Cost: 42.95s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 4.7720	Cost: 13.93s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 4.5187	Cost: 12.12s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 4.5302	Cost: 9.31s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.4985	Cost: 5.89s
Train Epoch: 311 	Average Loss: 4.6572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9904

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 9.976154028306446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 4.9891	Cost: 33.46s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 4.7278	Cost: 8.06s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 4.4043	Cost: 10.41s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 4.4897	Cost: 8.93s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 4.5910	Cost: 8.47s
Train Epoch: 312 	Average Loss: 4.6528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0477

Learning rate: 9.976000554454652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 5.1022	Cost: 33.23s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 4.7396	Cost: 8.42s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 4.5276	Cost: 16.79s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 4.5628	Cost: 11.99s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 4.5455	Cost: 12.36s
Train Epoch: 313 	Average Loss: 4.6534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0120

Learning rate: 9.975846589491293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 4.8698	Cost: 35.50s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 4.6375	Cost: 9.89s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 4.4067	Cost: 9.35s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 4.4901	Cost: 7.06s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 4.4477	Cost: 15.38s
Train Epoch: 314 	Average Loss: 4.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9804

Saving model as e314_model.pt & e314_waveforms_supplementary.hdf5
Learning rate: 9.975692133431563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 5.0353	Cost: 28.77s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 4.7296	Cost: 9.86s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 4.5873	Cost: 21.25s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 4.5594	Cost: 12.24s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 4.5406	Cost: 11.89s
Train Epoch: 315 	Average Loss: 4.6588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0074

Learning rate: 9.975537186290708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 5.0484	Cost: 33.95s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 4.6428	Cost: 13.97s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 4.4561	Cost: 22.18s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 4.5062	Cost: 11.41s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 4.5047	Cost: 28.88s
Train Epoch: 316 	Average Loss: 4.6077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9937

Learning rate: 9.975381748084019e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 4.8421	Cost: 34.63s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 4.6868	Cost: 6.96s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 4.4491	Cost: 16.94s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 4.4767	Cost: 12.33s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 4.3991	Cost: 11.84s
Train Epoch: 317 	Average Loss: 4.6137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9896

Learning rate: 9.975225818826839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 4.9359	Cost: 33.33s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 4.6417	Cost: 11.43s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 4.5134	Cost: 12.08s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 4.5513	Cost: 12.03s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 4.4090	Cost: 8.03s
Train Epoch: 318 	Average Loss: 4.5926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0008

Learning rate: 9.975069398534559e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 5.0782	Cost: 29.28s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 4.6413	Cost: 9.97s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 4.4656	Cost: 15.91s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 4.5345	Cost: 7.04s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 4.4974	Cost: 12.38s
Train Epoch: 319 	Average Loss: 4.6089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9878

Learning rate: 9.974912487222611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 5.0632	Cost: 36.35s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 4.6030	Cost: 12.96s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 4.4358	Cost: 13.75s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 4.5474	Cost: 12.03s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 4.4155	Cost: 11.95s
Train Epoch: 320 	Average Loss: 4.5725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0008

Learning rate: 9.974755084906488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 5.0965	Cost: 33.77s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 4.6495	Cost: 6.51s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.4215	Cost: 14.22s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 4.5013	Cost: 8.71s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 4.4757	Cost: 9.66s
Train Epoch: 321 	Average Loss: 4.5813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8952

Saving model as e321_model.pt & e321_waveforms_supplementary.hdf5
Learning rate: 9.974597191601719e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 5.0422	Cost: 32.41s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 4.5392	Cost: 13.10s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.5038	Cost: 18.30s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 4.5452	Cost: 11.90s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 4.5009	Cost: 11.89s
Train Epoch: 322 	Average Loss: 4.5704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9396

Learning rate: 9.974438807323893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 4.9006	Cost: 30.51s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 4.6042	Cost: 6.65s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.4463	Cost: 12.12s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 4.6076	Cost: 9.06s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.5529	Cost: 9.41s
Train Epoch: 323 	Average Loss: 4.5496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9861

Learning rate: 9.97427993208864e-05
