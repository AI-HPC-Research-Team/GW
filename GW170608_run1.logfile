Nestedspace(activation='elu', apply_unconditional_transform=False, base_transform_type='rq-coupling', basis_dir='data/GW170608_sample_prior_basis/', batch_norm=True, batch_size=2048, bw_dstar=None, cuda=True, data_dir='data/GW170608_sample_prior_basis/', detectors=None, distance_prior=None, distance_prior_fn='uniform_distance', dont_sample_extrinsic_only=False, dropout_probability=0.0, epochs=10000, flow_lr=None, hidden_dims=512, kl_annealing=True, lr=0.0001, lr_anneal_method='cosine', lr_annealing=True, mixed_alpha=0.0, mode='train', model_dir='models/GW170608_sample_uniform_100basis_all_posterior_prior/', model_source='new', model_type='nde', nbins=8, nflows=15, nsample=100000, nsamples_target_event=50000, num_transform_blocks=10, output_freq=10, sampling_from='posterior', save=True, save_aux_filename='waveforms_supplementary.hdf5', save_model_name='model.pt', snr_annealing=False, snr_threshold=None, steplr_gamma=0.5, steplr_step_size=80, tail_bound=1.0, truncate_basis=100)
Waveform directory data/GW170608_sample_prior_basis/
Model directory models/GW170608_sample_uniform_100basis_all_posterior_prior/
Device cuda
Loading dataset
Sampling 100000 sets of parameters from posterior prior.
sample_extrinsic_only: False
init training...
init relative whitening...
Truncating reduced basis from 600 to 100 elements.
initialidze reduced basis aux...
Building time translation matrices.
calculate threshold standardizatison...
  Generating 90000 detector waveforms
Setting extrinsic parameters to fiducial values.
  Calculating new standardization factors.
sample_extrinsic_only: False
Detectors: ['H1', 'L1']

Constructing model of type nde

Initial learning rate 0.0001
Using cosine LR annealing.

Model hyperparameters:
input_dim 	 15
num_flow_steps 	 15
context_dim 	 400
base_transform_kwargs
	 hidden_dim 	 512
	 num_transform_blocks 	 10
	 activation 	 elu
	 dropout_probability 	 0.0
	 batch_norm 	 True
	 num_bins 	 8
	 tail_bound 	 1.0
	 apply_unconditional_transform 	 False
	 base_transform_type 	 rq-coupling

Training for 10000 epochs
Starting timer
Learning rate: 0.0001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1 [0/90000 (0%)]	Loss: 28.1263	Cost: 34.24s
Train Epoch: 1 [20480/90000 (23%)]	Loss: 21.6519	Cost: 8.44s
Train Epoch: 1 [40960/90000 (45%)]	Loss: 21.1229	Cost: 13.75s
Train Epoch: 1 [61440/90000 (68%)]	Loss: 20.4153	Cost: 8.71s
Train Epoch: 1 [81920/90000 (91%)]	Loss: 19.9399	Cost: 8.40s
Train Epoch: 1 	Average Loss: 21.4910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 20.0075

Saving model as e1_model.pt & e1_waveforms_supplementary.hdf5
Learning rate: 9.999999753259892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 2 [0/90000 (0%)]	Loss: 19.7500	Cost: 39.44s
Train Epoch: 2 [20480/90000 (23%)]	Loss: 19.5515	Cost: 14.57s
Train Epoch: 2 [40960/90000 (45%)]	Loss: 19.1584	Cost: 12.46s
Train Epoch: 2 [61440/90000 (68%)]	Loss: 18.6711	Cost: 11.99s
Train Epoch: 2 [81920/90000 (91%)]	Loss: 18.0652	Cost: 12.08s
Train Epoch: 2 	Average Loss: 19.0560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 18.0766

Saving model as e2_model.pt & e2_waveforms_supplementary.hdf5
Learning rate: 9.999999013039593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 3 [0/90000 (0%)]	Loss: 17.7904	Cost: 49.73s
Train Epoch: 3 [20480/90000 (23%)]	Loss: 17.2947	Cost: 6.13s
Train Epoch: 3 [40960/90000 (45%)]	Loss: 16.6550	Cost: 13.81s
Train Epoch: 3 [61440/90000 (68%)]	Loss: 16.3136	Cost: 8.54s
Train Epoch: 3 [81920/90000 (91%)]	Loss: 15.8011	Cost: 8.52s
Train Epoch: 3 	Average Loss: 16.7189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 15.8545

Saving model as e3_model.pt & e3_waveforms_supplementary.hdf5
Learning rate: 9.999997779339173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 4 [0/90000 (0%)]	Loss: 15.9242	Cost: 27.87s
Train Epoch: 4 [20480/90000 (23%)]	Loss: 15.4200	Cost: 11.21s
Train Epoch: 4 [40960/90000 (45%)]	Loss: 15.2373	Cost: 19.45s
Train Epoch: 4 [61440/90000 (68%)]	Loss: 15.2595	Cost: 13.36s
Train Epoch: 4 [81920/90000 (91%)]	Loss: 14.7220	Cost: 12.19s
Train Epoch: 4 	Average Loss: 15.2638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.9164

Saving model as e4_model.pt & e4_waveforms_supplementary.hdf5
Learning rate: 9.99999605215876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 5 [0/90000 (0%)]	Loss: 14.7698	Cost: 54.40s
Train Epoch: 5 [20480/90000 (23%)]	Loss: 14.6254	Cost: 6.27s
Train Epoch: 5 [40960/90000 (45%)]	Loss: 14.2107	Cost: 14.83s
Train Epoch: 5 [61440/90000 (68%)]	Loss: 14.4416	Cost: 8.74s
Train Epoch: 5 [81920/90000 (91%)]	Loss: 14.1512	Cost: 8.07s
Train Epoch: 5 	Average Loss: 14.4544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 14.1439

Saving model as e5_model.pt & e5_waveforms_supplementary.hdf5
Learning rate: 9.999993831498517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 6 [0/90000 (0%)]	Loss: 14.2611	Cost: 29.22s
Train Epoch: 6 [20480/90000 (23%)]	Loss: 14.1751	Cost: 11.34s
Train Epoch: 6 [40960/90000 (45%)]	Loss: 13.8206	Cost: 15.55s
Train Epoch: 6 [61440/90000 (68%)]	Loss: 13.8935	Cost: 12.33s
Train Epoch: 6 [81920/90000 (91%)]	Loss: 13.7157	Cost: 12.06s
Train Epoch: 6 	Average Loss: 13.9790
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.7930

Saving model as e6_model.pt & e6_waveforms_supplementary.hdf5
Learning rate: 9.999991117358668e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 7 [0/90000 (0%)]	Loss: 13.8158	Cost: 35.26s
Train Epoch: 7 [20480/90000 (23%)]	Loss: 13.7918	Cost: 7.67s
Train Epoch: 7 [40960/90000 (45%)]	Loss: 13.4578	Cost: 13.38s
Train Epoch: 7 [61440/90000 (68%)]	Loss: 13.6386	Cost: 8.45s
Train Epoch: 7 [81920/90000 (91%)]	Loss: 13.4195	Cost: 8.87s
Train Epoch: 7 	Average Loss: 13.6555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.5561

Saving model as e7_model.pt & e7_waveforms_supplementary.hdf5
Learning rate: 9.99998790973948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 8 [0/90000 (0%)]	Loss: 13.5314	Cost: 28.84s
Train Epoch: 8 [20480/90000 (23%)]	Loss: 13.3642	Cost: 7.20s
Train Epoch: 8 [40960/90000 (45%)]	Loss: 13.2599	Cost: 17.06s
Train Epoch: 8 [61440/90000 (68%)]	Loss: 13.2898	Cost: 14.38s
Train Epoch: 8 [81920/90000 (91%)]	Loss: 13.1315	Cost: 12.51s
Train Epoch: 8 	Average Loss: 13.3408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 13.1568

Saving model as e8_model.pt & e8_waveforms_supplementary.hdf5
Learning rate: 9.99998420864127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 9 [0/90000 (0%)]	Loss: 13.2160	Cost: 31.98s
Train Epoch: 9 [20480/90000 (23%)]	Loss: 13.0682	Cost: 6.39s
Train Epoch: 9 [40960/90000 (45%)]	Loss: 12.8386	Cost: 14.72s
Train Epoch: 9 [61440/90000 (68%)]	Loss: 12.9870	Cost: 9.99s
Train Epoch: 9 [81920/90000 (91%)]	Loss: 12.7902	Cost: 11.65s
Train Epoch: 9 	Average Loss: 13.0051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.8311

Saving model as e9_model.pt & e9_waveforms_supplementary.hdf5
Learning rate: 9.999980014064402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 10 [0/90000 (0%)]	Loss: 12.8917	Cost: 35.88s
Train Epoch: 10 [20480/90000 (23%)]	Loss: 12.8421	Cost: 10.30s
Train Epoch: 10 [40960/90000 (45%)]	Loss: 12.5350	Cost: 15.11s
Train Epoch: 10 [61440/90000 (68%)]	Loss: 12.8359	Cost: 12.26s
Train Epoch: 10 [81920/90000 (91%)]	Loss: 12.6651	Cost: 12.04s
Train Epoch: 10 	Average Loss: 12.7761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.6871

Saving model as e10_model.pt & e10_waveforms_supplementary.hdf5
Learning rate: 9.999975326009292e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 11 [0/90000 (0%)]	Loss: 12.5531	Cost: 40.65s
Train Epoch: 11 [20480/90000 (23%)]	Loss: 12.6462	Cost: 7.94s
Train Epoch: 11 [40960/90000 (45%)]	Loss: 12.3813	Cost: 9.58s
Train Epoch: 11 [61440/90000 (68%)]	Loss: 12.5535	Cost: 7.67s
Train Epoch: 11 [81920/90000 (91%)]	Loss: 12.4982	Cost: 13.38s
Train Epoch: 11 	Average Loss: 12.5833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.4601

Saving model as e11_model.pt & e11_waveforms_supplementary.hdf5
Learning rate: 9.999970144476398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 12 [0/90000 (0%)]	Loss: 12.4046	Cost: 31.99s
Train Epoch: 12 [20480/90000 (23%)]	Loss: 12.4621	Cost: 10.71s
Train Epoch: 12 [40960/90000 (45%)]	Loss: 12.3343	Cost: 14.08s
Train Epoch: 12 [61440/90000 (68%)]	Loss: 12.4055	Cost: 12.57s
Train Epoch: 12 [81920/90000 (91%)]	Loss: 12.0562	Cost: 12.06s
Train Epoch: 12 	Average Loss: 12.4156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.3679

Saving model as e12_model.pt & e12_waveforms_supplementary.hdf5
Learning rate: 9.999964469466236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 13 [0/90000 (0%)]	Loss: 12.4542	Cost: 38.98s
Train Epoch: 13 [20480/90000 (23%)]	Loss: 12.2507	Cost: 11.69s
Train Epoch: 13 [40960/90000 (45%)]	Loss: 12.1969	Cost: 7.71s
Train Epoch: 13 [61440/90000 (68%)]	Loss: 12.1785	Cost: 6.13s
Train Epoch: 13 [81920/90000 (91%)]	Loss: 12.1052	Cost: 12.62s
Train Epoch: 13 	Average Loss: 12.2440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.1837

Saving model as e13_model.pt & e13_waveforms_supplementary.hdf5
Learning rate: 9.999958300979366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 14 [0/90000 (0%)]	Loss: 12.3850	Cost: 32.97s
Train Epoch: 14 [20480/90000 (23%)]	Loss: 12.1855	Cost: 9.00s
Train Epoch: 14 [40960/90000 (45%)]	Loss: 11.9864	Cost: 23.59s
Train Epoch: 14 [61440/90000 (68%)]	Loss: 12.0246	Cost: 12.14s
Train Epoch: 14 [81920/90000 (91%)]	Loss: 12.0203	Cost: 11.82s
Train Epoch: 14 	Average Loss: 12.1295
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 12.0842

Saving model as e14_model.pt & e14_waveforms_supplementary.hdf5
Learning rate: 9.999951639016395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 15 [0/90000 (0%)]	Loss: 11.9553	Cost: 51.35s
Train Epoch: 15 [20480/90000 (23%)]	Loss: 12.0678	Cost: 11.03s
Train Epoch: 15 [40960/90000 (45%)]	Loss: 11.8608	Cost: 6.10s
Train Epoch: 15 [61440/90000 (68%)]	Loss: 12.0553	Cost: 6.47s
Train Epoch: 15 [81920/90000 (91%)]	Loss: 11.8616	Cost: 12.67s
Train Epoch: 15 	Average Loss: 11.9646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.9413

Saving model as e15_model.pt & e15_waveforms_supplementary.hdf5
Learning rate: 9.999944483577981e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 16 [0/90000 (0%)]	Loss: 11.9860	Cost: 27.94s
Train Epoch: 16 [20480/90000 (23%)]	Loss: 11.7465	Cost: 7.17s
Train Epoch: 16 [40960/90000 (45%)]	Loss: 11.7042	Cost: 19.98s
Train Epoch: 16 [61440/90000 (68%)]	Loss: 11.7444	Cost: 12.63s
Train Epoch: 16 [81920/90000 (91%)]	Loss: 11.6494	Cost: 12.25s
Train Epoch: 16 	Average Loss: 11.7931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.7734

Saving model as e16_model.pt & e16_waveforms_supplementary.hdf5
Learning rate: 9.99993683466483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 17 [0/90000 (0%)]	Loss: 11.5938	Cost: 33.05s
Train Epoch: 17 [20480/90000 (23%)]	Loss: 11.7385	Cost: 12.19s
Train Epoch: 17 [40960/90000 (45%)]	Loss: 11.5702	Cost: 8.51s
Train Epoch: 17 [61440/90000 (68%)]	Loss: 11.6372	Cost: 6.55s
Train Epoch: 17 [81920/90000 (91%)]	Loss: 11.5060	Cost: 14.30s
Train Epoch: 17 	Average Loss: 11.6705
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.5396

Saving model as e17_model.pt & e17_waveforms_supplementary.hdf5
Learning rate: 9.999928692277696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 18 [0/90000 (0%)]	Loss: 11.5314	Cost: 32.28s
Train Epoch: 18 [20480/90000 (23%)]	Loss: 11.5775	Cost: 10.37s
Train Epoch: 18 [40960/90000 (45%)]	Loss: 11.4740	Cost: 15.81s
Train Epoch: 18 [61440/90000 (68%)]	Loss: 11.5312	Cost: 12.12s
Train Epoch: 18 [81920/90000 (91%)]	Loss: 11.4111	Cost: 12.07s
Train Epoch: 18 	Average Loss: 11.5341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.4855

Saving model as e18_model.pt & e18_waveforms_supplementary.hdf5
Learning rate: 9.999920056417385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 19 [0/90000 (0%)]	Loss: 11.4134	Cost: 39.64s
Train Epoch: 19 [20480/90000 (23%)]	Loss: 11.4049	Cost: 6.24s
Train Epoch: 19 [40960/90000 (45%)]	Loss: 11.3203	Cost: 12.64s
Train Epoch: 19 [61440/90000 (68%)]	Loss: 11.2652	Cost: 8.84s
Train Epoch: 19 [81920/90000 (91%)]	Loss: 11.1478	Cost: 11.23s
Train Epoch: 19 	Average Loss: 11.4000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.3759

Saving model as e19_model.pt & e19_waveforms_supplementary.hdf5
Learning rate: 9.999910927084749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 20 [0/90000 (0%)]	Loss: 11.3284	Cost: 31.33s
Train Epoch: 20 [20480/90000 (23%)]	Loss: 11.2879	Cost: 7.94s
Train Epoch: 20 [40960/90000 (45%)]	Loss: 11.1148	Cost: 15.97s
Train Epoch: 20 [61440/90000 (68%)]	Loss: 11.1649	Cost: 12.09s
Train Epoch: 20 [81920/90000 (91%)]	Loss: 11.0898	Cost: 11.82s
Train Epoch: 20 	Average Loss: 11.2299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.2385

Saving model as e20_model.pt & e20_waveforms_supplementary.hdf5
Learning rate: 9.999901304280687e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 21 [0/90000 (0%)]	Loss: 11.1095	Cost: 32.13s
Train Epoch: 21 [20480/90000 (23%)]	Loss: 11.1308	Cost: 11.33s
Train Epoch: 21 [40960/90000 (45%)]	Loss: 10.9782	Cost: 10.26s
Train Epoch: 21 [61440/90000 (68%)]	Loss: 11.0776	Cost: 6.06s
Train Epoch: 21 [81920/90000 (91%)]	Loss: 11.0590	Cost: 6.97s
Train Epoch: 21 	Average Loss: 11.1001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 11.0477

Saving model as e21_model.pt & e21_waveforms_supplementary.hdf5
Learning rate: 9.99989118800615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 22 [0/90000 (0%)]	Loss: 11.0852	Cost: 27.32s
Train Epoch: 22 [20480/90000 (23%)]	Loss: 11.0377	Cost: 8.99s
Train Epoch: 22 [40960/90000 (45%)]	Loss: 10.9486	Cost: 22.53s
Train Epoch: 22 [61440/90000 (68%)]	Loss: 11.0682	Cost: 13.79s
Train Epoch: 22 [81920/90000 (91%)]	Loss: 10.9786	Cost: 12.92s
Train Epoch: 22 	Average Loss: 10.9950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.9016

Saving model as e22_model.pt & e22_waveforms_supplementary.hdf5
Learning rate: 9.999880578262136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 23 [0/90000 (0%)]	Loss: 10.9337	Cost: 53.54s
Train Epoch: 23 [20480/90000 (23%)]	Loss: 10.8241	Cost: 6.13s
Train Epoch: 23 [40960/90000 (45%)]	Loss: 10.7199	Cost: 15.29s
Train Epoch: 23 [61440/90000 (68%)]	Loss: 10.8556	Cost: 8.52s
Train Epoch: 23 [81920/90000 (91%)]	Loss: 10.7735	Cost: 8.45s
Train Epoch: 23 	Average Loss: 10.8662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.8406

Saving model as e23_model.pt & e23_waveforms_supplementary.hdf5
Learning rate: 9.999869475049693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 24 [0/90000 (0%)]	Loss: 10.7128	Cost: 29.15s
Train Epoch: 24 [20480/90000 (23%)]	Loss: 10.6506	Cost: 9.68s
Train Epoch: 24 [40960/90000 (45%)]	Loss: 10.7327	Cost: 18.16s
Train Epoch: 24 [61440/90000 (68%)]	Loss: 10.6197	Cost: 12.58s
Train Epoch: 24 [81920/90000 (91%)]	Loss: 10.6650	Cost: 11.84s
Train Epoch: 24 	Average Loss: 10.7164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6632

Saving model as e24_model.pt & e24_waveforms_supplementary.hdf5
Learning rate: 9.999857878369916e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 25 [0/90000 (0%)]	Loss: 10.6051	Cost: 35.63s
Train Epoch: 25 [20480/90000 (23%)]	Loss: 10.5341	Cost: 7.44s
Train Epoch: 25 [40960/90000 (45%)]	Loss: 10.4949	Cost: 13.42s
Train Epoch: 25 [61440/90000 (68%)]	Loss: 10.4662	Cost: 8.44s
Train Epoch: 25 [81920/90000 (91%)]	Loss: 10.6233	Cost: 8.04s
Train Epoch: 25 	Average Loss: 10.6267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.6949

Learning rate: 9.99984578822395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 26 [0/90000 (0%)]	Loss: 10.5988	Cost: 29.03s
Train Epoch: 26 [20480/90000 (23%)]	Loss: 10.6161	Cost: 9.50s
Train Epoch: 26 [40960/90000 (45%)]	Loss: 10.3140	Cost: 13.78s
Train Epoch: 26 [61440/90000 (68%)]	Loss: 10.3850	Cost: 12.49s
Train Epoch: 26 [81920/90000 (91%)]	Loss: 10.5837	Cost: 12.80s
Train Epoch: 26 	Average Loss: 10.5002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.5145

Saving model as e26_model.pt & e26_waveforms_supplementary.hdf5
Learning rate: 9.999833204612988e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 27 [0/90000 (0%)]	Loss: 10.4457	Cost: 32.55s
Train Epoch: 27 [20480/90000 (23%)]	Loss: 10.3536	Cost: 11.71s
Train Epoch: 27 [40960/90000 (45%)]	Loss: 10.2856	Cost: 8.91s
Train Epoch: 27 [61440/90000 (68%)]	Loss: 10.3021	Cost: 9.38s
Train Epoch: 27 [81920/90000 (91%)]	Loss: 10.3257	Cost: 10.89s
Train Epoch: 27 	Average Loss: 10.3609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.3605

Saving model as e27_model.pt & e27_waveforms_supplementary.hdf5
Learning rate: 9.999820127538271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 28 [0/90000 (0%)]	Loss: 10.4496	Cost: 33.49s
Train Epoch: 28 [20480/90000 (23%)]	Loss: 10.3124	Cost: 9.04s
Train Epoch: 28 [40960/90000 (45%)]	Loss: 10.2610	Cost: 15.45s
Train Epoch: 28 [61440/90000 (68%)]	Loss: 10.1480	Cost: 12.61s
Train Epoch: 28 [81920/90000 (91%)]	Loss: 10.2394	Cost: 12.08s
Train Epoch: 28 	Average Loss: 10.2513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.2601

Saving model as e28_model.pt & e28_waveforms_supplementary.hdf5
Learning rate: 9.999806557001093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 29 [0/90000 (0%)]	Loss: 10.2560	Cost: 35.77s
Train Epoch: 29 [20480/90000 (23%)]	Loss: 10.1860	Cost: 11.95s
Train Epoch: 29 [40960/90000 (45%)]	Loss: 10.0506	Cost: 11.00s
Train Epoch: 29 [61440/90000 (68%)]	Loss: 10.0231	Cost: 6.47s
Train Epoch: 29 [81920/90000 (91%)]	Loss: 10.2045	Cost: 7.95s
Train Epoch: 29 	Average Loss: 10.1596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.1727

Saving model as e29_model.pt & e29_waveforms_supplementary.hdf5
Learning rate: 9.99979249300279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 30 [0/90000 (0%)]	Loss: 10.1156	Cost: 32.24s
Train Epoch: 30 [20480/90000 (23%)]	Loss: 10.0529	Cost: 9.24s
Train Epoch: 30 [40960/90000 (45%)]	Loss: 9.9726	Cost: 18.69s
Train Epoch: 30 [61440/90000 (68%)]	Loss: 9.9715	Cost: 12.70s
Train Epoch: 30 [81920/90000 (91%)]	Loss: 10.0371	Cost: 12.11s
Train Epoch: 30 	Average Loss: 10.0516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 10.0786

Saving model as e30_model.pt & e30_waveforms_supplementary.hdf5
Learning rate: 9.99977793554475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 31 [0/90000 (0%)]	Loss: 9.9411	Cost: 35.81s
Train Epoch: 31 [20480/90000 (23%)]	Loss: 10.0297	Cost: 11.06s
Train Epoch: 31 [40960/90000 (45%)]	Loss: 9.8693	Cost: 9.14s
Train Epoch: 31 [61440/90000 (68%)]	Loss: 9.9080	Cost: 6.34s
Train Epoch: 31 [81920/90000 (91%)]	Loss: 10.0068	Cost: 14.15s
Train Epoch: 31 	Average Loss: 9.9553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9121

Saving model as e31_model.pt & e31_waveforms_supplementary.hdf5
Learning rate: 9.999762884628413e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 32 [0/90000 (0%)]	Loss: 9.8805	Cost: 33.54s
Train Epoch: 32 [20480/90000 (23%)]	Loss: 9.8105	Cost: 8.80s
Train Epoch: 32 [40960/90000 (45%)]	Loss: 9.7842	Cost: 22.77s
Train Epoch: 32 [61440/90000 (68%)]	Loss: 9.8144	Cost: 12.20s
Train Epoch: 32 [81920/90000 (91%)]	Loss: 9.7943	Cost: 11.76s
Train Epoch: 32 	Average Loss: 9.8753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.9292

Learning rate: 9.999747340255259e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 33 [0/90000 (0%)]	Loss: 9.8655	Cost: 45.53s
Train Epoch: 33 [20480/90000 (23%)]	Loss: 9.7781	Cost: 11.70s
Train Epoch: 33 [40960/90000 (45%)]	Loss: 9.7495	Cost: 7.13s
Train Epoch: 33 [61440/90000 (68%)]	Loss: 9.6740	Cost: 6.29s
Train Epoch: 33 [81920/90000 (91%)]	Loss: 9.8150	Cost: 10.87s
Train Epoch: 33 	Average Loss: 9.7773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.7935

Saving model as e33_model.pt & e33_waveforms_supplementary.hdf5
Learning rate: 9.999731302426829e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 34 [0/90000 (0%)]	Loss: 9.7649	Cost: 29.62s
Train Epoch: 34 [20480/90000 (23%)]	Loss: 9.6485	Cost: 6.61s
Train Epoch: 34 [40960/90000 (45%)]	Loss: 9.6352	Cost: 18.81s
Train Epoch: 34 [61440/90000 (68%)]	Loss: 9.6736	Cost: 14.41s
Train Epoch: 34 [81920/90000 (91%)]	Loss: 9.6543	Cost: 12.31s
Train Epoch: 34 	Average Loss: 9.6964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6368

Saving model as e34_model.pt & e34_waveforms_supplementary.hdf5
Learning rate: 9.999714771144701e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 35 [0/90000 (0%)]	Loss: 9.6388	Cost: 33.23s
Train Epoch: 35 [20480/90000 (23%)]	Loss: 9.6500	Cost: 8.24s
Train Epoch: 35 [40960/90000 (45%)]	Loss: 9.5225	Cost: 15.42s
Train Epoch: 35 [61440/90000 (68%)]	Loss: 9.5164	Cost: 8.91s
Train Epoch: 35 [81920/90000 (91%)]	Loss: 9.4917	Cost: 10.46s
Train Epoch: 35 	Average Loss: 9.5806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.6007

Saving model as e35_model.pt & e35_waveforms_supplementary.hdf5
Learning rate: 9.999697746410508e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 36 [0/90000 (0%)]	Loss: 9.5368	Cost: 34.06s
Train Epoch: 36 [20480/90000 (23%)]	Loss: 9.5361	Cost: 13.46s
Train Epoch: 36 [40960/90000 (45%)]	Loss: 9.3674	Cost: 15.29s
Train Epoch: 36 [61440/90000 (68%)]	Loss: 9.4373	Cost: 12.09s
Train Epoch: 36 [81920/90000 (91%)]	Loss: 9.5428	Cost: 12.03s
Train Epoch: 36 	Average Loss: 9.5151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.5309

Saving model as e36_model.pt & e36_waveforms_supplementary.hdf5
Learning rate: 9.99968022822593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 37 [0/90000 (0%)]	Loss: 9.4990	Cost: 34.01s
Train Epoch: 37 [20480/90000 (23%)]	Loss: 9.4525	Cost: 6.34s
Train Epoch: 37 [40960/90000 (45%)]	Loss: 9.3540	Cost: 12.99s
Train Epoch: 37 [61440/90000 (68%)]	Loss: 9.4447	Cost: 8.98s
Train Epoch: 37 [81920/90000 (91%)]	Loss: 9.3320	Cost: 9.62s
Train Epoch: 37 	Average Loss: 9.4316
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.4151

Saving model as e37_model.pt & e37_waveforms_supplementary.hdf5
Learning rate: 9.999662216592697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 38 [0/90000 (0%)]	Loss: 9.4585	Cost: 30.26s
Train Epoch: 38 [20480/90000 (23%)]	Loss: 9.3188	Cost: 10.50s
Train Epoch: 38 [40960/90000 (45%)]	Loss: 9.3041	Cost: 20.39s
Train Epoch: 38 [61440/90000 (68%)]	Loss: 9.2323	Cost: 12.06s
Train Epoch: 38 [81920/90000 (91%)]	Loss: 9.2945	Cost: 11.87s
Train Epoch: 38 	Average Loss: 9.3594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.3670

Saving model as e38_model.pt & e38_waveforms_supplementary.hdf5
Learning rate: 9.999643711512586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 39 [0/90000 (0%)]	Loss: 9.2685	Cost: 28.23s
Train Epoch: 39 [20480/90000 (23%)]	Loss: 9.3391	Cost: 6.36s
Train Epoch: 39 [40960/90000 (45%)]	Loss: 9.1541	Cost: 13.74s
Train Epoch: 39 [61440/90000 (68%)]	Loss: 9.2399	Cost: 8.50s
Train Epoch: 39 [81920/90000 (91%)]	Loss: 9.1293	Cost: 9.30s
Train Epoch: 39 	Average Loss: 9.2801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2818

Saving model as e39_model.pt & e39_waveforms_supplementary.hdf5
Learning rate: 9.999624712987422e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 40 [0/90000 (0%)]	Loss: 9.2611	Cost: 29.11s
Train Epoch: 40 [20480/90000 (23%)]	Loss: 9.1805	Cost: 11.87s
Train Epoch: 40 [40960/90000 (45%)]	Loss: 9.1068	Cost: 15.43s
Train Epoch: 40 [61440/90000 (68%)]	Loss: 9.1508	Cost: 12.90s
Train Epoch: 40 [81920/90000 (91%)]	Loss: 9.2509	Cost: 12.18s
Train Epoch: 40 	Average Loss: 9.2119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.2067

Saving model as e40_model.pt & e40_waveforms_supplementary.hdf5
Learning rate: 9.999605221019082e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 41 [0/90000 (0%)]	Loss: 9.1250	Cost: 30.68s
Train Epoch: 41 [20480/90000 (23%)]	Loss: 9.1444	Cost: 11.90s
Train Epoch: 41 [40960/90000 (45%)]	Loss: 9.1379	Cost: 8.94s
Train Epoch: 41 [61440/90000 (68%)]	Loss: 9.1481	Cost: 7.86s
Train Epoch: 41 [81920/90000 (91%)]	Loss: 9.0316	Cost: 13.20s
Train Epoch: 41 	Average Loss: 9.1259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0624

Saving model as e41_model.pt & e41_waveforms_supplementary.hdf5
Learning rate: 9.999585235609488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 42 [0/90000 (0%)]	Loss: 9.0512	Cost: 31.98s
Train Epoch: 42 [20480/90000 (23%)]	Loss: 8.9697	Cost: 10.14s
Train Epoch: 42 [40960/90000 (45%)]	Loss: 8.8990	Cost: 14.83s
Train Epoch: 42 [61440/90000 (68%)]	Loss: 8.9445	Cost: 12.19s
Train Epoch: 42 [81920/90000 (91%)]	Loss: 8.9296	Cost: 12.06s
Train Epoch: 42 	Average Loss: 9.0398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0600

Saving model as e42_model.pt & e42_waveforms_supplementary.hdf5
Learning rate: 9.999564756760615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 43 [0/90000 (0%)]	Loss: 9.0772	Cost: 38.15s
Train Epoch: 43 [20480/90000 (23%)]	Loss: 9.0708	Cost: 11.89s
Train Epoch: 43 [40960/90000 (45%)]	Loss: 9.0144	Cost: 7.26s
Train Epoch: 43 [61440/90000 (68%)]	Loss: 9.1140	Cost: 6.48s
Train Epoch: 43 [81920/90000 (91%)]	Loss: 9.0767	Cost: 10.66s
Train Epoch: 43 	Average Loss: 9.0097
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 9.0248

Saving model as e43_model.pt & e43_waveforms_supplementary.hdf5
Learning rate: 9.999543784474483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 44 [0/90000 (0%)]	Loss: 9.0587	Cost: 32.94s
Train Epoch: 44 [20480/90000 (23%)]	Loss: 8.9845	Cost: 7.54s
Train Epoch: 44 [40960/90000 (45%)]	Loss: 8.9018	Cost: 18.36s
Train Epoch: 44 [61440/90000 (68%)]	Loss: 8.8417	Cost: 12.20s
Train Epoch: 44 [81920/90000 (91%)]	Loss: 8.9264	Cost: 12.36s
Train Epoch: 44 	Average Loss: 8.9277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.9647

Saving model as e44_model.pt & e44_waveforms_supplementary.hdf5
Learning rate: 9.99952231875316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 45 [0/90000 (0%)]	Loss: 8.9238	Cost: 32.17s
Train Epoch: 45 [20480/90000 (23%)]	Loss: 8.8188	Cost: 6.33s
Train Epoch: 45 [40960/90000 (45%)]	Loss: 8.7264	Cost: 16.89s
Train Epoch: 45 [61440/90000 (68%)]	Loss: 8.8079	Cost: 9.36s
Train Epoch: 45 [81920/90000 (91%)]	Loss: 8.8908	Cost: 9.20s
Train Epoch: 45 	Average Loss: 8.8472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.8659

Saving model as e45_model.pt & e45_waveforms_supplementary.hdf5
Learning rate: 9.999500359598768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 46 [0/90000 (0%)]	Loss: 8.7930	Cost: 28.11s
Train Epoch: 46 [20480/90000 (23%)]	Loss: 8.7545	Cost: 14.96s
Train Epoch: 46 [40960/90000 (45%)]	Loss: 8.6430	Cost: 17.92s
Train Epoch: 46 [61440/90000 (68%)]	Loss: 8.8863	Cost: 12.68s
Train Epoch: 46 [81920/90000 (91%)]	Loss: 8.7686	Cost: 12.03s
Train Epoch: 46 	Average Loss: 8.7842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7940

Saving model as e46_model.pt & e46_waveforms_supplementary.hdf5
Learning rate: 9.999477907013472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 47 [0/90000 (0%)]	Loss: 8.8112	Cost: 36.79s
Train Epoch: 47 [20480/90000 (23%)]	Loss: 8.7301	Cost: 10.85s
Train Epoch: 47 [40960/90000 (45%)]	Loss: 8.6993	Cost: 11.41s
Train Epoch: 47 [61440/90000 (68%)]	Loss: 8.5955	Cost: 8.61s
Train Epoch: 47 [81920/90000 (91%)]	Loss: 8.6555	Cost: 12.22s
Train Epoch: 47 	Average Loss: 8.7197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.7690

Saving model as e47_model.pt & e47_waveforms_supplementary.hdf5
Learning rate: 9.999454960999486e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 48 [0/90000 (0%)]	Loss: 8.5417	Cost: 30.62s
Train Epoch: 48 [20480/90000 (23%)]	Loss: 8.5485	Cost: 7.40s
Train Epoch: 48 [40960/90000 (45%)]	Loss: 8.6174	Cost: 16.34s
Train Epoch: 48 [61440/90000 (68%)]	Loss: 8.5800	Cost: 12.34s
Train Epoch: 48 [81920/90000 (91%)]	Loss: 8.6964	Cost: 12.24s
Train Epoch: 48 	Average Loss: 8.6681
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.6621

Saving model as e48_model.pt & e48_waveforms_supplementary.hdf5
Learning rate: 9.99943152155908e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 49 [0/90000 (0%)]	Loss: 8.6640	Cost: 40.40s
Train Epoch: 49 [20480/90000 (23%)]	Loss: 8.6341	Cost: 6.32s
Train Epoch: 49 [40960/90000 (45%)]	Loss: 8.4551	Cost: 15.06s
Train Epoch: 49 [61440/90000 (68%)]	Loss: 8.4419	Cost: 8.64s
Train Epoch: 49 [81920/90000 (91%)]	Loss: 8.6100	Cost: 9.43s
Train Epoch: 49 	Average Loss: 8.6012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5952

Saving model as e49_model.pt & e49_waveforms_supplementary.hdf5
Learning rate: 9.999407588694566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 50 [0/90000 (0%)]	Loss: 8.7155	Cost: 28.82s
Train Epoch: 50 [20480/90000 (23%)]	Loss: 8.6980	Cost: 8.50s
Train Epoch: 50 [40960/90000 (45%)]	Loss: 8.3961	Cost: 16.31s
Train Epoch: 50 [61440/90000 (68%)]	Loss: 8.4845	Cost: 12.31s
Train Epoch: 50 [81920/90000 (91%)]	Loss: 8.5771	Cost: 12.37s
Train Epoch: 50 	Average Loss: 8.5664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5563

Saving model as e50_model.pt & e50_waveforms_supplementary.hdf5
Learning rate: 9.999383162408302e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 51 [0/90000 (0%)]	Loss: 8.5846	Cost: 36.43s
Train Epoch: 51 [20480/90000 (23%)]	Loss: 8.4760	Cost: 6.22s
Train Epoch: 51 [40960/90000 (45%)]	Loss: 8.3612	Cost: 15.25s
Train Epoch: 51 [61440/90000 (68%)]	Loss: 8.4231	Cost: 9.38s
Train Epoch: 51 [81920/90000 (91%)]	Loss: 8.4451	Cost: 11.94s
Train Epoch: 51 	Average Loss: 8.4989
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.5479

Saving model as e51_model.pt & e51_waveforms_supplementary.hdf5
Learning rate: 9.999358242702702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 52 [0/90000 (0%)]	Loss: 8.4831	Cost: 36.54s
Train Epoch: 52 [20480/90000 (23%)]	Loss: 8.3436	Cost: 15.00s
Train Epoch: 52 [40960/90000 (45%)]	Loss: 8.3642	Cost: 14.55s
Train Epoch: 52 [61440/90000 (68%)]	Loss: 8.3010	Cost: 12.17s
Train Epoch: 52 [81920/90000 (91%)]	Loss: 8.4101	Cost: 11.84s
Train Epoch: 52 	Average Loss: 8.4279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.3962

Saving model as e52_model.pt & e52_waveforms_supplementary.hdf5
Learning rate: 9.999332829580225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 53 [0/90000 (0%)]	Loss: 8.4617	Cost: 37.51s
Train Epoch: 53 [20480/90000 (23%)]	Loss: 8.1934	Cost: 6.33s
Train Epoch: 53 [40960/90000 (45%)]	Loss: 8.3217	Cost: 13.05s
Train Epoch: 53 [61440/90000 (68%)]	Loss: 8.4849	Cost: 8.59s
Train Epoch: 53 [81920/90000 (91%)]	Loss: 8.3410	Cost: 8.67s
Train Epoch: 53 	Average Loss: 8.3807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.4206

Learning rate: 9.99930692304338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 54 [0/90000 (0%)]	Loss: 8.4783	Cost: 27.78s
Train Epoch: 54 [20480/90000 (23%)]	Loss: 8.2844	Cost: 8.83s
Train Epoch: 54 [40960/90000 (45%)]	Loss: 8.2616	Cost: 20.93s
Train Epoch: 54 [61440/90000 (68%)]	Loss: 8.2720	Cost: 12.33s
Train Epoch: 54 [81920/90000 (91%)]	Loss: 8.1588	Cost: 11.90s
Train Epoch: 54 	Average Loss: 8.2930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2391

Saving model as e54_model.pt & e54_waveforms_supplementary.hdf5
Learning rate: 9.999280523094723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 55 [0/90000 (0%)]	Loss: 8.4213	Cost: 45.52s
Train Epoch: 55 [20480/90000 (23%)]	Loss: 8.2674	Cost: 6.71s
Train Epoch: 55 [40960/90000 (45%)]	Loss: 8.1774	Cost: 12.39s
Train Epoch: 55 [61440/90000 (68%)]	Loss: 8.2295	Cost: 8.75s
Train Epoch: 55 [81920/90000 (91%)]	Loss: 8.1360	Cost: 8.68s
Train Epoch: 55 	Average Loss: 8.2539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2584

Learning rate: 9.999253629736859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 56 [0/90000 (0%)]	Loss: 8.3026	Cost: 34.34s
Train Epoch: 56 [20480/90000 (23%)]	Loss: 8.2164	Cost: 11.11s
Train Epoch: 56 [40960/90000 (45%)]	Loss: 8.1864	Cost: 20.96s
Train Epoch: 56 [61440/90000 (68%)]	Loss: 8.2188	Cost: 12.31s
Train Epoch: 56 [81920/90000 (91%)]	Loss: 8.1822	Cost: 11.96s
Train Epoch: 56 	Average Loss: 8.2163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.2248

Saving model as e56_model.pt & e56_waveforms_supplementary.hdf5
Learning rate: 9.999226242972442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 57 [0/90000 (0%)]	Loss: 8.1156	Cost: 36.95s
Train Epoch: 57 [20480/90000 (23%)]	Loss: 8.0652	Cost: 11.28s
Train Epoch: 57 [40960/90000 (45%)]	Loss: 8.0789	Cost: 10.36s
Train Epoch: 57 [61440/90000 (68%)]	Loss: 8.1414	Cost: 8.45s
Train Epoch: 57 [81920/90000 (91%)]	Loss: 8.1492	Cost: 11.76s
Train Epoch: 57 	Average Loss: 8.1620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1073

Saving model as e57_model.pt & e57_waveforms_supplementary.hdf5
Learning rate: 9.999198362804177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 58 [0/90000 (0%)]	Loss: 8.2776	Cost: 31.55s
Train Epoch: 58 [20480/90000 (23%)]	Loss: 8.0843	Cost: 7.36s
Train Epoch: 58 [40960/90000 (45%)]	Loss: 8.0105	Cost: 17.63s
Train Epoch: 58 [61440/90000 (68%)]	Loss: 7.9574	Cost: 12.19s
Train Epoch: 58 [81920/90000 (91%)]	Loss: 8.0296	Cost: 12.19s
Train Epoch: 58 	Average Loss: 8.0924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.1292

Learning rate: 9.999169989234814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 59 [0/90000 (0%)]	Loss: 8.0541	Cost: 32.60s
Train Epoch: 59 [20480/90000 (23%)]	Loss: 7.9452	Cost: 12.28s
Train Epoch: 59 [40960/90000 (45%)]	Loss: 8.0104	Cost: 10.81s
Train Epoch: 59 [61440/90000 (68%)]	Loss: 8.0473	Cost: 6.19s
Train Epoch: 59 [81920/90000 (91%)]	Loss: 7.9750	Cost: 9.52s
Train Epoch: 59 	Average Loss: 8.0554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 8.0403

Saving model as e59_model.pt & e59_waveforms_supplementary.hdf5
Learning rate: 9.999141122267153e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 60 [0/90000 (0%)]	Loss: 7.8952	Cost: 30.07s
Train Epoch: 60 [20480/90000 (23%)]	Loss: 7.8544	Cost: 8.06s
Train Epoch: 60 [40960/90000 (45%)]	Loss: 8.0156	Cost: 16.90s
Train Epoch: 60 [61440/90000 (68%)]	Loss: 7.9549	Cost: 13.10s
Train Epoch: 60 [81920/90000 (91%)]	Loss: 7.8923	Cost: 11.99s
Train Epoch: 60 	Average Loss: 8.0177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9781

Saving model as e60_model.pt & e60_waveforms_supplementary.hdf5
Learning rate: 9.999111761904044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 61 [0/90000 (0%)]	Loss: 7.9424	Cost: 34.25s
Train Epoch: 61 [20480/90000 (23%)]	Loss: 7.8552	Cost: 12.59s
Train Epoch: 61 [40960/90000 (45%)]	Loss: 7.9556	Cost: 7.96s
Train Epoch: 61 [61440/90000 (68%)]	Loss: 7.9127	Cost: 6.46s
Train Epoch: 61 [81920/90000 (91%)]	Loss: 7.8808	Cost: 12.78s
Train Epoch: 61 	Average Loss: 7.9620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9766

Saving model as e61_model.pt & e61_waveforms_supplementary.hdf5
Learning rate: 9.999081908148385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 62 [0/90000 (0%)]	Loss: 8.0777	Cost: 33.00s
Train Epoch: 62 [20480/90000 (23%)]	Loss: 7.8802	Cost: 10.77s
Train Epoch: 62 [40960/90000 (45%)]	Loss: 7.9414	Cost: 18.93s
Train Epoch: 62 [61440/90000 (68%)]	Loss: 7.8322	Cost: 11.96s
Train Epoch: 62 [81920/90000 (91%)]	Loss: 7.7652	Cost: 11.93s
Train Epoch: 62 	Average Loss: 7.9430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9392

Saving model as e62_model.pt & e62_waveforms_supplementary.hdf5
Learning rate: 9.999051561003123e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 63 [0/90000 (0%)]	Loss: 7.9113	Cost: 33.15s
Train Epoch: 63 [20480/90000 (23%)]	Loss: 7.9949	Cost: 10.55s
Train Epoch: 63 [40960/90000 (45%)]	Loss: 7.7447	Cost: 9.16s
Train Epoch: 63 [61440/90000 (68%)]	Loss: 7.8139	Cost: 6.20s
Train Epoch: 63 [81920/90000 (91%)]	Loss: 7.9262	Cost: 13.10s
Train Epoch: 63 	Average Loss: 7.9293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.9124

Saving model as e63_model.pt & e63_waveforms_supplementary.hdf5
Learning rate: 9.999020720471253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 64 [0/90000 (0%)]	Loss: 7.8101	Cost: 29.21s
Train Epoch: 64 [20480/90000 (23%)]	Loss: 7.8529	Cost: 11.55s
Train Epoch: 64 [40960/90000 (45%)]	Loss: 7.7458	Cost: 14.60s
Train Epoch: 64 [61440/90000 (68%)]	Loss: 7.7987	Cost: 13.98s
Train Epoch: 64 [81920/90000 (91%)]	Loss: 7.7399	Cost: 12.07s
Train Epoch: 64 	Average Loss: 7.8520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8745

Saving model as e64_model.pt & e64_waveforms_supplementary.hdf5
Learning rate: 9.998989386555816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 65 [0/90000 (0%)]	Loss: 7.9477	Cost: 47.81s
Train Epoch: 65 [20480/90000 (23%)]	Loss: 7.7580	Cost: 10.74s
Train Epoch: 65 [40960/90000 (45%)]	Loss: 7.7908	Cost: 7.72s
Train Epoch: 65 [61440/90000 (68%)]	Loss: 7.7954	Cost: 6.64s
Train Epoch: 65 [81920/90000 (91%)]	Loss: 7.9170	Cost: 13.80s
Train Epoch: 65 	Average Loss: 7.8245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8467

Saving model as e65_model.pt & e65_waveforms_supplementary.hdf5
Learning rate: 9.998957559259906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 66 [0/90000 (0%)]	Loss: 7.8713	Cost: 32.64s
Train Epoch: 66 [20480/90000 (23%)]	Loss: 7.7776	Cost: 7.24s
Train Epoch: 66 [40960/90000 (45%)]	Loss: 7.7857	Cost: 17.26s
Train Epoch: 66 [61440/90000 (68%)]	Loss: 7.7385	Cost: 12.21s
Train Epoch: 66 [81920/90000 (91%)]	Loss: 7.6887	Cost: 12.14s
Train Epoch: 66 	Average Loss: 7.7873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.8342

Saving model as e66_model.pt & e66_waveforms_supplementary.hdf5
Learning rate: 9.998925238586665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 67 [0/90000 (0%)]	Loss: 7.8647	Cost: 35.02s
Train Epoch: 67 [20480/90000 (23%)]	Loss: 7.7434	Cost: 7.65s
Train Epoch: 67 [40960/90000 (45%)]	Loss: 7.7044	Cost: 13.62s
Train Epoch: 67 [61440/90000 (68%)]	Loss: 7.6278	Cost: 8.51s
Train Epoch: 67 [81920/90000 (91%)]	Loss: 7.7302	Cost: 8.59s
Train Epoch: 67 	Average Loss: 7.7520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7398

Saving model as e67_model.pt & e67_waveforms_supplementary.hdf5
Learning rate: 9.998892424539283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 68 [0/90000 (0%)]	Loss: 7.7032	Cost: 27.72s
Train Epoch: 68 [20480/90000 (23%)]	Loss: 7.7341	Cost: 9.04s
Train Epoch: 68 [40960/90000 (45%)]	Loss: 7.7003	Cost: 14.90s
Train Epoch: 68 [61440/90000 (68%)]	Loss: 7.7149	Cost: 12.09s
Train Epoch: 68 [81920/90000 (91%)]	Loss: 7.6314	Cost: 12.60s
Train Epoch: 68 	Average Loss: 7.7051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6877

Saving model as e68_model.pt & e68_waveforms_supplementary.hdf5
Learning rate: 9.998859117121e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 69 [0/90000 (0%)]	Loss: 7.6705	Cost: 35.24s
Train Epoch: 69 [20480/90000 (23%)]	Loss: 7.5949	Cost: 9.69s
Train Epoch: 69 [40960/90000 (45%)]	Loss: 7.5753	Cost: 8.93s
Train Epoch: 69 [61440/90000 (68%)]	Loss: 7.6681	Cost: 8.72s
Train Epoch: 69 [81920/90000 (91%)]	Loss: 7.6467	Cost: 15.05s
Train Epoch: 69 	Average Loss: 7.6839
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6905

Learning rate: 9.998825316335099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 70 [0/90000 (0%)]	Loss: 7.5012	Cost: 36.84s
Train Epoch: 70 [20480/90000 (23%)]	Loss: 7.5695	Cost: 8.34s
Train Epoch: 70 [40960/90000 (45%)]	Loss: 7.6768	Cost: 17.65s
Train Epoch: 70 [61440/90000 (68%)]	Loss: 7.6717	Cost: 12.09s
Train Epoch: 70 [81920/90000 (91%)]	Loss: 7.6110	Cost: 12.08s
Train Epoch: 70 	Average Loss: 7.6613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.7238

Learning rate: 9.99879102218492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 71 [0/90000 (0%)]	Loss: 7.6786	Cost: 33.83s
Train Epoch: 71 [20480/90000 (23%)]	Loss: 7.4733	Cost: 11.61s
Train Epoch: 71 [40960/90000 (45%)]	Loss: 7.6972	Cost: 6.29s
Train Epoch: 71 [61440/90000 (68%)]	Loss: 7.6551	Cost: 6.88s
Train Epoch: 71 [81920/90000 (91%)]	Loss: 7.5487	Cost: 15.25s
Train Epoch: 71 	Average Loss: 7.6083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5933

Saving model as e71_model.pt & e71_waveforms_supplementary.hdf5
Learning rate: 9.998756234673847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 72 [0/90000 (0%)]	Loss: 7.6638	Cost: 30.62s
Train Epoch: 72 [20480/90000 (23%)]	Loss: 7.5724	Cost: 10.51s
Train Epoch: 72 [40960/90000 (45%)]	Loss: 7.4226	Cost: 14.42s
Train Epoch: 72 [61440/90000 (68%)]	Loss: 7.6294	Cost: 13.79s
Train Epoch: 72 [81920/90000 (91%)]	Loss: 7.5892	Cost: 12.08s
Train Epoch: 72 	Average Loss: 7.5758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.6036

Learning rate: 9.998720953805312e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 73 [0/90000 (0%)]	Loss: 7.5078	Cost: 38.35s
Train Epoch: 73 [20480/90000 (23%)]	Loss: 7.4241	Cost: 12.43s
Train Epoch: 73 [40960/90000 (45%)]	Loss: 7.5988	Cost: 12.09s
Train Epoch: 73 [61440/90000 (68%)]	Loss: 7.5320	Cost: 7.46s
Train Epoch: 73 [81920/90000 (91%)]	Loss: 7.4351	Cost: 6.13s
Train Epoch: 73 	Average Loss: 7.5436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5518

Saving model as e73_model.pt & e73_waveforms_supplementary.hdf5
Learning rate: 9.998685179582798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 74 [0/90000 (0%)]	Loss: 7.5712	Cost: 32.49s
Train Epoch: 74 [20480/90000 (23%)]	Loss: 7.3948	Cost: 10.50s
Train Epoch: 74 [40960/90000 (45%)]	Loss: 7.5731	Cost: 20.60s
Train Epoch: 74 [61440/90000 (68%)]	Loss: 7.4149	Cost: 12.36s
Train Epoch: 74 [81920/90000 (91%)]	Loss: 7.3204	Cost: 11.79s
Train Epoch: 74 	Average Loss: 7.5154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.5652

Learning rate: 9.998648912009835e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 75 [0/90000 (0%)]	Loss: 7.3739	Cost: 31.10s
Train Epoch: 75 [20480/90000 (23%)]	Loss: 7.3855	Cost: 11.72s
Train Epoch: 75 [40960/90000 (45%)]	Loss: 7.5064	Cost: 6.16s
Train Epoch: 75 [61440/90000 (68%)]	Loss: 7.4330	Cost: 6.11s
Train Epoch: 75 [81920/90000 (91%)]	Loss: 7.2873	Cost: 13.94s
Train Epoch: 75 	Average Loss: 7.4689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4524

Saving model as e75_model.pt & e75_waveforms_supplementary.hdf5
Learning rate: 9.998612151090003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 76 [0/90000 (0%)]	Loss: 7.5028	Cost: 29.99s
Train Epoch: 76 [20480/90000 (23%)]	Loss: 7.4690	Cost: 10.90s
Train Epoch: 76 [40960/90000 (45%)]	Loss: 7.4180	Cost: 22.21s
Train Epoch: 76 [61440/90000 (68%)]	Loss: 7.3562	Cost: 12.70s
Train Epoch: 76 [81920/90000 (91%)]	Loss: 7.3998	Cost: 11.92s
Train Epoch: 76 	Average Loss: 7.4487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4668

Learning rate: 9.998574896826931e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 77 [0/90000 (0%)]	Loss: 7.4738	Cost: 44.25s
Train Epoch: 77 [20480/90000 (23%)]	Loss: 7.4272	Cost: 6.01s
Train Epoch: 77 [40960/90000 (45%)]	Loss: 7.3819	Cost: 15.11s
Train Epoch: 77 [61440/90000 (68%)]	Loss: 7.4121	Cost: 8.60s
Train Epoch: 77 [81920/90000 (91%)]	Loss: 7.3719	Cost: 8.76s
Train Epoch: 77 	Average Loss: 7.4106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4662

Learning rate: 9.998537149224293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 78 [0/90000 (0%)]	Loss: 7.4360	Cost: 30.09s
Train Epoch: 78 [20480/90000 (23%)]	Loss: 7.2861	Cost: 6.92s
Train Epoch: 78 [40960/90000 (45%)]	Loss: 7.3899	Cost: 18.45s
Train Epoch: 78 [61440/90000 (68%)]	Loss: 7.3409	Cost: 12.37s
Train Epoch: 78 [81920/90000 (91%)]	Loss: 7.2839	Cost: 12.04s
Train Epoch: 78 	Average Loss: 7.3862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.4055

Saving model as e78_model.pt & e78_waveforms_supplementary.hdf5
Learning rate: 9.998498908285819e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 79 [0/90000 (0%)]	Loss: 7.4530	Cost: 34.52s
Train Epoch: 79 [20480/90000 (23%)]	Loss: 7.2330	Cost: 7.57s
Train Epoch: 79 [40960/90000 (45%)]	Loss: 7.2651	Cost: 13.68s
Train Epoch: 79 [61440/90000 (68%)]	Loss: 7.3077	Cost: 8.54s
Train Epoch: 79 [81920/90000 (91%)]	Loss: 7.2642	Cost: 9.02s
Train Epoch: 79 	Average Loss: 7.3570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3894

Saving model as e79_model.pt & e79_waveforms_supplementary.hdf5
Learning rate: 9.998460174015279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 80 [0/90000 (0%)]	Loss: 7.4370	Cost: 27.46s
Train Epoch: 80 [20480/90000 (23%)]	Loss: 7.3237	Cost: 8.30s
Train Epoch: 80 [40960/90000 (45%)]	Loss: 7.3287	Cost: 15.91s
Train Epoch: 80 [61440/90000 (68%)]	Loss: 7.3058	Cost: 12.07s
Train Epoch: 80 [81920/90000 (91%)]	Loss: 7.2171	Cost: 12.40s
Train Epoch: 80 	Average Loss: 7.3298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3292

Saving model as e80_model.pt & e80_waveforms_supplementary.hdf5
Learning rate: 9.998420946416499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 81 [0/90000 (0%)]	Loss: 7.5740	Cost: 33.68s
Train Epoch: 81 [20480/90000 (23%)]	Loss: 7.2921	Cost: 9.23s
Train Epoch: 81 [40960/90000 (45%)]	Loss: 7.2601	Cost: 9.17s
Train Epoch: 81 [61440/90000 (68%)]	Loss: 7.0982	Cost: 8.89s
Train Epoch: 81 [81920/90000 (91%)]	Loss: 7.3292	Cost: 13.49s
Train Epoch: 81 	Average Loss: 7.3011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3699

Learning rate: 9.998381225493349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 82 [0/90000 (0%)]	Loss: 7.4121	Cost: 32.02s
Train Epoch: 82 [20480/90000 (23%)]	Loss: 7.1979	Cost: 11.24s
Train Epoch: 82 [40960/90000 (45%)]	Loss: 7.2878	Cost: 17.90s
Train Epoch: 82 [61440/90000 (68%)]	Loss: 7.2555	Cost: 12.38s
Train Epoch: 82 [81920/90000 (91%)]	Loss: 7.2781	Cost: 11.83s
Train Epoch: 82 	Average Loss: 7.2823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3480

Learning rate: 9.998341011249749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 83 [0/90000 (0%)]	Loss: 7.3127	Cost: 39.56s
Train Epoch: 83 [20480/90000 (23%)]	Loss: 7.2948	Cost: 11.18s
Train Epoch: 83 [40960/90000 (45%)]	Loss: 7.2803	Cost: 7.97s
Train Epoch: 83 [61440/90000 (68%)]	Loss: 7.1555	Cost: 6.18s
Train Epoch: 83 [81920/90000 (91%)]	Loss: 7.3152	Cost: 13.45s
Train Epoch: 83 	Average Loss: 7.2782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.3146

Saving model as e83_model.pt & e83_waveforms_supplementary.hdf5
Learning rate: 9.99830030368967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 84 [0/90000 (0%)]	Loss: 7.3634	Cost: 30.05s
Train Epoch: 84 [20480/90000 (23%)]	Loss: 7.0806	Cost: 10.07s
Train Epoch: 84 [40960/90000 (45%)]	Loss: 7.1849	Cost: 18.98s
Train Epoch: 84 [61440/90000 (68%)]	Loss: 7.0763	Cost: 12.53s
Train Epoch: 84 [81920/90000 (91%)]	Loss: 7.1187	Cost: 12.20s
Train Epoch: 84 	Average Loss: 7.2042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2341

Saving model as e84_model.pt & e84_waveforms_supplementary.hdf5
Learning rate: 9.998259102817127e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 85 [0/90000 (0%)]	Loss: 7.1774	Cost: 41.75s
Train Epoch: 85 [20480/90000 (23%)]	Loss: 7.1771	Cost: 8.37s
Train Epoch: 85 [40960/90000 (45%)]	Loss: 7.1157	Cost: 10.96s
Train Epoch: 85 [61440/90000 (68%)]	Loss: 7.2142	Cost: 8.96s
Train Epoch: 85 [81920/90000 (91%)]	Loss: 7.0841	Cost: 12.23s
Train Epoch: 85 	Average Loss: 7.2000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.2359

Learning rate: 9.99821740863619e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 86 [0/90000 (0%)]	Loss: 7.0945	Cost: 48.71s
Train Epoch: 86 [20480/90000 (23%)]	Loss: 7.0703	Cost: 12.33s
Train Epoch: 86 [40960/90000 (45%)]	Loss: 7.1555	Cost: 12.26s
Train Epoch: 86 [61440/90000 (68%)]	Loss: 7.2144	Cost: 12.14s
Train Epoch: 86 [81920/90000 (91%)]	Loss: 7.0207	Cost: 11.90s
Train Epoch: 86 	Average Loss: 7.1384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1478

Saving model as e86_model.pt & e86_waveforms_supplementary.hdf5
Learning rate: 9.99817522115097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 87 [0/90000 (0%)]	Loss: 7.1024	Cost: 43.46s
Train Epoch: 87 [20480/90000 (23%)]	Loss: 7.1098	Cost: 6.18s
Train Epoch: 87 [40960/90000 (45%)]	Loss: 7.2740	Cost: 13.47s
Train Epoch: 87 [61440/90000 (68%)]	Loss: 7.1056	Cost: 8.55s
Train Epoch: 87 [81920/90000 (91%)]	Loss: 7.0362	Cost: 8.34s
Train Epoch: 87 	Average Loss: 7.1400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1684

Learning rate: 9.998132540365634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 88 [0/90000 (0%)]	Loss: 7.2303	Cost: 28.69s
Train Epoch: 88 [20480/90000 (23%)]	Loss: 7.0815	Cost: 7.83s
Train Epoch: 88 [40960/90000 (45%)]	Loss: 7.2147	Cost: 18.65s
Train Epoch: 88 [61440/90000 (68%)]	Loss: 7.1422	Cost: 13.24s
Train Epoch: 88 [81920/90000 (91%)]	Loss: 6.9562	Cost: 12.10s
Train Epoch: 88 	Average Loss: 7.1285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.1337

Saving model as e88_model.pt & e88_waveforms_supplementary.hdf5
Learning rate: 9.998089366284391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 89 [0/90000 (0%)]	Loss: 7.1606	Cost: 44.85s
Train Epoch: 89 [20480/90000 (23%)]	Loss: 7.0295	Cost: 10.46s
Train Epoch: 89 [40960/90000 (45%)]	Loss: 7.1177	Cost: 10.92s
Train Epoch: 89 [61440/90000 (68%)]	Loss: 7.1466	Cost: 6.13s
Train Epoch: 89 [81920/90000 (91%)]	Loss: 6.9694	Cost: 12.61s
Train Epoch: 89 	Average Loss: 7.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0938

Saving model as e89_model.pt & e89_waveforms_supplementary.hdf5
Learning rate: 9.998045698911504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 90 [0/90000 (0%)]	Loss: 7.0008	Cost: 31.41s
Train Epoch: 90 [20480/90000 (23%)]	Loss: 7.0556	Cost: 6.92s
Train Epoch: 90 [40960/90000 (45%)]	Loss: 7.1005	Cost: 17.21s
Train Epoch: 90 [61440/90000 (68%)]	Loss: 6.9708	Cost: 12.67s
Train Epoch: 90 [81920/90000 (91%)]	Loss: 7.0835	Cost: 12.04s
Train Epoch: 90 	Average Loss: 7.0692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0890

Saving model as e90_model.pt & e90_waveforms_supplementary.hdf5
Learning rate: 9.998001538251281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 91 [0/90000 (0%)]	Loss: 7.1834	Cost: 43.82s
Train Epoch: 91 [20480/90000 (23%)]	Loss: 7.0987	Cost: 8.97s
Train Epoch: 91 [40960/90000 (45%)]	Loss: 7.0510	Cost: 10.01s
Train Epoch: 91 [61440/90000 (68%)]	Loss: 6.9855	Cost: 8.22s
Train Epoch: 91 [81920/90000 (91%)]	Loss: 6.8907	Cost: 10.42s
Train Epoch: 91 	Average Loss: 7.0359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0682

Saving model as e91_model.pt & e91_waveforms_supplementary.hdf5
Learning rate: 9.997956884308085e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 92 [0/90000 (0%)]	Loss: 7.0298	Cost: 27.51s
Train Epoch: 92 [20480/90000 (23%)]	Loss: 7.0267	Cost: 8.66s
Train Epoch: 92 [40960/90000 (45%)]	Loss: 7.0210	Cost: 15.16s
Train Epoch: 92 [61440/90000 (68%)]	Loss: 6.9675	Cost: 11.93s
Train Epoch: 92 [81920/90000 (91%)]	Loss: 6.9683	Cost: 12.49s
Train Epoch: 92 	Average Loss: 7.0238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0626

Saving model as e92_model.pt & e92_waveforms_supplementary.hdf5
Learning rate: 9.99791173708632e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 93 [0/90000 (0%)]	Loss: 7.0322	Cost: 32.60s
Train Epoch: 93 [20480/90000 (23%)]	Loss: 6.9554	Cost: 10.31s
Train Epoch: 93 [40960/90000 (45%)]	Loss: 7.0218	Cost: 8.17s
Train Epoch: 93 [61440/90000 (68%)]	Loss: 6.9099	Cost: 10.30s
Train Epoch: 93 [81920/90000 (91%)]	Loss: 6.9625	Cost: 12.70s
Train Epoch: 93 	Average Loss: 6.9945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0467

Saving model as e93_model.pt & e93_waveforms_supplementary.hdf5
Learning rate: 9.997866096590442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 94 [0/90000 (0%)]	Loss: 7.1491	Cost: 33.66s
Train Epoch: 94 [20480/90000 (23%)]	Loss: 7.0460	Cost: 8.48s
Train Epoch: 94 [40960/90000 (45%)]	Loss: 6.9780	Cost: 18.36s
Train Epoch: 94 [61440/90000 (68%)]	Loss: 6.8174	Cost: 12.21s
Train Epoch: 94 [81920/90000 (91%)]	Loss: 7.0212	Cost: 11.89s
Train Epoch: 94 	Average Loss: 6.9916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0153

Saving model as e94_model.pt & e94_waveforms_supplementary.hdf5
Learning rate: 9.997819962824954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 95 [0/90000 (0%)]	Loss: 6.9836	Cost: 38.75s
Train Epoch: 95 [20480/90000 (23%)]	Loss: 6.9701	Cost: 10.75s
Train Epoch: 95 [40960/90000 (45%)]	Loss: 6.9919	Cost: 6.30s
Train Epoch: 95 [61440/90000 (68%)]	Loss: 6.8311	Cost: 7.14s
Train Epoch: 95 [81920/90000 (91%)]	Loss: 6.8698	Cost: 13.38s
Train Epoch: 95 	Average Loss: 6.9468
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9491

Saving model as e95_model.pt & e95_waveforms_supplementary.hdf5
Learning rate: 9.997773335794414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 96 [0/90000 (0%)]	Loss: 6.9399	Cost: 33.26s
Train Epoch: 96 [20480/90000 (23%)]	Loss: 6.9564	Cost: 10.27s
Train Epoch: 96 [40960/90000 (45%)]	Loss: 7.0105	Cost: 15.44s
Train Epoch: 96 [61440/90000 (68%)]	Loss: 6.9198	Cost: 12.19s
Train Epoch: 96 [81920/90000 (91%)]	Loss: 6.8607	Cost: 12.02s
Train Epoch: 96 	Average Loss: 6.9493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9360

Saving model as e96_model.pt & e96_waveforms_supplementary.hdf5
Learning rate: 9.99772621550342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 97 [0/90000 (0%)]	Loss: 6.9251	Cost: 34.49s
Train Epoch: 97 [20480/90000 (23%)]	Loss: 6.8762	Cost: 9.12s
Train Epoch: 97 [40960/90000 (45%)]	Loss: 6.8922	Cost: 7.88s
Train Epoch: 97 [61440/90000 (68%)]	Loss: 6.8233	Cost: 7.76s
Train Epoch: 97 [81920/90000 (91%)]	Loss: 6.8496	Cost: 14.02s
Train Epoch: 97 	Average Loss: 6.9042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 7.0058

Learning rate: 9.997678601956623e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 98 [0/90000 (0%)]	Loss: 6.9233	Cost: 27.05s
Train Epoch: 98 [20480/90000 (23%)]	Loss: 6.8912	Cost: 7.39s
Train Epoch: 98 [40960/90000 (45%)]	Loss: 6.8536	Cost: 21.49s
Train Epoch: 98 [61440/90000 (68%)]	Loss: 6.8210	Cost: 13.78s
Train Epoch: 98 [81920/90000 (91%)]	Loss: 6.8210	Cost: 12.17s
Train Epoch: 98 	Average Loss: 6.8863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9184

Saving model as e98_model.pt & e98_waveforms_supplementary.hdf5
Learning rate: 9.997630495158724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 99 [0/90000 (0%)]	Loss: 6.9240	Cost: 32.51s
Train Epoch: 99 [20480/90000 (23%)]	Loss: 6.8984	Cost: 11.85s
Train Epoch: 99 [40960/90000 (45%)]	Loss: 6.8622	Cost: 8.22s
Train Epoch: 99 [61440/90000 (68%)]	Loss: 6.7516	Cost: 6.43s
Train Epoch: 99 [81920/90000 (91%)]	Loss: 6.8028	Cost: 15.42s
Train Epoch: 99 	Average Loss: 6.8613
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.9305

Learning rate: 9.997581895114468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 100 [0/90000 (0%)]	Loss: 6.8852	Cost: 29.27s
Train Epoch: 100 [20480/90000 (23%)]	Loss: 6.8027	Cost: 9.78s
Train Epoch: 100 [40960/90000 (45%)]	Loss: 6.8716	Cost: 17.25s
Train Epoch: 100 [61440/90000 (68%)]	Loss: 6.9701	Cost: 12.41s
Train Epoch: 100 [81920/90000 (91%)]	Loss: 6.7063	Cost: 12.18s
Train Epoch: 100 	Average Loss: 6.8516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8690

Saving model as e100_model.pt & e100_waveforms_supplementary.hdf5
Learning rate: 9.997532801828656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 101 [0/90000 (0%)]	Loss: 6.8821	Cost: 36.14s
Train Epoch: 101 [20480/90000 (23%)]	Loss: 6.6689	Cost: 13.44s
Train Epoch: 101 [40960/90000 (45%)]	Loss: 6.7816	Cost: 7.86s
Train Epoch: 101 [61440/90000 (68%)]	Loss: 6.8198	Cost: 6.56s
Train Epoch: 101 [81920/90000 (91%)]	Loss: 6.7423	Cost: 14.06s
Train Epoch: 101 	Average Loss: 6.8149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8800

Learning rate: 9.997483215306129e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 102 [0/90000 (0%)]	Loss: 6.8620	Cost: 32.29s
Train Epoch: 102 [20480/90000 (23%)]	Loss: 6.8590	Cost: 7.39s
Train Epoch: 102 [40960/90000 (45%)]	Loss: 6.8271	Cost: 17.57s
Train Epoch: 102 [61440/90000 (68%)]	Loss: 6.7456	Cost: 11.98s
Train Epoch: 102 [81920/90000 (91%)]	Loss: 6.7755	Cost: 11.99s
Train Epoch: 102 	Average Loss: 6.8285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7634

Saving model as e102_model.pt & e102_waveforms_supplementary.hdf5
Learning rate: 9.997433135551784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 103 [0/90000 (0%)]	Loss: 6.7611	Cost: 31.47s
Train Epoch: 103 [20480/90000 (23%)]	Loss: 6.7982	Cost: 11.58s
Train Epoch: 103 [40960/90000 (45%)]	Loss: 6.7229	Cost: 7.55s
Train Epoch: 103 [61440/90000 (68%)]	Loss: 6.6986	Cost: 6.60s
Train Epoch: 103 [81920/90000 (91%)]	Loss: 6.6716	Cost: 14.68s
Train Epoch: 103 	Average Loss: 6.7758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.8483

Learning rate: 9.99738256257056e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 104 [0/90000 (0%)]	Loss: 6.8594	Cost: 34.90s
Train Epoch: 104 [20480/90000 (23%)]	Loss: 6.7729	Cost: 7.67s
Train Epoch: 104 [40960/90000 (45%)]	Loss: 6.7410	Cost: 20.47s
Train Epoch: 104 [61440/90000 (68%)]	Loss: 6.7499	Cost: 12.00s
Train Epoch: 104 [81920/90000 (91%)]	Loss: 6.7273	Cost: 12.19s
Train Epoch: 104 	Average Loss: 6.7846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7599

Saving model as e104_model.pt & e104_waveforms_supplementary.hdf5
Learning rate: 9.997331496367453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 105 [0/90000 (0%)]	Loss: 6.7584	Cost: 32.22s
Train Epoch: 105 [20480/90000 (23%)]	Loss: 6.6879	Cost: 11.88s
Train Epoch: 105 [40960/90000 (45%)]	Loss: 6.7941	Cost: 8.19s
Train Epoch: 105 [61440/90000 (68%)]	Loss: 6.6754	Cost: 6.57s
Train Epoch: 105 [81920/90000 (91%)]	Loss: 6.7110	Cost: 12.89s
Train Epoch: 105 	Average Loss: 6.7438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7877

Learning rate: 9.997279936947499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 106 [0/90000 (0%)]	Loss: 6.6922	Cost: 32.47s
Train Epoch: 106 [20480/90000 (23%)]	Loss: 6.6850	Cost: 10.72s
Train Epoch: 106 [40960/90000 (45%)]	Loss: 6.7027	Cost: 18.13s
Train Epoch: 106 [61440/90000 (68%)]	Loss: 6.6465	Cost: 12.37s
Train Epoch: 106 [81920/90000 (91%)]	Loss: 6.5864	Cost: 11.99s
Train Epoch: 106 	Average Loss: 6.7204
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7333

Saving model as e106_model.pt & e106_waveforms_supplementary.hdf5
Learning rate: 9.997227884315788e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 107 [0/90000 (0%)]	Loss: 6.7411	Cost: 39.20s
Train Epoch: 107 [20480/90000 (23%)]	Loss: 6.7159	Cost: 8.89s
Train Epoch: 107 [40960/90000 (45%)]	Loss: 6.6971	Cost: 9.00s
Train Epoch: 107 [61440/90000 (68%)]	Loss: 6.6304	Cost: 8.06s
Train Epoch: 107 [81920/90000 (91%)]	Loss: 6.6480	Cost: 13.13s
Train Epoch: 107 	Average Loss: 6.7391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6953

Saving model as e107_model.pt & e107_waveforms_supplementary.hdf5
Learning rate: 9.997175338477459e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 108 [0/90000 (0%)]	Loss: 6.7192	Cost: 32.07s
Train Epoch: 108 [20480/90000 (23%)]	Loss: 6.6825	Cost: 8.33s
Train Epoch: 108 [40960/90000 (45%)]	Loss: 6.6101	Cost: 16.42s
Train Epoch: 108 [61440/90000 (68%)]	Loss: 6.6838	Cost: 12.52s
Train Epoch: 108 [81920/90000 (91%)]	Loss: 6.6478	Cost: 12.14s
Train Epoch: 108 	Average Loss: 6.7075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7057

Learning rate: 9.997122299437696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 109 [0/90000 (0%)]	Loss: 6.6787	Cost: 31.92s
Train Epoch: 109 [20480/90000 (23%)]	Loss: 6.6562	Cost: 10.36s
Train Epoch: 109 [40960/90000 (45%)]	Loss: 6.6099	Cost: 12.56s
Train Epoch: 109 [61440/90000 (68%)]	Loss: 6.5559	Cost: 9.79s
Train Epoch: 109 [81920/90000 (91%)]	Loss: 6.6440	Cost: 14.40s
Train Epoch: 109 	Average Loss: 6.6873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.7291

Learning rate: 9.997068767201736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 110 [0/90000 (0%)]	Loss: 6.6318	Cost: 35.37s
Train Epoch: 110 [20480/90000 (23%)]	Loss: 6.7322	Cost: 10.07s
Train Epoch: 110 [40960/90000 (45%)]	Loss: 6.6643	Cost: 19.19s
Train Epoch: 110 [61440/90000 (68%)]	Loss: 6.5748	Cost: 12.52s
Train Epoch: 110 [81920/90000 (91%)]	Loss: 6.6543	Cost: 11.76s
Train Epoch: 110 	Average Loss: 6.6211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6734

Saving model as e110_model.pt & e110_waveforms_supplementary.hdf5
Learning rate: 9.997014741774862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 111 [0/90000 (0%)]	Loss: 6.6159	Cost: 53.15s
Train Epoch: 111 [20480/90000 (23%)]	Loss: 6.6502	Cost: 6.19s
Train Epoch: 111 [40960/90000 (45%)]	Loss: 6.6778	Cost: 14.06s
Train Epoch: 111 [61440/90000 (68%)]	Loss: 6.6897	Cost: 8.55s
Train Epoch: 111 [81920/90000 (91%)]	Loss: 6.6257	Cost: 7.88s
Train Epoch: 111 	Average Loss: 6.6379
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6977

Learning rate: 9.996960223162402e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 112 [0/90000 (0%)]	Loss: 6.6874	Cost: 77.52s
Train Epoch: 112 [20480/90000 (23%)]	Loss: 6.6251	Cost: 20.29s
Train Epoch: 112 [40960/90000 (45%)]	Loss: 6.5929	Cost: 58.25s
Train Epoch: 112 [61440/90000 (68%)]	Loss: 6.5047	Cost: 18.56s
Train Epoch: 112 [81920/90000 (91%)]	Loss: 6.5383	Cost: 37.12s
Train Epoch: 112 	Average Loss: 6.6094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6301

Saving model as e112_model.pt & e112_waveforms_supplementary.hdf5
Learning rate: 9.996905211369744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 113 [0/90000 (0%)]	Loss: 6.6983	Cost: 95.55s
Train Epoch: 113 [20480/90000 (23%)]	Loss: 6.6484	Cost: 16.46s
Train Epoch: 113 [40960/90000 (45%)]	Loss: 6.6594	Cost: 38.20s
Train Epoch: 113 [61440/90000 (68%)]	Loss: 6.4816	Cost: 10.62s
Train Epoch: 113 [81920/90000 (91%)]	Loss: 6.5285	Cost: 43.28s
Train Epoch: 113 	Average Loss: 6.6120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6320

Learning rate: 9.996849706402311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 114 [0/90000 (0%)]	Loss: 6.6670	Cost: 39.21s
Train Epoch: 114 [20480/90000 (23%)]	Loss: 6.5410	Cost: 14.28s
Train Epoch: 114 [40960/90000 (45%)]	Loss: 6.4974	Cost: 15.09s
Train Epoch: 114 [61440/90000 (68%)]	Loss: 6.4918	Cost: 12.21s
Train Epoch: 114 [81920/90000 (91%)]	Loss: 6.4361	Cost: 9.92s
Train Epoch: 114 	Average Loss: 6.5756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6542

Learning rate: 9.996793708265583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 115 [0/90000 (0%)]	Loss: 6.5917	Cost: 28.14s
Train Epoch: 115 [20480/90000 (23%)]	Loss: 6.5624	Cost: 8.99s
Train Epoch: 115 [40960/90000 (45%)]	Loss: 6.5199	Cost: 9.96s
Train Epoch: 115 [61440/90000 (68%)]	Loss: 6.4796	Cost: 8.93s
Train Epoch: 115 [81920/90000 (91%)]	Loss: 6.4723	Cost: 8.40s
Train Epoch: 115 	Average Loss: 6.5632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.6354

Learning rate: 9.996737216965088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 116 [0/90000 (0%)]	Loss: 6.6261	Cost: 33.99s
Train Epoch: 116 [20480/90000 (23%)]	Loss: 6.5705	Cost: 12.27s
Train Epoch: 116 [40960/90000 (45%)]	Loss: 6.4208	Cost: 14.35s
Train Epoch: 116 [61440/90000 (68%)]	Loss: 6.4684	Cost: 12.36s
Train Epoch: 116 [81920/90000 (91%)]	Loss: 6.4897	Cost: 10.48s
Train Epoch: 116 	Average Loss: 6.5558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5383

Saving model as e116_model.pt & e116_waveforms_supplementary.hdf5
Learning rate: 9.9966802325064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 117 [0/90000 (0%)]	Loss: 6.5507	Cost: 31.82s
Train Epoch: 117 [20480/90000 (23%)]	Loss: 6.5754	Cost: 9.21s
Train Epoch: 117 [40960/90000 (45%)]	Loss: 6.5106	Cost: 18.77s
Train Epoch: 117 [61440/90000 (68%)]	Loss: 6.4945	Cost: 9.10s
Train Epoch: 117 [81920/90000 (91%)]	Loss: 6.4129	Cost: 9.03s
Train Epoch: 117 	Average Loss: 6.5284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5019

Saving model as e117_model.pt & e117_waveforms_supplementary.hdf5
Learning rate: 9.996622754895145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 118 [0/90000 (0%)]	Loss: 6.4632	Cost: 37.48s
Train Epoch: 118 [20480/90000 (23%)]	Loss: 6.4365	Cost: 7.39s
Train Epoch: 118 [40960/90000 (45%)]	Loss: 6.5246	Cost: 18.31s
Train Epoch: 118 [61440/90000 (68%)]	Loss: 6.4476	Cost: 12.12s
Train Epoch: 118 [81920/90000 (91%)]	Loss: 6.4534	Cost: 12.02s
Train Epoch: 118 	Average Loss: 6.5048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5253

Learning rate: 9.996564784136994e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 119 [0/90000 (0%)]	Loss: 6.5068	Cost: 33.70s
Train Epoch: 119 [20480/90000 (23%)]	Loss: 6.4600	Cost: 9.86s
Train Epoch: 119 [40960/90000 (45%)]	Loss: 6.5638	Cost: 11.06s
Train Epoch: 119 [61440/90000 (68%)]	Loss: 6.3992	Cost: 9.18s
Train Epoch: 119 [81920/90000 (91%)]	Loss: 6.4872	Cost: 11.88s
Train Epoch: 119 	Average Loss: 6.4880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5586

Learning rate: 9.99650632023767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 120 [0/90000 (0%)]	Loss: 6.5798	Cost: 35.59s
Train Epoch: 120 [20480/90000 (23%)]	Loss: 6.6070	Cost: 11.19s
Train Epoch: 120 [40960/90000 (45%)]	Loss: 6.4497	Cost: 21.94s
Train Epoch: 120 [61440/90000 (68%)]	Loss: 6.3147	Cost: 12.08s
Train Epoch: 120 [81920/90000 (91%)]	Loss: 6.4734	Cost: 11.95s
Train Epoch: 120 	Average Loss: 6.4699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5489

Learning rate: 9.996447363202941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 121 [0/90000 (0%)]	Loss: 6.4486	Cost: 38.12s
Train Epoch: 121 [20480/90000 (23%)]	Loss: 6.3722	Cost: 6.47s
Train Epoch: 121 [40960/90000 (45%)]	Loss: 6.3888	Cost: 14.87s
Train Epoch: 121 [61440/90000 (68%)]	Loss: 6.5024	Cost: 8.54s
Train Epoch: 121 [81920/90000 (91%)]	Loss: 6.3846	Cost: 8.94s
Train Epoch: 121 	Average Loss: 6.4735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5446

Learning rate: 9.996387913038628e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 122 [0/90000 (0%)]	Loss: 6.4351	Cost: 34.17s
Train Epoch: 122 [20480/90000 (23%)]	Loss: 6.3681	Cost: 11.02s
Train Epoch: 122 [40960/90000 (45%)]	Loss: 6.3475	Cost: 19.26s
Train Epoch: 122 [61440/90000 (68%)]	Loss: 6.4383	Cost: 12.51s
Train Epoch: 122 [81920/90000 (91%)]	Loss: 6.5784	Cost: 12.04s
Train Epoch: 122 	Average Loss: 6.4515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5778

Learning rate: 9.996327969750598e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 123 [0/90000 (0%)]	Loss: 6.6383	Cost: 36.62s
Train Epoch: 123 [20480/90000 (23%)]	Loss: 6.4210	Cost: 6.42s
Train Epoch: 123 [40960/90000 (45%)]	Loss: 6.4125	Cost: 14.25s
Train Epoch: 123 [61440/90000 (68%)]	Loss: 6.4658	Cost: 8.56s
Train Epoch: 123 [81920/90000 (91%)]	Loss: 6.3777	Cost: 9.05s
Train Epoch: 123 	Average Loss: 6.4662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5166

Learning rate: 9.996267533344767e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 124 [0/90000 (0%)]	Loss: 6.6979	Cost: 30.56s
Train Epoch: 124 [20480/90000 (23%)]	Loss: 6.3063	Cost: 8.70s
Train Epoch: 124 [40960/90000 (45%)]	Loss: 6.4197	Cost: 17.41s
Train Epoch: 124 [61440/90000 (68%)]	Loss: 6.4079	Cost: 14.34s
Train Epoch: 124 [81920/90000 (91%)]	Loss: 6.4117	Cost: 12.52s
Train Epoch: 124 	Average Loss: 6.4180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.5084

Learning rate: 9.996206603827099e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 125 [0/90000 (0%)]	Loss: 6.4975	Cost: 38.44s
Train Epoch: 125 [20480/90000 (23%)]	Loss: 6.4552	Cost: 13.88s
Train Epoch: 125 [40960/90000 (45%)]	Loss: 6.3408	Cost: 12.05s
Train Epoch: 125 [61440/90000 (68%)]	Loss: 6.2868	Cost: 6.23s
Train Epoch: 125 [81920/90000 (91%)]	Loss: 6.2819	Cost: 9.63s
Train Epoch: 125 	Average Loss: 6.3846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4067

Saving model as e125_model.pt & e125_waveforms_supplementary.hdf5
Learning rate: 9.99614518120361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 126 [0/90000 (0%)]	Loss: 6.3748	Cost: 33.08s
Train Epoch: 126 [20480/90000 (23%)]	Loss: 6.4128	Cost: 8.75s
Train Epoch: 126 [40960/90000 (45%)]	Loss: 6.3245	Cost: 9.95s
Train Epoch: 126 [61440/90000 (68%)]	Loss: 6.4086	Cost: 6.56s
Train Epoch: 126 [81920/90000 (91%)]	Loss: 6.3149	Cost: 18.55s
Train Epoch: 126 	Average Loss: 6.3737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4837

Learning rate: 9.99608326548036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 127 [0/90000 (0%)]	Loss: 6.5417	Cost: 46.84s
Train Epoch: 127 [20480/90000 (23%)]	Loss: 6.5310	Cost: 11.91s
Train Epoch: 127 [40960/90000 (45%)]	Loss: 6.3048	Cost: 11.31s
Train Epoch: 127 [61440/90000 (68%)]	Loss: 6.3544	Cost: 6.41s
Train Epoch: 127 [81920/90000 (91%)]	Loss: 6.3307	Cost: 8.69s
Train Epoch: 127 	Average Loss: 6.3816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4381

Learning rate: 9.996020856663458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 128 [0/90000 (0%)]	Loss: 6.5058	Cost: 30.42s
Train Epoch: 128 [20480/90000 (23%)]	Loss: 6.4278	Cost: 5.95s
Train Epoch: 128 [40960/90000 (45%)]	Loss: 6.2824	Cost: 15.01s
Train Epoch: 128 [61440/90000 (68%)]	Loss: 6.3719	Cost: 12.45s
Train Epoch: 128 [81920/90000 (91%)]	Loss: 6.3970	Cost: 14.04s
Train Epoch: 128 	Average Loss: 6.3594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4599

Learning rate: 9.995957954759067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 129 [0/90000 (0%)]	Loss: 6.3490	Cost: 36.09s
Train Epoch: 129 [20480/90000 (23%)]	Loss: 6.5151	Cost: 12.63s
Train Epoch: 129 [40960/90000 (45%)]	Loss: 6.3339	Cost: 12.31s
Train Epoch: 129 [61440/90000 (68%)]	Loss: 6.2903	Cost: 10.67s
Train Epoch: 129 [81920/90000 (91%)]	Loss: 6.2832	Cost: 7.19s
Train Epoch: 129 	Average Loss: 6.3388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4648

Learning rate: 9.995894559773395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 130 [0/90000 (0%)]	Loss: 6.4175	Cost: 35.23s
Train Epoch: 130 [20480/90000 (23%)]	Loss: 6.3130	Cost: 10.86s
Train Epoch: 130 [40960/90000 (45%)]	Loss: 6.3118	Cost: 9.89s
Train Epoch: 130 [61440/90000 (68%)]	Loss: 6.2203	Cost: 8.91s
Train Epoch: 130 [81920/90000 (91%)]	Loss: 6.3310	Cost: 18.73s
Train Epoch: 130 	Average Loss: 6.3429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3666

Saving model as e130_model.pt & e130_waveforms_supplementary.hdf5
Learning rate: 9.995830671712695e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 131 [0/90000 (0%)]	Loss: 6.5239	Cost: 39.67s
Train Epoch: 131 [20480/90000 (23%)]	Loss: 6.3551	Cost: 10.83s
Train Epoch: 131 [40960/90000 (45%)]	Loss: 6.3239	Cost: 12.65s
Train Epoch: 131 [61440/90000 (68%)]	Loss: 6.3963	Cost: 11.69s
Train Epoch: 131 [81920/90000 (91%)]	Loss: 6.3810	Cost: 6.25s
Train Epoch: 131 	Average Loss: 6.3253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.4084

Learning rate: 9.995766290583277e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 132 [0/90000 (0%)]	Loss: 6.3193	Cost: 30.54s
Train Epoch: 132 [20480/90000 (23%)]	Loss: 6.3454	Cost: 9.10s
Train Epoch: 132 [40960/90000 (45%)]	Loss: 6.2718	Cost: 10.92s
Train Epoch: 132 [61440/90000 (68%)]	Loss: 6.2074	Cost: 7.31s
Train Epoch: 132 [81920/90000 (91%)]	Loss: 6.3324	Cost: 11.75s
Train Epoch: 132 	Average Loss: 6.3078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3512

Saving model as e132_model.pt & e132_waveforms_supplementary.hdf5
Learning rate: 9.995701416391493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 133 [0/90000 (0%)]	Loss: 6.2999	Cost: 40.89s
Train Epoch: 133 [20480/90000 (23%)]	Loss: 6.3656	Cost: 11.90s
Train Epoch: 133 [40960/90000 (45%)]	Loss: 6.2350	Cost: 12.38s
Train Epoch: 133 [61440/90000 (68%)]	Loss: 6.2141	Cost: 12.18s
Train Epoch: 133 [81920/90000 (91%)]	Loss: 6.3627	Cost: 7.78s
Train Epoch: 133 	Average Loss: 6.2831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3813

Learning rate: 9.995636049143747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 134 [0/90000 (0%)]	Loss: 6.4911	Cost: 30.84s
Train Epoch: 134 [20480/90000 (23%)]	Loss: 6.3839	Cost: 10.80s
Train Epoch: 134 [40960/90000 (45%)]	Loss: 6.1868	Cost: 11.86s
Train Epoch: 134 [61440/90000 (68%)]	Loss: 6.2812	Cost: 10.04s
Train Epoch: 134 [81920/90000 (91%)]	Loss: 6.1560	Cost: 8.37s
Train Epoch: 134 	Average Loss: 6.2753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3636

Learning rate: 9.995570188846488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 135 [0/90000 (0%)]	Loss: 6.4748	Cost: 35.42s
Train Epoch: 135 [20480/90000 (23%)]	Loss: 6.3367	Cost: 9.47s
Train Epoch: 135 [40960/90000 (45%)]	Loss: 6.1959	Cost: 24.01s
Train Epoch: 135 [61440/90000 (68%)]	Loss: 6.2499	Cost: 12.39s
Train Epoch: 135 [81920/90000 (91%)]	Loss: 6.3103	Cost: 11.87s
Train Epoch: 135 	Average Loss: 6.2707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3676

Learning rate: 9.99550383550622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 136 [0/90000 (0%)]	Loss: 6.3231	Cost: 43.37s
Train Epoch: 136 [20480/90000 (23%)]	Loss: 6.2785	Cost: 11.76s
Train Epoch: 136 [40960/90000 (45%)]	Loss: 6.2054	Cost: 7.76s
Train Epoch: 136 [61440/90000 (68%)]	Loss: 6.2762	Cost: 6.46s
Train Epoch: 136 [81920/90000 (91%)]	Loss: 6.1202	Cost: 13.01s
Train Epoch: 136 	Average Loss: 6.2809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3539

Learning rate: 9.995436989129488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 137 [0/90000 (0%)]	Loss: 6.4593	Cost: 29.51s
Train Epoch: 137 [20480/90000 (23%)]	Loss: 6.3292	Cost: 6.30s
Train Epoch: 137 [40960/90000 (45%)]	Loss: 6.2142	Cost: 20.98s
Train Epoch: 137 [61440/90000 (68%)]	Loss: 6.1924	Cost: 12.85s
Train Epoch: 137 [81920/90000 (91%)]	Loss: 6.2284	Cost: 12.25s
Train Epoch: 137 	Average Loss: 6.2485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3453

Saving model as e137_model.pt & e137_waveforms_supplementary.hdf5
Learning rate: 9.99536964972289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 138 [0/90000 (0%)]	Loss: 6.3294	Cost: 47.30s
Train Epoch: 138 [20480/90000 (23%)]	Loss: 6.2514	Cost: 12.20s
Train Epoch: 138 [40960/90000 (45%)]	Loss: 6.2980	Cost: 9.07s
Train Epoch: 138 [61440/90000 (68%)]	Loss: 6.1096	Cost: 6.19s
Train Epoch: 138 [81920/90000 (91%)]	Loss: 6.0229	Cost: 13.72s
Train Epoch: 138 	Average Loss: 6.2459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2503

Saving model as e138_model.pt & e138_waveforms_supplementary.hdf5
Learning rate: 9.995301817293077e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 139 [0/90000 (0%)]	Loss: 6.3704	Cost: 32.21s
Train Epoch: 139 [20480/90000 (23%)]	Loss: 6.1288	Cost: 8.77s
Train Epoch: 139 [40960/90000 (45%)]	Loss: 6.0921	Cost: 15.94s
Train Epoch: 139 [61440/90000 (68%)]	Loss: 6.2098	Cost: 12.23s
Train Epoch: 139 [81920/90000 (91%)]	Loss: 6.1480	Cost: 12.49s
Train Epoch: 139 	Average Loss: 6.2036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2864

Learning rate: 9.995233491846737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 140 [0/90000 (0%)]	Loss: 6.2702	Cost: 60.65s
Train Epoch: 140 [20480/90000 (23%)]	Loss: 6.1874	Cost: 10.41s
Train Epoch: 140 [40960/90000 (45%)]	Loss: 6.1930	Cost: 8.65s
Train Epoch: 140 [61440/90000 (68%)]	Loss: 6.1518	Cost: 6.93s
Train Epoch: 140 [81920/90000 (91%)]	Loss: 6.1486	Cost: 12.59s
Train Epoch: 140 	Average Loss: 6.1745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.3187

Learning rate: 9.995164673390618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 141 [0/90000 (0%)]	Loss: 6.3032	Cost: 29.21s
Train Epoch: 141 [20480/90000 (23%)]	Loss: 6.1562	Cost: 6.74s
Train Epoch: 141 [40960/90000 (45%)]	Loss: 6.1056	Cost: 17.28s
Train Epoch: 141 [61440/90000 (68%)]	Loss: 6.1005	Cost: 11.49s
Train Epoch: 141 [81920/90000 (91%)]	Loss: 6.0334	Cost: 12.87s
Train Epoch: 141 	Average Loss: 6.1776
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2274

Saving model as e141_model.pt & e141_waveforms_supplementary.hdf5
Learning rate: 9.995095361931511e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 142 [0/90000 (0%)]	Loss: 6.1836	Cost: 60.83s
Train Epoch: 142 [20480/90000 (23%)]	Loss: 6.2066	Cost: 12.82s
Train Epoch: 142 [40960/90000 (45%)]	Loss: 6.0870	Cost: 30.15s
Train Epoch: 142 [61440/90000 (68%)]	Loss: 6.1879	Cost: 12.08s
Train Epoch: 142 [81920/90000 (91%)]	Loss: 6.0999	Cost: 12.66s
Train Epoch: 142 	Average Loss: 6.1976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2624

Learning rate: 9.995025557476254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 143 [0/90000 (0%)]	Loss: 6.2638	Cost: 36.95s
Train Epoch: 143 [20480/90000 (23%)]	Loss: 6.1729	Cost: 7.75s
Train Epoch: 143 [40960/90000 (45%)]	Loss: 5.9593	Cost: 16.45s
Train Epoch: 143 [61440/90000 (68%)]	Loss: 6.1778	Cost: 12.14s
Train Epoch: 143 [81920/90000 (91%)]	Loss: 6.0294	Cost: 12.16s
Train Epoch: 143 	Average Loss: 6.1273
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.2152

Saving model as e143_model.pt & e143_waveforms_supplementary.hdf5
Learning rate: 9.99495526003174e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 144 [0/90000 (0%)]	Loss: 6.0905	Cost: 32.17s
Train Epoch: 144 [20480/90000 (23%)]	Loss: 6.1370	Cost: 10.52s
Train Epoch: 144 [40960/90000 (45%)]	Loss: 6.0923	Cost: 10.38s
Train Epoch: 144 [61440/90000 (68%)]	Loss: 6.1260	Cost: 6.80s
Train Epoch: 144 [81920/90000 (91%)]	Loss: 6.0303	Cost: 14.18s
Train Epoch: 144 	Average Loss: 6.1241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1803

Saving model as e144_model.pt & e144_waveforms_supplementary.hdf5
Learning rate: 9.994884469604905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 145 [0/90000 (0%)]	Loss: 6.3429	Cost: 32.75s
Train Epoch: 145 [20480/90000 (23%)]	Loss: 6.0927	Cost: 10.17s
Train Epoch: 145 [40960/90000 (45%)]	Loss: 6.1513	Cost: 20.17s
Train Epoch: 145 [61440/90000 (68%)]	Loss: 6.1178	Cost: 12.18s
Train Epoch: 145 [81920/90000 (91%)]	Loss: 5.9675	Cost: 12.00s
Train Epoch: 145 	Average Loss: 6.1306
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1699

Saving model as e145_model.pt & e145_waveforms_supplementary.hdf5
Learning rate: 9.994813186202739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 146 [0/90000 (0%)]	Loss: 6.1690	Cost: 34.08s
Train Epoch: 146 [20480/90000 (23%)]	Loss: 6.1628	Cost: 8.12s
Train Epoch: 146 [40960/90000 (45%)]	Loss: 6.0294	Cost: 16.33s
Train Epoch: 146 [61440/90000 (68%)]	Loss: 6.0552	Cost: 8.84s
Train Epoch: 146 [81920/90000 (91%)]	Loss: 6.1336	Cost: 11.84s
Train Epoch: 146 	Average Loss: 6.1203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1507

Saving model as e146_model.pt & e146_waveforms_supplementary.hdf5
Learning rate: 9.994741409832273e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 147 [0/90000 (0%)]	Loss: 6.1643	Cost: 49.78s
Train Epoch: 147 [20480/90000 (23%)]	Loss: 5.9923	Cost: 11.59s
Train Epoch: 147 [40960/90000 (45%)]	Loss: 6.0620	Cost: 13.04s
Train Epoch: 147 [61440/90000 (68%)]	Loss: 6.0510	Cost: 12.04s
Train Epoch: 147 [81920/90000 (91%)]	Loss: 6.0750	Cost: 11.71s
Train Epoch: 147 	Average Loss: 6.1098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1778

Learning rate: 9.994669140500594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 148 [0/90000 (0%)]	Loss: 6.1256	Cost: 33.66s
Train Epoch: 148 [20480/90000 (23%)]	Loss: 6.1439	Cost: 9.52s
Train Epoch: 148 [40960/90000 (45%)]	Loss: 5.9378	Cost: 10.03s
Train Epoch: 148 [61440/90000 (68%)]	Loss: 6.0519	Cost: 7.26s
Train Epoch: 148 [81920/90000 (91%)]	Loss: 5.9944	Cost: 14.65s
Train Epoch: 148 	Average Loss: 6.0888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1102

Saving model as e148_model.pt & e148_waveforms_supplementary.hdf5
Learning rate: 9.994596378214833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 149 [0/90000 (0%)]	Loss: 6.1751	Cost: 32.47s
Train Epoch: 149 [20480/90000 (23%)]	Loss: 6.0971	Cost: 10.38s
Train Epoch: 149 [40960/90000 (45%)]	Loss: 5.9614	Cost: 19.29s
Train Epoch: 149 [61440/90000 (68%)]	Loss: 6.1187	Cost: 12.74s
Train Epoch: 149 [81920/90000 (91%)]	Loss: 5.9743	Cost: 11.88s
Train Epoch: 149 	Average Loss: 6.0788
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1220

Learning rate: 9.994523122982173e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 150 [0/90000 (0%)]	Loss: 6.0931	Cost: 34.42s
Train Epoch: 150 [20480/90000 (23%)]	Loss: 6.0487	Cost: 12.42s
Train Epoch: 150 [40960/90000 (45%)]	Loss: 6.0233	Cost: 7.96s
Train Epoch: 150 [61440/90000 (68%)]	Loss: 6.0403	Cost: 6.89s
Train Epoch: 150 [81920/90000 (91%)]	Loss: 5.9036	Cost: 12.73s
Train Epoch: 150 	Average Loss: 6.0543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0515

Saving model as e150_model.pt & e150_waveforms_supplementary.hdf5
Learning rate: 9.994449374809844e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 151 [0/90000 (0%)]	Loss: 6.0288	Cost: 38.77s
Train Epoch: 151 [20480/90000 (23%)]	Loss: 5.9694	Cost: 10.66s
Train Epoch: 151 [40960/90000 (45%)]	Loss: 6.0819	Cost: 17.71s
Train Epoch: 151 [61440/90000 (68%)]	Loss: 6.0099	Cost: 12.04s
Train Epoch: 151 [81920/90000 (91%)]	Loss: 6.0304	Cost: 11.95s
Train Epoch: 151 	Average Loss: 6.0769
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1707

Learning rate: 9.994375133705122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 152 [0/90000 (0%)]	Loss: 6.1241	Cost: 43.35s
Train Epoch: 152 [20480/90000 (23%)]	Loss: 6.1390	Cost: 10.69s
Train Epoch: 152 [40960/90000 (45%)]	Loss: 5.9668	Cost: 6.89s
Train Epoch: 152 [61440/90000 (68%)]	Loss: 5.9571	Cost: 6.14s
Train Epoch: 152 [81920/90000 (91%)]	Loss: 5.9302	Cost: 13.01s
Train Epoch: 152 	Average Loss: 6.0246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0677

Learning rate: 9.994300399675336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 153 [0/90000 (0%)]	Loss: 6.2463	Cost: 31.70s
Train Epoch: 153 [20480/90000 (23%)]	Loss: 6.0630	Cost: 8.45s
Train Epoch: 153 [40960/90000 (45%)]	Loss: 5.9639	Cost: 22.19s
Train Epoch: 153 [61440/90000 (68%)]	Loss: 6.0298	Cost: 12.80s
Train Epoch: 153 [81920/90000 (91%)]	Loss: 5.8402	Cost: 15.20s
Train Epoch: 153 	Average Loss: 6.0182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0190

Saving model as e153_model.pt & e153_waveforms_supplementary.hdf5
Learning rate: 9.994225172727863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 154 [0/90000 (0%)]	Loss: 6.0942	Cost: 37.38s
Train Epoch: 154 [20480/90000 (23%)]	Loss: 6.0141	Cost: 9.49s
Train Epoch: 154 [40960/90000 (45%)]	Loss: 5.9210	Cost: 10.42s
Train Epoch: 154 [61440/90000 (68%)]	Loss: 5.9484	Cost: 8.85s
Train Epoch: 154 [81920/90000 (91%)]	Loss: 5.8031	Cost: 13.80s
Train Epoch: 154 	Average Loss: 5.9992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0476

Learning rate: 9.994149452870126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 155 [0/90000 (0%)]	Loss: 6.0392	Cost: 30.07s
Train Epoch: 155 [20480/90000 (23%)]	Loss: 5.8425	Cost: 10.89s
Train Epoch: 155 [40960/90000 (45%)]	Loss: 5.9551	Cost: 20.88s
Train Epoch: 155 [61440/90000 (68%)]	Loss: 5.9987	Cost: 12.14s
Train Epoch: 155 [81920/90000 (91%)]	Loss: 5.9663	Cost: 11.90s
Train Epoch: 155 	Average Loss: 5.9842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1378

Learning rate: 9.9940732401096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 156 [0/90000 (0%)]	Loss: 6.1294	Cost: 36.20s
Train Epoch: 156 [20480/90000 (23%)]	Loss: 5.9545	Cost: 7.88s
Train Epoch: 156 [40960/90000 (45%)]	Loss: 5.9397	Cost: 12.42s
Train Epoch: 156 [61440/90000 (68%)]	Loss: 6.1020	Cost: 9.00s
Train Epoch: 156 [81920/90000 (91%)]	Loss: 5.8659	Cost: 12.49s
Train Epoch: 156 	Average Loss: 6.0034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9978

Saving model as e156_model.pt & e156_waveforms_supplementary.hdf5
Learning rate: 9.993996534453805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 157 [0/90000 (0%)]	Loss: 6.1065	Cost: 41.58s
Train Epoch: 157 [20480/90000 (23%)]	Loss: 5.9484	Cost: 11.86s
Train Epoch: 157 [40960/90000 (45%)]	Loss: 5.9291	Cost: 12.55s
Train Epoch: 157 [61440/90000 (68%)]	Loss: 6.0263	Cost: 12.06s
Train Epoch: 157 [81920/90000 (91%)]	Loss: 5.9306	Cost: 11.92s
Train Epoch: 157 	Average Loss: 5.9841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0724

Learning rate: 9.993919335910311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 158 [0/90000 (0%)]	Loss: 6.0500	Cost: 32.23s
Train Epoch: 158 [20480/90000 (23%)]	Loss: 5.9103	Cost: 12.20s
Train Epoch: 158 [40960/90000 (45%)]	Loss: 5.8875	Cost: 9.50s
Train Epoch: 158 [61440/90000 (68%)]	Loss: 6.0483	Cost: 6.11s
Train Epoch: 158 [81920/90000 (91%)]	Loss: 5.9073	Cost: 10.85s
Train Epoch: 158 	Average Loss: 5.9729
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0423

Learning rate: 9.993841644486739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 159 [0/90000 (0%)]	Loss: 6.0186	Cost: 29.76s
Train Epoch: 159 [20480/90000 (23%)]	Loss: 5.9055	Cost: 9.54s
Train Epoch: 159 [40960/90000 (45%)]	Loss: 5.9072	Cost: 25.58s
Train Epoch: 159 [61440/90000 (68%)]	Loss: 5.9495	Cost: 12.86s
Train Epoch: 159 [81920/90000 (91%)]	Loss: 5.9185	Cost: 12.00s
Train Epoch: 159 	Average Loss: 5.9549
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.1010

Learning rate: 9.993763460190757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 160 [0/90000 (0%)]	Loss: 6.1714	Cost: 49.41s
Train Epoch: 160 [20480/90000 (23%)]	Loss: 5.9573	Cost: 6.24s
Train Epoch: 160 [40960/90000 (45%)]	Loss: 5.8571	Cost: 14.44s
Train Epoch: 160 [61440/90000 (68%)]	Loss: 5.8533	Cost: 8.53s
Train Epoch: 160 [81920/90000 (91%)]	Loss: 5.9769	Cost: 8.66s
Train Epoch: 160 	Average Loss: 5.9488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0418

Learning rate: 9.993684783030081e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 161 [0/90000 (0%)]	Loss: 6.0968	Cost: 30.25s
Train Epoch: 161 [20480/90000 (23%)]	Loss: 5.9502	Cost: 7.71s
Train Epoch: 161 [40960/90000 (45%)]	Loss: 5.8619	Cost: 24.76s
Train Epoch: 161 [61440/90000 (68%)]	Loss: 5.9498	Cost: 11.97s
Train Epoch: 161 [81920/90000 (91%)]	Loss: 5.7687	Cost: 12.18s
Train Epoch: 161 	Average Loss: 5.9566
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0672

Learning rate: 9.993605613012475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 162 [0/90000 (0%)]	Loss: 6.1717	Cost: 43.37s
Train Epoch: 162 [20480/90000 (23%)]	Loss: 5.9350	Cost: 10.15s
Train Epoch: 162 [40960/90000 (45%)]	Loss: 5.8706	Cost: 10.84s
Train Epoch: 162 [61440/90000 (68%)]	Loss: 5.8969	Cost: 6.45s
Train Epoch: 162 [81920/90000 (91%)]	Loss: 5.9388	Cost: 12.05s
Train Epoch: 162 	Average Loss: 5.9283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0165

Learning rate: 9.993525950145754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 163 [0/90000 (0%)]	Loss: 5.8960	Cost: 29.91s
Train Epoch: 163 [20480/90000 (23%)]	Loss: 5.9581	Cost: 7.38s
Train Epoch: 163 [40960/90000 (45%)]	Loss: 5.8397	Cost: 22.12s
Train Epoch: 163 [61440/90000 (68%)]	Loss: 5.9432	Cost: 12.47s
Train Epoch: 163 [81920/90000 (91%)]	Loss: 5.8286	Cost: 12.02s
Train Epoch: 163 	Average Loss: 5.9291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0622

Learning rate: 9.993445794437781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 164 [0/90000 (0%)]	Loss: 6.0316	Cost: 85.00s
Train Epoch: 164 [20480/90000 (23%)]	Loss: 5.9196	Cost: 14.63s
Train Epoch: 164 [40960/90000 (45%)]	Loss: 5.7855	Cost: 18.41s
Train Epoch: 164 [61440/90000 (68%)]	Loss: 5.8699	Cost: 10.88s
Train Epoch: 164 [81920/90000 (91%)]	Loss: 5.8607	Cost: 24.65s
Train Epoch: 164 	Average Loss: 5.9117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0034

Learning rate: 9.993365145896465e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 165 [0/90000 (0%)]	Loss: 6.0262	Cost: 39.32s
Train Epoch: 165 [20480/90000 (23%)]	Loss: 5.9498	Cost: 6.49s
Train Epoch: 165 [40960/90000 (45%)]	Loss: 5.7862	Cost: 17.92s
Train Epoch: 165 [61440/90000 (68%)]	Loss: 5.8780	Cost: 12.11s
Train Epoch: 165 [81920/90000 (91%)]	Loss: 5.7621	Cost: 11.83s
Train Epoch: 165 	Average Loss: 5.8893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9735

Saving model as e165_model.pt & e165_waveforms_supplementary.hdf5
Learning rate: 9.993284004529768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 166 [0/90000 (0%)]	Loss: 5.9759	Cost: 30.95s
Train Epoch: 166 [20480/90000 (23%)]	Loss: 6.0114	Cost: 8.37s
Train Epoch: 166 [40960/90000 (45%)]	Loss: 5.8043	Cost: 11.40s
Train Epoch: 166 [61440/90000 (68%)]	Loss: 5.8925	Cost: 6.17s
Train Epoch: 166 [81920/90000 (91%)]	Loss: 5.7087	Cost: 15.74s
Train Epoch: 166 	Average Loss: 5.8805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9731

Saving model as e166_model.pt & e166_waveforms_supplementary.hdf5
Learning rate: 9.993202370345697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 167 [0/90000 (0%)]	Loss: 5.9566	Cost: 43.42s
Train Epoch: 167 [20480/90000 (23%)]	Loss: 5.8308	Cost: 13.57s
Train Epoch: 167 [40960/90000 (45%)]	Loss: 5.7291	Cost: 13.48s
Train Epoch: 167 [61440/90000 (68%)]	Loss: 5.8501	Cost: 12.21s
Train Epoch: 167 [81920/90000 (91%)]	Loss: 5.8063	Cost: 11.93s
Train Epoch: 167 	Average Loss: 5.8908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0331

Learning rate: 9.993120243352309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 168 [0/90000 (0%)]	Loss: 6.1272	Cost: 44.97s
Train Epoch: 168 [20480/90000 (23%)]	Loss: 5.8926	Cost: 7.53s
Train Epoch: 168 [40960/90000 (45%)]	Loss: 5.8409	Cost: 11.36s
Train Epoch: 168 [61440/90000 (68%)]	Loss: 5.7543	Cost: 8.99s
Train Epoch: 168 [81920/90000 (91%)]	Loss: 5.7880	Cost: 8.88s
Train Epoch: 168 	Average Loss: 5.8727
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9734

Learning rate: 9.993037623557708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 169 [0/90000 (0%)]	Loss: 6.1665	Cost: 29.12s
Train Epoch: 169 [20480/90000 (23%)]	Loss: 5.8840	Cost: 12.85s
Train Epoch: 169 [40960/90000 (45%)]	Loss: 5.8346	Cost: 17.44s
Train Epoch: 169 [61440/90000 (68%)]	Loss: 5.9119	Cost: 12.33s
Train Epoch: 169 [81920/90000 (91%)]	Loss: 5.7426	Cost: 11.89s
Train Epoch: 169 	Average Loss: 5.8519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 6.0018

Learning rate: 9.992954510970051e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 170 [0/90000 (0%)]	Loss: 5.8755	Cost: 39.58s
Train Epoch: 170 [20480/90000 (23%)]	Loss: 5.8122	Cost: 12.50s
Train Epoch: 170 [40960/90000 (45%)]	Loss: 5.7036	Cost: 12.08s
Train Epoch: 170 [61440/90000 (68%)]	Loss: 5.7747	Cost: 10.68s
Train Epoch: 170 [81920/90000 (91%)]	Loss: 5.6777	Cost: 6.10s
Train Epoch: 170 	Average Loss: 5.8368
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9722

Saving model as e170_model.pt & e170_waveforms_supplementary.hdf5
Learning rate: 9.99287090559754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 171 [0/90000 (0%)]	Loss: 5.9311	Cost: 28.17s
Train Epoch: 171 [20480/90000 (23%)]	Loss: 5.8144	Cost: 6.55s
Train Epoch: 171 [40960/90000 (45%)]	Loss: 5.7027	Cost: 13.77s
Train Epoch: 171 [61440/90000 (68%)]	Loss: 5.7321	Cost: 8.62s
Train Epoch: 171 [81920/90000 (91%)]	Loss: 5.8105	Cost: 7.35s
Train Epoch: 171 	Average Loss: 5.8337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9225

Saving model as e171_model.pt & e171_waveforms_supplementary.hdf5
Learning rate: 9.992786807448426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 172 [0/90000 (0%)]	Loss: 6.0631	Cost: 34.68s
Train Epoch: 172 [20480/90000 (23%)]	Loss: 5.7979	Cost: 12.87s
Train Epoch: 172 [40960/90000 (45%)]	Loss: 5.7275	Cost: 14.97s
Train Epoch: 172 [61440/90000 (68%)]	Loss: 5.8091	Cost: 12.89s
Train Epoch: 172 [81920/90000 (91%)]	Loss: 5.8350	Cost: 11.36s
Train Epoch: 172 	Average Loss: 5.8277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8900

Saving model as e172_model.pt & e172_waveforms_supplementary.hdf5
Learning rate: 9.992702216531012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 173 [0/90000 (0%)]	Loss: 5.7045	Cost: 34.71s
Train Epoch: 173 [20480/90000 (23%)]	Loss: 5.8288	Cost: 9.62s
Train Epoch: 173 [40960/90000 (45%)]	Loss: 5.7161	Cost: 12.83s
Train Epoch: 173 [61440/90000 (68%)]	Loss: 5.7804	Cost: 8.79s
Train Epoch: 173 [81920/90000 (91%)]	Loss: 5.7131	Cost: 11.46s
Train Epoch: 173 	Average Loss: 5.8028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8681

Saving model as e173_model.pt & e173_waveforms_supplementary.hdf5
Learning rate: 9.992617132853643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 174 [0/90000 (0%)]	Loss: 5.8003	Cost: 32.98s
Train Epoch: 174 [20480/90000 (23%)]	Loss: 5.7612	Cost: 10.43s
Train Epoch: 174 [40960/90000 (45%)]	Loss: 5.7065	Cost: 16.83s
Train Epoch: 174 [61440/90000 (68%)]	Loss: 5.8472	Cost: 12.11s
Train Epoch: 174 [81920/90000 (91%)]	Loss: 5.6609	Cost: 12.21s
Train Epoch: 174 	Average Loss: 5.7927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8661

Saving model as e174_model.pt & e174_waveforms_supplementary.hdf5
Learning rate: 9.992531556424718e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 175 [0/90000 (0%)]	Loss: 5.7915	Cost: 50.58s
Train Epoch: 175 [20480/90000 (23%)]	Loss: 5.7673	Cost: 7.03s
Train Epoch: 175 [40960/90000 (45%)]	Loss: 5.7227	Cost: 14.26s
Train Epoch: 175 [61440/90000 (68%)]	Loss: 5.8069	Cost: 8.65s
Train Epoch: 175 [81920/90000 (91%)]	Loss: 5.7097	Cost: 8.03s
Train Epoch: 175 	Average Loss: 5.7917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8815

Learning rate: 9.992445487252684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 176 [0/90000 (0%)]	Loss: 5.9897	Cost: 29.68s
Train Epoch: 176 [20480/90000 (23%)]	Loss: 5.7205	Cost: 8.50s
Train Epoch: 176 [40960/90000 (45%)]	Loss: 5.6306	Cost: 16.70s
Train Epoch: 176 [61440/90000 (68%)]	Loss: 5.6935	Cost: 11.97s
Train Epoch: 176 [81920/90000 (91%)]	Loss: 5.7741	Cost: 12.00s
Train Epoch: 176 	Average Loss: 5.7826
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8703

Learning rate: 9.992358925346033e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 177 [0/90000 (0%)]	Loss: 5.9466	Cost: 32.47s
Train Epoch: 177 [20480/90000 (23%)]	Loss: 5.8613	Cost: 10.63s
Train Epoch: 177 [40960/90000 (45%)]	Loss: 5.6388	Cost: 8.92s
Train Epoch: 177 [61440/90000 (68%)]	Loss: 5.7968	Cost: 6.11s
Train Epoch: 177 [81920/90000 (91%)]	Loss: 5.7278	Cost: 13.49s
Train Epoch: 177 	Average Loss: 5.7805
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.9378

Learning rate: 9.992271870713308e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 178 [0/90000 (0%)]	Loss: 5.8553	Cost: 29.79s
Train Epoch: 178 [20480/90000 (23%)]	Loss: 5.8444	Cost: 10.69s
Train Epoch: 178 [40960/90000 (45%)]	Loss: 5.6623	Cost: 21.30s
Train Epoch: 178 [61440/90000 (68%)]	Loss: 5.7508	Cost: 13.13s
Train Epoch: 178 [81920/90000 (91%)]	Loss: 5.7751	Cost: 12.20s
Train Epoch: 178 	Average Loss: 5.7725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8700

Learning rate: 9.992184323363105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 179 [0/90000 (0%)]	Loss: 5.9023	Cost: 52.73s
Train Epoch: 179 [20480/90000 (23%)]	Loss: 5.7435	Cost: 6.38s
Train Epoch: 179 [40960/90000 (45%)]	Loss: 5.6381	Cost: 14.37s
Train Epoch: 179 [61440/90000 (68%)]	Loss: 5.7674	Cost: 8.48s
Train Epoch: 179 [81920/90000 (91%)]	Loss: 5.8582	Cost: 8.33s
Train Epoch: 179 	Average Loss: 5.7726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8600

Saving model as e179_model.pt & e179_waveforms_supplementary.hdf5
Learning rate: 9.992096283304062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 180 [0/90000 (0%)]	Loss: 5.9649	Cost: 29.72s
Train Epoch: 180 [20480/90000 (23%)]	Loss: 5.8071	Cost: 7.87s
Train Epoch: 180 [40960/90000 (45%)]	Loss: 5.6436	Cost: 17.26s
Train Epoch: 180 [61440/90000 (68%)]	Loss: 5.7175	Cost: 13.15s
Train Epoch: 180 [81920/90000 (91%)]	Loss: 5.6308	Cost: 12.21s
Train Epoch: 180 	Average Loss: 5.7428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8927

Learning rate: 9.992007750544869e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 181 [0/90000 (0%)]	Loss: 5.8219	Cost: 45.22s
Train Epoch: 181 [20480/90000 (23%)]	Loss: 5.8431	Cost: 11.72s
Train Epoch: 181 [40960/90000 (45%)]	Loss: 5.7527	Cost: 8.03s
Train Epoch: 181 [61440/90000 (68%)]	Loss: 5.7246	Cost: 6.35s
Train Epoch: 181 [81920/90000 (91%)]	Loss: 5.5761	Cost: 12.28s
Train Epoch: 181 	Average Loss: 5.7631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8615

Learning rate: 9.991918725094262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 182 [0/90000 (0%)]	Loss: 5.7630	Cost: 30.69s
Train Epoch: 182 [20480/90000 (23%)]	Loss: 5.7977	Cost: 7.35s
Train Epoch: 182 [40960/90000 (45%)]	Loss: 5.5196	Cost: 17.93s
Train Epoch: 182 [61440/90000 (68%)]	Loss: 5.7210	Cost: 14.60s
Train Epoch: 182 [81920/90000 (91%)]	Loss: 5.6273	Cost: 14.80s
Train Epoch: 182 	Average Loss: 5.7111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8088

Saving model as e182_model.pt & e182_waveforms_supplementary.hdf5
Learning rate: 9.99182920696103e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 183 [0/90000 (0%)]	Loss: 5.8655	Cost: 34.51s
Train Epoch: 183 [20480/90000 (23%)]	Loss: 5.7261	Cost: 11.51s
Train Epoch: 183 [40960/90000 (45%)]	Loss: 5.6690	Cost: 10.78s
Train Epoch: 183 [61440/90000 (68%)]	Loss: 5.6456	Cost: 7.74s
Train Epoch: 183 [81920/90000 (91%)]	Loss: 5.6259	Cost: 13.55s
Train Epoch: 183 	Average Loss: 5.7106
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8917

Learning rate: 9.991739196154006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 184 [0/90000 (0%)]	Loss: 5.7668	Cost: 33.69s
Train Epoch: 184 [20480/90000 (23%)]	Loss: 5.6784	Cost: 9.91s
Train Epoch: 184 [40960/90000 (45%)]	Loss: 5.5798	Cost: 19.08s
Train Epoch: 184 [61440/90000 (68%)]	Loss: 5.7847	Cost: 12.16s
Train Epoch: 184 [81920/90000 (91%)]	Loss: 5.6527	Cost: 12.14s
Train Epoch: 184 	Average Loss: 5.7083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8239

Learning rate: 9.991648692682075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 185 [0/90000 (0%)]	Loss: 5.6739	Cost: 42.52s
Train Epoch: 185 [20480/90000 (23%)]	Loss: 5.6930	Cost: 6.18s
Train Epoch: 185 [40960/90000 (45%)]	Loss: 5.6482	Cost: 14.64s
Train Epoch: 185 [61440/90000 (68%)]	Loss: 5.6718	Cost: 8.72s
Train Epoch: 185 [81920/90000 (91%)]	Loss: 5.5676	Cost: 10.49s
Train Epoch: 185 	Average Loss: 5.6956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7691

Saving model as e185_model.pt & e185_waveforms_supplementary.hdf5
Learning rate: 9.991557696554169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 186 [0/90000 (0%)]	Loss: 5.7407	Cost: 29.94s
Train Epoch: 186 [20480/90000 (23%)]	Loss: 5.6142	Cost: 10.83s
Train Epoch: 186 [40960/90000 (45%)]	Loss: 5.5298	Cost: 16.10s
Train Epoch: 186 [61440/90000 (68%)]	Loss: 5.6920	Cost: 12.28s
Train Epoch: 186 [81920/90000 (91%)]	Loss: 5.6189	Cost: 12.20s
Train Epoch: 186 	Average Loss: 5.6849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8233

Learning rate: 9.99146620777927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 187 [0/90000 (0%)]	Loss: 5.8346	Cost: 32.11s
Train Epoch: 187 [20480/90000 (23%)]	Loss: 5.7453	Cost: 8.82s
Train Epoch: 187 [40960/90000 (45%)]	Loss: 5.5255	Cost: 9.97s
Train Epoch: 187 [61440/90000 (68%)]	Loss: 5.6619	Cost: 6.67s
Train Epoch: 187 [81920/90000 (91%)]	Loss: 5.5764	Cost: 13.89s
Train Epoch: 187 	Average Loss: 5.6757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8022

Learning rate: 9.991374226366404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 188 [0/90000 (0%)]	Loss: 5.8849	Cost: 28.86s
Train Epoch: 188 [20480/90000 (23%)]	Loss: 5.6809	Cost: 8.95s
Train Epoch: 188 [40960/90000 (45%)]	Loss: 5.5753	Cost: 23.17s
Train Epoch: 188 [61440/90000 (68%)]	Loss: 5.5863	Cost: 11.61s
Train Epoch: 188 [81920/90000 (91%)]	Loss: 5.5563	Cost: 16.25s
Train Epoch: 188 	Average Loss: 5.6722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7969

Learning rate: 9.991281752324654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 189 [0/90000 (0%)]	Loss: 5.6228	Cost: 43.98s
Train Epoch: 189 [20480/90000 (23%)]	Loss: 5.6714	Cost: 11.94s
Train Epoch: 189 [40960/90000 (45%)]	Loss: 5.5850	Cost: 7.76s
Train Epoch: 189 [61440/90000 (68%)]	Loss: 5.6763	Cost: 6.26s
Train Epoch: 189 [81920/90000 (91%)]	Loss: 5.6139	Cost: 13.84s
Train Epoch: 189 	Average Loss: 5.6499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.8100

Learning rate: 9.991188785663142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 190 [0/90000 (0%)]	Loss: 5.8329	Cost: 30.10s
Train Epoch: 190 [20480/90000 (23%)]	Loss: 5.6033	Cost: 7.85s
Train Epoch: 190 [40960/90000 (45%)]	Loss: 5.5181	Cost: 18.79s
Train Epoch: 190 [61440/90000 (68%)]	Loss: 5.5033	Cost: 12.29s
Train Epoch: 190 [81920/90000 (91%)]	Loss: 5.4792	Cost: 12.10s
Train Epoch: 190 	Average Loss: 5.6367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7474

Saving model as e190_model.pt & e190_waveforms_supplementary.hdf5
Learning rate: 9.991095326391049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 191 [0/90000 (0%)]	Loss: 5.8078	Cost: 41.90s
Train Epoch: 191 [20480/90000 (23%)]	Loss: 5.6485	Cost: 12.12s
Train Epoch: 191 [40960/90000 (45%)]	Loss: 5.4944	Cost: 7.20s
Train Epoch: 191 [61440/90000 (68%)]	Loss: 5.6123	Cost: 6.13s
Train Epoch: 191 [81920/90000 (91%)]	Loss: 5.5235	Cost: 13.81s
Train Epoch: 191 	Average Loss: 5.6392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7428

Saving model as e191_model.pt & e191_waveforms_supplementary.hdf5
Learning rate: 9.991001374517595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 192 [0/90000 (0%)]	Loss: 5.5974	Cost: 28.76s
Train Epoch: 192 [20480/90000 (23%)]	Loss: 5.6981	Cost: 7.06s
Train Epoch: 192 [40960/90000 (45%)]	Loss: 5.5032	Cost: 18.80s
Train Epoch: 192 [61440/90000 (68%)]	Loss: 5.5352	Cost: 14.68s
Train Epoch: 192 [81920/90000 (91%)]	Loss: 5.5549	Cost: 13.42s
Train Epoch: 192 	Average Loss: 5.6269
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7804

Learning rate: 9.990906930052053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 193 [0/90000 (0%)]	Loss: 5.8077	Cost: 39.08s
Train Epoch: 193 [20480/90000 (23%)]	Loss: 5.6049	Cost: 13.25s
Train Epoch: 193 [40960/90000 (45%)]	Loss: 5.4470	Cost: 11.48s
Train Epoch: 193 [61440/90000 (68%)]	Loss: 5.5262	Cost: 8.16s
Train Epoch: 193 [81920/90000 (91%)]	Loss: 5.4366	Cost: 10.17s
Train Epoch: 193 	Average Loss: 5.6207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7578

Learning rate: 9.990811993003745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 194 [0/90000 (0%)]	Loss: 5.6395	Cost: 35.55s
Train Epoch: 194 [20480/90000 (23%)]	Loss: 5.6438	Cost: 8.58s
Train Epoch: 194 [40960/90000 (45%)]	Loss: 5.5139	Cost: 11.56s
Train Epoch: 194 [61440/90000 (68%)]	Loss: 5.4680	Cost: 7.10s
Train Epoch: 194 [81920/90000 (91%)]	Loss: 5.4486	Cost: 18.58s
Train Epoch: 194 	Average Loss: 5.5960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7096

Saving model as e194_model.pt & e194_waveforms_supplementary.hdf5
Learning rate: 9.990716563382042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 195 [0/90000 (0%)]	Loss: 5.7009	Cost: 41.49s
Train Epoch: 195 [20480/90000 (23%)]	Loss: 5.6776	Cost: 13.03s
Train Epoch: 195 [40960/90000 (45%)]	Loss: 5.4848	Cost: 12.55s
Train Epoch: 195 [61440/90000 (68%)]	Loss: 5.5037	Cost: 10.35s
Train Epoch: 195 [81920/90000 (91%)]	Loss: 5.5678	Cost: 6.59s
Train Epoch: 195 	Average Loss: 5.6053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7158

Learning rate: 9.990620641196361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 196 [0/90000 (0%)]	Loss: 5.6535	Cost: 35.77s
Train Epoch: 196 [20480/90000 (23%)]	Loss: 5.6651	Cost: 8.05s
Train Epoch: 196 [40960/90000 (45%)]	Loss: 5.4855	Cost: 13.71s
Train Epoch: 196 [61440/90000 (68%)]	Loss: 5.6096	Cost: 8.54s
Train Epoch: 196 [81920/90000 (91%)]	Loss: 5.5448	Cost: 6.67s
Train Epoch: 196 	Average Loss: 5.5846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7539

Learning rate: 9.99052422645617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 197 [0/90000 (0%)]	Loss: 5.8026	Cost: 28.93s
Train Epoch: 197 [20480/90000 (23%)]	Loss: 5.5687	Cost: 8.72s
Train Epoch: 197 [40960/90000 (45%)]	Loss: 5.3071	Cost: 17.62s
Train Epoch: 197 [61440/90000 (68%)]	Loss: 5.5043	Cost: 11.75s
Train Epoch: 197 [81920/90000 (91%)]	Loss: 5.4893	Cost: 11.96s
Train Epoch: 197 	Average Loss: 5.5798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7368

Learning rate: 9.990427319170984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 198 [0/90000 (0%)]	Loss: 5.6619	Cost: 31.83s
Train Epoch: 198 [20480/90000 (23%)]	Loss: 5.6701	Cost: 12.36s
Train Epoch: 198 [40960/90000 (45%)]	Loss: 5.5069	Cost: 8.12s
Train Epoch: 198 [61440/90000 (68%)]	Loss: 5.5575	Cost: 7.20s
Train Epoch: 198 [81920/90000 (91%)]	Loss: 5.4741	Cost: 13.79s
Train Epoch: 198 	Average Loss: 5.5894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6963

Saving model as e198_model.pt & e198_waveforms_supplementary.hdf5
Learning rate: 9.990329919350368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 199 [0/90000 (0%)]	Loss: 5.7309	Cost: 82.12s
Train Epoch: 199 [20480/90000 (23%)]	Loss: 5.7059	Cost: 16.71s
Train Epoch: 199 [40960/90000 (45%)]	Loss: 5.3835	Cost: 29.23s
Train Epoch: 199 [61440/90000 (68%)]	Loss: 5.5468	Cost: 17.34s
Train Epoch: 199 [81920/90000 (91%)]	Loss: 5.5105	Cost: 21.17s
Train Epoch: 199 	Average Loss: 5.5562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7436

Learning rate: 9.990232027003935e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 200 [0/90000 (0%)]	Loss: 5.7710	Cost: 29.75s
Train Epoch: 200 [20480/90000 (23%)]	Loss: 5.5643	Cost: 10.13s
Train Epoch: 200 [40960/90000 (45%)]	Loss: 5.4148	Cost: 9.76s
Train Epoch: 200 [61440/90000 (68%)]	Loss: 5.5940	Cost: 8.18s
Train Epoch: 200 [81920/90000 (91%)]	Loss: 5.5536	Cost: 18.83s
Train Epoch: 200 	Average Loss: 5.5703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7112

Learning rate: 9.990133642141346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 201 [0/90000 (0%)]	Loss: 5.8491	Cost: 37.96s
Train Epoch: 201 [20480/90000 (23%)]	Loss: 5.6316	Cost: 14.33s
Train Epoch: 201 [40960/90000 (45%)]	Loss: 5.4571	Cost: 12.19s
Train Epoch: 201 [61440/90000 (68%)]	Loss: 5.6109	Cost: 11.80s
Train Epoch: 201 [81920/90000 (91%)]	Loss: 5.4574	Cost: 6.27s
Train Epoch: 201 	Average Loss: 5.5684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6787

Saving model as e201_model.pt & e201_waveforms_supplementary.hdf5
Learning rate: 9.990034764772311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 202 [0/90000 (0%)]	Loss: 5.5497	Cost: 28.74s
Train Epoch: 202 [20480/90000 (23%)]	Loss: 5.6284	Cost: 8.77s
Train Epoch: 202 [40960/90000 (45%)]	Loss: 5.4272	Cost: 10.21s
Train Epoch: 202 [61440/90000 (68%)]	Loss: 5.5102	Cost: 9.01s
Train Epoch: 202 [81920/90000 (91%)]	Loss: 5.4821	Cost: 11.88s
Train Epoch: 202 	Average Loss: 5.5322
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6898

Learning rate: 9.98993539490659e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 203 [0/90000 (0%)]	Loss: 5.7672	Cost: 31.07s
Train Epoch: 203 [20480/90000 (23%)]	Loss: 5.4293	Cost: 13.29s
Train Epoch: 203 [40960/90000 (45%)]	Loss: 5.4313	Cost: 14.69s
Train Epoch: 203 [61440/90000 (68%)]	Loss: 5.5374	Cost: 12.69s
Train Epoch: 203 [81920/90000 (91%)]	Loss: 5.4357	Cost: 9.08s
Train Epoch: 203 	Average Loss: 5.5357
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7255

Learning rate: 9.989835532553989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 204 [0/90000 (0%)]	Loss: 5.7594	Cost: 33.93s
Train Epoch: 204 [20480/90000 (23%)]	Loss: 5.5667	Cost: 11.43s
Train Epoch: 204 [40960/90000 (45%)]	Loss: 5.3484	Cost: 11.04s
Train Epoch: 204 [61440/90000 (68%)]	Loss: 5.5477	Cost: 9.17s
Train Epoch: 204 [81920/90000 (91%)]	Loss: 5.4042	Cost: 15.76s
Train Epoch: 204 	Average Loss: 5.5278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6944

Learning rate: 9.989735177724366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 205 [0/90000 (0%)]	Loss: 5.6777	Cost: 32.87s
Train Epoch: 205 [20480/90000 (23%)]	Loss: 5.5558	Cost: 6.49s
Train Epoch: 205 [40960/90000 (45%)]	Loss: 5.3472	Cost: 20.60s
Train Epoch: 205 [61440/90000 (68%)]	Loss: 5.5117	Cost: 12.06s
Train Epoch: 205 [81920/90000 (91%)]	Loss: 5.3686	Cost: 12.06s
Train Epoch: 205 	Average Loss: 5.4998
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6756

Saving model as e205_model.pt & e205_waveforms_supplementary.hdf5
Learning rate: 9.989634330427624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 206 [0/90000 (0%)]	Loss: 5.6739	Cost: 34.40s
Train Epoch: 206 [20480/90000 (23%)]	Loss: 5.5113	Cost: 10.46s
Train Epoch: 206 [40960/90000 (45%)]	Loss: 5.4040	Cost: 10.55s
Train Epoch: 206 [61440/90000 (68%)]	Loss: 5.4304	Cost: 6.51s
Train Epoch: 206 [81920/90000 (91%)]	Loss: 5.4328	Cost: 13.46s
Train Epoch: 206 	Average Loss: 5.4942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6414

Saving model as e206_model.pt & e206_waveforms_supplementary.hdf5
Learning rate: 9.989532990673716e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 207 [0/90000 (0%)]	Loss: 5.5476	Cost: 31.84s
Train Epoch: 207 [20480/90000 (23%)]	Loss: 5.5114	Cost: 10.06s
Train Epoch: 207 [40960/90000 (45%)]	Loss: 5.4040	Cost: 13.52s
Train Epoch: 207 [61440/90000 (68%)]	Loss: 5.4512	Cost: 13.36s
Train Epoch: 207 [81920/90000 (91%)]	Loss: 5.4438	Cost: 11.84s
Train Epoch: 207 	Average Loss: 5.4967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6326

Saving model as e207_model.pt & e207_waveforms_supplementary.hdf5
Learning rate: 9.989431158472645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 208 [0/90000 (0%)]	Loss: 5.6747	Cost: 41.95s
Train Epoch: 208 [20480/90000 (23%)]	Loss: 5.6276	Cost: 11.96s
Train Epoch: 208 [40960/90000 (45%)]	Loss: 5.3877	Cost: 12.07s
Train Epoch: 208 [61440/90000 (68%)]	Loss: 5.4764	Cost: 8.46s
Train Epoch: 208 [81920/90000 (91%)]	Loss: 5.3968	Cost: 6.23s
Train Epoch: 208 	Average Loss: 5.4996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6636

Learning rate: 9.98932883383446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 209 [0/90000 (0%)]	Loss: 5.6730	Cost: 29.26s
Train Epoch: 209 [20480/90000 (23%)]	Loss: 5.4771	Cost: 9.04s
Train Epoch: 209 [40960/90000 (45%)]	Loss: 5.2840	Cost: 10.75s
Train Epoch: 209 [61440/90000 (68%)]	Loss: 5.4448	Cost: 8.66s
Train Epoch: 209 [81920/90000 (91%)]	Loss: 5.4657	Cost: 9.38s
Train Epoch: 209 	Average Loss: 5.4958
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.7167

Learning rate: 9.989226016769262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 210 [0/90000 (0%)]	Loss: 5.5858	Cost: 29.11s
Train Epoch: 210 [20480/90000 (23%)]	Loss: 5.4730	Cost: 10.71s
Train Epoch: 210 [40960/90000 (45%)]	Loss: 5.3951	Cost: 15.33s
Train Epoch: 210 [61440/90000 (68%)]	Loss: 5.4389	Cost: 13.64s
Train Epoch: 210 [81920/90000 (91%)]	Loss: 5.4740	Cost: 11.94s
Train Epoch: 210 	Average Loss: 5.4664
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6901

Learning rate: 9.989122707287198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 211 [0/90000 (0%)]	Loss: 5.7712	Cost: 47.83s
Train Epoch: 211 [20480/90000 (23%)]	Loss: 5.5091	Cost: 11.72s
Train Epoch: 211 [40960/90000 (45%)]	Loss: 5.3983	Cost: 7.54s
Train Epoch: 211 [61440/90000 (68%)]	Loss: 5.3965	Cost: 6.16s
Train Epoch: 211 [81920/90000 (91%)]	Loss: 5.3294	Cost: 11.59s
Train Epoch: 211 	Average Loss: 5.4715
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5865

Saving model as e211_model.pt & e211_waveforms_supplementary.hdf5
Learning rate: 9.989018905398462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 212 [0/90000 (0%)]	Loss: 5.6262	Cost: 28.79s
Train Epoch: 212 [20480/90000 (23%)]	Loss: 5.5669	Cost: 7.20s
Train Epoch: 212 [40960/90000 (45%)]	Loss: 5.2851	Cost: 18.23s
Train Epoch: 212 [61440/90000 (68%)]	Loss: 5.4014	Cost: 13.59s
Train Epoch: 212 [81920/90000 (91%)]	Loss: 5.3333	Cost: 12.41s
Train Epoch: 212 	Average Loss: 5.4593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6198

Learning rate: 9.9889146111133e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 213 [0/90000 (0%)]	Loss: 5.6548	Cost: 35.98s
Train Epoch: 213 [20480/90000 (23%)]	Loss: 5.4641	Cost: 12.21s
Train Epoch: 213 [40960/90000 (45%)]	Loss: 5.3709	Cost: 7.95s
Train Epoch: 213 [61440/90000 (68%)]	Loss: 5.3759	Cost: 7.37s
Train Epoch: 213 [81920/90000 (91%)]	Loss: 5.2353	Cost: 15.39s
Train Epoch: 213 	Average Loss: 5.4534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5325

Saving model as e213_model.pt & e213_waveforms_supplementary.hdf5
Learning rate: 9.988809824442008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 214 [0/90000 (0%)]	Loss: 5.5500	Cost: 28.04s
Train Epoch: 214 [20480/90000 (23%)]	Loss: 5.5589	Cost: 10.22s
Train Epoch: 214 [40960/90000 (45%)]	Loss: 5.3879	Cost: 13.84s
Train Epoch: 214 [61440/90000 (68%)]	Loss: 5.4569	Cost: 12.96s
Train Epoch: 214 [81920/90000 (91%)]	Loss: 5.3172	Cost: 12.01s
Train Epoch: 214 	Average Loss: 5.4206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.6107

Learning rate: 9.988704545394925e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 215 [0/90000 (0%)]	Loss: 5.5373	Cost: 45.58s
Train Epoch: 215 [20480/90000 (23%)]	Loss: 5.5444	Cost: 11.58s
Train Epoch: 215 [40960/90000 (45%)]	Loss: 5.4262	Cost: 11.11s
Train Epoch: 215 [61440/90000 (68%)]	Loss: 5.3841	Cost: 7.15s
Train Epoch: 215 [81920/90000 (91%)]	Loss: 5.3823	Cost: 9.18s
Train Epoch: 215 	Average Loss: 5.4503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5858

Learning rate: 9.988598773982444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 216 [0/90000 (0%)]	Loss: 5.5966	Cost: 44.40s
Train Epoch: 216 [20480/90000 (23%)]	Loss: 5.5241	Cost: 6.00s
Train Epoch: 216 [40960/90000 (45%)]	Loss: 5.3580	Cost: 13.03s
Train Epoch: 216 [61440/90000 (68%)]	Loss: 5.3567	Cost: 10.59s
Train Epoch: 216 [81920/90000 (91%)]	Loss: 5.2484	Cost: 16.78s
Train Epoch: 216 	Average Loss: 5.4325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5672

Learning rate: 9.988492510215002e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 217 [0/90000 (0%)]	Loss: 5.5179	Cost: 39.81s
Train Epoch: 217 [20480/90000 (23%)]	Loss: 5.4558	Cost: 12.56s
Train Epoch: 217 [40960/90000 (45%)]	Loss: 5.3261	Cost: 12.24s
Train Epoch: 217 [61440/90000 (68%)]	Loss: 5.3828	Cost: 7.22s
Train Epoch: 217 [81920/90000 (91%)]	Loss: 5.2635	Cost: 6.38s
Train Epoch: 217 	Average Loss: 5.4067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5244

Saving model as e217_model.pt & e217_waveforms_supplementary.hdf5
Learning rate: 9.988385754103088e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 218 [0/90000 (0%)]	Loss: 5.4801	Cost: 32.26s
Train Epoch: 218 [20480/90000 (23%)]	Loss: 5.4767	Cost: 8.64s
Train Epoch: 218 [40960/90000 (45%)]	Loss: 5.2594	Cost: 14.20s
Train Epoch: 218 [61440/90000 (68%)]	Loss: 5.3051	Cost: 9.13s
Train Epoch: 218 [81920/90000 (91%)]	Loss: 5.3372	Cost: 16.68s
Train Epoch: 218 	Average Loss: 5.4080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5488

Learning rate: 9.988278505657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 219 [0/90000 (0%)]	Loss: 5.4955	Cost: 42.01s
Train Epoch: 219 [20480/90000 (23%)]	Loss: 5.4293	Cost: 12.69s
Train Epoch: 219 [40960/90000 (45%)]	Loss: 5.2419	Cost: 12.26s
Train Epoch: 219 [61440/90000 (68%)]	Loss: 5.3935	Cost: 9.67s
Train Epoch: 219 [81920/90000 (91%)]	Loss: 5.3065	Cost: 6.36s
Train Epoch: 219 	Average Loss: 5.3879
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5208

Saving model as e219_model.pt & e219_waveforms_supplementary.hdf5
Learning rate: 9.988170764888036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 220 [0/90000 (0%)]	Loss: 5.4205	Cost: 30.53s
Train Epoch: 220 [20480/90000 (23%)]	Loss: 5.5102	Cost: 9.93s
Train Epoch: 220 [40960/90000 (45%)]	Loss: 5.1697	Cost: 9.21s
Train Epoch: 220 [61440/90000 (68%)]	Loss: 5.3574	Cost: 7.97s
Train Epoch: 220 [81920/90000 (91%)]	Loss: 5.3026	Cost: 13.61s
Train Epoch: 220 	Average Loss: 5.4031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5076

Saving model as e220_model.pt & e220_waveforms_supplementary.hdf5
Learning rate: 9.988062531806117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 221 [0/90000 (0%)]	Loss: 5.6623	Cost: 44.27s
Train Epoch: 221 [20480/90000 (23%)]	Loss: 5.3757	Cost: 12.79s
Train Epoch: 221 [40960/90000 (45%)]	Loss: 5.2523	Cost: 12.11s
Train Epoch: 221 [61440/90000 (68%)]	Loss: 5.3031	Cost: 10.52s
Train Epoch: 221 [81920/90000 (91%)]	Loss: 5.2040	Cost: 6.34s
Train Epoch: 221 	Average Loss: 5.3833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5082

Learning rate: 9.987953806422163e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 222 [0/90000 (0%)]	Loss: 5.4533	Cost: 28.65s
Train Epoch: 222 [20480/90000 (23%)]	Loss: 5.4194	Cost: 8.85s
Train Epoch: 222 [40960/90000 (45%)]	Loss: 5.2733	Cost: 10.16s
Train Epoch: 222 [61440/90000 (68%)]	Loss: 5.3516	Cost: 9.44s
Train Epoch: 222 [81920/90000 (91%)]	Loss: 5.3691	Cost: 8.05s
Train Epoch: 222 	Average Loss: 5.3822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5684

Learning rate: 9.987844588746906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 223 [0/90000 (0%)]	Loss: 5.5576	Cost: 32.32s
Train Epoch: 223 [20480/90000 (23%)]	Loss: 5.4490	Cost: 12.23s
Train Epoch: 223 [40960/90000 (45%)]	Loss: 5.2266	Cost: 15.52s
Train Epoch: 223 [61440/90000 (68%)]	Loss: 5.3170	Cost: 12.37s
Train Epoch: 223 [81920/90000 (91%)]	Loss: 5.1809	Cost: 12.02s
Train Epoch: 223 	Average Loss: 5.3637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5451

Learning rate: 9.987734878791122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 224 [0/90000 (0%)]	Loss: 5.4399	Cost: 32.57s
Train Epoch: 224 [20480/90000 (23%)]	Loss: 5.3821	Cost: 13.57s
Train Epoch: 224 [40960/90000 (45%)]	Loss: 5.2138	Cost: 12.95s
Train Epoch: 224 [61440/90000 (68%)]	Loss: 5.4018	Cost: 8.11s
Train Epoch: 224 [81920/90000 (91%)]	Loss: 5.3303	Cost: 13.81s
Train Epoch: 224 	Average Loss: 5.3684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5498

Learning rate: 9.987624676565643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 225 [0/90000 (0%)]	Loss: 5.5698	Cost: 33.89s
Train Epoch: 225 [20480/90000 (23%)]	Loss: 5.4166	Cost: 10.40s
Train Epoch: 225 [40960/90000 (45%)]	Loss: 5.2350	Cost: 20.31s
Train Epoch: 225 [61440/90000 (68%)]	Loss: 5.3071	Cost: 11.85s
Train Epoch: 225 [81920/90000 (91%)]	Loss: 5.2778	Cost: 12.23s
Train Epoch: 225 	Average Loss: 5.3611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5045

Saving model as e225_model.pt & e225_waveforms_supplementary.hdf5
Learning rate: 9.987513982081342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 226 [0/90000 (0%)]	Loss: 5.5997	Cost: 41.44s
Train Epoch: 226 [20480/90000 (23%)]	Loss: 5.4523	Cost: 6.80s
Train Epoch: 226 [40960/90000 (45%)]	Loss: 5.1697	Cost: 14.73s
Train Epoch: 226 [61440/90000 (68%)]	Loss: 5.2546	Cost: 8.87s
Train Epoch: 226 [81920/90000 (91%)]	Loss: 5.2542	Cost: 8.91s
Train Epoch: 226 	Average Loss: 5.3276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4592

Saving model as e226_model.pt & e226_waveforms_supplementary.hdf5
Learning rate: 9.987402795349145e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 227 [0/90000 (0%)]	Loss: 5.4842	Cost: 30.23s
Train Epoch: 227 [20480/90000 (23%)]	Loss: 5.4083	Cost: 10.42s
Train Epoch: 227 [40960/90000 (45%)]	Loss: 5.2101	Cost: 13.28s
Train Epoch: 227 [61440/90000 (68%)]	Loss: 5.2837	Cost: 11.97s
Train Epoch: 227 [81920/90000 (91%)]	Loss: 5.2267	Cost: 12.00s
Train Epoch: 227 	Average Loss: 5.3471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5692

Learning rate: 9.987291116380029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 228 [0/90000 (0%)]	Loss: 5.4608	Cost: 31.09s
Train Epoch: 228 [20480/90000 (23%)]	Loss: 5.4430	Cost: 11.84s
Train Epoch: 228 [40960/90000 (45%)]	Loss: 5.2173	Cost: 7.10s
Train Epoch: 228 [61440/90000 (68%)]	Loss: 5.2434	Cost: 6.13s
Train Epoch: 228 [81920/90000 (91%)]	Loss: 5.2774	Cost: 14.91s
Train Epoch: 228 	Average Loss: 5.3178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5369

Learning rate: 9.98717894518501e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 229 [0/90000 (0%)]	Loss: 5.3621	Cost: 29.42s
Train Epoch: 229 [20480/90000 (23%)]	Loss: 5.3525	Cost: 11.36s
Train Epoch: 229 [40960/90000 (45%)]	Loss: 5.2369	Cost: 12.67s
Train Epoch: 229 [61440/90000 (68%)]	Loss: 5.3385	Cost: 14.48s
Train Epoch: 229 [81920/90000 (91%)]	Loss: 5.1844	Cost: 12.22s
Train Epoch: 229 	Average Loss: 5.3058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4681

Learning rate: 9.987066281775164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 230 [0/90000 (0%)]	Loss: 5.4117	Cost: 49.54s
Train Epoch: 230 [20480/90000 (23%)]	Loss: 5.4227	Cost: 12.12s
Train Epoch: 230 [40960/90000 (45%)]	Loss: 5.1390	Cost: 6.68s
Train Epoch: 230 [61440/90000 (68%)]	Loss: 5.3936	Cost: 6.37s
Train Epoch: 230 [81920/90000 (91%)]	Loss: 5.2161	Cost: 13.42s
Train Epoch: 230 	Average Loss: 5.3225
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5257

Learning rate: 9.98695312616161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 231 [0/90000 (0%)]	Loss: 5.5415	Cost: 26.86s
Train Epoch: 231 [20480/90000 (23%)]	Loss: 5.3709	Cost: 9.45s
Train Epoch: 231 [40960/90000 (45%)]	Loss: 5.1678	Cost: 15.95s
Train Epoch: 231 [61440/90000 (68%)]	Loss: 5.2859	Cost: 12.70s
Train Epoch: 231 [81920/90000 (91%)]	Loss: 5.2674	Cost: 11.89s
Train Epoch: 231 	Average Loss: 5.3100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5023

Learning rate: 9.986839478355513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 232 [0/90000 (0%)]	Loss: 5.3926	Cost: 48.96s
Train Epoch: 232 [20480/90000 (23%)]	Loss: 5.3109	Cost: 11.05s
Train Epoch: 232 [40960/90000 (45%)]	Loss: 5.2244	Cost: 8.35s
Train Epoch: 232 [61440/90000 (68%)]	Loss: 5.1672	Cost: 6.45s
Train Epoch: 232 [81920/90000 (91%)]	Loss: 5.1415	Cost: 12.62s
Train Epoch: 232 	Average Loss: 5.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5073

Learning rate: 9.986725338368092e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 233 [0/90000 (0%)]	Loss: 5.4815	Cost: 30.71s
Train Epoch: 233 [20480/90000 (23%)]	Loss: 5.3078	Cost: 12.14s
Train Epoch: 233 [40960/90000 (45%)]	Loss: 5.1468	Cost: 17.22s
Train Epoch: 233 [61440/90000 (68%)]	Loss: 5.3293	Cost: 12.97s
Train Epoch: 233 [81920/90000 (91%)]	Loss: 5.1288	Cost: 12.47s
Train Epoch: 233 	Average Loss: 5.2843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4461

Saving model as e233_model.pt & e233_waveforms_supplementary.hdf5
Learning rate: 9.986610706210612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 234 [0/90000 (0%)]	Loss: 5.4180	Cost: 57.44s
Train Epoch: 234 [20480/90000 (23%)]	Loss: 5.4210	Cost: 6.04s
Train Epoch: 234 [40960/90000 (45%)]	Loss: 5.0675	Cost: 12.29s
Train Epoch: 234 [61440/90000 (68%)]	Loss: 5.3330	Cost: 8.59s
Train Epoch: 234 [81920/90000 (91%)]	Loss: 5.2629	Cost: 8.59s
Train Epoch: 234 	Average Loss: 5.2933
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4092

Saving model as e234_model.pt & e234_waveforms_supplementary.hdf5
Learning rate: 9.986495581894385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 235 [0/90000 (0%)]	Loss: 5.3884	Cost: 31.02s
Train Epoch: 235 [20480/90000 (23%)]	Loss: 5.2877	Cost: 11.49s
Train Epoch: 235 [40960/90000 (45%)]	Loss: 5.1162	Cost: 12.58s
Train Epoch: 235 [61440/90000 (68%)]	Loss: 5.2082	Cost: 12.38s
Train Epoch: 235 [81920/90000 (91%)]	Loss: 5.2264	Cost: 12.07s
Train Epoch: 235 	Average Loss: 5.2778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5007

Learning rate: 9.986379965430775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 236 [0/90000 (0%)]	Loss: 5.4058	Cost: 33.21s
Train Epoch: 236 [20480/90000 (23%)]	Loss: 5.3637	Cost: 8.31s
Train Epoch: 236 [40960/90000 (45%)]	Loss: 5.1735	Cost: 13.99s
Train Epoch: 236 [61440/90000 (68%)]	Loss: 5.2496	Cost: 8.40s
Train Epoch: 236 [81920/90000 (91%)]	Loss: 5.1624	Cost: 8.81s
Train Epoch: 236 	Average Loss: 5.2817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4393

Learning rate: 9.986263856831194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 237 [0/90000 (0%)]	Loss: 5.3808	Cost: 30.17s
Train Epoch: 237 [20480/90000 (23%)]	Loss: 5.3202	Cost: 10.94s
Train Epoch: 237 [40960/90000 (45%)]	Loss: 5.0931	Cost: 17.22s
Train Epoch: 237 [61440/90000 (68%)]	Loss: 5.1414	Cost: 12.73s
Train Epoch: 237 [81920/90000 (91%)]	Loss: 5.0668	Cost: 12.49s
Train Epoch: 237 	Average Loss: 5.2249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4304

Learning rate: 9.9861472561071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 238 [0/90000 (0%)]	Loss: 5.4675	Cost: 31.98s
Train Epoch: 238 [20480/90000 (23%)]	Loss: 5.2459	Cost: 9.33s
Train Epoch: 238 [40960/90000 (45%)]	Loss: 5.0927	Cost: 12.53s
Train Epoch: 238 [61440/90000 (68%)]	Loss: 5.1165	Cost: 8.76s
Train Epoch: 238 [81920/90000 (91%)]	Loss: 5.2597	Cost: 12.27s
Train Epoch: 238 	Average Loss: 5.2458
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.5033

Learning rate: 9.98603016327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 239 [0/90000 (0%)]	Loss: 5.5455	Cost: 48.93s
Train Epoch: 239 [20480/90000 (23%)]	Loss: 5.2322	Cost: 9.41s
Train Epoch: 239 [40960/90000 (45%)]	Loss: 5.0555	Cost: 15.87s
Train Epoch: 239 [61440/90000 (68%)]	Loss: 5.1682	Cost: 12.16s
Train Epoch: 239 [81920/90000 (91%)]	Loss: 4.9869	Cost: 12.05s
Train Epoch: 239 	Average Loss: 5.2245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4192

Learning rate: 9.985912578331452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 240 [0/90000 (0%)]	Loss: 5.3105	Cost: 37.68s
Train Epoch: 240 [20480/90000 (23%)]	Loss: 5.3606	Cost: 9.98s
Train Epoch: 240 [40960/90000 (45%)]	Loss: 5.0585	Cost: 9.72s
Train Epoch: 240 [61440/90000 (68%)]	Loss: 5.0305	Cost: 6.82s
Train Epoch: 240 [81920/90000 (91%)]	Loss: 5.2438	Cost: 14.80s
Train Epoch: 240 	Average Loss: 5.2301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4253

Learning rate: 9.985794501303059e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 241 [0/90000 (0%)]	Loss: 5.4927	Cost: 40.08s
Train Epoch: 241 [20480/90000 (23%)]	Loss: 5.3217	Cost: 10.46s
Train Epoch: 241 [40960/90000 (45%)]	Loss: 5.1836	Cost: 17.45s
Train Epoch: 241 [61440/90000 (68%)]	Loss: 5.1360	Cost: 12.34s
Train Epoch: 241 [81920/90000 (91%)]	Loss: 5.1766	Cost: 11.84s
Train Epoch: 241 	Average Loss: 5.2347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4497

Learning rate: 9.985675932196479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 242 [0/90000 (0%)]	Loss: 5.3029	Cost: 36.02s
Train Epoch: 242 [20480/90000 (23%)]	Loss: 5.2924	Cost: 10.14s
Train Epoch: 242 [40960/90000 (45%)]	Loss: 5.1303	Cost: 8.51s
Train Epoch: 242 [61440/90000 (68%)]	Loss: 5.1625	Cost: 6.31s
Train Epoch: 242 [81920/90000 (91%)]	Loss: 5.1063	Cost: 14.40s
Train Epoch: 242 	Average Loss: 5.2069
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3663

Saving model as e242_model.pt & e242_waveforms_supplementary.hdf5
Learning rate: 9.985556871023408e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 243 [0/90000 (0%)]	Loss: 5.2885	Cost: 35.61s
Train Epoch: 243 [20480/90000 (23%)]	Loss: 5.3366	Cost: 9.26s
Train Epoch: 243 [40960/90000 (45%)]	Loss: 5.0559	Cost: 20.78s
Train Epoch: 243 [61440/90000 (68%)]	Loss: 5.1288	Cost: 12.19s
Train Epoch: 243 [81920/90000 (91%)]	Loss: 5.1135	Cost: 11.94s
Train Epoch: 243 	Average Loss: 5.1764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4457

Learning rate: 9.985437317795604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 244 [0/90000 (0%)]	Loss: 5.3865	Cost: 28.07s
Train Epoch: 244 [20480/90000 (23%)]	Loss: 5.2471	Cost: 6.36s
Train Epoch: 244 [40960/90000 (45%)]	Loss: 5.0617	Cost: 14.55s
Train Epoch: 244 [61440/90000 (68%)]	Loss: 5.1578	Cost: 8.61s
Train Epoch: 244 [81920/90000 (91%)]	Loss: 5.0867	Cost: 8.50s
Train Epoch: 244 	Average Loss: 5.2070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4866

Learning rate: 9.985317272524864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 245 [0/90000 (0%)]	Loss: 5.5428	Cost: 32.34s
Train Epoch: 245 [20480/90000 (23%)]	Loss: 5.1843	Cost: 13.25s
Train Epoch: 245 [40960/90000 (45%)]	Loss: 5.0875	Cost: 19.57s
Train Epoch: 245 [61440/90000 (68%)]	Loss: 5.0907	Cost: 12.55s
Train Epoch: 245 [81920/90000 (91%)]	Loss: 5.1547	Cost: 11.96s
Train Epoch: 245 	Average Loss: 5.1766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4431

Learning rate: 9.985196735223035e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 246 [0/90000 (0%)]	Loss: 5.2775	Cost: 39.65s
Train Epoch: 246 [20480/90000 (23%)]	Loss: 5.1448	Cost: 11.96s
Train Epoch: 246 [40960/90000 (45%)]	Loss: 5.1334	Cost: 8.18s
Train Epoch: 246 [61440/90000 (68%)]	Loss: 5.1059	Cost: 6.62s
Train Epoch: 246 [81920/90000 (91%)]	Loss: 5.0645	Cost: 13.34s
Train Epoch: 246 	Average Loss: 5.1787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4202

Learning rate: 9.985075705902012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 247 [0/90000 (0%)]	Loss: 5.3891	Cost: 29.54s
Train Epoch: 247 [20480/90000 (23%)]	Loss: 5.2185	Cost: 11.20s
Train Epoch: 247 [40960/90000 (45%)]	Loss: 5.0734	Cost: 20.57s
Train Epoch: 247 [61440/90000 (68%)]	Loss: 5.1690	Cost: 12.25s
Train Epoch: 247 [81920/90000 (91%)]	Loss: 5.1356	Cost: 12.26s
Train Epoch: 247 	Average Loss: 5.1855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3907

Learning rate: 9.984954184573743e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 248 [0/90000 (0%)]	Loss: 5.5543	Cost: 54.55s
Train Epoch: 248 [20480/90000 (23%)]	Loss: 5.2340	Cost: 6.48s
Train Epoch: 248 [40960/90000 (45%)]	Loss: 4.9884	Cost: 13.30s
Train Epoch: 248 [61440/90000 (68%)]	Loss: 5.0483	Cost: 8.74s
Train Epoch: 248 [81920/90000 (91%)]	Loss: 5.0313	Cost: 8.38s
Train Epoch: 248 	Average Loss: 5.1520
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3669

Learning rate: 9.984832171250219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 249 [0/90000 (0%)]	Loss: 5.4567	Cost: 28.58s
Train Epoch: 249 [20480/90000 (23%)]	Loss: 5.1990	Cost: 8.31s
Train Epoch: 249 [40960/90000 (45%)]	Loss: 5.0923	Cost: 16.95s
Train Epoch: 249 [61440/90000 (68%)]	Loss: 5.0392	Cost: 12.39s
Train Epoch: 249 [81920/90000 (91%)]	Loss: 5.1351	Cost: 12.22s
Train Epoch: 249 	Average Loss: 5.1666
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.4119

Learning rate: 9.984709665943483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 250 [0/90000 (0%)]	Loss: 5.5062	Cost: 31.84s
Train Epoch: 250 [20480/90000 (23%)]	Loss: 5.2785	Cost: 11.84s
Train Epoch: 250 [40960/90000 (45%)]	Loss: 5.0224	Cost: 10.52s
Train Epoch: 250 [61440/90000 (68%)]	Loss: 5.0806	Cost: 6.45s
Train Epoch: 250 [81920/90000 (91%)]	Loss: 5.0405	Cost: 11.36s
Train Epoch: 250 	Average Loss: 5.1863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3951

Learning rate: 9.98458666866563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 251 [0/90000 (0%)]	Loss: 5.4699	Cost: 35.32s
Train Epoch: 251 [20480/90000 (23%)]	Loss: 5.1431	Cost: 6.58s
Train Epoch: 251 [40960/90000 (45%)]	Loss: 4.9127	Cost: 16.45s
Train Epoch: 251 [61440/90000 (68%)]	Loss: 5.0162	Cost: 9.56s
Train Epoch: 251 [81920/90000 (91%)]	Loss: 5.0132	Cost: 14.67s
Train Epoch: 251 	Average Loss: 5.1404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3560

Saving model as e251_model.pt & e251_waveforms_supplementary.hdf5
Learning rate: 9.984463179428794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 252 [0/90000 (0%)]	Loss: 5.2940	Cost: 50.27s
Train Epoch: 252 [20480/90000 (23%)]	Loss: 5.2160	Cost: 9.99s
Train Epoch: 252 [40960/90000 (45%)]	Loss: 5.0076	Cost: 8.02s
Train Epoch: 252 [61440/90000 (68%)]	Loss: 4.9020	Cost: 6.57s
Train Epoch: 252 [81920/90000 (91%)]	Loss: 4.9994	Cost: 14.56s
Train Epoch: 252 	Average Loss: 5.0977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3463

Saving model as e252_model.pt & e252_waveforms_supplementary.hdf5
Learning rate: 9.984339198245162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 253 [0/90000 (0%)]	Loss: 5.2813	Cost: 33.30s
Train Epoch: 253 [20480/90000 (23%)]	Loss: 5.1853	Cost: 10.07s
Train Epoch: 253 [40960/90000 (45%)]	Loss: 4.9715	Cost: 15.28s
Train Epoch: 253 [61440/90000 (68%)]	Loss: 5.0369	Cost: 12.18s
Train Epoch: 253 [81920/90000 (91%)]	Loss: 5.0928	Cost: 12.26s
Train Epoch: 253 	Average Loss: 5.1207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3439

Saving model as e253_model.pt & e253_waveforms_supplementary.hdf5
Learning rate: 9.984214725126977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 254 [0/90000 (0%)]	Loss: 5.4017	Cost: 29.86s
Train Epoch: 254 [20480/90000 (23%)]	Loss: 5.2712	Cost: 11.15s
Train Epoch: 254 [40960/90000 (45%)]	Loss: 4.9157	Cost: 10.06s
Train Epoch: 254 [61440/90000 (68%)]	Loss: 5.0183	Cost: 9.60s
Train Epoch: 254 [81920/90000 (91%)]	Loss: 5.0259	Cost: 12.08s
Train Epoch: 254 	Average Loss: 5.1180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3688

Learning rate: 9.98408976008652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 255 [0/90000 (0%)]	Loss: 5.3877	Cost: 33.78s
Train Epoch: 255 [20480/90000 (23%)]	Loss: 5.1627	Cost: 10.48s
Train Epoch: 255 [40960/90000 (45%)]	Loss: 4.9003	Cost: 18.21s
Train Epoch: 255 [61440/90000 (68%)]	Loss: 5.0197	Cost: 12.52s
Train Epoch: 255 [81920/90000 (91%)]	Loss: 4.9632	Cost: 11.93s
Train Epoch: 255 	Average Loss: 5.1042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3174

Saving model as e255_model.pt & e255_waveforms_supplementary.hdf5
Learning rate: 9.983964303136122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 256 [0/90000 (0%)]	Loss: 5.2801	Cost: 49.08s
Train Epoch: 256 [20480/90000 (23%)]	Loss: 5.1610	Cost: 10.98s
Train Epoch: 256 [40960/90000 (45%)]	Loss: 4.9451	Cost: 6.94s
Train Epoch: 256 [61440/90000 (68%)]	Loss: 5.1006	Cost: 6.56s
Train Epoch: 256 [81920/90000 (91%)]	Loss: 5.1415	Cost: 13.93s
Train Epoch: 256 	Average Loss: 5.1139
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3636

Learning rate: 9.98383835428817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 257 [0/90000 (0%)]	Loss: 5.3703	Cost: 30.88s
Train Epoch: 257 [20480/90000 (23%)]	Loss: 5.1923	Cost: 7.95s
Train Epoch: 257 [40960/90000 (45%)]	Loss: 4.9762	Cost: 23.86s
Train Epoch: 257 [61440/90000 (68%)]	Loss: 5.0179	Cost: 12.33s
Train Epoch: 257 [81920/90000 (91%)]	Loss: 4.9755	Cost: 12.13s
Train Epoch: 257 	Average Loss: 5.1047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2866

Saving model as e257_model.pt & e257_waveforms_supplementary.hdf5
Learning rate: 9.983711913555091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 258 [0/90000 (0%)]	Loss: 5.3609	Cost: 50.50s
Train Epoch: 258 [20480/90000 (23%)]	Loss: 5.1601	Cost: 6.99s
Train Epoch: 258 [40960/90000 (45%)]	Loss: 4.9393	Cost: 14.21s
Train Epoch: 258 [61440/90000 (68%)]	Loss: 5.0749	Cost: 8.64s
Train Epoch: 258 [81920/90000 (91%)]	Loss: 4.9548	Cost: 9.11s
Train Epoch: 258 	Average Loss: 5.0913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3043

Learning rate: 9.983584980949367e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 259 [0/90000 (0%)]	Loss: 5.2106	Cost: 34.57s
Train Epoch: 259 [20480/90000 (23%)]	Loss: 5.2117	Cost: 11.69s
Train Epoch: 259 [40960/90000 (45%)]	Loss: 4.9901	Cost: 13.06s
Train Epoch: 259 [61440/90000 (68%)]	Loss: 5.0425	Cost: 12.31s
Train Epoch: 259 [81920/90000 (91%)]	Loss: 5.1331	Cost: 12.16s
Train Epoch: 259 	Average Loss: 5.1915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3238

Learning rate: 9.983457556483523e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 260 [0/90000 (0%)]	Loss: 5.4948	Cost: 49.03s
Train Epoch: 260 [20480/90000 (23%)]	Loss: 5.1176	Cost: 11.03s
Train Epoch: 260 [40960/90000 (45%)]	Loss: 4.9699	Cost: 7.42s
Train Epoch: 260 [61440/90000 (68%)]	Loss: 5.0887	Cost: 6.96s
Train Epoch: 260 [81920/90000 (91%)]	Loss: 4.9169	Cost: 13.65s
Train Epoch: 260 	Average Loss: 5.1221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3461

Learning rate: 9.983329640170136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 261 [0/90000 (0%)]	Loss: 5.3403	Cost: 27.07s
Train Epoch: 261 [20480/90000 (23%)]	Loss: 5.1327	Cost: 7.45s
Train Epoch: 261 [40960/90000 (45%)]	Loss: 4.9778	Cost: 17.70s
Train Epoch: 261 [61440/90000 (68%)]	Loss: 4.9812	Cost: 12.24s
Train Epoch: 261 [81920/90000 (91%)]	Loss: 4.9527	Cost: 12.23s
Train Epoch: 261 	Average Loss: 5.0911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3382

Learning rate: 9.983201232021833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 262 [0/90000 (0%)]	Loss: 5.2756	Cost: 36.55s
Train Epoch: 262 [20480/90000 (23%)]	Loss: 5.1511	Cost: 12.35s
Train Epoch: 262 [40960/90000 (45%)]	Loss: 5.0580	Cost: 8.12s
Train Epoch: 262 [61440/90000 (68%)]	Loss: 4.9091	Cost: 9.14s
Train Epoch: 262 [81920/90000 (91%)]	Loss: 4.9625	Cost: 12.39s
Train Epoch: 262 	Average Loss: 5.0709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2795

Saving model as e262_model.pt & e262_waveforms_supplementary.hdf5
Learning rate: 9.983072332051286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 263 [0/90000 (0%)]	Loss: 5.2626	Cost: 34.61s
Train Epoch: 263 [20480/90000 (23%)]	Loss: 5.1025	Cost: 9.14s
Train Epoch: 263 [40960/90000 (45%)]	Loss: 4.9579	Cost: 16.74s
Train Epoch: 263 [61440/90000 (68%)]	Loss: 5.0303	Cost: 12.08s
Train Epoch: 263 [81920/90000 (91%)]	Loss: 4.9753	Cost: 11.89s
Train Epoch: 263 	Average Loss: 5.0547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2709

Saving model as e263_model.pt & e263_waveforms_supplementary.hdf5
Learning rate: 9.982942940271217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 264 [0/90000 (0%)]	Loss: 5.4357	Cost: 38.83s
Train Epoch: 264 [20480/90000 (23%)]	Loss: 5.0347	Cost: 12.52s
Train Epoch: 264 [40960/90000 (45%)]	Loss: 4.9793	Cost: 6.68s
Train Epoch: 264 [61440/90000 (68%)]	Loss: 5.0300	Cost: 6.26s
Train Epoch: 264 [81920/90000 (91%)]	Loss: 4.8773	Cost: 14.04s
Train Epoch: 264 	Average Loss: 5.0428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2871

Learning rate: 9.982813056694397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 265 [0/90000 (0%)]	Loss: 5.1654	Cost: 39.71s
Train Epoch: 265 [20480/90000 (23%)]	Loss: 5.0624	Cost: 7.98s
Train Epoch: 265 [40960/90000 (45%)]	Loss: 4.9134	Cost: 20.79s
Train Epoch: 265 [61440/90000 (68%)]	Loss: 4.9913	Cost: 12.01s
Train Epoch: 265 [81920/90000 (91%)]	Loss: 4.9226	Cost: 12.03s
Train Epoch: 265 	Average Loss: 5.0126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2678

Saving model as e265_model.pt & e265_waveforms_supplementary.hdf5
Learning rate: 9.982682681333644e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 266 [0/90000 (0%)]	Loss: 5.3442	Cost: 85.46s
Train Epoch: 266 [20480/90000 (23%)]	Loss: 5.0972	Cost: 11.02s
Train Epoch: 266 [40960/90000 (45%)]	Loss: 4.8856	Cost: 22.56s
Train Epoch: 266 [61440/90000 (68%)]	Loss: 4.9425	Cost: 10.86s
Train Epoch: 266 [81920/90000 (91%)]	Loss: 4.9242	Cost: 24.72s
Train Epoch: 266 	Average Loss: 5.0279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2992

Learning rate: 9.982551814201825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 267 [0/90000 (0%)]	Loss: 5.2183	Cost: 34.95s
Train Epoch: 267 [20480/90000 (23%)]	Loss: 5.0394	Cost: 13.13s
Train Epoch: 267 [40960/90000 (45%)]	Loss: 4.9171	Cost: 13.70s
Train Epoch: 267 [61440/90000 (68%)]	Loss: 5.0565	Cost: 12.29s
Train Epoch: 267 [81920/90000 (91%)]	Loss: 4.8855	Cost: 11.91s
Train Epoch: 267 	Average Loss: 5.0234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3491

Learning rate: 9.982420455311858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 268 [0/90000 (0%)]	Loss: 5.3689	Cost: 35.58s
Train Epoch: 268 [20480/90000 (23%)]	Loss: 5.0573	Cost: 11.77s
Train Epoch: 268 [40960/90000 (45%)]	Loss: 4.8600	Cost: 7.96s
Train Epoch: 268 [61440/90000 (68%)]	Loss: 5.0450	Cost: 6.28s
Train Epoch: 268 [81920/90000 (91%)]	Loss: 5.0385	Cost: 12.53s
Train Epoch: 268 	Average Loss: 5.0383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2894

Learning rate: 9.982288604676707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 269 [0/90000 (0%)]	Loss: 5.2690	Cost: 31.23s
Train Epoch: 269 [20480/90000 (23%)]	Loss: 4.9792	Cost: 10.16s
Train Epoch: 269 [40960/90000 (45%)]	Loss: 4.9075	Cost: 25.67s
Train Epoch: 269 [61440/90000 (68%)]	Loss: 4.9411	Cost: 13.25s
Train Epoch: 269 [81920/90000 (91%)]	Loss: 4.9499	Cost: 11.93s
Train Epoch: 269 	Average Loss: 5.0195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2776

Learning rate: 9.982156262309383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 270 [0/90000 (0%)]	Loss: 5.2806	Cost: 43.81s
Train Epoch: 270 [20480/90000 (23%)]	Loss: 5.1056	Cost: 6.05s
Train Epoch: 270 [40960/90000 (45%)]	Loss: 4.8165	Cost: 15.59s
Train Epoch: 270 [61440/90000 (68%)]	Loss: 4.9328	Cost: 8.45s
Train Epoch: 270 [81920/90000 (91%)]	Loss: 4.8346	Cost: 8.41s
Train Epoch: 270 	Average Loss: 5.0041
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2966

Learning rate: 9.98202342822295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 271 [0/90000 (0%)]	Loss: 5.3199	Cost: 31.63s
Train Epoch: 271 [20480/90000 (23%)]	Loss: 5.1067	Cost: 7.82s
Train Epoch: 271 [40960/90000 (45%)]	Loss: 4.8654	Cost: 17.40s
Train Epoch: 271 [61440/90000 (68%)]	Loss: 4.9397	Cost: 12.84s
Train Epoch: 271 [81920/90000 (91%)]	Loss: 4.9108	Cost: 11.84s
Train Epoch: 271 	Average Loss: 4.9888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2109

Saving model as e271_model.pt & e271_waveforms_supplementary.hdf5
Learning rate: 9.981890102430519e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 272 [0/90000 (0%)]	Loss: 5.1831	Cost: 48.63s
Train Epoch: 272 [20480/90000 (23%)]	Loss: 4.8985	Cost: 6.25s
Train Epoch: 272 [40960/90000 (45%)]	Loss: 4.8953	Cost: 14.87s
Train Epoch: 272 [61440/90000 (68%)]	Loss: 4.8702	Cost: 8.58s
Train Epoch: 272 [81920/90000 (91%)]	Loss: 4.9026	Cost: 8.86s
Train Epoch: 272 	Average Loss: 4.9583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2666

Learning rate: 9.981756284945245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 273 [0/90000 (0%)]	Loss: 5.2770	Cost: 28.42s
Train Epoch: 273 [20480/90000 (23%)]	Loss: 4.9404	Cost: 7.08s
Train Epoch: 273 [40960/90000 (45%)]	Loss: 4.8397	Cost: 17.09s
Train Epoch: 273 [61440/90000 (68%)]	Loss: 4.8936	Cost: 12.10s
Train Epoch: 273 [81920/90000 (91%)]	Loss: 4.8797	Cost: 12.31s
Train Epoch: 273 	Average Loss: 4.9601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.3429

Learning rate: 9.98162197578034e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 274 [0/90000 (0%)]	Loss: 5.2243	Cost: 33.48s
Train Epoch: 274 [20480/90000 (23%)]	Loss: 4.9819	Cost: 8.05s
Train Epoch: 274 [40960/90000 (45%)]	Loss: 4.7435	Cost: 13.26s
Train Epoch: 274 [61440/90000 (68%)]	Loss: 4.8418	Cost: 9.44s
Train Epoch: 274 [81920/90000 (91%)]	Loss: 4.8441	Cost: 13.23s
Train Epoch: 274 	Average Loss: 4.9435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2225

Learning rate: 9.981487174949054e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 275 [0/90000 (0%)]	Loss: 5.2061	Cost: 39.96s
Train Epoch: 275 [20480/90000 (23%)]	Loss: 4.9400	Cost: 10.83s
Train Epoch: 275 [40960/90000 (45%)]	Loss: 4.8090	Cost: 12.79s
Train Epoch: 275 [61440/90000 (68%)]	Loss: 4.9341	Cost: 12.14s
Train Epoch: 275 [81920/90000 (91%)]	Loss: 4.7621	Cost: 12.08s
Train Epoch: 275 	Average Loss: 4.9532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1942

Saving model as e275_model.pt & e275_waveforms_supplementary.hdf5
Learning rate: 9.981351882464696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 276 [0/90000 (0%)]	Loss: 5.1219	Cost: 31.95s
Train Epoch: 276 [20480/90000 (23%)]	Loss: 4.9760	Cost: 9.42s
Train Epoch: 276 [40960/90000 (45%)]	Loss: 4.9608	Cost: 10.86s
Train Epoch: 276 [61440/90000 (68%)]	Loss: 4.8788	Cost: 8.85s
Train Epoch: 276 [81920/90000 (91%)]	Loss: 4.7807	Cost: 12.42s
Train Epoch: 276 	Average Loss: 4.9444
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1764

Saving model as e276_model.pt & e276_waveforms_supplementary.hdf5
Learning rate: 9.981216098340617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 277 [0/90000 (0%)]	Loss: 5.1721	Cost: 29.62s
Train Epoch: 277 [20480/90000 (23%)]	Loss: 4.9214	Cost: 7.93s
Train Epoch: 277 [40960/90000 (45%)]	Loss: 4.8276	Cost: 16.44s
Train Epoch: 277 [61440/90000 (68%)]	Loss: 4.8379	Cost: 12.39s
Train Epoch: 277 [81920/90000 (91%)]	Loss: 4.8558	Cost: 12.40s
Train Epoch: 277 	Average Loss: 4.9314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2487

Learning rate: 9.981079822590219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 278 [0/90000 (0%)]	Loss: 5.1792	Cost: 33.34s
Train Epoch: 278 [20480/90000 (23%)]	Loss: 5.0169	Cost: 11.68s
Train Epoch: 278 [40960/90000 (45%)]	Loss: 4.7399	Cost: 7.69s
Train Epoch: 278 [61440/90000 (68%)]	Loss: 4.9071	Cost: 6.55s
Train Epoch: 278 [81920/90000 (91%)]	Loss: 4.8656	Cost: 13.05s
Train Epoch: 278 	Average Loss: 4.9385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1955

Learning rate: 9.980943055226952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 279 [0/90000 (0%)]	Loss: 5.0085	Cost: 29.05s
Train Epoch: 279 [20480/90000 (23%)]	Loss: 4.9316	Cost: 12.10s
Train Epoch: 279 [40960/90000 (45%)]	Loss: 4.8100	Cost: 20.63s
Train Epoch: 279 [61440/90000 (68%)]	Loss: 4.7923	Cost: 12.54s
Train Epoch: 279 [81920/90000 (91%)]	Loss: 4.8131	Cost: 12.19s
Train Epoch: 279 	Average Loss: 4.9268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1508

Saving model as e279_model.pt & e279_waveforms_supplementary.hdf5
Learning rate: 9.980805796264313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 280 [0/90000 (0%)]	Loss: 5.1567	Cost: 45.83s
Train Epoch: 280 [20480/90000 (23%)]	Loss: 4.9213	Cost: 6.15s
Train Epoch: 280 [40960/90000 (45%)]	Loss: 4.8671	Cost: 13.52s
Train Epoch: 280 [61440/90000 (68%)]	Loss: 4.8234	Cost: 8.56s
Train Epoch: 280 [81920/90000 (91%)]	Loss: 4.7086	Cost: 7.91s
Train Epoch: 280 	Average Loss: 4.9200
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1706

Learning rate: 9.98066804571585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 281 [0/90000 (0%)]	Loss: 5.1868	Cost: 28.46s
Train Epoch: 281 [20480/90000 (23%)]	Loss: 4.9364	Cost: 8.43s
Train Epoch: 281 [40960/90000 (45%)]	Loss: 4.8687	Cost: 21.19s
Train Epoch: 281 [61440/90000 (68%)]	Loss: 4.8569	Cost: 12.74s
Train Epoch: 281 [81920/90000 (91%)]	Loss: 4.9131	Cost: 11.94s
Train Epoch: 281 	Average Loss: 4.9053
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2254

Learning rate: 9.980529803595159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 282 [0/90000 (0%)]	Loss: 5.2459	Cost: 31.72s
Train Epoch: 282 [20480/90000 (23%)]	Loss: 4.9547	Cost: 10.41s
Train Epoch: 282 [40960/90000 (45%)]	Loss: 4.7081	Cost: 9.24s
Train Epoch: 282 [61440/90000 (68%)]	Loss: 4.8709	Cost: 7.46s
Train Epoch: 282 [81920/90000 (91%)]	Loss: 4.8015	Cost: 12.52s
Train Epoch: 282 	Average Loss: 4.9004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2168

Learning rate: 9.980391069915883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 283 [0/90000 (0%)]	Loss: 5.1974	Cost: 27.90s
Train Epoch: 283 [20480/90000 (23%)]	Loss: 4.8937	Cost: 8.85s
Train Epoch: 283 [40960/90000 (45%)]	Loss: 4.7574	Cost: 15.89s
Train Epoch: 283 [61440/90000 (68%)]	Loss: 4.7220	Cost: 13.33s
Train Epoch: 283 [81920/90000 (91%)]	Loss: 4.8027	Cost: 12.57s
Train Epoch: 283 	Average Loss: 4.8792
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2086

Learning rate: 9.980251844691714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 284 [0/90000 (0%)]	Loss: 5.0310	Cost: 37.30s
Train Epoch: 284 [20480/90000 (23%)]	Loss: 5.0803	Cost: 10.14s
Train Epoch: 284 [40960/90000 (45%)]	Loss: 4.7880	Cost: 11.07s
Train Epoch: 284 [61440/90000 (68%)]	Loss: 4.8754	Cost: 8.52s
Train Epoch: 284 [81920/90000 (91%)]	Loss: 4.8308	Cost: 11.22s
Train Epoch: 284 	Average Loss: 4.8941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1858

Learning rate: 9.980112127936395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 285 [0/90000 (0%)]	Loss: 5.1390	Cost: 31.43s
Train Epoch: 285 [20480/90000 (23%)]	Loss: 4.9412	Cost: 8.13s
Train Epoch: 285 [40960/90000 (45%)]	Loss: 4.7899	Cost: 17.69s
Train Epoch: 285 [61440/90000 (68%)]	Loss: 4.8773	Cost: 13.15s
Train Epoch: 285 [81920/90000 (91%)]	Loss: 4.8503	Cost: 12.80s
Train Epoch: 285 	Average Loss: 4.9186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2553

Learning rate: 9.979971919663715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 286 [0/90000 (0%)]	Loss: 5.1194	Cost: 40.10s
Train Epoch: 286 [20480/90000 (23%)]	Loss: 4.8996	Cost: 10.98s
Train Epoch: 286 [40960/90000 (45%)]	Loss: 4.7912	Cost: 12.10s
Train Epoch: 286 [61440/90000 (68%)]	Loss: 4.8975	Cost: 12.35s
Train Epoch: 286 [81920/90000 (91%)]	Loss: 4.6981	Cost: 7.59s
Train Epoch: 286 	Average Loss: 4.8709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2458

Learning rate: 9.97983121988751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 287 [0/90000 (0%)]	Loss: 5.1433	Cost: 36.17s
Train Epoch: 287 [20480/90000 (23%)]	Loss: 4.9986	Cost: 6.40s
Train Epoch: 287 [40960/90000 (45%)]	Loss: 4.6706	Cost: 14.22s
Train Epoch: 287 [61440/90000 (68%)]	Loss: 4.7379	Cost: 8.75s
Train Epoch: 287 [81920/90000 (91%)]	Loss: 4.8660	Cost: 8.81s
Train Epoch: 287 	Average Loss: 4.8698
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.2276

Learning rate: 9.97969002862167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 288 [0/90000 (0%)]	Loss: 5.2674	Cost: 34.91s
Train Epoch: 288 [20480/90000 (23%)]	Loss: 4.8149	Cost: 8.21s
Train Epoch: 288 [40960/90000 (45%)]	Loss: 4.6775	Cost: 17.99s
Train Epoch: 288 [61440/90000 (68%)]	Loss: 4.7861	Cost: 12.12s
Train Epoch: 288 [81920/90000 (91%)]	Loss: 4.7754	Cost: 12.12s
Train Epoch: 288 	Average Loss: 4.8609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1550

Learning rate: 9.979548345880126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 289 [0/90000 (0%)]	Loss: 5.2247	Cost: 31.15s
Train Epoch: 289 [20480/90000 (23%)]	Loss: 4.8709	Cost: 8.71s
Train Epoch: 289 [40960/90000 (45%)]	Loss: 4.6937	Cost: 9.64s
Train Epoch: 289 [61440/90000 (68%)]	Loss: 4.8552	Cost: 8.34s
Train Epoch: 289 [81920/90000 (91%)]	Loss: 4.7789	Cost: 12.17s
Train Epoch: 289 	Average Loss: 4.8614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1854

Learning rate: 9.979406171676863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 290 [0/90000 (0%)]	Loss: 5.2666	Cost: 29.09s
Train Epoch: 290 [20480/90000 (23%)]	Loss: 4.9208	Cost: 10.32s
Train Epoch: 290 [40960/90000 (45%)]	Loss: 4.7338	Cost: 22.04s
Train Epoch: 290 [61440/90000 (68%)]	Loss: 4.6702	Cost: 13.47s
Train Epoch: 290 [81920/90000 (91%)]	Loss: 4.8411	Cost: 12.11s
Train Epoch: 290 	Average Loss: 4.8405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1442

Saving model as e290_model.pt & e290_waveforms_supplementary.hdf5
Learning rate: 9.979263506025915e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 291 [0/90000 (0%)]	Loss: 5.1478	Cost: 59.36s
Train Epoch: 291 [20480/90000 (23%)]	Loss: 4.9050	Cost: 7.58s
Train Epoch: 291 [40960/90000 (45%)]	Loss: 4.6845	Cost: 11.56s
Train Epoch: 291 [61440/90000 (68%)]	Loss: 4.8526	Cost: 8.64s
Train Epoch: 291 [81920/90000 (91%)]	Loss: 4.8500	Cost: 8.29s
Train Epoch: 291 	Average Loss: 4.8473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1168

Saving model as e291_model.pt & e291_waveforms_supplementary.hdf5
Learning rate: 9.97912034894136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 292 [0/90000 (0%)]	Loss: 5.0580	Cost: 30.99s
Train Epoch: 292 [20480/90000 (23%)]	Loss: 4.8644	Cost: 12.16s
Train Epoch: 292 [40960/90000 (45%)]	Loss: 4.6405	Cost: 17.05s
Train Epoch: 292 [61440/90000 (68%)]	Loss: 4.6910	Cost: 12.14s
Train Epoch: 292 [81920/90000 (91%)]	Loss: 4.7752	Cost: 12.09s
Train Epoch: 292 	Average Loss: 4.8305
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1391

Learning rate: 9.978976700437328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 293 [0/90000 (0%)]	Loss: 5.1297	Cost: 38.55s
Train Epoch: 293 [20480/90000 (23%)]	Loss: 4.9204	Cost: 8.24s
Train Epoch: 293 [40960/90000 (45%)]	Loss: 4.7248	Cost: 12.66s
Train Epoch: 293 [61440/90000 (68%)]	Loss: 4.8254	Cost: 9.18s
Train Epoch: 293 [81920/90000 (91%)]	Loss: 4.7654	Cost: 12.03s
Train Epoch: 293 	Average Loss: 4.8301
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1186

Learning rate: 9.978832560527998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 294 [0/90000 (0%)]	Loss: 5.2052	Cost: 28.15s
Train Epoch: 294 [20480/90000 (23%)]	Loss: 4.7872	Cost: 9.82s
Train Epoch: 294 [40960/90000 (45%)]	Loss: 4.6042	Cost: 17.14s
Train Epoch: 294 [61440/90000 (68%)]	Loss: 4.7165	Cost: 12.13s
Train Epoch: 294 [81920/90000 (91%)]	Loss: 4.6888	Cost: 12.19s
Train Epoch: 294 	Average Loss: 4.8073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1330

Learning rate: 9.978687929227592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 295 [0/90000 (0%)]	Loss: 5.1823	Cost: 38.74s
Train Epoch: 295 [20480/90000 (23%)]	Loss: 4.8272	Cost: 12.46s
Train Epoch: 295 [40960/90000 (45%)]	Loss: 4.8062	Cost: 12.11s
Train Epoch: 295 [61440/90000 (68%)]	Loss: 4.8077	Cost: 7.07s
Train Epoch: 295 [81920/90000 (91%)]	Loss: 4.6813	Cost: 10.01s
Train Epoch: 295 	Average Loss: 4.7974
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1374

Learning rate: 9.978542806550388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 296 [0/90000 (0%)]	Loss: 5.1149	Cost: 46.60s
Train Epoch: 296 [20480/90000 (23%)]	Loss: 4.8824	Cost: 6.76s
Train Epoch: 296 [40960/90000 (45%)]	Loss: 4.6558	Cost: 17.71s
Train Epoch: 296 [61440/90000 (68%)]	Loss: 4.7644	Cost: 12.22s
Train Epoch: 296 [81920/90000 (91%)]	Loss: 4.5935	Cost: 11.93s
Train Epoch: 296 	Average Loss: 4.8009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1454

Learning rate: 9.978397192510708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 297 [0/90000 (0%)]	Loss: 5.1199	Cost: 33.23s
Train Epoch: 297 [20480/90000 (23%)]	Loss: 4.7293	Cost: 6.40s
Train Epoch: 297 [40960/90000 (45%)]	Loss: 4.6778	Cost: 14.22s
Train Epoch: 297 [61440/90000 (68%)]	Loss: 4.7585	Cost: 8.91s
Train Epoch: 297 [81920/90000 (91%)]	Loss: 4.6130	Cost: 12.20s
Train Epoch: 297 	Average Loss: 4.7674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1690

Learning rate: 9.978251087122923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 298 [0/90000 (0%)]	Loss: 4.9052	Cost: 35.14s
Train Epoch: 298 [20480/90000 (23%)]	Loss: 4.8522	Cost: 13.06s
Train Epoch: 298 [40960/90000 (45%)]	Loss: 4.5626	Cost: 16.22s
Train Epoch: 298 [61440/90000 (68%)]	Loss: 4.7179	Cost: 12.11s
Train Epoch: 298 [81920/90000 (91%)]	Loss: 4.7312	Cost: 11.96s
Train Epoch: 298 	Average Loss: 4.7802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1464

Learning rate: 9.978104490401455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 299 [0/90000 (0%)]	Loss: 5.1257	Cost: 46.30s
Train Epoch: 299 [20480/90000 (23%)]	Loss: 4.8468	Cost: 9.28s
Train Epoch: 299 [40960/90000 (45%)]	Loss: 4.5646	Cost: 7.36s
Train Epoch: 299 [61440/90000 (68%)]	Loss: 4.6914	Cost: 7.92s
Train Epoch: 299 [81920/90000 (91%)]	Loss: 4.5841	Cost: 13.53s
Train Epoch: 299 	Average Loss: 4.7546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1247

Learning rate: 9.977957402360771e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 300 [0/90000 (0%)]	Loss: 5.1240	Cost: 33.19s
Train Epoch: 300 [20480/90000 (23%)]	Loss: 4.8262	Cost: 10.79s
Train Epoch: 300 [40960/90000 (45%)]	Loss: 4.5227	Cost: 20.82s
Train Epoch: 300 [61440/90000 (68%)]	Loss: 4.6707	Cost: 11.91s
Train Epoch: 300 [81920/90000 (91%)]	Loss: 4.6553	Cost: 12.12s
Train Epoch: 300 	Average Loss: 4.7371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1248

Learning rate: 9.977809823015388e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 301 [0/90000 (0%)]	Loss: 5.1634	Cost: 30.49s
Train Epoch: 301 [20480/90000 (23%)]	Loss: 4.7897	Cost: 6.50s
Train Epoch: 301 [40960/90000 (45%)]	Loss: 4.7094	Cost: 14.18s
Train Epoch: 301 [61440/90000 (68%)]	Loss: 4.6477	Cost: 9.59s
Train Epoch: 301 [81920/90000 (91%)]	Loss: 4.5956	Cost: 12.16s
Train Epoch: 301 	Average Loss: 4.7562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1368

Learning rate: 9.97766175237987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 302 [0/90000 (0%)]	Loss: 5.1152	Cost: 27.84s
Train Epoch: 302 [20480/90000 (23%)]	Loss: 4.8049	Cost: 8.82s
Train Epoch: 302 [40960/90000 (45%)]	Loss: 4.5882	Cost: 22.18s
Train Epoch: 302 [61440/90000 (68%)]	Loss: 4.6531	Cost: 14.23s
Train Epoch: 302 [81920/90000 (91%)]	Loss: 4.5975	Cost: 11.97s
Train Epoch: 302 	Average Loss: 4.7345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0895

Saving model as e302_model.pt & e302_waveforms_supplementary.hdf5
Learning rate: 9.977513190468834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 303 [0/90000 (0%)]	Loss: 5.0678	Cost: 36.97s
Train Epoch: 303 [20480/90000 (23%)]	Loss: 4.7600	Cost: 13.63s
Train Epoch: 303 [40960/90000 (45%)]	Loss: 4.6916	Cost: 9.53s
Train Epoch: 303 [61440/90000 (68%)]	Loss: 4.6618	Cost: 6.27s
Train Epoch: 303 [81920/90000 (91%)]	Loss: 4.5377	Cost: 14.54s
Train Epoch: 303 	Average Loss: 4.7168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1984

Learning rate: 9.977364137296942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 304 [0/90000 (0%)]	Loss: 5.0642	Cost: 31.07s
Train Epoch: 304 [20480/90000 (23%)]	Loss: 4.7904	Cost: 10.29s
Train Epoch: 304 [40960/90000 (45%)]	Loss: 4.5932	Cost: 18.93s
Train Epoch: 304 [61440/90000 (68%)]	Loss: 4.7112	Cost: 12.09s
Train Epoch: 304 [81920/90000 (91%)]	Loss: 4.5386	Cost: 12.14s
Train Epoch: 304 	Average Loss: 4.7088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0234

Saving model as e304_model.pt & e304_waveforms_supplementary.hdf5
Learning rate: 9.977214592878902e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 305 [0/90000 (0%)]	Loss: 4.9342	Cost: 38.95s
Train Epoch: 305 [20480/90000 (23%)]	Loss: 4.8484	Cost: 7.16s
Train Epoch: 305 [40960/90000 (45%)]	Loss: 4.5078	Cost: 12.46s
Train Epoch: 305 [61440/90000 (68%)]	Loss: 4.6573	Cost: 8.94s
Train Epoch: 305 [81920/90000 (91%)]	Loss: 4.5645	Cost: 8.68s
Train Epoch: 305 	Average Loss: 4.7075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.1160

Learning rate: 9.977064557229477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 306 [0/90000 (0%)]	Loss: 5.1413	Cost: 29.37s
Train Epoch: 306 [20480/90000 (23%)]	Loss: 4.7657	Cost: 11.79s
Train Epoch: 306 [40960/90000 (45%)]	Loss: 4.5705	Cost: 18.38s
Train Epoch: 306 [61440/90000 (68%)]	Loss: 4.6826	Cost: 12.25s
Train Epoch: 306 [81920/90000 (91%)]	Loss: 4.5195	Cost: 11.86s
Train Epoch: 306 	Average Loss: 4.7174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0561

Learning rate: 9.976914030363472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 307 [0/90000 (0%)]	Loss: 4.9581	Cost: 39.41s
Train Epoch: 307 [20480/90000 (23%)]	Loss: 4.6825	Cost: 8.57s
Train Epoch: 307 [40960/90000 (45%)]	Loss: 4.5602	Cost: 10.89s
Train Epoch: 307 [61440/90000 (68%)]	Loss: 4.6605	Cost: 8.09s
Train Epoch: 307 [81920/90000 (91%)]	Loss: 4.6342	Cost: 9.89s
Train Epoch: 307 	Average Loss: 4.7060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0864

Learning rate: 9.976763012295747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 308 [0/90000 (0%)]	Loss: 5.0660	Cost: 30.91s
Train Epoch: 308 [20480/90000 (23%)]	Loss: 4.6883	Cost: 7.07s
Train Epoch: 308 [40960/90000 (45%)]	Loss: 4.5085	Cost: 20.82s
Train Epoch: 308 [61440/90000 (68%)]	Loss: 4.6658	Cost: 13.92s
Train Epoch: 308 [81920/90000 (91%)]	Loss: 4.6119	Cost: 12.56s
Train Epoch: 308 	Average Loss: 4.6801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0943

Learning rate: 9.976611503041203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 309 [0/90000 (0%)]	Loss: 5.0172	Cost: 43.07s
Train Epoch: 309 [20480/90000 (23%)]	Loss: 4.7053	Cost: 11.30s
Train Epoch: 309 [40960/90000 (45%)]	Loss: 4.5579	Cost: 8.43s
Train Epoch: 309 [61440/90000 (68%)]	Loss: 4.6461	Cost: 6.10s
Train Epoch: 309 [81920/90000 (91%)]	Loss: 4.5705	Cost: 14.82s
Train Epoch: 309 	Average Loss: 4.6947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0337

Learning rate: 9.976459502614796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 310 [0/90000 (0%)]	Loss: 4.9192	Cost: 27.66s
Train Epoch: 310 [20480/90000 (23%)]	Loss: 4.6233	Cost: 8.55s
Train Epoch: 310 [40960/90000 (45%)]	Loss: 4.5063	Cost: 17.16s
Train Epoch: 310 [61440/90000 (68%)]	Loss: 4.5920	Cost: 11.47s
Train Epoch: 310 [81920/90000 (91%)]	Loss: 4.5449	Cost: 14.82s
Train Epoch: 310 	Average Loss: 4.6744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0359

Learning rate: 9.976307011031527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 311 [0/90000 (0%)]	Loss: 5.1122	Cost: 42.95s
Train Epoch: 311 [20480/90000 (23%)]	Loss: 4.7720	Cost: 13.93s
Train Epoch: 311 [40960/90000 (45%)]	Loss: 4.5187	Cost: 12.12s
Train Epoch: 311 [61440/90000 (68%)]	Loss: 4.5302	Cost: 9.31s
Train Epoch: 311 [81920/90000 (91%)]	Loss: 4.4985	Cost: 5.89s
Train Epoch: 311 	Average Loss: 4.6572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9904

Saving model as e311_model.pt & e311_waveforms_supplementary.hdf5
Learning rate: 9.976154028306446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 312 [0/90000 (0%)]	Loss: 4.9891	Cost: 33.46s
Train Epoch: 312 [20480/90000 (23%)]	Loss: 4.7278	Cost: 8.06s
Train Epoch: 312 [40960/90000 (45%)]	Loss: 4.4043	Cost: 10.41s
Train Epoch: 312 [61440/90000 (68%)]	Loss: 4.4897	Cost: 8.93s
Train Epoch: 312 [81920/90000 (91%)]	Loss: 4.5910	Cost: 8.47s
Train Epoch: 312 	Average Loss: 4.6528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0477

Learning rate: 9.976000554454652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 313 [0/90000 (0%)]	Loss: 5.1022	Cost: 33.23s
Train Epoch: 313 [20480/90000 (23%)]	Loss: 4.7396	Cost: 8.42s
Train Epoch: 313 [40960/90000 (45%)]	Loss: 4.5276	Cost: 16.79s
Train Epoch: 313 [61440/90000 (68%)]	Loss: 4.5628	Cost: 11.99s
Train Epoch: 313 [81920/90000 (91%)]	Loss: 4.5455	Cost: 12.36s
Train Epoch: 313 	Average Loss: 4.6534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0120

Learning rate: 9.975846589491293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 314 [0/90000 (0%)]	Loss: 4.8698	Cost: 35.50s
Train Epoch: 314 [20480/90000 (23%)]	Loss: 4.6375	Cost: 9.89s
Train Epoch: 314 [40960/90000 (45%)]	Loss: 4.4067	Cost: 9.35s
Train Epoch: 314 [61440/90000 (68%)]	Loss: 4.4901	Cost: 7.06s
Train Epoch: 314 [81920/90000 (91%)]	Loss: 4.4477	Cost: 15.38s
Train Epoch: 314 	Average Loss: 4.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9804

Saving model as e314_model.pt & e314_waveforms_supplementary.hdf5
Learning rate: 9.975692133431563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 315 [0/90000 (0%)]	Loss: 5.0353	Cost: 28.77s
Train Epoch: 315 [20480/90000 (23%)]	Loss: 4.7296	Cost: 9.86s
Train Epoch: 315 [40960/90000 (45%)]	Loss: 4.5873	Cost: 21.25s
Train Epoch: 315 [61440/90000 (68%)]	Loss: 4.5594	Cost: 12.24s
Train Epoch: 315 [81920/90000 (91%)]	Loss: 4.5406	Cost: 11.89s
Train Epoch: 315 	Average Loss: 4.6588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0074

Learning rate: 9.975537186290708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 316 [0/90000 (0%)]	Loss: 5.0484	Cost: 33.95s
Train Epoch: 316 [20480/90000 (23%)]	Loss: 4.6428	Cost: 13.97s
Train Epoch: 316 [40960/90000 (45%)]	Loss: 4.4561	Cost: 22.18s
Train Epoch: 316 [61440/90000 (68%)]	Loss: 4.5062	Cost: 11.41s
Train Epoch: 316 [81920/90000 (91%)]	Loss: 4.5047	Cost: 28.88s
Train Epoch: 316 	Average Loss: 4.6077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9937

Learning rate: 9.975381748084019e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 317 [0/90000 (0%)]	Loss: 4.8421	Cost: 34.63s
Train Epoch: 317 [20480/90000 (23%)]	Loss: 4.6868	Cost: 6.96s
Train Epoch: 317 [40960/90000 (45%)]	Loss: 4.4491	Cost: 16.94s
Train Epoch: 317 [61440/90000 (68%)]	Loss: 4.4767	Cost: 12.33s
Train Epoch: 317 [81920/90000 (91%)]	Loss: 4.3991	Cost: 11.84s
Train Epoch: 317 	Average Loss: 4.6137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9896

Learning rate: 9.975225818826839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 318 [0/90000 (0%)]	Loss: 4.9359	Cost: 33.33s
Train Epoch: 318 [20480/90000 (23%)]	Loss: 4.6417	Cost: 11.43s
Train Epoch: 318 [40960/90000 (45%)]	Loss: 4.5134	Cost: 12.08s
Train Epoch: 318 [61440/90000 (68%)]	Loss: 4.5513	Cost: 12.03s
Train Epoch: 318 [81920/90000 (91%)]	Loss: 4.4090	Cost: 8.03s
Train Epoch: 318 	Average Loss: 4.5926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0008

Learning rate: 9.975069398534559e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 319 [0/90000 (0%)]	Loss: 5.0782	Cost: 29.28s
Train Epoch: 319 [20480/90000 (23%)]	Loss: 4.6413	Cost: 9.97s
Train Epoch: 319 [40960/90000 (45%)]	Loss: 4.4656	Cost: 15.91s
Train Epoch: 319 [61440/90000 (68%)]	Loss: 4.5345	Cost: 7.04s
Train Epoch: 319 [81920/90000 (91%)]	Loss: 4.4974	Cost: 12.38s
Train Epoch: 319 	Average Loss: 4.6089
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9878

Learning rate: 9.974912487222611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 320 [0/90000 (0%)]	Loss: 5.0632	Cost: 36.35s
Train Epoch: 320 [20480/90000 (23%)]	Loss: 4.6030	Cost: 12.96s
Train Epoch: 320 [40960/90000 (45%)]	Loss: 4.4358	Cost: 13.75s
Train Epoch: 320 [61440/90000 (68%)]	Loss: 4.5474	Cost: 12.03s
Train Epoch: 320 [81920/90000 (91%)]	Loss: 4.4155	Cost: 11.95s
Train Epoch: 320 	Average Loss: 4.5725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 5.0008

Learning rate: 9.974755084906488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 321 [0/90000 (0%)]	Loss: 5.0965	Cost: 33.77s
Train Epoch: 321 [20480/90000 (23%)]	Loss: 4.6495	Cost: 6.51s
Train Epoch: 321 [40960/90000 (45%)]	Loss: 4.4215	Cost: 14.22s
Train Epoch: 321 [61440/90000 (68%)]	Loss: 4.5013	Cost: 8.71s
Train Epoch: 321 [81920/90000 (91%)]	Loss: 4.4757	Cost: 9.66s
Train Epoch: 321 	Average Loss: 4.5813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8952

Saving model as e321_model.pt & e321_waveforms_supplementary.hdf5
Learning rate: 9.974597191601719e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 322 [0/90000 (0%)]	Loss: 5.0422	Cost: 32.41s
Train Epoch: 322 [20480/90000 (23%)]	Loss: 4.5392	Cost: 13.10s
Train Epoch: 322 [40960/90000 (45%)]	Loss: 4.5038	Cost: 18.30s
Train Epoch: 322 [61440/90000 (68%)]	Loss: 4.5452	Cost: 11.90s
Train Epoch: 322 [81920/90000 (91%)]	Loss: 4.5009	Cost: 11.89s
Train Epoch: 322 	Average Loss: 4.5704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9396

Learning rate: 9.974438807323893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 323 [0/90000 (0%)]	Loss: 4.9006	Cost: 30.51s
Train Epoch: 323 [20480/90000 (23%)]	Loss: 4.6042	Cost: 6.65s
Train Epoch: 323 [40960/90000 (45%)]	Loss: 4.4463	Cost: 12.12s
Train Epoch: 323 [61440/90000 (68%)]	Loss: 4.6076	Cost: 9.06s
Train Epoch: 323 [81920/90000 (91%)]	Loss: 4.5529	Cost: 9.41s
Train Epoch: 323 	Average Loss: 4.5496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9861

Learning rate: 9.97427993208864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 324 [0/90000 (0%)]	Loss: 4.9148	Cost: 28.27s
Train Epoch: 324 [20480/90000 (23%)]	Loss: 4.6518	Cost: 6.73s
Train Epoch: 324 [40960/90000 (45%)]	Loss: 4.2592	Cost: 22.80s
Train Epoch: 324 [61440/90000 (68%)]	Loss: 4.4168	Cost: 13.95s
Train Epoch: 324 [81920/90000 (91%)]	Loss: 4.4160	Cost: 12.14s
Train Epoch: 324 	Average Loss: 4.5242
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9478

Learning rate: 9.97412056591164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 325 [0/90000 (0%)]	Loss: 4.9001	Cost: 34.83s
Train Epoch: 325 [20480/90000 (23%)]	Loss: 4.6618	Cost: 14.11s
Train Epoch: 325 [40960/90000 (45%)]	Loss: 4.3753	Cost: 9.58s
Train Epoch: 325 [61440/90000 (68%)]	Loss: 4.5348	Cost: 8.21s
Train Epoch: 325 [81920/90000 (91%)]	Loss: 4.4334	Cost: 10.84s
Train Epoch: 325 	Average Loss: 4.5359
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9515

Learning rate: 9.973960708808621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 326 [0/90000 (0%)]	Loss: 5.1297	Cost: 33.49s
Train Epoch: 326 [20480/90000 (23%)]	Loss: 4.6432	Cost: 6.70s
Train Epoch: 326 [40960/90000 (45%)]	Loss: 4.4233	Cost: 18.65s
Train Epoch: 326 [61440/90000 (68%)]	Loss: 4.5441	Cost: 12.59s
Train Epoch: 326 [81920/90000 (91%)]	Loss: 4.4287	Cost: 12.00s
Train Epoch: 326 	Average Loss: 4.5429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9458

Learning rate: 9.97380036079536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 327 [0/90000 (0%)]	Loss: 5.0746	Cost: 44.01s
Train Epoch: 327 [20480/90000 (23%)]	Loss: 4.6264	Cost: 11.03s
Train Epoch: 327 [40960/90000 (45%)]	Loss: 4.3792	Cost: 7.60s
Train Epoch: 327 [61440/90000 (68%)]	Loss: 4.4562	Cost: 6.35s
Train Epoch: 327 [81920/90000 (91%)]	Loss: 4.3955	Cost: 14.67s
Train Epoch: 327 	Average Loss: 4.5230
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9317

Learning rate: 9.973639521887684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 328 [0/90000 (0%)]	Loss: 4.9609	Cost: 33.58s
Train Epoch: 328 [20480/90000 (23%)]	Loss: 4.5263	Cost: 6.94s
Train Epoch: 328 [40960/90000 (45%)]	Loss: 4.3750	Cost: 18.38s
Train Epoch: 328 [61440/90000 (68%)]	Loss: 4.5208	Cost: 12.19s
Train Epoch: 328 [81920/90000 (91%)]	Loss: 4.4228	Cost: 11.94s
Train Epoch: 328 	Average Loss: 4.5191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8997

Learning rate: 9.973478192101466e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 329 [0/90000 (0%)]	Loss: 4.9458	Cost: 33.04s
Train Epoch: 329 [20480/90000 (23%)]	Loss: 4.6114	Cost: 12.50s
Train Epoch: 329 [40960/90000 (45%)]	Loss: 4.3290	Cost: 8.82s
Train Epoch: 329 [61440/90000 (68%)]	Loss: 4.4346	Cost: 8.45s
Train Epoch: 329 [81920/90000 (91%)]	Loss: 4.4466	Cost: 17.49s
Train Epoch: 329 	Average Loss: 4.4997
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8539

Saving model as e329_model.pt & e329_waveforms_supplementary.hdf5
Learning rate: 9.973316371452633e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 330 [0/90000 (0%)]	Loss: 4.8499	Cost: 33.52s
Train Epoch: 330 [20480/90000 (23%)]	Loss: 4.4994	Cost: 9.19s
Train Epoch: 330 [40960/90000 (45%)]	Loss: 4.3759	Cost: 25.09s
Train Epoch: 330 [61440/90000 (68%)]	Loss: 4.3859	Cost: 11.87s
Train Epoch: 330 [81920/90000 (91%)]	Loss: 4.3498	Cost: 11.94s
Train Epoch: 330 	Average Loss: 4.4825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9528

Learning rate: 9.97315405995715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 331 [0/90000 (0%)]	Loss: 4.8225	Cost: 42.79s
Train Epoch: 331 [20480/90000 (23%)]	Loss: 4.5648	Cost: 7.13s
Train Epoch: 331 [40960/90000 (45%)]	Loss: 4.3878	Cost: 12.23s
Train Epoch: 331 [61440/90000 (68%)]	Loss: 4.3807	Cost: 8.66s
Train Epoch: 331 [81920/90000 (91%)]	Loss: 4.4249	Cost: 9.16s
Train Epoch: 331 	Average Loss: 4.4770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9030

Learning rate: 9.97299125763104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 332 [0/90000 (0%)]	Loss: 4.8862	Cost: 30.07s
Train Epoch: 332 [20480/90000 (23%)]	Loss: 4.3891	Cost: 10.07s
Train Epoch: 332 [40960/90000 (45%)]	Loss: 4.3413	Cost: 19.14s
Train Epoch: 332 [61440/90000 (68%)]	Loss: 4.4170	Cost: 12.00s
Train Epoch: 332 [81920/90000 (91%)]	Loss: 4.3076	Cost: 12.10s
Train Epoch: 332 	Average Loss: 4.4763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8999

Learning rate: 9.972827964490369e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 333 [0/90000 (0%)]	Loss: 4.8390	Cost: 40.55s
Train Epoch: 333 [20480/90000 (23%)]	Loss: 4.5179	Cost: 12.21s
Train Epoch: 333 [40960/90000 (45%)]	Loss: 4.3217	Cost: 8.00s
Train Epoch: 333 [61440/90000 (68%)]	Loss: 4.3979	Cost: 6.42s
Train Epoch: 333 [81920/90000 (91%)]	Loss: 4.2658	Cost: 13.41s
Train Epoch: 333 	Average Loss: 4.4573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8732

Learning rate: 9.972664180551254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 334 [0/90000 (0%)]	Loss: 4.8670	Cost: 31.05s
Train Epoch: 334 [20480/90000 (23%)]	Loss: 4.4880	Cost: 10.79s
Train Epoch: 334 [40960/90000 (45%)]	Loss: 4.3206	Cost: 22.14s
Train Epoch: 334 [61440/90000 (68%)]	Loss: 4.5317	Cost: 12.16s
Train Epoch: 334 [81920/90000 (91%)]	Loss: 4.3910	Cost: 11.83s
Train Epoch: 334 	Average Loss: 4.4624
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8823

Learning rate: 9.972499905829862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 335 [0/90000 (0%)]	Loss: 5.0216	Cost: 47.36s
Train Epoch: 335 [20480/90000 (23%)]	Loss: 4.5138	Cost: 10.87s
Train Epoch: 335 [40960/90000 (45%)]	Loss: 4.2664	Cost: 9.60s
Train Epoch: 335 [61440/90000 (68%)]	Loss: 4.3944	Cost: 6.23s
Train Epoch: 335 [81920/90000 (91%)]	Loss: 4.2456	Cost: 9.31s
Train Epoch: 335 	Average Loss: 4.4469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8957

Learning rate: 9.972335140342403e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 336 [0/90000 (0%)]	Loss: 4.8900	Cost: 29.50s
Train Epoch: 336 [20480/90000 (23%)]	Loss: 4.4594	Cost: 8.92s
Train Epoch: 336 [40960/90000 (45%)]	Loss: 4.2260	Cost: 11.96s
Train Epoch: 336 [61440/90000 (68%)]	Loss: 4.3137	Cost: 8.48s
Train Epoch: 336 [81920/90000 (91%)]	Loss: 4.2942	Cost: 20.17s
Train Epoch: 336 	Average Loss: 4.4309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8582

Learning rate: 9.972169884105142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 337 [0/90000 (0%)]	Loss: 4.8122	Cost: 37.62s
Train Epoch: 337 [20480/90000 (23%)]	Loss: 4.5327	Cost: 12.25s
Train Epoch: 337 [40960/90000 (45%)]	Loss: 4.3341	Cost: 12.19s
Train Epoch: 337 [61440/90000 (68%)]	Loss: 4.2969	Cost: 12.29s
Train Epoch: 337 [81920/90000 (91%)]	Loss: 4.2886	Cost: 6.35s
Train Epoch: 337 	Average Loss: 4.4184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.9116

Learning rate: 9.972004137134385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 338 [0/90000 (0%)]	Loss: 4.8081	Cost: 30.72s
Train Epoch: 338 [20480/90000 (23%)]	Loss: 4.4944	Cost: 8.85s
Train Epoch: 338 [40960/90000 (45%)]	Loss: 4.2583	Cost: 10.25s
Train Epoch: 338 [61440/90000 (68%)]	Loss: 4.3109	Cost: 8.66s
Train Epoch: 338 [81920/90000 (91%)]	Loss: 4.1561	Cost: 9.27s
Train Epoch: 338 	Average Loss: 4.3988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8107

Saving model as e338_model.pt & e338_waveforms_supplementary.hdf5
Learning rate: 9.971837899446494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 339 [0/90000 (0%)]	Loss: 4.7280	Cost: 33.00s
Train Epoch: 339 [20480/90000 (23%)]	Loss: 4.4158	Cost: 14.67s
Train Epoch: 339 [40960/90000 (45%)]	Loss: 4.3292	Cost: 14.31s
Train Epoch: 339 [61440/90000 (68%)]	Loss: 4.2891	Cost: 12.23s
Train Epoch: 339 [81920/90000 (91%)]	Loss: 4.2884	Cost: 6.96s
Train Epoch: 339 	Average Loss: 4.3887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8316

Learning rate: 9.971671171057876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 340 [0/90000 (0%)]	Loss: 4.8738	Cost: 40.85s
Train Epoch: 340 [20480/90000 (23%)]	Loss: 4.4936	Cost: 8.95s
Train Epoch: 340 [40960/90000 (45%)]	Loss: 4.2989	Cost: 10.76s
Train Epoch: 340 [61440/90000 (68%)]	Loss: 4.3688	Cost: 8.57s
Train Epoch: 340 [81920/90000 (91%)]	Loss: 4.2539	Cost: 7.46s
Train Epoch: 340 	Average Loss: 4.4075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8048

Saving model as e340_model.pt & e340_waveforms_supplementary.hdf5
Learning rate: 9.971503951984984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 341 [0/90000 (0%)]	Loss: 4.7381	Cost: 32.79s
Train Epoch: 341 [20480/90000 (23%)]	Loss: 4.3905	Cost: 6.91s
Train Epoch: 341 [40960/90000 (45%)]	Loss: 4.1627	Cost: 18.15s
Train Epoch: 341 [61440/90000 (68%)]	Loss: 4.3411	Cost: 12.13s
Train Epoch: 341 [81920/90000 (91%)]	Loss: 4.3161	Cost: 11.92s
Train Epoch: 341 	Average Loss: 4.3799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8214

Learning rate: 9.971336242244322e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 342 [0/90000 (0%)]	Loss: 4.7568	Cost: 33.65s
Train Epoch: 342 [20480/90000 (23%)]	Loss: 4.3900	Cost: 10.80s
Train Epoch: 342 [40960/90000 (45%)]	Loss: 4.1993	Cost: 7.46s
Train Epoch: 342 [61440/90000 (68%)]	Loss: 4.4106	Cost: 7.02s
Train Epoch: 342 [81920/90000 (91%)]	Loss: 4.1910	Cost: 14.84s
Train Epoch: 342 	Average Loss: 4.4022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8115

Learning rate: 9.971168041852446e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 343 [0/90000 (0%)]	Loss: 4.8329	Cost: 34.74s
Train Epoch: 343 [20480/90000 (23%)]	Loss: 4.4445	Cost: 11.31s
Train Epoch: 343 [40960/90000 (45%)]	Loss: 4.2921	Cost: 20.11s
Train Epoch: 343 [61440/90000 (68%)]	Loss: 4.2987	Cost: 11.93s
Train Epoch: 343 [81920/90000 (91%)]	Loss: 4.1449	Cost: 11.95s
Train Epoch: 343 	Average Loss: 4.3620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7937

Saving model as e343_model.pt & e343_waveforms_supplementary.hdf5
Learning rate: 9.970999350825954e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 344 [0/90000 (0%)]	Loss: 4.7163	Cost: 39.76s
Train Epoch: 344 [20480/90000 (23%)]	Loss: 4.3531	Cost: 6.20s
Train Epoch: 344 [40960/90000 (45%)]	Loss: 4.2895	Cost: 12.88s
Train Epoch: 344 [61440/90000 (68%)]	Loss: 4.2981	Cost: 9.08s
Train Epoch: 344 [81920/90000 (91%)]	Loss: 4.2903	Cost: 8.89s
Train Epoch: 344 	Average Loss: 4.3885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8312

Learning rate: 9.970830169181494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 345 [0/90000 (0%)]	Loss: 4.8016	Cost: 40.61s
Train Epoch: 345 [20480/90000 (23%)]	Loss: 4.3877	Cost: 12.86s
Train Epoch: 345 [40960/90000 (45%)]	Loss: 4.2095	Cost: 12.40s
Train Epoch: 345 [61440/90000 (68%)]	Loss: 4.3074	Cost: 12.03s
Train Epoch: 345 [81920/90000 (91%)]	Loss: 4.2922	Cost: 11.98s
Train Epoch: 345 	Average Loss: 4.3659
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.8107

Learning rate: 9.970660496935765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 346 [0/90000 (0%)]	Loss: 4.8296	Cost: 31.59s
Train Epoch: 346 [20480/90000 (23%)]	Loss: 4.4017	Cost: 10.34s
Train Epoch: 346 [40960/90000 (45%)]	Loss: 4.1284	Cost: 6.22s
Train Epoch: 346 [61440/90000 (68%)]	Loss: 4.2850	Cost: 6.37s
Train Epoch: 346 [81920/90000 (91%)]	Loss: 4.1857	Cost: 15.79s
Train Epoch: 346 	Average Loss: 4.3595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7549

Saving model as e346_model.pt & e346_waveforms_supplementary.hdf5
Learning rate: 9.970490334105514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 347 [0/90000 (0%)]	Loss: 4.6857	Cost: 27.52s
Train Epoch: 347 [20480/90000 (23%)]	Loss: 4.4272	Cost: 10.76s
Train Epoch: 347 [40960/90000 (45%)]	Loss: 4.1941	Cost: 20.44s
Train Epoch: 347 [61440/90000 (68%)]	Loss: 4.1651	Cost: 13.70s
Train Epoch: 347 [81920/90000 (91%)]	Loss: 4.2591	Cost: 11.83s
Train Epoch: 347 	Average Loss: 4.3396
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7950

Learning rate: 9.970319680707532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 348 [0/90000 (0%)]	Loss: 4.9383	Cost: 59.85s
Train Epoch: 348 [20480/90000 (23%)]	Loss: 4.3067	Cost: 6.09s
Train Epoch: 348 [40960/90000 (45%)]	Loss: 4.1522	Cost: 13.48s
Train Epoch: 348 [61440/90000 (68%)]	Loss: 4.3668	Cost: 8.52s
Train Epoch: 348 [81920/90000 (91%)]	Loss: 4.0969	Cost: 7.67s
Train Epoch: 348 	Average Loss: 4.3324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7366

Saving model as e348_model.pt & e348_waveforms_supplementary.hdf5
Learning rate: 9.970148536758666e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 349 [0/90000 (0%)]	Loss: 4.7579	Cost: 27.90s
Train Epoch: 349 [20480/90000 (23%)]	Loss: 4.3471	Cost: 9.31s
Train Epoch: 349 [40960/90000 (45%)]	Loss: 4.2110	Cost: 16.40s
Train Epoch: 349 [61440/90000 (68%)]	Loss: 4.1514	Cost: 12.65s
Train Epoch: 349 [81920/90000 (91%)]	Loss: 4.2095	Cost: 12.07s
Train Epoch: 349 	Average Loss: 4.2987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7905

Learning rate: 9.969976902275804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 350 [0/90000 (0%)]	Loss: 4.6834	Cost: 37.49s
Train Epoch: 350 [20480/90000 (23%)]	Loss: 4.3825	Cost: 11.89s
Train Epoch: 350 [40960/90000 (45%)]	Loss: 4.2198	Cost: 7.06s
Train Epoch: 350 [61440/90000 (68%)]	Loss: 4.2597	Cost: 6.19s
Train Epoch: 350 [81920/90000 (91%)]	Loss: 4.2479	Cost: 13.20s
Train Epoch: 350 	Average Loss: 4.3207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7561

Learning rate: 9.969804777275889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 351 [0/90000 (0%)]	Loss: 4.7817	Cost: 26.88s
Train Epoch: 351 [20480/90000 (23%)]	Loss: 4.2243	Cost: 6.44s
Train Epoch: 351 [40960/90000 (45%)]	Loss: 4.2213	Cost: 25.16s
Train Epoch: 351 [61440/90000 (68%)]	Loss: 4.1400	Cost: 14.20s
Train Epoch: 351 [81920/90000 (91%)]	Loss: 4.1429	Cost: 12.21s
Train Epoch: 351 	Average Loss: 4.3050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7278

Saving model as e351_model.pt & e351_waveforms_supplementary.hdf5
Learning rate: 9.969632161775905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 352 [0/90000 (0%)]	Loss: 4.7397	Cost: 33.32s
Train Epoch: 352 [20480/90000 (23%)]	Loss: 4.1617	Cost: 11.44s
Train Epoch: 352 [40960/90000 (45%)]	Loss: 4.0308	Cost: 9.98s
Train Epoch: 352 [61440/90000 (68%)]	Loss: 4.2181	Cost: 9.39s
Train Epoch: 352 [81920/90000 (91%)]	Loss: 4.1211	Cost: 11.04s
Train Epoch: 352 	Average Loss: 4.2592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6890

Saving model as e352_model.pt & e352_waveforms_supplementary.hdf5
Learning rate: 9.969459055792892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 353 [0/90000 (0%)]	Loss: 4.5579	Cost: 34.44s
Train Epoch: 353 [20480/90000 (23%)]	Loss: 4.3317	Cost: 9.25s
Train Epoch: 353 [40960/90000 (45%)]	Loss: 4.1607	Cost: 19.32s
Train Epoch: 353 [61440/90000 (68%)]	Loss: 4.2388	Cost: 12.70s
Train Epoch: 353 [81920/90000 (91%)]	Loss: 4.1342	Cost: 11.71s
Train Epoch: 353 	Average Loss: 4.2913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7342

Learning rate: 9.969285459343932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 354 [0/90000 (0%)]	Loss: 4.6904	Cost: 32.96s
Train Epoch: 354 [20480/90000 (23%)]	Loss: 4.2940	Cost: 10.59s
Train Epoch: 354 [40960/90000 (45%)]	Loss: 4.1362	Cost: 8.52s
Train Epoch: 354 [61440/90000 (68%)]	Loss: 4.1570	Cost: 8.33s
Train Epoch: 354 [81920/90000 (91%)]	Loss: 4.0707	Cost: 12.86s
Train Epoch: 354 	Average Loss: 4.2745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7401

Learning rate: 9.96911137244616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 355 [0/90000 (0%)]	Loss: 4.7203	Cost: 35.18s
Train Epoch: 355 [20480/90000 (23%)]	Loss: 4.3414	Cost: 7.11s
Train Epoch: 355 [40960/90000 (45%)]	Loss: 4.1462	Cost: 20.56s
Train Epoch: 355 [61440/90000 (68%)]	Loss: 4.1817	Cost: 12.30s
Train Epoch: 355 [81920/90000 (91%)]	Loss: 4.2022	Cost: 12.03s
Train Epoch: 355 	Average Loss: 4.2752
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7832

Learning rate: 9.968936795116758e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 356 [0/90000 (0%)]	Loss: 4.8020	Cost: 33.95s
Train Epoch: 356 [20480/90000 (23%)]	Loss: 4.3660	Cost: 11.56s
Train Epoch: 356 [40960/90000 (45%)]	Loss: 4.0952	Cost: 8.16s
Train Epoch: 356 [61440/90000 (68%)]	Loss: 4.1811	Cost: 7.19s
Train Epoch: 356 [81920/90000 (91%)]	Loss: 4.1814	Cost: 15.03s
Train Epoch: 356 	Average Loss: 4.2616
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7445

Learning rate: 9.968761727372955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 357 [0/90000 (0%)]	Loss: 4.7149	Cost: 34.25s
Train Epoch: 357 [20480/90000 (23%)]	Loss: 4.2575	Cost: 7.93s
Train Epoch: 357 [40960/90000 (45%)]	Loss: 4.1740	Cost: 19.36s
Train Epoch: 357 [61440/90000 (68%)]	Loss: 4.2539	Cost: 12.32s
Train Epoch: 357 [81920/90000 (91%)]	Loss: 4.1488	Cost: 12.16s
Train Epoch: 357 	Average Loss: 4.2639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7356

Learning rate: 9.96858616923203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 358 [0/90000 (0%)]	Loss: 4.6892	Cost: 46.65s
Train Epoch: 358 [20480/90000 (23%)]	Loss: 4.2795	Cost: 12.17s
Train Epoch: 358 [40960/90000 (45%)]	Loss: 4.0933	Cost: 7.39s
Train Epoch: 358 [61440/90000 (68%)]	Loss: 4.0793	Cost: 6.33s
Train Epoch: 358 [81920/90000 (91%)]	Loss: 4.1181	Cost: 11.34s
Train Epoch: 358 	Average Loss: 4.2234
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.7665

Learning rate: 9.96841012071131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 359 [0/90000 (0%)]	Loss: 4.7303	Cost: 27.03s
Train Epoch: 359 [20480/90000 (23%)]	Loss: 4.3603	Cost: 10.55s
Train Epoch: 359 [40960/90000 (45%)]	Loss: 4.1542	Cost: 26.12s
Train Epoch: 359 [61440/90000 (68%)]	Loss: 4.0746	Cost: 13.54s
Train Epoch: 359 [81920/90000 (91%)]	Loss: 4.1592	Cost: 12.18s
Train Epoch: 359 	Average Loss: 4.2362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6812

Saving model as e359_model.pt & e359_waveforms_supplementary.hdf5
Learning rate: 9.968233581828168e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 360 [0/90000 (0%)]	Loss: 4.7504	Cost: 40.24s
Train Epoch: 360 [20480/90000 (23%)]	Loss: 4.3048	Cost: 9.80s
Train Epoch: 360 [40960/90000 (45%)]	Loss: 4.0324	Cost: 10.01s
Train Epoch: 360 [61440/90000 (68%)]	Loss: 4.0410	Cost: 7.42s
Train Epoch: 360 [81920/90000 (91%)]	Loss: 4.0149	Cost: 12.66s
Train Epoch: 360 	Average Loss: 4.1986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6667

Saving model as e360_model.pt & e360_waveforms_supplementary.hdf5
Learning rate: 9.968056552600032e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 361 [0/90000 (0%)]	Loss: 4.6863	Cost: 36.26s
Train Epoch: 361 [20480/90000 (23%)]	Loss: 4.2784	Cost: 11.06s
Train Epoch: 361 [40960/90000 (45%)]	Loss: 4.0915	Cost: 14.83s
Train Epoch: 361 [61440/90000 (68%)]	Loss: 4.2616	Cost: 11.53s
Train Epoch: 361 [81920/90000 (91%)]	Loss: 4.0908	Cost: 12.17s
Train Epoch: 361 	Average Loss: 4.1946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6248

Saving model as e361_model.pt & e361_waveforms_supplementary.hdf5
Learning rate: 9.967879033044371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 362 [0/90000 (0%)]	Loss: 4.6817	Cost: 49.18s
Train Epoch: 362 [20480/90000 (23%)]	Loss: 4.1886	Cost: 6.25s
Train Epoch: 362 [40960/90000 (45%)]	Loss: 3.9926	Cost: 13.27s
Train Epoch: 362 [61440/90000 (68%)]	Loss: 4.1742	Cost: 8.49s
Train Epoch: 362 [81920/90000 (91%)]	Loss: 3.9629	Cost: 8.36s
Train Epoch: 362 	Average Loss: 4.1873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6434

Learning rate: 9.967701023178707e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 363 [0/90000 (0%)]	Loss: 4.6032	Cost: 28.24s
Train Epoch: 363 [20480/90000 (23%)]	Loss: 4.2588	Cost: 6.84s
Train Epoch: 363 [40960/90000 (45%)]	Loss: 4.1330	Cost: 17.22s
Train Epoch: 363 [61440/90000 (68%)]	Loss: 4.1865	Cost: 12.52s
Train Epoch: 363 [81920/90000 (91%)]	Loss: 4.1160	Cost: 12.35s
Train Epoch: 363 	Average Loss: 4.2065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6927

Learning rate: 9.967522523020609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 364 [0/90000 (0%)]	Loss: 4.6209	Cost: 33.61s
Train Epoch: 364 [20480/90000 (23%)]	Loss: 4.2688	Cost: 11.40s
Train Epoch: 364 [40960/90000 (45%)]	Loss: 3.9927	Cost: 10.40s
Train Epoch: 364 [61440/90000 (68%)]	Loss: 4.1645	Cost: 8.30s
Train Epoch: 364 [81920/90000 (91%)]	Loss: 4.0409	Cost: 15.18s
Train Epoch: 364 	Average Loss: 4.1693
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6607

Learning rate: 9.967343532587693e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 365 [0/90000 (0%)]	Loss: 4.7085	Cost: 32.32s
Train Epoch: 365 [20480/90000 (23%)]	Loss: 4.1618	Cost: 10.98s
Train Epoch: 365 [40960/90000 (45%)]	Loss: 3.9818	Cost: 18.60s
Train Epoch: 365 [61440/90000 (68%)]	Loss: 4.1185	Cost: 12.05s
Train Epoch: 365 [81920/90000 (91%)]	Loss: 4.0753	Cost: 11.83s
Train Epoch: 365 	Average Loss: 4.1767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6746

Learning rate: 9.967164051897624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 366 [0/90000 (0%)]	Loss: 4.6678	Cost: 45.90s
Train Epoch: 366 [20480/90000 (23%)]	Loss: 4.2069	Cost: 8.08s
Train Epoch: 366 [40960/90000 (45%)]	Loss: 4.0276	Cost: 11.43s
Train Epoch: 366 [61440/90000 (68%)]	Loss: 4.1210	Cost: 9.10s
Train Epoch: 366 [81920/90000 (91%)]	Loss: 4.0169	Cost: 11.93s
Train Epoch: 366 	Average Loss: 4.1477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6735

Learning rate: 9.966984080968118e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 367 [0/90000 (0%)]	Loss: 4.6142	Cost: 35.24s
Train Epoch: 367 [20480/90000 (23%)]	Loss: 4.1924	Cost: 7.31s
Train Epoch: 367 [40960/90000 (45%)]	Loss: 3.9851	Cost: 16.54s
Train Epoch: 367 [61440/90000 (68%)]	Loss: 4.0492	Cost: 12.41s
Train Epoch: 367 [81920/90000 (91%)]	Loss: 4.1016	Cost: 11.70s
Train Epoch: 367 	Average Loss: 4.1672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6952

Learning rate: 9.966803619816938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 368 [0/90000 (0%)]	Loss: 4.6944	Cost: 31.88s
Train Epoch: 368 [20480/90000 (23%)]	Loss: 4.1837	Cost: 11.23s
Train Epoch: 368 [40960/90000 (45%)]	Loss: 3.9533	Cost: 9.62s
Train Epoch: 368 [61440/90000 (68%)]	Loss: 4.1755	Cost: 6.06s
Train Epoch: 368 [81920/90000 (91%)]	Loss: 4.0397	Cost: 9.40s
Train Epoch: 368 	Average Loss: 4.1504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6608

Learning rate: 9.966622668461892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 369 [0/90000 (0%)]	Loss: 4.6758	Cost: 32.01s
Train Epoch: 369 [20480/90000 (23%)]	Loss: 4.1727	Cost: 10.75s
Train Epoch: 369 [40960/90000 (45%)]	Loss: 4.0712	Cost: 18.82s
Train Epoch: 369 [61440/90000 (68%)]	Loss: 4.0423	Cost: 12.19s
Train Epoch: 369 [81920/90000 (91%)]	Loss: 4.0021	Cost: 12.17s
Train Epoch: 369 	Average Loss: 4.1211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5804

Saving model as e369_model.pt & e369_waveforms_supplementary.hdf5
Learning rate: 9.96644122692084e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 370 [0/90000 (0%)]	Loss: 4.5892	Cost: 39.87s
Train Epoch: 370 [20480/90000 (23%)]	Loss: 4.0677	Cost: 8.97s
Train Epoch: 370 [40960/90000 (45%)]	Loss: 3.9454	Cost: 10.32s
Train Epoch: 370 [61440/90000 (68%)]	Loss: 4.1587	Cost: 8.37s
Train Epoch: 370 [81920/90000 (91%)]	Loss: 3.8449	Cost: 10.54s
Train Epoch: 370 	Average Loss: 4.0903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6607

Learning rate: 9.966259295211689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 371 [0/90000 (0%)]	Loss: 4.4159	Cost: 27.24s
Train Epoch: 371 [20480/90000 (23%)]	Loss: 4.2158	Cost: 7.46s
Train Epoch: 371 [40960/90000 (45%)]	Loss: 3.9844	Cost: 23.65s
Train Epoch: 371 [61440/90000 (68%)]	Loss: 4.1394	Cost: 12.07s
Train Epoch: 371 [81920/90000 (91%)]	Loss: 4.0034	Cost: 11.69s
Train Epoch: 371 	Average Loss: 4.1300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5737

Saving model as e371_model.pt & e371_waveforms_supplementary.hdf5
Learning rate: 9.966076873352397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 372 [0/90000 (0%)]	Loss: 4.5407	Cost: 43.35s
Train Epoch: 372 [20480/90000 (23%)]	Loss: 4.2240	Cost: 11.59s
Train Epoch: 372 [40960/90000 (45%)]	Loss: 4.0285	Cost: 8.39s
Train Epoch: 372 [61440/90000 (68%)]	Loss: 4.0656	Cost: 6.31s
Train Epoch: 372 [81920/90000 (91%)]	Loss: 4.0181	Cost: 12.27s
Train Epoch: 372 	Average Loss: 4.1191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6222

Learning rate: 9.965893961360968e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 373 [0/90000 (0%)]	Loss: 4.7202	Cost: 30.78s
Train Epoch: 373 [20480/90000 (23%)]	Loss: 4.1434	Cost: 10.65s
Train Epoch: 373 [40960/90000 (45%)]	Loss: 3.9379	Cost: 24.13s
Train Epoch: 373 [61440/90000 (68%)]	Loss: 4.0462	Cost: 12.44s
Train Epoch: 373 [81920/90000 (91%)]	Loss: 4.0116	Cost: 12.04s
Train Epoch: 373 	Average Loss: 4.1186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6241

Learning rate: 9.965710559255453e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 374 [0/90000 (0%)]	Loss: 4.4838	Cost: 51.96s
Train Epoch: 374 [20480/90000 (23%)]	Loss: 4.2165	Cost: 8.22s
Train Epoch: 374 [40960/90000 (45%)]	Loss: 3.9766	Cost: 12.09s
Train Epoch: 374 [61440/90000 (68%)]	Loss: 3.9668	Cost: 8.54s
Train Epoch: 374 [81920/90000 (91%)]	Loss: 3.9297	Cost: 8.69s
Train Epoch: 374 	Average Loss: 4.0582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6235

Learning rate: 9.965526667053955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 375 [0/90000 (0%)]	Loss: 4.6955	Cost: 30.07s
Train Epoch: 375 [20480/90000 (23%)]	Loss: 4.1857	Cost: 7.10s
Train Epoch: 375 [40960/90000 (45%)]	Loss: 3.9409	Cost: 18.11s
Train Epoch: 375 [61440/90000 (68%)]	Loss: 4.0671	Cost: 12.23s
Train Epoch: 375 [81920/90000 (91%)]	Loss: 3.9180	Cost: 11.81s
Train Epoch: 375 	Average Loss: 4.0929
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6131

Learning rate: 9.965342284774624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 376 [0/90000 (0%)]	Loss: 4.6361	Cost: 32.71s
Train Epoch: 376 [20480/90000 (23%)]	Loss: 4.1910	Cost: 12.34s
Train Epoch: 376 [40960/90000 (45%)]	Loss: 3.9811	Cost: 8.46s
Train Epoch: 376 [61440/90000 (68%)]	Loss: 4.0270	Cost: 6.37s
Train Epoch: 376 [81920/90000 (91%)]	Loss: 3.8387	Cost: 12.91s
Train Epoch: 376 	Average Loss: 4.0878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5581

Saving model as e376_model.pt & e376_waveforms_supplementary.hdf5
Learning rate: 9.965157412435655e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 377 [0/90000 (0%)]	Loss: 4.5274	Cost: 30.44s
Train Epoch: 377 [20480/90000 (23%)]	Loss: 4.0658	Cost: 8.03s
Train Epoch: 377 [40960/90000 (45%)]	Loss: 3.9247	Cost: 16.82s
Train Epoch: 377 [61440/90000 (68%)]	Loss: 3.9445	Cost: 11.88s
Train Epoch: 377 [81920/90000 (91%)]	Loss: 3.8312	Cost: 12.89s
Train Epoch: 377 	Average Loss: 4.0491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5619

Learning rate: 9.964972050055294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 378 [0/90000 (0%)]	Loss: 4.4934	Cost: 35.12s
Train Epoch: 378 [20480/90000 (23%)]	Loss: 4.0727	Cost: 9.24s
Train Epoch: 378 [40960/90000 (45%)]	Loss: 3.9791	Cost: 10.60s
Train Epoch: 378 [61440/90000 (68%)]	Loss: 4.0139	Cost: 8.92s
Train Epoch: 378 [81920/90000 (91%)]	Loss: 3.9093	Cost: 14.87s
Train Epoch: 378 	Average Loss: 4.0585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.6236

Learning rate: 9.964786197651839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 379 [0/90000 (0%)]	Loss: 4.6881	Cost: 41.58s
Train Epoch: 379 [20480/90000 (23%)]	Loss: 3.9730	Cost: 7.00s
Train Epoch: 379 [40960/90000 (45%)]	Loss: 3.8301	Cost: 18.67s
Train Epoch: 379 [61440/90000 (68%)]	Loss: 3.9593	Cost: 12.29s
Train Epoch: 379 [81920/90000 (91%)]	Loss: 3.8767	Cost: 12.10s
Train Epoch: 379 	Average Loss: 4.0155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5652

Learning rate: 9.96459985524363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 380 [0/90000 (0%)]	Loss: 4.4756	Cost: 34.70s
Train Epoch: 380 [20480/90000 (23%)]	Loss: 3.9629	Cost: 11.78s
Train Epoch: 380 [40960/90000 (45%)]	Loss: 3.9201	Cost: 12.15s
Train Epoch: 380 [61440/90000 (68%)]	Loss: 3.9557	Cost: 8.98s
Train Epoch: 380 [81920/90000 (91%)]	Loss: 3.8177	Cost: 6.27s
Train Epoch: 380 	Average Loss: 3.9971
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5584

Learning rate: 9.96441302284906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 381 [0/90000 (0%)]	Loss: 4.4112	Cost: 30.06s
Train Epoch: 381 [20480/90000 (23%)]	Loss: 4.0989	Cost: 8.73s
Train Epoch: 381 [40960/90000 (45%)]	Loss: 3.8060	Cost: 10.23s
Train Epoch: 381 [61440/90000 (68%)]	Loss: 4.0280	Cost: 7.24s
Train Epoch: 381 [81920/90000 (91%)]	Loss: 3.8765	Cost: 17.30s
Train Epoch: 381 	Average Loss: 3.9963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5367

Saving model as e381_model.pt & e381_waveforms_supplementary.hdf5
Learning rate: 9.964225700486566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 382 [0/90000 (0%)]	Loss: 4.6282	Cost: 38.84s
Train Epoch: 382 [20480/90000 (23%)]	Loss: 4.0331	Cost: 14.35s
Train Epoch: 382 [40960/90000 (45%)]	Loss: 3.7930	Cost: 12.26s
Train Epoch: 382 [61440/90000 (68%)]	Loss: 3.9044	Cost: 12.08s
Train Epoch: 382 [81920/90000 (91%)]	Loss: 3.9734	Cost: 8.00s
Train Epoch: 382 	Average Loss: 4.0042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5522

Learning rate: 9.96403788817464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 383 [0/90000 (0%)]	Loss: 4.6262	Cost: 29.38s
Train Epoch: 383 [20480/90000 (23%)]	Loss: 3.9836	Cost: 9.31s
Train Epoch: 383 [40960/90000 (45%)]	Loss: 3.8887	Cost: 11.14s
Train Epoch: 383 [61440/90000 (68%)]	Loss: 4.0037	Cost: 8.57s
Train Epoch: 383 [81920/90000 (91%)]	Loss: 3.9681	Cost: 8.75s
Train Epoch: 383 	Average Loss: 3.9931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5919

Learning rate: 9.963849585931816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 384 [0/90000 (0%)]	Loss: 4.4348	Cost: 29.52s
Train Epoch: 384 [20480/90000 (23%)]	Loss: 4.1081	Cost: 9.43s
Train Epoch: 384 [40960/90000 (45%)]	Loss: 3.9264	Cost: 23.37s
Train Epoch: 384 [61440/90000 (68%)]	Loss: 4.1269	Cost: 12.16s
Train Epoch: 384 [81920/90000 (91%)]	Loss: 3.7909	Cost: 11.84s
Train Epoch: 384 	Average Loss: 4.0401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5665

Learning rate: 9.963660793776678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 385 [0/90000 (0%)]	Loss: 4.5690	Cost: 55.42s
Train Epoch: 385 [20480/90000 (23%)]	Loss: 4.0584	Cost: 6.45s
Train Epoch: 385 [40960/90000 (45%)]	Loss: 3.9005	Cost: 12.67s
Train Epoch: 385 [61440/90000 (68%)]	Loss: 4.0813	Cost: 8.74s
Train Epoch: 385 [81920/90000 (91%)]	Loss: 3.9032	Cost: 8.52s
Train Epoch: 385 	Average Loss: 4.0202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5384

Learning rate: 9.963471511727859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 386 [0/90000 (0%)]	Loss: 4.3782	Cost: 27.11s
Train Epoch: 386 [20480/90000 (23%)]	Loss: 3.9402	Cost: 8.77s
Train Epoch: 386 [40960/90000 (45%)]	Loss: 3.7921	Cost: 16.23s
Train Epoch: 386 [61440/90000 (68%)]	Loss: 3.8867	Cost: 12.76s
Train Epoch: 386 [81920/90000 (91%)]	Loss: 3.7662	Cost: 12.16s
Train Epoch: 386 	Average Loss: 3.9638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5324

Saving model as e386_model.pt & e386_waveforms_supplementary.hdf5
Learning rate: 9.963281739804043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 387 [0/90000 (0%)]	Loss: 4.5163	Cost: 32.74s
Train Epoch: 387 [20480/90000 (23%)]	Loss: 3.9467	Cost: 8.16s
Train Epoch: 387 [40960/90000 (45%)]	Loss: 3.7634	Cost: 13.15s
Train Epoch: 387 [61440/90000 (68%)]	Loss: 3.8453	Cost: 8.71s
Train Epoch: 387 [81920/90000 (91%)]	Loss: 3.7648	Cost: 10.48s
Train Epoch: 387 	Average Loss: 3.9703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5035

Saving model as e387_model.pt & e387_waveforms_supplementary.hdf5
Learning rate: 9.963091478023956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 388 [0/90000 (0%)]	Loss: 4.5052	Cost: 28.32s
Train Epoch: 388 [20480/90000 (23%)]	Loss: 4.0793	Cost: 9.69s
Train Epoch: 388 [40960/90000 (45%)]	Loss: 3.6941	Cost: 15.61s
Train Epoch: 388 [61440/90000 (68%)]	Loss: 3.8543	Cost: 13.11s
Train Epoch: 388 [81920/90000 (91%)]	Loss: 3.8671	Cost: 12.18s
Train Epoch: 388 	Average Loss: 3.9395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5525

Learning rate: 9.962900726406379e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 389 [0/90000 (0%)]	Loss: 4.5396	Cost: 45.14s
Train Epoch: 389 [20480/90000 (23%)]	Loss: 3.9827	Cost: 11.79s
Train Epoch: 389 [40960/90000 (45%)]	Loss: 3.7526	Cost: 9.14s
Train Epoch: 389 [61440/90000 (68%)]	Loss: 3.9558	Cost: 6.47s
Train Epoch: 389 [81920/90000 (91%)]	Loss: 3.7928	Cost: 14.39s
Train Epoch: 389 	Average Loss: 3.9637
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5524

Learning rate: 9.962709484970139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 390 [0/90000 (0%)]	Loss: 4.4156	Cost: 29.86s
Train Epoch: 390 [20480/90000 (23%)]	Loss: 3.9766	Cost: 7.13s
Train Epoch: 390 [40960/90000 (45%)]	Loss: 3.7197	Cost: 17.53s
Train Epoch: 390 [61440/90000 (68%)]	Loss: 3.9551	Cost: 12.16s
Train Epoch: 390 [81920/90000 (91%)]	Loss: 3.7486	Cost: 11.86s
Train Epoch: 390 	Average Loss: 3.9507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5218

Learning rate: 9.962517753734109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 391 [0/90000 (0%)]	Loss: 4.3493	Cost: 31.33s
Train Epoch: 391 [20480/90000 (23%)]	Loss: 3.9539	Cost: 12.50s
Train Epoch: 391 [40960/90000 (45%)]	Loss: 3.8539	Cost: 11.46s
Train Epoch: 391 [61440/90000 (68%)]	Loss: 3.8084	Cost: 6.31s
Train Epoch: 391 [81920/90000 (91%)]	Loss: 3.8413	Cost: 7.92s
Train Epoch: 391 	Average Loss: 3.9271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5274

Learning rate: 9.962325532717212e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 392 [0/90000 (0%)]	Loss: 4.4344	Cost: 37.89s
Train Epoch: 392 [20480/90000 (23%)]	Loss: 3.8174	Cost: 10.04s
Train Epoch: 392 [40960/90000 (45%)]	Loss: 3.6736	Cost: 20.11s
Train Epoch: 392 [61440/90000 (68%)]	Loss: 3.9064	Cost: 11.92s
Train Epoch: 392 [81920/90000 (91%)]	Loss: 3.8159	Cost: 11.82s
Train Epoch: 392 	Average Loss: 3.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5609

Learning rate: 9.96213282193842e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 393 [0/90000 (0%)]	Loss: 4.4786	Cost: 43.11s
Train Epoch: 393 [20480/90000 (23%)]	Loss: 3.9294	Cost: 7.25s
Train Epoch: 393 [40960/90000 (45%)]	Loss: 3.7659	Cost: 12.18s
Train Epoch: 393 [61440/90000 (68%)]	Loss: 3.8060	Cost: 8.66s
Train Epoch: 393 [81920/90000 (91%)]	Loss: 3.7381	Cost: 8.12s
Train Epoch: 393 	Average Loss: 3.9015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.5018

Saving model as e393_model.pt & e393_waveforms_supplementary.hdf5
Learning rate: 9.961939621416751e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 394 [0/90000 (0%)]	Loss: 4.3357	Cost: 31.53s
Train Epoch: 394 [20480/90000 (23%)]	Loss: 3.9210	Cost: 11.53s
Train Epoch: 394 [40960/90000 (45%)]	Loss: 3.7468	Cost: 17.77s
Train Epoch: 394 [61440/90000 (68%)]	Loss: 3.8504	Cost: 12.24s
Train Epoch: 394 [81920/90000 (91%)]	Loss: 3.7154	Cost: 11.97s
Train Epoch: 394 	Average Loss: 3.8843
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4963

Saving model as e394_model.pt & e394_waveforms_supplementary.hdf5
Learning rate: 9.961745931171276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 395 [0/90000 (0%)]	Loss: 4.5975	Cost: 30.86s
Train Epoch: 395 [20480/90000 (23%)]	Loss: 3.8562	Cost: 6.33s
Train Epoch: 395 [40960/90000 (45%)]	Loss: 3.7134	Cost: 14.22s
Train Epoch: 395 [61440/90000 (68%)]	Loss: 3.7825	Cost: 8.62s
Train Epoch: 395 [81920/90000 (91%)]	Loss: 3.6846	Cost: 8.55s
Train Epoch: 395 	Average Loss: 3.8500
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4204

Saving model as e395_model.pt & e395_waveforms_supplementary.hdf5
Learning rate: 9.96155175122111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 396 [0/90000 (0%)]	Loss: 4.3855	Cost: 27.71s
Train Epoch: 396 [20480/90000 (23%)]	Loss: 3.9717	Cost: 7.00s
Train Epoch: 396 [40960/90000 (45%)]	Loss: 3.6524	Cost: 17.94s
Train Epoch: 396 [61440/90000 (68%)]	Loss: 3.7818	Cost: 13.26s
Train Epoch: 396 [81920/90000 (91%)]	Loss: 3.7439	Cost: 13.08s
Train Epoch: 396 	Average Loss: 3.8774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4847

Learning rate: 9.96135708158542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 397 [0/90000 (0%)]	Loss: 4.4849	Cost: 38.03s
Train Epoch: 397 [20480/90000 (23%)]	Loss: 3.8880	Cost: 13.05s
Train Epoch: 397 [40960/90000 (45%)]	Loss: 3.6942	Cost: 12.22s
Train Epoch: 397 [61440/90000 (68%)]	Loss: 3.8518	Cost: 8.53s
Train Epoch: 397 [81920/90000 (91%)]	Loss: 3.6753	Cost: 6.29s
Train Epoch: 397 	Average Loss: 3.8447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4537

Learning rate: 9.961161922283415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 398 [0/90000 (0%)]	Loss: 4.5685	Cost: 34.48s
Train Epoch: 398 [20480/90000 (23%)]	Loss: 3.7847	Cost: 8.89s
Train Epoch: 398 [40960/90000 (45%)]	Loss: 3.7723	Cost: 10.80s
Train Epoch: 398 [61440/90000 (68%)]	Loss: 3.7751	Cost: 8.73s
Train Epoch: 398 [81920/90000 (91%)]	Loss: 3.7436	Cost: 9.04s
Train Epoch: 398 	Average Loss: 3.8382
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4258

Learning rate: 9.960966273334359e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 399 [0/90000 (0%)]	Loss: 4.3946	Cost: 32.38s
Train Epoch: 399 [20480/90000 (23%)]	Loss: 3.9656	Cost: 13.31s
Train Epoch: 399 [40960/90000 (45%)]	Loss: 3.7966	Cost: 17.76s
Train Epoch: 399 [61440/90000 (68%)]	Loss: 3.7677	Cost: 12.22s
Train Epoch: 399 [81920/90000 (91%)]	Loss: 3.6681	Cost: 12.02s
Train Epoch: 399 	Average Loss: 3.8338
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3927

Saving model as e399_model.pt & e399_waveforms_supplementary.hdf5
Learning rate: 9.960770134757561e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 400 [0/90000 (0%)]	Loss: 4.3484	Cost: 54.36s
Train Epoch: 400 [20480/90000 (23%)]	Loss: 3.8536	Cost: 8.73s
Train Epoch: 400 [40960/90000 (45%)]	Loss: 3.6766	Cost: 8.83s
Train Epoch: 400 [61440/90000 (68%)]	Loss: 3.7160	Cost: 8.88s
Train Epoch: 400 [81920/90000 (91%)]	Loss: 3.6659	Cost: 8.78s
Train Epoch: 400 	Average Loss: 3.8162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4019

Learning rate: 9.96057350657238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 401 [0/90000 (0%)]	Loss: 4.3347	Cost: 29.38s
Train Epoch: 401 [20480/90000 (23%)]	Loss: 3.9154	Cost: 8.72s
Train Epoch: 401 [40960/90000 (45%)]	Loss: 3.6742	Cost: 16.33s
Train Epoch: 401 [61440/90000 (68%)]	Loss: 3.6437	Cost: 12.31s
Train Epoch: 401 [81920/90000 (91%)]	Loss: 3.6288	Cost: 12.18s
Train Epoch: 401 	Average Loss: 3.8008
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4285

Learning rate: 9.960376388798222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 402 [0/90000 (0%)]	Loss: 4.3352	Cost: 33.14s
Train Epoch: 402 [20480/90000 (23%)]	Loss: 3.9084	Cost: 11.94s
Train Epoch: 402 [40960/90000 (45%)]	Loss: 3.7431	Cost: 7.77s
Train Epoch: 402 [61440/90000 (68%)]	Loss: 3.7076	Cost: 6.46s
Train Epoch: 402 [81920/90000 (91%)]	Loss: 3.6816	Cost: 14.92s
Train Epoch: 402 	Average Loss: 3.8232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3862

Saving model as e402_model.pt & e402_waveforms_supplementary.hdf5
Learning rate: 9.960178781454541e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 403 [0/90000 (0%)]	Loss: 4.3623	Cost: 30.05s
Train Epoch: 403 [20480/90000 (23%)]	Loss: 3.7987	Cost: 7.18s
Train Epoch: 403 [40960/90000 (45%)]	Loss: 3.6490	Cost: 25.88s
Train Epoch: 403 [61440/90000 (68%)]	Loss: 3.7774	Cost: 12.18s
Train Epoch: 403 [81920/90000 (91%)]	Loss: 3.6967	Cost: 12.11s
Train Epoch: 403 	Average Loss: 3.7887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4192

Learning rate: 9.959980684560841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 404 [0/90000 (0%)]	Loss: 4.3790	Cost: 35.73s
Train Epoch: 404 [20480/90000 (23%)]	Loss: 3.8088	Cost: 11.91s
Train Epoch: 404 [40960/90000 (45%)]	Loss: 3.7659	Cost: 10.78s
Train Epoch: 404 [61440/90000 (68%)]	Loss: 3.6990	Cost: 7.41s
Train Epoch: 404 [81920/90000 (91%)]	Loss: 3.7249	Cost: 13.41s
Train Epoch: 404 	Average Loss: 3.8124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4663

Learning rate: 9.959782098136674e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 405 [0/90000 (0%)]	Loss: 4.4763	Cost: 38.98s
Train Epoch: 405 [20480/90000 (23%)]	Loss: 3.8352	Cost: 6.65s
Train Epoch: 405 [40960/90000 (45%)]	Loss: 3.5510	Cost: 18.00s
Train Epoch: 405 [61440/90000 (68%)]	Loss: 3.6938	Cost: 12.23s
Train Epoch: 405 [81920/90000 (91%)]	Loss: 3.6026	Cost: 11.83s
Train Epoch: 405 	Average Loss: 3.7753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3045

Saving model as e405_model.pt & e405_waveforms_supplementary.hdf5
Learning rate: 9.959583022201639e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 406 [0/90000 (0%)]	Loss: 4.3849	Cost: 30.07s
Train Epoch: 406 [20480/90000 (23%)]	Loss: 3.6551	Cost: 11.13s
Train Epoch: 406 [40960/90000 (45%)]	Loss: 3.5768	Cost: 8.30s
Train Epoch: 406 [61440/90000 (68%)]	Loss: 3.5938	Cost: 6.40s
Train Epoch: 406 [81920/90000 (91%)]	Loss: 3.5776	Cost: 14.80s
Train Epoch: 406 	Average Loss: 3.7563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3929

Learning rate: 9.959383456775382e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 407 [0/90000 (0%)]	Loss: 4.1759	Cost: 42.56s
Train Epoch: 407 [20480/90000 (23%)]	Loss: 4.0531	Cost: 10.78s
Train Epoch: 407 [40960/90000 (45%)]	Loss: 3.6503	Cost: 15.47s
Train Epoch: 407 [61440/90000 (68%)]	Loss: 3.7917	Cost: 11.86s
Train Epoch: 407 [81920/90000 (91%)]	Loss: 3.7499	Cost: 11.98s
Train Epoch: 407 	Average Loss: 3.8476
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.4578

Learning rate: 9.959183401877603e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 408 [0/90000 (0%)]	Loss: 4.2703	Cost: 36.41s
Train Epoch: 408 [20480/90000 (23%)]	Loss: 3.8358	Cost: 6.53s
Train Epoch: 408 [40960/90000 (45%)]	Loss: 3.6128	Cost: 14.09s
Train Epoch: 408 [61440/90000 (68%)]	Loss: 3.7310	Cost: 8.96s
Train Epoch: 408 [81920/90000 (91%)]	Loss: 3.6321	Cost: 11.57s
Train Epoch: 408 	Average Loss: 3.7694
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3390

Learning rate: 9.958982857528043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 409 [0/90000 (0%)]	Loss: 4.2374	Cost: 30.62s
Train Epoch: 409 [20480/90000 (23%)]	Loss: 3.7007	Cost: 9.33s
Train Epoch: 409 [40960/90000 (45%)]	Loss: 3.6612	Cost: 16.47s
Train Epoch: 409 [61440/90000 (68%)]	Loss: 3.6480	Cost: 13.48s
Train Epoch: 409 [81920/90000 (91%)]	Loss: 3.6300	Cost: 11.95s
Train Epoch: 409 	Average Loss: 3.7390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3559

Learning rate: 9.958781823746497e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 410 [0/90000 (0%)]	Loss: 4.4591	Cost: 39.30s
Train Epoch: 410 [20480/90000 (23%)]	Loss: 3.7164	Cost: 12.44s
Train Epoch: 410 [40960/90000 (45%)]	Loss: 3.6258	Cost: 8.50s
Train Epoch: 410 [61440/90000 (68%)]	Loss: 3.7345	Cost: 6.17s
Train Epoch: 410 [81920/90000 (91%)]	Loss: 3.6069	Cost: 15.30s
Train Epoch: 410 	Average Loss: 3.7704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3363

Learning rate: 9.958580300552807e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 411 [0/90000 (0%)]	Loss: 4.3201	Cost: 28.73s
Train Epoch: 411 [20480/90000 (23%)]	Loss: 3.7367	Cost: 10.45s
Train Epoch: 411 [40960/90000 (45%)]	Loss: 3.6160	Cost: 24.76s
Train Epoch: 411 [61440/90000 (68%)]	Loss: 3.7047	Cost: 12.29s
Train Epoch: 411 [81920/90000 (91%)]	Loss: 3.6503	Cost: 11.95s
Train Epoch: 411 	Average Loss: 3.7530
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3530

Learning rate: 9.95837828796686e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 412 [0/90000 (0%)]	Loss: 4.2689	Cost: 57.13s
Train Epoch: 412 [20480/90000 (23%)]	Loss: 3.7235	Cost: 6.01s
Train Epoch: 412 [40960/90000 (45%)]	Loss: 3.6548	Cost: 14.02s
Train Epoch: 412 [61440/90000 (68%)]	Loss: 3.5261	Cost: 8.58s
Train Epoch: 412 [81920/90000 (91%)]	Loss: 3.5424	Cost: 8.66s
Train Epoch: 412 	Average Loss: 3.7261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3782

Learning rate: 9.958175786008596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 413 [0/90000 (0%)]	Loss: 4.3075	Cost: 27.56s
Train Epoch: 413 [20480/90000 (23%)]	Loss: 3.7666	Cost: 7.28s
Train Epoch: 413 [40960/90000 (45%)]	Loss: 3.5352	Cost: 17.17s
Train Epoch: 413 [61440/90000 (68%)]	Loss: 3.5836	Cost: 12.61s
Train Epoch: 413 [81920/90000 (91%)]	Loss: 3.5363	Cost: 12.75s
Train Epoch: 413 	Average Loss: 3.6962
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3395

Learning rate: 9.957972794698001e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 414 [0/90000 (0%)]	Loss: 4.2710	Cost: 42.62s
Train Epoch: 414 [20480/90000 (23%)]	Loss: 3.6848	Cost: 11.26s
Train Epoch: 414 [40960/90000 (45%)]	Loss: 3.4966	Cost: 9.49s
Train Epoch: 414 [61440/90000 (68%)]	Loss: 3.6299	Cost: 6.27s
Train Epoch: 414 [81920/90000 (91%)]	Loss: 3.5232	Cost: 15.08s
Train Epoch: 414 	Average Loss: 3.6992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3370

Learning rate: 9.957769314055109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 415 [0/90000 (0%)]	Loss: 4.2036	Cost: 30.90s
Train Epoch: 415 [20480/90000 (23%)]	Loss: 3.6446	Cost: 6.68s
Train Epoch: 415 [40960/90000 (45%)]	Loss: 3.5477	Cost: 16.40s
Train Epoch: 415 [61440/90000 (68%)]	Loss: 3.6297	Cost: 12.60s
Train Epoch: 415 [81920/90000 (91%)]	Loss: 3.3788	Cost: 12.27s
Train Epoch: 415 	Average Loss: 3.6545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3088

Learning rate: 9.957565344100001e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 416 [0/90000 (0%)]	Loss: 4.3262	Cost: 56.34s
Train Epoch: 416 [20480/90000 (23%)]	Loss: 3.7261	Cost: 8.49s
Train Epoch: 416 [40960/90000 (45%)]	Loss: 3.5533	Cost: 10.68s
Train Epoch: 416 [61440/90000 (68%)]	Loss: 3.5277	Cost: 8.90s
Train Epoch: 416 [81920/90000 (91%)]	Loss: 3.6703	Cost: 10.47s
Train Epoch: 416 	Average Loss: 3.6898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3075

Learning rate: 9.95736088485281e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 417 [0/90000 (0%)]	Loss: 4.3650	Cost: 28.49s
Train Epoch: 417 [20480/90000 (23%)]	Loss: 3.7885	Cost: 6.65s
Train Epoch: 417 [40960/90000 (45%)]	Loss: 3.5074	Cost: 17.48s
Train Epoch: 417 [61440/90000 (68%)]	Loss: 3.5701	Cost: 13.02s
Train Epoch: 417 [81920/90000 (91%)]	Loss: 3.5445	Cost: 12.50s
Train Epoch: 417 	Average Loss: 3.6605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3172

Learning rate: 9.957155936333717e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 418 [0/90000 (0%)]	Loss: 4.2352	Cost: 34.07s
Train Epoch: 418 [20480/90000 (23%)]	Loss: 3.7018	Cost: 12.74s
Train Epoch: 418 [40960/90000 (45%)]	Loss: 3.4769	Cost: 10.04s
Train Epoch: 418 [61440/90000 (68%)]	Loss: 3.5672	Cost: 9.38s
Train Epoch: 418 [81920/90000 (91%)]	Loss: 3.5214	Cost: 13.77s
Train Epoch: 418 	Average Loss: 3.6523
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2596

Saving model as e418_model.pt & e418_waveforms_supplementary.hdf5
Learning rate: 9.956950498562945e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 419 [0/90000 (0%)]	Loss: 4.2604	Cost: 33.99s
Train Epoch: 419 [20480/90000 (23%)]	Loss: 3.6954	Cost: 10.04s
Train Epoch: 419 [40960/90000 (45%)]	Loss: 3.5771	Cost: 13.88s
Train Epoch: 419 [61440/90000 (68%)]	Loss: 3.6002	Cost: 12.03s
Train Epoch: 419 [81920/90000 (91%)]	Loss: 3.3814	Cost: 12.12s
Train Epoch: 419 	Average Loss: 3.6265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3338

Learning rate: 9.956744571560774e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 420 [0/90000 (0%)]	Loss: 4.3714	Cost: 37.21s
Train Epoch: 420 [20480/90000 (23%)]	Loss: 3.6237	Cost: 12.37s
Train Epoch: 420 [40960/90000 (45%)]	Loss: 3.4955	Cost: 8.91s
Train Epoch: 420 [61440/90000 (68%)]	Loss: 3.5931	Cost: 6.44s
Train Epoch: 420 [81920/90000 (91%)]	Loss: 3.5017	Cost: 10.71s
Train Epoch: 420 	Average Loss: 3.6325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3208

Learning rate: 9.956538155347526e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 421 [0/90000 (0%)]	Loss: 4.4476	Cost: 33.61s
Train Epoch: 421 [20480/90000 (23%)]	Loss: 3.6451	Cost: 6.21s
Train Epoch: 421 [40960/90000 (45%)]	Loss: 3.3904	Cost: 15.24s
Train Epoch: 421 [61440/90000 (68%)]	Loss: 3.4916	Cost: 12.37s
Train Epoch: 421 [81920/90000 (91%)]	Loss: 3.5154	Cost: 14.42s
Train Epoch: 421 	Average Loss: 3.6258
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3609

Learning rate: 9.956331249943575e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 422 [0/90000 (0%)]	Loss: 4.3753	Cost: 30.52s
Train Epoch: 422 [20480/90000 (23%)]	Loss: 3.7229	Cost: 12.28s
Train Epoch: 422 [40960/90000 (45%)]	Loss: 3.5654	Cost: 12.20s
Train Epoch: 422 [61440/90000 (68%)]	Loss: 3.5149	Cost: 7.39s
Train Epoch: 422 [81920/90000 (91%)]	Loss: 3.3707	Cost: 8.85s
Train Epoch: 422 	Average Loss: 3.6345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3080

Learning rate: 9.956123855369338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 423 [0/90000 (0%)]	Loss: 4.2791	Cost: 35.29s
Train Epoch: 423 [20480/90000 (23%)]	Loss: 3.5573	Cost: 9.39s
Train Epoch: 423 [40960/90000 (45%)]	Loss: 3.4959	Cost: 19.68s
Train Epoch: 423 [61440/90000 (68%)]	Loss: 3.5739	Cost: 12.04s
Train Epoch: 423 [81920/90000 (91%)]	Loss: 3.4378	Cost: 11.98s
Train Epoch: 423 	Average Loss: 3.6035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2804

Learning rate: 9.95591597164529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 424 [0/90000 (0%)]	Loss: 4.3233	Cost: 40.65s
Train Epoch: 424 [20480/90000 (23%)]	Loss: 3.5225	Cost: 11.90s
Train Epoch: 424 [40960/90000 (45%)]	Loss: 3.4172	Cost: 9.39s
Train Epoch: 424 [61440/90000 (68%)]	Loss: 3.5318	Cost: 6.30s
Train Epoch: 424 [81920/90000 (91%)]	Loss: 3.4777	Cost: 10.94s
Train Epoch: 424 	Average Loss: 3.6082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3431

Learning rate: 9.955707598791946e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 425 [0/90000 (0%)]	Loss: 4.2145	Cost: 28.35s
Train Epoch: 425 [20480/90000 (23%)]	Loss: 3.6015	Cost: 7.68s
Train Epoch: 425 [40960/90000 (45%)]	Loss: 3.3991	Cost: 16.28s
Train Epoch: 425 [61440/90000 (68%)]	Loss: 3.5716	Cost: 11.61s
Train Epoch: 425 [81920/90000 (91%)]	Loss: 3.4265	Cost: 13.22s
Train Epoch: 425 	Average Loss: 3.5981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1615

Saving model as e425_model.pt & e425_waveforms_supplementary.hdf5
Learning rate: 9.955498736829867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 426 [0/90000 (0%)]	Loss: 4.2553	Cost: 39.07s
Train Epoch: 426 [20480/90000 (23%)]	Loss: 3.5060	Cost: 12.35s
Train Epoch: 426 [40960/90000 (45%)]	Loss: 3.4381	Cost: 8.56s
Train Epoch: 426 [61440/90000 (68%)]	Loss: 3.5392	Cost: 6.26s
Train Epoch: 426 [81920/90000 (91%)]	Loss: 3.4086	Cost: 12.64s
Train Epoch: 426 	Average Loss: 3.5536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2334

Learning rate: 9.955289385779672e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 427 [0/90000 (0%)]	Loss: 4.0353	Cost: 38.02s
Train Epoch: 427 [20480/90000 (23%)]	Loss: 3.5949	Cost: 9.99s
Train Epoch: 427 [40960/90000 (45%)]	Loss: 3.4665	Cost: 22.24s
Train Epoch: 427 [61440/90000 (68%)]	Loss: 3.3385	Cost: 12.16s
Train Epoch: 427 [81920/90000 (91%)]	Loss: 3.4286	Cost: 12.19s
Train Epoch: 427 	Average Loss: 3.5699
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.3048

Learning rate: 9.955079545662022e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 428 [0/90000 (0%)]	Loss: 4.3039	Cost: 57.08s
Train Epoch: 428 [20480/90000 (23%)]	Loss: 3.5799	Cost: 6.31s
Train Epoch: 428 [40960/90000 (45%)]	Loss: 3.3639	Cost: 13.06s
Train Epoch: 428 [61440/90000 (68%)]	Loss: 3.4449	Cost: 8.84s
Train Epoch: 428 [81920/90000 (91%)]	Loss: 3.3452	Cost: 8.40s
Train Epoch: 428 	Average Loss: 3.5385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2260

Learning rate: 9.954869216497627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 429 [0/90000 (0%)]	Loss: 4.2462	Cost: 28.60s
Train Epoch: 429 [20480/90000 (23%)]	Loss: 3.6337	Cost: 8.63s
Train Epoch: 429 [40960/90000 (45%)]	Loss: 3.3915	Cost: 21.12s
Train Epoch: 429 [61440/90000 (68%)]	Loss: 3.4167	Cost: 12.30s
Train Epoch: 429 [81920/90000 (91%)]	Loss: 3.3825	Cost: 11.85s
Train Epoch: 429 	Average Loss: 3.5275
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1716

Learning rate: 9.954658398307247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 430 [0/90000 (0%)]	Loss: 4.1360	Cost: 42.57s
Train Epoch: 430 [20480/90000 (23%)]	Loss: 3.5035	Cost: 6.38s
Train Epoch: 430 [40960/90000 (45%)]	Loss: 3.3174	Cost: 14.01s
Train Epoch: 430 [61440/90000 (68%)]	Loss: 3.4414	Cost: 8.37s
Train Epoch: 430 [81920/90000 (91%)]	Loss: 3.3931	Cost: 8.71s
Train Epoch: 430 	Average Loss: 3.5153
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2472

Learning rate: 9.954447091111686e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 431 [0/90000 (0%)]	Loss: 4.2857	Cost: 29.21s
Train Epoch: 431 [20480/90000 (23%)]	Loss: 3.7275	Cost: 9.18s
Train Epoch: 431 [40960/90000 (45%)]	Loss: 3.3972	Cost: 20.33s
Train Epoch: 431 [61440/90000 (68%)]	Loss: 3.5073	Cost: 13.18s
Train Epoch: 431 [81920/90000 (91%)]	Loss: 3.4798	Cost: 12.20s
Train Epoch: 431 	Average Loss: 3.5970
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2859

Learning rate: 9.954235294931802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 432 [0/90000 (0%)]	Loss: 4.3167	Cost: 33.17s
Train Epoch: 432 [20480/90000 (23%)]	Loss: 3.5796	Cost: 14.43s
Train Epoch: 432 [40960/90000 (45%)]	Loss: 3.3357	Cost: 11.09s
Train Epoch: 432 [61440/90000 (68%)]	Loss: 3.5053	Cost: 7.83s
Train Epoch: 432 [81920/90000 (91%)]	Loss: 3.3313	Cost: 15.61s
Train Epoch: 432 	Average Loss: 3.5262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1610

Saving model as e432_model.pt & e432_waveforms_supplementary.hdf5
Learning rate: 9.954023009788497e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 433 [0/90000 (0%)]	Loss: 4.1517	Cost: 38.61s
Train Epoch: 433 [20480/90000 (23%)]	Loss: 3.4839	Cost: 7.67s
Train Epoch: 433 [40960/90000 (45%)]	Loss: 3.2904	Cost: 17.36s
Train Epoch: 433 [61440/90000 (68%)]	Loss: 3.4112	Cost: 11.98s
Train Epoch: 433 [81920/90000 (91%)]	Loss: 3.3473	Cost: 12.11s
Train Epoch: 433 	Average Loss: 3.5042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1871

Learning rate: 9.953810235702723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 434 [0/90000 (0%)]	Loss: 4.2488	Cost: 32.11s
Train Epoch: 434 [20480/90000 (23%)]	Loss: 3.5014	Cost: 11.80s
Train Epoch: 434 [40960/90000 (45%)]	Loss: 3.2633	Cost: 8.02s
Train Epoch: 434 [61440/90000 (68%)]	Loss: 3.6143	Cost: 6.44s
Train Epoch: 434 [81920/90000 (91%)]	Loss: 3.2098	Cost: 16.07s
Train Epoch: 434 	Average Loss: 3.4848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2203

Learning rate: 9.95359697269548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 435 [0/90000 (0%)]	Loss: 4.2697	Cost: 29.03s
Train Epoch: 435 [20480/90000 (23%)]	Loss: 3.6049	Cost: 9.13s
Train Epoch: 435 [40960/90000 (45%)]	Loss: 3.3143	Cost: 21.76s
Train Epoch: 435 [61440/90000 (68%)]	Loss: 3.3846	Cost: 12.20s
Train Epoch: 435 [81920/90000 (91%)]	Loss: 3.3562	Cost: 12.22s
Train Epoch: 435 	Average Loss: 3.5051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2486

Learning rate: 9.953383220787815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 436 [0/90000 (0%)]	Loss: 4.1522	Cost: 37.11s
Train Epoch: 436 [20480/90000 (23%)]	Loss: 3.4558	Cost: 11.14s
Train Epoch: 436 [40960/90000 (45%)]	Loss: 3.3699	Cost: 9.49s
Train Epoch: 436 [61440/90000 (68%)]	Loss: 3.3749	Cost: 6.46s
Train Epoch: 436 [81920/90000 (91%)]	Loss: 3.3392	Cost: 16.39s
Train Epoch: 436 	Average Loss: 3.4611
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1981

Learning rate: 9.953168980000828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 437 [0/90000 (0%)]	Loss: 4.1660	Cost: 45.55s
Train Epoch: 437 [20480/90000 (23%)]	Loss: 3.4755	Cost: 6.62s
Train Epoch: 437 [40960/90000 (45%)]	Loss: 3.3080	Cost: 17.34s
Train Epoch: 437 [61440/90000 (68%)]	Loss: 3.4981	Cost: 12.07s
Train Epoch: 437 [81920/90000 (91%)]	Loss: 3.2879	Cost: 11.88s
Train Epoch: 437 	Average Loss: 3.4813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1616

Learning rate: 9.95295425035566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 438 [0/90000 (0%)]	Loss: 4.0687	Cost: 30.61s
Train Epoch: 438 [20480/90000 (23%)]	Loss: 3.5124	Cost: 8.87s
Train Epoch: 438 [40960/90000 (45%)]	Loss: 3.2722	Cost: 10.03s
Train Epoch: 438 [61440/90000 (68%)]	Loss: 3.4794	Cost: 7.58s
Train Epoch: 438 [81920/90000 (91%)]	Loss: 3.2469	Cost: 14.56s
Train Epoch: 438 	Average Loss: 3.4454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2473

Learning rate: 9.952739031873505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 439 [0/90000 (0%)]	Loss: 4.1116	Cost: 35.69s
Train Epoch: 439 [20480/90000 (23%)]	Loss: 3.3745	Cost: 13.24s
Train Epoch: 439 [40960/90000 (45%)]	Loss: 3.2771	Cost: 16.99s
Train Epoch: 439 [61440/90000 (68%)]	Loss: 3.2960	Cost: 12.26s
Train Epoch: 439 [81920/90000 (91%)]	Loss: 3.3125	Cost: 11.44s
Train Epoch: 439 	Average Loss: 3.4274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0720

Saving model as e439_model.pt & e439_waveforms_supplementary.hdf5
Learning rate: 9.952523324575606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 440 [0/90000 (0%)]	Loss: 4.0756	Cost: 33.43s
Train Epoch: 440 [20480/90000 (23%)]	Loss: 3.4756	Cost: 7.18s
Train Epoch: 440 [40960/90000 (45%)]	Loss: 3.2374	Cost: 13.76s
Train Epoch: 440 [61440/90000 (68%)]	Loss: 3.3398	Cost: 8.73s
Train Epoch: 440 [81920/90000 (91%)]	Loss: 3.2675	Cost: 8.43s
Train Epoch: 440 	Average Loss: 3.4061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1651

Learning rate: 9.952307128483249e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 441 [0/90000 (0%)]	Loss: 4.2222	Cost: 34.70s
Train Epoch: 441 [20480/90000 (23%)]	Loss: 3.4716	Cost: 10.16s
Train Epoch: 441 [40960/90000 (45%)]	Loss: 3.2683	Cost: 20.70s
Train Epoch: 441 [61440/90000 (68%)]	Loss: 3.2555	Cost: 12.31s
Train Epoch: 441 [81920/90000 (91%)]	Loss: 3.2368	Cost: 11.91s
Train Epoch: 441 	Average Loss: 3.4157
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1790

Learning rate: 9.952090443617776e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 442 [0/90000 (0%)]	Loss: 4.1394	Cost: 35.16s
Train Epoch: 442 [20480/90000 (23%)]	Loss: 3.4041	Cost: 10.83s
Train Epoch: 442 [40960/90000 (45%)]	Loss: 3.2344	Cost: 8.91s
Train Epoch: 442 [61440/90000 (68%)]	Loss: 3.2625	Cost: 6.16s
Train Epoch: 442 [81920/90000 (91%)]	Loss: 3.4040	Cost: 12.41s
Train Epoch: 442 	Average Loss: 3.4104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2712

Learning rate: 9.95187327000057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 443 [0/90000 (0%)]	Loss: 4.2436	Cost: 29.23s
Train Epoch: 443 [20480/90000 (23%)]	Loss: 3.6073	Cost: 9.34s
Train Epoch: 443 [40960/90000 (45%)]	Loss: 3.2042	Cost: 25.82s
Train Epoch: 443 [61440/90000 (68%)]	Loss: 3.2676	Cost: 14.09s
Train Epoch: 443 [81920/90000 (91%)]	Loss: 3.1204	Cost: 12.08s
Train Epoch: 443 	Average Loss: 3.4477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1899

Learning rate: 9.951655607653065e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 444 [0/90000 (0%)]	Loss: 4.0963	Cost: 50.67s
Train Epoch: 444 [20480/90000 (23%)]	Loss: 3.5174	Cost: 6.25s
Train Epoch: 444 [40960/90000 (45%)]	Loss: 3.2254	Cost: 14.53s
Train Epoch: 444 [61440/90000 (68%)]	Loss: 3.3534	Cost: 8.67s
Train Epoch: 444 [81920/90000 (91%)]	Loss: 3.1600	Cost: 8.75s
Train Epoch: 444 	Average Loss: 3.4202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1583

Learning rate: 9.951437456596745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 445 [0/90000 (0%)]	Loss: 4.1237	Cost: 31.32s
Train Epoch: 445 [20480/90000 (23%)]	Loss: 3.4563	Cost: 7.16s
Train Epoch: 445 [40960/90000 (45%)]	Loss: 3.2931	Cost: 18.34s
Train Epoch: 445 [61440/90000 (68%)]	Loss: 3.3392	Cost: 12.45s
Train Epoch: 445 [81920/90000 (91%)]	Loss: 3.1477	Cost: 11.91s
Train Epoch: 445 	Average Loss: 3.4079
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1206

Learning rate: 9.951218816853138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 446 [0/90000 (0%)]	Loss: 4.2113	Cost: 38.25s
Train Epoch: 446 [20480/90000 (23%)]	Loss: 3.5003	Cost: 11.37s
Train Epoch: 446 [40960/90000 (45%)]	Loss: 3.2046	Cost: 7.40s
Train Epoch: 446 [61440/90000 (68%)]	Loss: 3.3063	Cost: 6.37s
Train Epoch: 446 [81920/90000 (91%)]	Loss: 3.1752	Cost: 13.63s
Train Epoch: 446 	Average Loss: 3.3815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1078

Learning rate: 9.950999688443825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 447 [0/90000 (0%)]	Loss: 4.1027	Cost: 26.46s
Train Epoch: 447 [20480/90000 (23%)]	Loss: 3.3513	Cost: 8.96s
Train Epoch: 447 [40960/90000 (45%)]	Loss: 3.1621	Cost: 15.30s
Train Epoch: 447 [61440/90000 (68%)]	Loss: 3.4311	Cost: 12.21s
Train Epoch: 447 [81920/90000 (91%)]	Loss: 3.1435	Cost: 13.11s
Train Epoch: 447 	Average Loss: 3.3981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0623

Saving model as e447_model.pt & e447_waveforms_supplementary.hdf5
Learning rate: 9.950780071390434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 448 [0/90000 (0%)]	Loss: 3.9968	Cost: 32.92s
Train Epoch: 448 [20480/90000 (23%)]	Loss: 3.5107	Cost: 9.37s
Train Epoch: 448 [40960/90000 (45%)]	Loss: 3.1614	Cost: 12.39s
Train Epoch: 448 [61440/90000 (68%)]	Loss: 3.2997	Cost: 9.28s
Train Epoch: 448 [81920/90000 (91%)]	Loss: 3.1216	Cost: 12.69s
Train Epoch: 448 	Average Loss: 3.3786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1693

Learning rate: 9.95055996571464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 449 [0/90000 (0%)]	Loss: 4.1811	Cost: 32.62s
Train Epoch: 449 [20480/90000 (23%)]	Loss: 3.3904	Cost: 13.13s
Train Epoch: 449 [40960/90000 (45%)]	Loss: 3.2137	Cost: 13.57s
Train Epoch: 449 [61440/90000 (68%)]	Loss: 3.2852	Cost: 12.24s
Train Epoch: 449 [81920/90000 (91%)]	Loss: 3.1236	Cost: 12.05s
Train Epoch: 449 	Average Loss: 3.3581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1573

Learning rate: 9.950339371438165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 450 [0/90000 (0%)]	Loss: 4.0537	Cost: 39.23s
Train Epoch: 450 [20480/90000 (23%)]	Loss: 3.4499	Cost: 12.11s
Train Epoch: 450 [40960/90000 (45%)]	Loss: 3.1183	Cost: 7.14s
Train Epoch: 450 [61440/90000 (68%)]	Loss: 3.3007	Cost: 6.17s
Train Epoch: 450 [81920/90000 (91%)]	Loss: 3.1212	Cost: 13.68s
Train Epoch: 450 	Average Loss: 3.3441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.2004

Learning rate: 9.950118288582781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 451 [0/90000 (0%)]	Loss: 4.1024	Cost: 32.63s
Train Epoch: 451 [20480/90000 (23%)]	Loss: 3.6066	Cost: 7.79s
Train Epoch: 451 [40960/90000 (45%)]	Loss: 3.3462	Cost: 16.99s
Train Epoch: 451 [61440/90000 (68%)]	Loss: 3.4896	Cost: 12.28s
Train Epoch: 451 [81920/90000 (91%)]	Loss: 3.2859	Cost: 12.16s
Train Epoch: 451 	Average Loss: 3.5083
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1696

Learning rate: 9.949896717170309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 452 [0/90000 (0%)]	Loss: 4.1063	Cost: 34.07s
Train Epoch: 452 [20480/90000 (23%)]	Loss: 3.3953	Cost: 8.27s
Train Epoch: 452 [40960/90000 (45%)]	Loss: 3.2077	Cost: 11.60s
Train Epoch: 452 [61440/90000 (68%)]	Loss: 3.1651	Cost: 8.72s
Train Epoch: 452 [81920/90000 (91%)]	Loss: 3.1198	Cost: 13.29s
Train Epoch: 452 	Average Loss: 3.3818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0950

Learning rate: 9.949674657222618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 453 [0/90000 (0%)]	Loss: 4.0271	Cost: 27.50s
Train Epoch: 453 [20480/90000 (23%)]	Loss: 3.4083	Cost: 8.98s
Train Epoch: 453 [40960/90000 (45%)]	Loss: 3.2519	Cost: 24.49s
Train Epoch: 453 [61440/90000 (68%)]	Loss: 3.2383	Cost: 12.91s
Train Epoch: 453 [81920/90000 (91%)]	Loss: 3.2905	Cost: 11.85s
Train Epoch: 453 	Average Loss: 3.3646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1399

Learning rate: 9.949452108761622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 454 [0/90000 (0%)]	Loss: 4.2486	Cost: 58.13s
Train Epoch: 454 [20480/90000 (23%)]	Loss: 3.4901	Cost: 10.69s
Train Epoch: 454 [40960/90000 (45%)]	Loss: 3.2414	Cost: 6.59s
Train Epoch: 454 [61440/90000 (68%)]	Loss: 3.2716	Cost: 6.36s
Train Epoch: 454 [81920/90000 (91%)]	Loss: 3.1115	Cost: 14.05s
Train Epoch: 454 	Average Loss: 3.3474
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0847

Learning rate: 9.949229071809287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 455 [0/90000 (0%)]	Loss: 4.0983	Cost: 27.73s
Train Epoch: 455 [20480/90000 (23%)]	Loss: 3.2055	Cost: 10.11s
Train Epoch: 455 [40960/90000 (45%)]	Loss: 3.0952	Cost: 22.46s
Train Epoch: 455 [61440/90000 (68%)]	Loss: 3.1617	Cost: 12.32s
Train Epoch: 455 [81920/90000 (91%)]	Loss: 3.0063	Cost: 12.18s
Train Epoch: 455 	Average Loss: 3.2967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0593

Saving model as e455_model.pt & e455_waveforms_supplementary.hdf5
Learning rate: 9.949005546387625e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 456 [0/90000 (0%)]	Loss: 4.0290	Cost: 39.47s
Train Epoch: 456 [20480/90000 (23%)]	Loss: 3.3341	Cost: 10.66s
Train Epoch: 456 [40960/90000 (45%)]	Loss: 3.1677	Cost: 7.83s
Train Epoch: 456 [61440/90000 (68%)]	Loss: 3.1137	Cost: 6.52s
Train Epoch: 456 [81920/90000 (91%)]	Loss: 3.1037	Cost: 14.10s
Train Epoch: 456 	Average Loss: 3.2639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.1028

Learning rate: 9.9487815325187e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 457 [0/90000 (0%)]	Loss: 4.1522	Cost: 26.83s
Train Epoch: 457 [20480/90000 (23%)]	Loss: 3.2371	Cost: 8.72s
Train Epoch: 457 [40960/90000 (45%)]	Loss: 3.1067	Cost: 15.95s
Train Epoch: 457 [61440/90000 (68%)]	Loss: 3.1326	Cost: 12.14s
Train Epoch: 457 [81920/90000 (91%)]	Loss: 3.1460	Cost: 12.42s
Train Epoch: 457 	Average Loss: 3.2682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0270

Saving model as e457_model.pt & e457_waveforms_supplementary.hdf5
Learning rate: 9.948557030224616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 458 [0/90000 (0%)]	Loss: 3.9103	Cost: 51.94s
Train Epoch: 458 [20480/90000 (23%)]	Loss: 3.2877	Cost: 8.87s
Train Epoch: 458 [40960/90000 (45%)]	Loss: 3.0353	Cost: 10.16s
Train Epoch: 458 [61440/90000 (68%)]	Loss: 3.1398	Cost: 8.01s
Train Epoch: 458 [81920/90000 (91%)]	Loss: 3.0490	Cost: 11.88s
Train Epoch: 458 	Average Loss: 3.2553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0181

Saving model as e458_model.pt & e458_waveforms_supplementary.hdf5
Learning rate: 9.948332039527536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 459 [0/90000 (0%)]	Loss: 4.1780	Cost: 29.10s
Train Epoch: 459 [20480/90000 (23%)]	Loss: 3.1834	Cost: 8.39s
Train Epoch: 459 [40960/90000 (45%)]	Loss: 2.9886	Cost: 16.50s
Train Epoch: 459 [61440/90000 (68%)]	Loss: 3.3403	Cost: 12.07s
Train Epoch: 459 [81920/90000 (91%)]	Loss: 3.1022	Cost: 12.41s
Train Epoch: 459 	Average Loss: 3.2713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0659

Learning rate: 9.948106560449663e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 460 [0/90000 (0%)]	Loss: 4.1416	Cost: 34.52s
Train Epoch: 460 [20480/90000 (23%)]	Loss: 3.3744	Cost: 10.83s
Train Epoch: 460 [40960/90000 (45%)]	Loss: 3.0403	Cost: 8.89s
Train Epoch: 460 [61440/90000 (68%)]	Loss: 3.1264	Cost: 6.34s
Train Epoch: 460 [81920/90000 (91%)]	Loss: 3.2006	Cost: 18.15s
Train Epoch: 460 	Average Loss: 3.2683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0337

Learning rate: 9.947880593013248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 461 [0/90000 (0%)]	Loss: 4.0773	Cost: 38.83s
Train Epoch: 461 [20480/90000 (23%)]	Loss: 3.2751	Cost: 11.11s
Train Epoch: 461 [40960/90000 (45%)]	Loss: 3.1201	Cost: 13.59s
Train Epoch: 461 [61440/90000 (68%)]	Loss: 3.2286	Cost: 12.08s
Train Epoch: 461 [81920/90000 (91%)]	Loss: 3.0437	Cost: 11.88s
Train Epoch: 461 	Average Loss: 3.2596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0287

Learning rate: 9.9476541372406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 462 [0/90000 (0%)]	Loss: 4.0625	Cost: 34.49s
Train Epoch: 462 [20480/90000 (23%)]	Loss: 3.2801	Cost: 12.53s
Train Epoch: 462 [40960/90000 (45%)]	Loss: 3.1344	Cost: 7.95s
Train Epoch: 462 [61440/90000 (68%)]	Loss: 3.2657	Cost: 6.44s
Train Epoch: 462 [81920/90000 (91%)]	Loss: 3.1158	Cost: 14.00s
Train Epoch: 462 	Average Loss: 3.2880
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0431

Learning rate: 9.947427193154066e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 463 [0/90000 (0%)]	Loss: 4.1068	Cost: 31.05s
Train Epoch: 463 [20480/90000 (23%)]	Loss: 3.2476	Cost: 6.73s
Train Epoch: 463 [40960/90000 (45%)]	Loss: 3.0871	Cost: 18.22s
Train Epoch: 463 [61440/90000 (68%)]	Loss: 3.1036	Cost: 12.63s
Train Epoch: 463 [81920/90000 (91%)]	Loss: 3.0503	Cost: 12.05s
Train Epoch: 463 	Average Loss: 3.2353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0527

Learning rate: 9.947199760776042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 464 [0/90000 (0%)]	Loss: 3.8716	Cost: 33.45s
Train Epoch: 464 [20480/90000 (23%)]	Loss: 3.0333	Cost: 10.23s
Train Epoch: 464 [40960/90000 (45%)]	Loss: 3.0415	Cost: 9.80s
Train Epoch: 464 [61440/90000 (68%)]	Loss: 3.1811	Cost: 6.36s
Train Epoch: 464 [81920/90000 (91%)]	Loss: 3.0628	Cost: 16.95s
Train Epoch: 464 	Average Loss: 3.1896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9912

Saving model as e464_model.pt & e464_waveforms_supplementary.hdf5
Learning rate: 9.946971840128976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 465 [0/90000 (0%)]	Loss: 3.9692	Cost: 35.27s
Train Epoch: 465 [20480/90000 (23%)]	Loss: 3.2469	Cost: 11.03s
Train Epoch: 465 [40960/90000 (45%)]	Loss: 3.0301	Cost: 20.06s
Train Epoch: 465 [61440/90000 (68%)]	Loss: 3.0237	Cost: 12.24s
Train Epoch: 465 [81920/90000 (91%)]	Loss: 2.9556	Cost: 12.07s
Train Epoch: 465 	Average Loss: 3.1975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0105

Learning rate: 9.946743431235365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 466 [0/90000 (0%)]	Loss: 4.0398	Cost: 43.24s
Train Epoch: 466 [20480/90000 (23%)]	Loss: 3.2173	Cost: 6.27s
Train Epoch: 466 [40960/90000 (45%)]	Loss: 3.0380	Cost: 14.22s
Train Epoch: 466 [61440/90000 (68%)]	Loss: 3.0484	Cost: 8.64s
Train Epoch: 466 [81920/90000 (91%)]	Loss: 3.0498	Cost: 8.74s
Train Epoch: 466 	Average Loss: 3.1853
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9348

Saving model as e466_model.pt & e466_waveforms_supplementary.hdf5
Learning rate: 9.94651453411775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 467 [0/90000 (0%)]	Loss: 3.9145	Cost: 35.67s
Train Epoch: 467 [20480/90000 (23%)]	Loss: 3.1629	Cost: 14.68s
Train Epoch: 467 [40960/90000 (45%)]	Loss: 3.0365	Cost: 15.34s
Train Epoch: 467 [61440/90000 (68%)]	Loss: 3.1121	Cost: 12.20s
Train Epoch: 467 [81920/90000 (91%)]	Loss: 2.9500	Cost: 12.02s
Train Epoch: 467 	Average Loss: 3.1540
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9993

Learning rate: 9.946285148798723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 468 [0/90000 (0%)]	Loss: 3.8665	Cost: 37.43s
Train Epoch: 468 [20480/90000 (23%)]	Loss: 3.0925	Cost: 11.40s
Train Epoch: 468 [40960/90000 (45%)]	Loss: 3.0061	Cost: 8.02s
Train Epoch: 468 [61440/90000 (68%)]	Loss: 3.0359	Cost: 6.29s
Train Epoch: 468 [81920/90000 (91%)]	Loss: 3.0581	Cost: 13.08s
Train Epoch: 468 	Average Loss: 3.1411
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9363

Learning rate: 9.946055275300923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 469 [0/90000 (0%)]	Loss: 3.7200	Cost: 33.34s
Train Epoch: 469 [20480/90000 (23%)]	Loss: 3.1811	Cost: 7.74s
Train Epoch: 469 [40960/90000 (45%)]	Loss: 2.8727	Cost: 19.55s
Train Epoch: 469 [61440/90000 (68%)]	Loss: 3.0237	Cost: 12.35s
Train Epoch: 469 [81920/90000 (91%)]	Loss: 2.9637	Cost: 12.08s
Train Epoch: 469 	Average Loss: 3.1112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0023

Learning rate: 9.945824913647039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 470 [0/90000 (0%)]	Loss: 3.9311	Cost: 46.33s
Train Epoch: 470 [20480/90000 (23%)]	Loss: 3.2120	Cost: 5.99s
Train Epoch: 470 [40960/90000 (45%)]	Loss: 2.9708	Cost: 13.78s
Train Epoch: 470 [61440/90000 (68%)]	Loss: 3.1026	Cost: 8.54s
Train Epoch: 470 [81920/90000 (91%)]	Loss: 2.9242	Cost: 8.33s
Train Epoch: 470 	Average Loss: 3.1409
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9513

Learning rate: 9.945594063859803e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 471 [0/90000 (0%)]	Loss: 4.0322	Cost: 30.13s
Train Epoch: 471 [20480/90000 (23%)]	Loss: 3.0973	Cost: 8.45s
Train Epoch: 471 [40960/90000 (45%)]	Loss: 2.9048	Cost: 16.88s
Train Epoch: 471 [61440/90000 (68%)]	Loss: 3.0453	Cost: 13.67s
Train Epoch: 471 [81920/90000 (91%)]	Loss: 2.9367	Cost: 13.17s
Train Epoch: 471 	Average Loss: 3.1113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9247

Saving model as e471_model.pt & e471_waveforms_supplementary.hdf5
Learning rate: 9.945362725962006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 472 [0/90000 (0%)]	Loss: 3.7484	Cost: 33.33s
Train Epoch: 472 [20480/90000 (23%)]	Loss: 3.1084	Cost: 11.10s
Train Epoch: 472 [40960/90000 (45%)]	Loss: 2.9659	Cost: 9.72s
Train Epoch: 472 [61440/90000 (68%)]	Loss: 3.0378	Cost: 8.90s
Train Epoch: 472 [81920/90000 (91%)]	Loss: 2.9668	Cost: 12.47s
Train Epoch: 472 	Average Loss: 3.1130
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9424

Learning rate: 9.945130899976472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 473 [0/90000 (0%)]	Loss: 3.7881	Cost: 33.83s
Train Epoch: 473 [20480/90000 (23%)]	Loss: 3.0954	Cost: 8.83s
Train Epoch: 473 [40960/90000 (45%)]	Loss: 3.0200	Cost: 17.46s
Train Epoch: 473 [61440/90000 (68%)]	Loss: 2.9285	Cost: 12.02s
Train Epoch: 473 [81920/90000 (91%)]	Loss: 2.9451	Cost: 11.97s
Train Epoch: 473 	Average Loss: 3.0955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9391

Learning rate: 9.944898585926086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 474 [0/90000 (0%)]	Loss: 3.9436	Cost: 37.78s
Train Epoch: 474 [20480/90000 (23%)]	Loss: 3.3006	Cost: 12.14s
Train Epoch: 474 [40960/90000 (45%)]	Loss: 3.0536	Cost: 6.78s
Train Epoch: 474 [61440/90000 (68%)]	Loss: 3.1493	Cost: 6.23s
Train Epoch: 474 [81920/90000 (91%)]	Loss: 2.8666	Cost: 14.84s
Train Epoch: 474 	Average Loss: 3.2309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9682

Learning rate: 9.944665783833775e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 475 [0/90000 (0%)]	Loss: 3.9341	Cost: 31.54s
Train Epoch: 475 [20480/90000 (23%)]	Loss: 3.0890	Cost: 7.14s
Train Epoch: 475 [40960/90000 (45%)]	Loss: 2.8585	Cost: 17.54s
Train Epoch: 475 [61440/90000 (68%)]	Loss: 3.0359	Cost: 12.31s
Train Epoch: 475 [81920/90000 (91%)]	Loss: 2.7966	Cost: 12.21s
Train Epoch: 475 	Average Loss: 3.0871
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9347

Learning rate: 9.944432493722518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 476 [0/90000 (0%)]	Loss: 3.7510	Cost: 33.62s
Train Epoch: 476 [20480/90000 (23%)]	Loss: 3.0978	Cost: 9.39s
Train Epoch: 476 [40960/90000 (45%)]	Loss: 2.8916	Cost: 17.00s
Train Epoch: 476 [61440/90000 (68%)]	Loss: 3.0123	Cost: 8.93s
Train Epoch: 476 [81920/90000 (91%)]	Loss: 2.8758	Cost: 12.58s
Train Epoch: 476 	Average Loss: 3.0709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9328

Learning rate: 9.944198715615337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 477 [0/90000 (0%)]	Loss: 3.9328	Cost: 32.52s
Train Epoch: 477 [20480/90000 (23%)]	Loss: 3.1589	Cost: 10.64s
Train Epoch: 477 [40960/90000 (45%)]	Loss: 3.0637	Cost: 24.14s
Train Epoch: 477 [61440/90000 (68%)]	Loss: 2.9443	Cost: 12.02s
Train Epoch: 477 [81920/90000 (91%)]	Loss: 3.0111	Cost: 11.85s
Train Epoch: 477 	Average Loss: 3.0852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9140

Saving model as e477_model.pt & e477_waveforms_supplementary.hdf5
Learning rate: 9.943964449535306e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 478 [0/90000 (0%)]	Loss: 3.9798	Cost: 49.90s
Train Epoch: 478 [20480/90000 (23%)]	Loss: 3.0380	Cost: 7.14s
Train Epoch: 478 [40960/90000 (45%)]	Loss: 2.8445	Cost: 12.30s
Train Epoch: 478 [61440/90000 (68%)]	Loss: 2.9951	Cost: 8.67s
Train Epoch: 478 [81920/90000 (91%)]	Loss: 2.8822	Cost: 7.37s
Train Epoch: 478 	Average Loss: 3.0565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8875

Saving model as e478_model.pt & e478_waveforms_supplementary.hdf5
Learning rate: 9.943729695505547e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 479 [0/90000 (0%)]	Loss: 3.7512	Cost: 28.06s
Train Epoch: 479 [20480/90000 (23%)]	Loss: 3.0594	Cost: 10.90s
Train Epoch: 479 [40960/90000 (45%)]	Loss: 2.9188	Cost: 21.89s
Train Epoch: 479 [61440/90000 (68%)]	Loss: 3.0666	Cost: 12.33s
Train Epoch: 479 [81920/90000 (91%)]	Loss: 2.9027	Cost: 12.13s
Train Epoch: 479 	Average Loss: 3.0643
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9645

Learning rate: 9.943494453549226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 480 [0/90000 (0%)]	Loss: 3.7281	Cost: 40.54s
Train Epoch: 480 [20480/90000 (23%)]	Loss: 3.1173	Cost: 7.85s
Train Epoch: 480 [40960/90000 (45%)]	Loss: 2.9377	Cost: 11.22s
Train Epoch: 480 [61440/90000 (68%)]	Loss: 3.0758	Cost: 9.70s
Train Epoch: 480 [81920/90000 (91%)]	Loss: 2.9357	Cost: 12.14s
Train Epoch: 480 	Average Loss: 3.1335
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9790

Learning rate: 9.943258723689565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 481 [0/90000 (0%)]	Loss: 4.0178	Cost: 30.59s
Train Epoch: 481 [20480/90000 (23%)]	Loss: 3.1678	Cost: 10.26s
Train Epoch: 481 [40960/90000 (45%)]	Loss: 2.9520	Cost: 20.85s
Train Epoch: 481 [61440/90000 (68%)]	Loss: 2.9200	Cost: 12.91s
Train Epoch: 481 [81920/90000 (91%)]	Loss: 2.7454	Cost: 11.77s
Train Epoch: 481 	Average Loss: 3.0617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9431

Learning rate: 9.943022505949827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 482 [0/90000 (0%)]	Loss: 3.9927	Cost: 57.76s
Train Epoch: 482 [20480/90000 (23%)]	Loss: 3.0724	Cost: 6.26s
Train Epoch: 482 [40960/90000 (45%)]	Loss: 2.8857	Cost: 13.66s
Train Epoch: 482 [61440/90000 (68%)]	Loss: 3.0085	Cost: 8.64s
Train Epoch: 482 [81920/90000 (91%)]	Loss: 2.7897	Cost: 9.18s
Train Epoch: 482 	Average Loss: 3.0741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9367

Learning rate: 9.942785800353326e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 483 [0/90000 (0%)]	Loss: 4.0614	Cost: 29.94s
Train Epoch: 483 [20480/90000 (23%)]	Loss: 3.0611	Cost: 7.99s
Train Epoch: 483 [40960/90000 (45%)]	Loss: 2.8776	Cost: 17.17s
Train Epoch: 483 [61440/90000 (68%)]	Loss: 2.8941	Cost: 12.25s
Train Epoch: 483 [81920/90000 (91%)]	Loss: 3.0136	Cost: 12.07s
Train Epoch: 483 	Average Loss: 3.0459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 4.0032

Learning rate: 9.942548606923424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 484 [0/90000 (0%)]	Loss: 3.8722	Cost: 34.56s
Train Epoch: 484 [20480/90000 (23%)]	Loss: 3.0509	Cost: 10.85s
Train Epoch: 484 [40960/90000 (45%)]	Loss: 2.9547	Cost: 9.07s
Train Epoch: 484 [61440/90000 (68%)]	Loss: 3.0288	Cost: 7.20s
Train Epoch: 484 [81920/90000 (91%)]	Loss: 2.8399	Cost: 15.37s
Train Epoch: 484 	Average Loss: 3.1000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8757

Saving model as e484_model.pt & e484_waveforms_supplementary.hdf5
Learning rate: 9.942310925683532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 485 [0/90000 (0%)]	Loss: 3.9450	Cost: 28.21s
Train Epoch: 485 [20480/90000 (23%)]	Loss: 3.1082	Cost: 10.86s
Train Epoch: 485 [40960/90000 (45%)]	Loss: 2.8275	Cost: 19.44s
Train Epoch: 485 [61440/90000 (68%)]	Loss: 2.9478	Cost: 12.07s
Train Epoch: 485 [81920/90000 (91%)]	Loss: 2.9634	Cost: 11.85s
Train Epoch: 485 	Average Loss: 3.0372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.9157

Learning rate: 9.942072756657107e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 486 [0/90000 (0%)]	Loss: 3.9898	Cost: 42.02s
Train Epoch: 486 [20480/90000 (23%)]	Loss: 2.8672	Cost: 12.36s
Train Epoch: 486 [40960/90000 (45%)]	Loss: 2.7937	Cost: 9.46s
Train Epoch: 486 [61440/90000 (68%)]	Loss: 2.8578	Cost: 7.12s
Train Epoch: 486 [81920/90000 (91%)]	Loss: 2.8166	Cost: 11.95s
Train Epoch: 486 	Average Loss: 2.9621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8129

Saving model as e486_model.pt & e486_waveforms_supplementary.hdf5
Learning rate: 9.941834099867654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 487 [0/90000 (0%)]	Loss: 3.7755	Cost: 36.59s
Train Epoch: 487 [20480/90000 (23%)]	Loss: 2.9880	Cost: 6.74s
Train Epoch: 487 [40960/90000 (45%)]	Loss: 2.7788	Cost: 17.14s
Train Epoch: 487 [61440/90000 (68%)]	Loss: 2.8714	Cost: 12.25s
Train Epoch: 487 [81920/90000 (91%)]	Loss: 2.7415	Cost: 11.88s
Train Epoch: 487 	Average Loss: 2.9564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7924

Saving model as e487_model.pt & e487_waveforms_supplementary.hdf5
Learning rate: 9.941594955338732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 488 [0/90000 (0%)]	Loss: 3.7609	Cost: 31.62s
Train Epoch: 488 [20480/90000 (23%)]	Loss: 3.0360	Cost: 10.64s
Train Epoch: 488 [40960/90000 (45%)]	Loss: 2.7572	Cost: 9.00s
Train Epoch: 488 [61440/90000 (68%)]	Loss: 2.8998	Cost: 6.74s
Train Epoch: 488 [81920/90000 (91%)]	Loss: 2.7063	Cost: 14.23s
Train Epoch: 488 	Average Loss: 2.9398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8174

Learning rate: 9.941355323093938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 489 [0/90000 (0%)]	Loss: 4.0063	Cost: 39.02s
Train Epoch: 489 [20480/90000 (23%)]	Loss: 2.8841	Cost: 13.28s
Train Epoch: 489 [40960/90000 (45%)]	Loss: 2.8775	Cost: 14.76s
Train Epoch: 489 [61440/90000 (68%)]	Loss: 2.8718	Cost: 11.82s
Train Epoch: 489 [81920/90000 (91%)]	Loss: 2.6917	Cost: 11.93s
Train Epoch: 489 	Average Loss: 2.9417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8122

Learning rate: 9.941115203156927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 490 [0/90000 (0%)]	Loss: 3.8123	Cost: 54.85s
Train Epoch: 490 [20480/90000 (23%)]	Loss: 3.0240	Cost: 7.66s
Train Epoch: 490 [40960/90000 (45%)]	Loss: 2.7426	Cost: 10.41s
Train Epoch: 490 [61440/90000 (68%)]	Loss: 2.8364	Cost: 9.57s
Train Epoch: 490 [81920/90000 (91%)]	Loss: 2.7448	Cost: 15.03s
Train Epoch: 490 	Average Loss: 2.9526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7967

Learning rate: 9.940874595551397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 491 [0/90000 (0%)]	Loss: 3.8265	Cost: 32.37s
Train Epoch: 491 [20480/90000 (23%)]	Loss: 2.8595	Cost: 11.47s
Train Epoch: 491 [40960/90000 (45%)]	Loss: 2.8351	Cost: 18.91s
Train Epoch: 491 [61440/90000 (68%)]	Loss: 2.7949	Cost: 12.27s
Train Epoch: 491 [81920/90000 (91%)]	Loss: 2.7640	Cost: 11.99s
Train Epoch: 491 	Average Loss: 2.9376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7889

Saving model as e491_model.pt & e491_waveforms_supplementary.hdf5
Learning rate: 9.940633500301093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 492 [0/90000 (0%)]	Loss: 3.7845	Cost: 29.81s
Train Epoch: 492 [20480/90000 (23%)]	Loss: 3.0466	Cost: 8.70s
Train Epoch: 492 [40960/90000 (45%)]	Loss: 2.6624	Cost: 11.50s
Train Epoch: 492 [61440/90000 (68%)]	Loss: 2.8766	Cost: 9.71s
Train Epoch: 492 [81920/90000 (91%)]	Loss: 2.7347	Cost: 12.13s
Train Epoch: 492 	Average Loss: 2.9098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7966

Learning rate: 9.940391917429813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 493 [0/90000 (0%)]	Loss: 3.7676	Cost: 28.36s
Train Epoch: 493 [20480/90000 (23%)]	Loss: 2.8471	Cost: 10.07s
Train Epoch: 493 [40960/90000 (45%)]	Loss: 2.7136	Cost: 21.95s
Train Epoch: 493 [61440/90000 (68%)]	Loss: 2.8157	Cost: 12.88s
Train Epoch: 493 [81920/90000 (91%)]	Loss: 2.6417	Cost: 11.99s
Train Epoch: 493 	Average Loss: 2.9026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7796

Saving model as e493_model.pt & e493_waveforms_supplementary.hdf5
Learning rate: 9.9401498469614e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 494 [0/90000 (0%)]	Loss: 3.7322	Cost: 56.06s
Train Epoch: 494 [20480/90000 (23%)]	Loss: 2.8760	Cost: 6.24s
Train Epoch: 494 [40960/90000 (45%)]	Loss: 2.7973	Cost: 13.41s
Train Epoch: 494 [61440/90000 (68%)]	Loss: 2.8254	Cost: 8.39s
Train Epoch: 494 [81920/90000 (91%)]	Loss: 2.8004	Cost: 7.76s
Train Epoch: 494 	Average Loss: 2.8785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8430

Learning rate: 9.93990728891974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 495 [0/90000 (0%)]	Loss: 3.7180	Cost: 29.09s
Train Epoch: 495 [20480/90000 (23%)]	Loss: 2.9383	Cost: 10.38s
Train Epoch: 495 [40960/90000 (45%)]	Loss: 2.9325	Cost: 18.39s
Train Epoch: 495 [61440/90000 (68%)]	Loss: 2.7786	Cost: 12.31s
Train Epoch: 495 [81920/90000 (91%)]	Loss: 2.7776	Cost: 12.02s
Train Epoch: 495 	Average Loss: 2.9336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.8400

Learning rate: 9.939664243328781e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 496 [0/90000 (0%)]	Loss: 3.6430	Cost: 40.46s
Train Epoch: 496 [20480/90000 (23%)]	Loss: 2.9221	Cost: 12.16s
Train Epoch: 496 [40960/90000 (45%)]	Loss: 2.7659	Cost: 7.25s
Train Epoch: 496 [61440/90000 (68%)]	Loss: 2.6894	Cost: 6.67s
Train Epoch: 496 [81920/90000 (91%)]	Loss: 2.7016	Cost: 12.95s
Train Epoch: 496 	Average Loss: 2.8710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7835

Learning rate: 9.939420710212505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 497 [0/90000 (0%)]	Loss: 3.6417	Cost: 29.55s
Train Epoch: 497 [20480/90000 (23%)]	Loss: 2.8457	Cost: 6.47s
Train Epoch: 497 [40960/90000 (45%)]	Loss: 2.7592	Cost: 18.71s
Train Epoch: 497 [61440/90000 (68%)]	Loss: 2.8276	Cost: 13.80s
Train Epoch: 497 [81920/90000 (91%)]	Loss: 2.6058	Cost: 12.37s
Train Epoch: 497 	Average Loss: 2.8598
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7508

Saving model as e497_model.pt & e497_waveforms_supplementary.hdf5
Learning rate: 9.939176689594949e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 498 [0/90000 (0%)]	Loss: 3.8358	Cost: 33.96s
Train Epoch: 498 [20480/90000 (23%)]	Loss: 2.8150	Cost: 8.58s
Train Epoch: 498 [40960/90000 (45%)]	Loss: 2.7725	Cost: 14.41s
Train Epoch: 498 [61440/90000 (68%)]	Loss: 2.7227	Cost: 8.53s
Train Epoch: 498 [81920/90000 (91%)]	Loss: 2.6392	Cost: 11.80s
Train Epoch: 498 	Average Loss: 2.8467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7287

Saving model as e498_model.pt & e498_waveforms_supplementary.hdf5
Learning rate: 9.938932181500198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 499 [0/90000 (0%)]	Loss: 3.6330	Cost: 29.77s
Train Epoch: 499 [20480/90000 (23%)]	Loss: 2.9177	Cost: 8.99s
Train Epoch: 499 [40960/90000 (45%)]	Loss: 2.7009	Cost: 15.69s
Train Epoch: 499 [61440/90000 (68%)]	Loss: 2.7328	Cost: 12.20s
Train Epoch: 499 [81920/90000 (91%)]	Loss: 2.5116	Cost: 12.12s
Train Epoch: 499 	Average Loss: 2.8074
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7290

Learning rate: 9.938687185952383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 500 [0/90000 (0%)]	Loss: 3.7561	Cost: 47.79s
Train Epoch: 500 [20480/90000 (23%)]	Loss: 2.8621	Cost: 10.65s
Train Epoch: 500 [40960/90000 (45%)]	Loss: 2.6770	Cost: 8.57s
Train Epoch: 500 [61440/90000 (68%)]	Loss: 2.8054	Cost: 7.35s
Train Epoch: 500 [81920/90000 (91%)]	Loss: 2.6449	Cost: 14.23s
Train Epoch: 500 	Average Loss: 2.8270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7278

Saving model as e500_model.pt & e500_waveforms_supplementary.hdf5
Learning rate: 9.938441702975683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 501 [0/90000 (0%)]	Loss: 3.5459	Cost: 29.99s
Train Epoch: 501 [20480/90000 (23%)]	Loss: 2.7662	Cost: 8.02s
Train Epoch: 501 [40960/90000 (45%)]	Loss: 2.6569	Cost: 16.94s
Train Epoch: 501 [61440/90000 (68%)]	Loss: 2.7587	Cost: 12.01s
Train Epoch: 501 [81920/90000 (91%)]	Loss: 2.5511	Cost: 12.18s
Train Epoch: 501 	Average Loss: 2.8036
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7797

Learning rate: 9.938195732594328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 502 [0/90000 (0%)]	Loss: 3.6620	Cost: 32.35s
Train Epoch: 502 [20480/90000 (23%)]	Loss: 2.8499	Cost: 11.97s
Train Epoch: 502 [40960/90000 (45%)]	Loss: 2.6735	Cost: 7.22s
Train Epoch: 502 [61440/90000 (68%)]	Loss: 2.8086	Cost: 8.75s
Train Epoch: 502 [81920/90000 (91%)]	Loss: 2.6999	Cost: 13.04s
Train Epoch: 502 	Average Loss: 2.8592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6831

Saving model as e502_model.pt & e502_waveforms_supplementary.hdf5
Learning rate: 9.937949274832593e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 503 [0/90000 (0%)]	Loss: 3.6239	Cost: 35.68s
Train Epoch: 503 [20480/90000 (23%)]	Loss: 2.7525	Cost: 7.76s
Train Epoch: 503 [40960/90000 (45%)]	Loss: 2.5429	Cost: 18.42s
Train Epoch: 503 [61440/90000 (68%)]	Loss: 2.6973	Cost: 12.39s
Train Epoch: 503 [81920/90000 (91%)]	Loss: 2.5526	Cost: 11.99s
Train Epoch: 503 	Average Loss: 2.8191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7517

Learning rate: 9.937702329714805e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 504 [0/90000 (0%)]	Loss: 3.7443	Cost: 37.49s
Train Epoch: 504 [20480/90000 (23%)]	Loss: 2.8418	Cost: 10.56s
Train Epoch: 504 [40960/90000 (45%)]	Loss: 2.6339	Cost: 7.71s
Train Epoch: 504 [61440/90000 (68%)]	Loss: 2.7064	Cost: 6.34s
Train Epoch: 504 [81920/90000 (91%)]	Loss: 2.7558	Cost: 13.63s
Train Epoch: 504 	Average Loss: 2.8038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7045

Learning rate: 9.937454897265332e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 505 [0/90000 (0%)]	Loss: 3.6740	Cost: 34.81s
Train Epoch: 505 [20480/90000 (23%)]	Loss: 2.8953	Cost: 10.18s
Train Epoch: 505 [40960/90000 (45%)]	Loss: 2.6909	Cost: 14.34s
Train Epoch: 505 [61440/90000 (68%)]	Loss: 2.7200	Cost: 12.32s
Train Epoch: 505 [81920/90000 (91%)]	Loss: 2.6766	Cost: 11.97s
Train Epoch: 505 	Average Loss: 2.8032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7618

Learning rate: 9.937206977508597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 506 [0/90000 (0%)]	Loss: 3.7670	Cost: 31.53s
Train Epoch: 506 [20480/90000 (23%)]	Loss: 2.8270	Cost: 12.17s
Train Epoch: 506 [40960/90000 (45%)]	Loss: 2.6623	Cost: 7.19s
Train Epoch: 506 [61440/90000 (68%)]	Loss: 2.6460	Cost: 7.39s
Train Epoch: 506 [81920/90000 (91%)]	Loss: 2.4973	Cost: 13.76s
Train Epoch: 506 	Average Loss: 2.8065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6281

Saving model as e506_model.pt & e506_waveforms_supplementary.hdf5
Learning rate: 9.936958570469071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 507 [0/90000 (0%)]	Loss: 3.5200	Cost: 31.03s
Train Epoch: 507 [20480/90000 (23%)]	Loss: 2.7366	Cost: 10.31s
Train Epoch: 507 [40960/90000 (45%)]	Loss: 2.7343	Cost: 24.68s
Train Epoch: 507 [61440/90000 (68%)]	Loss: 2.7528	Cost: 12.37s
Train Epoch: 507 [81920/90000 (91%)]	Loss: 2.6566	Cost: 11.79s
Train Epoch: 507 	Average Loss: 2.7498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7431

Learning rate: 9.936709676171268e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 508 [0/90000 (0%)]	Loss: 3.6914	Cost: 51.11s
Train Epoch: 508 [20480/90000 (23%)]	Loss: 2.7714	Cost: 6.39s
Train Epoch: 508 [40960/90000 (45%)]	Loss: 2.6142	Cost: 13.99s
Train Epoch: 508 [61440/90000 (68%)]	Loss: 2.8286	Cost: 8.54s
Train Epoch: 508 [81920/90000 (91%)]	Loss: 2.4915	Cost: 7.42s
Train Epoch: 508 	Average Loss: 2.7854
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6445

Learning rate: 9.936460294639754e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 509 [0/90000 (0%)]	Loss: 3.8322	Cost: 27.40s
Train Epoch: 509 [20480/90000 (23%)]	Loss: 2.6645	Cost: 8.58s
Train Epoch: 509 [40960/90000 (45%)]	Loss: 2.6188	Cost: 18.34s
Train Epoch: 509 [61440/90000 (68%)]	Loss: 2.6390	Cost: 12.37s
Train Epoch: 509 [81920/90000 (91%)]	Loss: 2.5918	Cost: 12.01s
Train Epoch: 509 	Average Loss: 2.7433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6897

Learning rate: 9.93621042589914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 510 [0/90000 (0%)]	Loss: 3.6380	Cost: 39.31s
Train Epoch: 510 [20480/90000 (23%)]	Loss: 2.7083	Cost: 12.05s
Train Epoch: 510 [40960/90000 (45%)]	Loss: 2.5972	Cost: 7.13s
Train Epoch: 510 [61440/90000 (68%)]	Loss: 2.6858	Cost: 6.17s
Train Epoch: 510 [81920/90000 (91%)]	Loss: 2.4960	Cost: 14.42s
Train Epoch: 510 	Average Loss: 2.7223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6309

Learning rate: 9.935960069974091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 511 [0/90000 (0%)]	Loss: 3.6672	Cost: 27.37s
Train Epoch: 511 [20480/90000 (23%)]	Loss: 2.8270	Cost: 8.79s
Train Epoch: 511 [40960/90000 (45%)]	Loss: 2.6310	Cost: 23.36s
Train Epoch: 511 [61440/90000 (68%)]	Loss: 2.5662	Cost: 13.44s
Train Epoch: 511 [81920/90000 (91%)]	Loss: 2.5363	Cost: 13.10s
Train Epoch: 511 	Average Loss: 2.7109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6842

Learning rate: 9.935709226889313e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 512 [0/90000 (0%)]	Loss: 3.5491	Cost: 51.53s
Train Epoch: 512 [20480/90000 (23%)]	Loss: 2.7519	Cost: 7.18s
Train Epoch: 512 [40960/90000 (45%)]	Loss: 2.4291	Cost: 13.34s
Train Epoch: 512 [61440/90000 (68%)]	Loss: 2.5983	Cost: 8.53s
Train Epoch: 512 [81920/90000 (91%)]	Loss: 2.3793	Cost: 8.85s
Train Epoch: 512 	Average Loss: 2.6772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5784

Saving model as e512_model.pt & e512_waveforms_supplementary.hdf5
Learning rate: 9.935457896669563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 513 [0/90000 (0%)]	Loss: 3.5726	Cost: 29.71s
Train Epoch: 513 [20480/90000 (23%)]	Loss: 2.7983	Cost: 8.00s
Train Epoch: 513 [40960/90000 (45%)]	Loss: 2.6680	Cost: 16.97s
Train Epoch: 513 [61440/90000 (68%)]	Loss: 2.6805	Cost: 12.25s
Train Epoch: 513 [81920/90000 (91%)]	Loss: 2.6525	Cost: 12.29s
Train Epoch: 513 	Average Loss: 2.7550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7176

Learning rate: 9.935206079339646e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 514 [0/90000 (0%)]	Loss: 3.8298	Cost: 37.40s
Train Epoch: 514 [20480/90000 (23%)]	Loss: 2.6703	Cost: 12.08s
Train Epoch: 514 [40960/90000 (45%)]	Loss: 2.6804	Cost: 9.71s
Train Epoch: 514 [61440/90000 (68%)]	Loss: 2.6103	Cost: 8.69s
Train Epoch: 514 [81920/90000 (91%)]	Loss: 2.4313	Cost: 18.33s
Train Epoch: 514 	Average Loss: 2.7174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6692

Learning rate: 9.934953774924418e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 515 [0/90000 (0%)]	Loss: 3.6974	Cost: 36.11s
Train Epoch: 515 [20480/90000 (23%)]	Loss: 2.6476	Cost: 8.66s
Train Epoch: 515 [40960/90000 (45%)]	Loss: 2.4976	Cost: 20.61s
Train Epoch: 515 [61440/90000 (68%)]	Loss: 2.4671	Cost: 11.97s
Train Epoch: 515 [81920/90000 (91%)]	Loss: 2.4726	Cost: 11.98s
Train Epoch: 515 	Average Loss: 2.6801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6051

Learning rate: 9.93470098344878e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 516 [0/90000 (0%)]	Loss: 3.5611	Cost: 41.33s
Train Epoch: 516 [20480/90000 (23%)]	Loss: 2.6558	Cost: 6.34s
Train Epoch: 516 [40960/90000 (45%)]	Loss: 2.5102	Cost: 15.04s
Train Epoch: 516 [61440/90000 (68%)]	Loss: 2.5931	Cost: 8.78s
Train Epoch: 516 [81920/90000 (91%)]	Loss: 2.5322	Cost: 11.99s
Train Epoch: 516 	Average Loss: 2.6635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6549

Learning rate: 9.934447704937678e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 517 [0/90000 (0%)]	Loss: 3.5710	Cost: 32.28s
Train Epoch: 517 [20480/90000 (23%)]	Loss: 2.5845	Cost: 6.89s
Train Epoch: 517 [40960/90000 (45%)]	Loss: 2.4914	Cost: 18.42s
Train Epoch: 517 [61440/90000 (68%)]	Loss: 2.5565	Cost: 12.16s
Train Epoch: 517 [81920/90000 (91%)]	Loss: 2.3893	Cost: 11.82s
Train Epoch: 517 	Average Loss: 2.6526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6297

Learning rate: 9.934193939416114e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 518 [0/90000 (0%)]	Loss: 3.5215	Cost: 29.35s
Train Epoch: 518 [20480/90000 (23%)]	Loss: 2.6507	Cost: 9.40s
Train Epoch: 518 [40960/90000 (45%)]	Loss: 2.4140	Cost: 9.87s
Train Epoch: 518 [61440/90000 (68%)]	Loss: 2.4252	Cost: 7.38s
Train Epoch: 518 [81920/90000 (91%)]	Loss: 2.5294	Cost: 11.83s
Train Epoch: 518 	Average Loss: 2.6645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6618

Learning rate: 9.933939686909132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 519 [0/90000 (0%)]	Loss: 3.2978	Cost: 33.34s
Train Epoch: 519 [20480/90000 (23%)]	Loss: 2.6577	Cost: 11.40s
Train Epoch: 519 [40960/90000 (45%)]	Loss: 2.5428	Cost: 23.71s
Train Epoch: 519 [61440/90000 (68%)]	Loss: 2.7016	Cost: 12.21s
Train Epoch: 519 [81920/90000 (91%)]	Loss: 2.5610	Cost: 12.11s
Train Epoch: 519 	Average Loss: 2.6696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.7012

Learning rate: 9.933684947441824e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 520 [0/90000 (0%)]	Loss: 3.6200	Cost: 37.89s
Train Epoch: 520 [20480/90000 (23%)]	Loss: 2.7394	Cost: 8.18s
Train Epoch: 520 [40960/90000 (45%)]	Loss: 2.4602	Cost: 13.22s
Train Epoch: 520 [61440/90000 (68%)]	Loss: 2.6365	Cost: 8.56s
Train Epoch: 520 [81920/90000 (91%)]	Loss: 2.4864	Cost: 9.99s
Train Epoch: 520 	Average Loss: 2.6712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6455

Learning rate: 9.933429721039335e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 521 [0/90000 (0%)]	Loss: 3.6628	Cost: 35.74s
Train Epoch: 521 [20480/90000 (23%)]	Loss: 2.7426	Cost: 10.01s
Train Epoch: 521 [40960/90000 (45%)]	Loss: 2.6957	Cost: 15.57s
Train Epoch: 521 [61440/90000 (68%)]	Loss: 2.6137	Cost: 12.62s
Train Epoch: 521 [81920/90000 (91%)]	Loss: 2.5382	Cost: 11.99s
Train Epoch: 521 	Average Loss: 2.7085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6875

Learning rate: 9.933174007726853e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 522 [0/90000 (0%)]	Loss: 3.6224	Cost: 51.06s
Train Epoch: 522 [20480/90000 (23%)]	Loss: 2.5819	Cost: 8.00s
Train Epoch: 522 [40960/90000 (45%)]	Loss: 2.4852	Cost: 9.51s
Train Epoch: 522 [61440/90000 (68%)]	Loss: 2.5727	Cost: 8.01s
Train Epoch: 522 [81920/90000 (91%)]	Loss: 2.3910	Cost: 11.83s
Train Epoch: 522 	Average Loss: 2.6340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5985

Learning rate: 9.932917807529615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 523 [0/90000 (0%)]	Loss: 3.6959	Cost: 28.15s
Train Epoch: 523 [20480/90000 (23%)]	Loss: 2.5689	Cost: 6.86s
Train Epoch: 523 [40960/90000 (45%)]	Loss: 2.4360	Cost: 19.97s
Train Epoch: 523 [61440/90000 (68%)]	Loss: 2.5021	Cost: 13.53s
Train Epoch: 523 [81920/90000 (91%)]	Loss: 2.4594	Cost: 12.17s
Train Epoch: 523 	Average Loss: 2.6048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5069

Saving model as e523_model.pt & e523_waveforms_supplementary.hdf5
Learning rate: 9.93266112047291e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 524 [0/90000 (0%)]	Loss: 3.6809	Cost: 34.47s
Train Epoch: 524 [20480/90000 (23%)]	Loss: 2.5681	Cost: 12.57s
Train Epoch: 524 [40960/90000 (45%)]	Loss: 2.4378	Cost: 9.08s
Train Epoch: 524 [61440/90000 (68%)]	Loss: 2.4529	Cost: 7.71s
Train Epoch: 524 [81920/90000 (91%)]	Loss: 2.2868	Cost: 13.44s
Train Epoch: 524 	Average Loss: 2.5646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6119

Learning rate: 9.932403946582067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 525 [0/90000 (0%)]	Loss: 3.5379	Cost: 29.95s
Train Epoch: 525 [20480/90000 (23%)]	Loss: 2.5031	Cost: 8.69s
Train Epoch: 525 [40960/90000 (45%)]	Loss: 2.3520	Cost: 17.05s
Train Epoch: 525 [61440/90000 (68%)]	Loss: 2.4739	Cost: 12.22s
Train Epoch: 525 [81920/90000 (91%)]	Loss: 2.4606	Cost: 12.16s
Train Epoch: 525 	Average Loss: 2.5734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6702

Learning rate: 9.932146285882473e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 526 [0/90000 (0%)]	Loss: 3.7150	Cost: 45.73s
Train Epoch: 526 [20480/90000 (23%)]	Loss: 2.5859	Cost: 12.34s
Train Epoch: 526 [40960/90000 (45%)]	Loss: 2.4283	Cost: 10.50s
Train Epoch: 526 [61440/90000 (68%)]	Loss: 2.4566	Cost: 6.71s
Train Epoch: 526 [81920/90000 (91%)]	Loss: 2.3115	Cost: 7.82s
Train Epoch: 526 	Average Loss: 2.6189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5539

Learning rate: 9.931888138399556e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 527 [0/90000 (0%)]	Loss: 3.6445	Cost: 34.35s
Train Epoch: 527 [20480/90000 (23%)]	Loss: 2.5454	Cost: 8.70s
Train Epoch: 527 [40960/90000 (45%)]	Loss: 2.3897	Cost: 9.35s
Train Epoch: 527 [61440/90000 (68%)]	Loss: 2.6070	Cost: 6.88s
Train Epoch: 527 [81920/90000 (91%)]	Loss: 2.3431	Cost: 15.20s
Train Epoch: 527 	Average Loss: 2.6166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5976

Learning rate: 9.931629504158793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 528 [0/90000 (0%)]	Loss: 3.5921	Cost: 30.92s
Train Epoch: 528 [20480/90000 (23%)]	Loss: 2.6047	Cost: 12.84s
Train Epoch: 528 [40960/90000 (45%)]	Loss: 2.3705	Cost: 12.13s
Train Epoch: 528 [61440/90000 (68%)]	Loss: 2.3962	Cost: 12.12s
Train Epoch: 528 [81920/90000 (91%)]	Loss: 2.3305	Cost: 10.53s
Train Epoch: 528 	Average Loss: 2.5276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5909

Learning rate: 9.931370383185712e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 529 [0/90000 (0%)]	Loss: 3.6909	Cost: 32.27s
Train Epoch: 529 [20480/90000 (23%)]	Loss: 2.4860	Cost: 8.09s
Train Epoch: 529 [40960/90000 (45%)]	Loss: 2.3745	Cost: 10.70s
Train Epoch: 529 [61440/90000 (68%)]	Loss: 2.3952	Cost: 10.46s
Train Epoch: 529 [81920/90000 (91%)]	Loss: 2.3389	Cost: 9.61s
Train Epoch: 529 	Average Loss: 2.5576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4748

Saving model as e529_model.pt & e529_waveforms_supplementary.hdf5
Learning rate: 9.931110775505886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 530 [0/90000 (0%)]	Loss: 3.4382	Cost: 39.30s
Train Epoch: 530 [20480/90000 (23%)]	Loss: 2.5153	Cost: 14.21s
Train Epoch: 530 [40960/90000 (45%)]	Loss: 2.3904	Cost: 12.87s
Train Epoch: 530 [61440/90000 (68%)]	Loss: 2.4459	Cost: 11.87s
Train Epoch: 530 [81920/90000 (91%)]	Loss: 2.4753	Cost: 11.57s
Train Epoch: 530 	Average Loss: 2.5679
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6180

Learning rate: 9.93085068114494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 531 [0/90000 (0%)]	Loss: 3.6514	Cost: 33.27s
Train Epoch: 531 [20480/90000 (23%)]	Loss: 2.6690	Cost: 10.97s
Train Epoch: 531 [40960/90000 (45%)]	Loss: 2.3844	Cost: 7.85s
Train Epoch: 531 [61440/90000 (68%)]	Loss: 2.4158	Cost: 6.27s
Train Epoch: 531 [81920/90000 (91%)]	Loss: 2.3018	Cost: 13.12s
Train Epoch: 531 	Average Loss: 2.5695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5070

Learning rate: 9.930590100128539e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 532 [0/90000 (0%)]	Loss: 3.4313	Cost: 34.18s
Train Epoch: 532 [20480/90000 (23%)]	Loss: 2.4145	Cost: 11.02s
Train Epoch: 532 [40960/90000 (45%)]	Loss: 2.3911	Cost: 19.57s
Train Epoch: 532 [61440/90000 (68%)]	Loss: 2.3988	Cost: 12.29s
Train Epoch: 532 [81920/90000 (91%)]	Loss: 2.4211	Cost: 11.87s
Train Epoch: 532 	Average Loss: 2.4868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5387

Learning rate: 9.930329032482406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 533 [0/90000 (0%)]	Loss: 3.4714	Cost: 36.14s
Train Epoch: 533 [20480/90000 (23%)]	Loss: 2.5003	Cost: 10.64s
Train Epoch: 533 [40960/90000 (45%)]	Loss: 2.3448	Cost: 9.11s
Train Epoch: 533 [61440/90000 (68%)]	Loss: 2.4961	Cost: 6.22s
Train Epoch: 533 [81920/90000 (91%)]	Loss: 2.3223	Cost: 11.97s
Train Epoch: 533 	Average Loss: 2.4955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5404

Learning rate: 9.930067478232305e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 534 [0/90000 (0%)]	Loss: 3.4793	Cost: 29.61s
Train Epoch: 534 [20480/90000 (23%)]	Loss: 2.5209	Cost: 10.65s
Train Epoch: 534 [40960/90000 (45%)]	Loss: 2.3377	Cost: 24.92s
Train Epoch: 534 [61440/90000 (68%)]	Loss: 2.4120	Cost: 13.27s
Train Epoch: 534 [81920/90000 (91%)]	Loss: 2.3375	Cost: 12.01s
Train Epoch: 534 	Average Loss: 2.4867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5214

Learning rate: 9.929805437404053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 535 [0/90000 (0%)]	Loss: 3.7502	Cost: 52.54s
Train Epoch: 535 [20480/90000 (23%)]	Loss: 2.5509	Cost: 6.34s
Train Epoch: 535 [40960/90000 (45%)]	Loss: 2.4479	Cost: 14.45s
Train Epoch: 535 [61440/90000 (68%)]	Loss: 2.4170	Cost: 8.45s
Train Epoch: 535 [81920/90000 (91%)]	Loss: 2.2801	Cost: 6.54s
Train Epoch: 535 	Average Loss: 2.5007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5893

Learning rate: 9.92954291002351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 536 [0/90000 (0%)]	Loss: 3.6342	Cost: 37.46s
Train Epoch: 536 [20480/90000 (23%)]	Loss: 2.5779	Cost: 12.97s
Train Epoch: 536 [40960/90000 (45%)]	Loss: 2.3144	Cost: 15.43s
Train Epoch: 536 [61440/90000 (68%)]	Loss: 2.4327	Cost: 12.35s
Train Epoch: 536 [81920/90000 (91%)]	Loss: 2.4669	Cost: 12.26s
Train Epoch: 536 	Average Loss: 2.5660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.6923

Learning rate: 9.929279896116587e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 537 [0/90000 (0%)]	Loss: 3.6580	Cost: 41.16s
Train Epoch: 537 [20480/90000 (23%)]	Loss: 2.4947	Cost: 6.34s
Train Epoch: 537 [40960/90000 (45%)]	Loss: 2.3797	Cost: 14.31s
Train Epoch: 537 [61440/90000 (68%)]	Loss: 2.3915	Cost: 8.64s
Train Epoch: 537 [81920/90000 (91%)]	Loss: 2.3616	Cost: 9.25s
Train Epoch: 537 	Average Loss: 2.5281
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5352

Learning rate: 9.929016395709243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 538 [0/90000 (0%)]	Loss: 3.4784	Cost: 25.29s
Train Epoch: 538 [20480/90000 (23%)]	Loss: 2.4274	Cost: 6.81s
Train Epoch: 538 [40960/90000 (45%)]	Loss: 2.3283	Cost: 16.14s
Train Epoch: 538 [61440/90000 (68%)]	Loss: 2.4026	Cost: 12.33s
Train Epoch: 538 [81920/90000 (91%)]	Loss: 2.2027	Cost: 12.99s
Train Epoch: 538 	Average Loss: 2.4751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5958

Learning rate: 9.928752408827483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 539 [0/90000 (0%)]	Loss: 3.5337	Cost: 36.17s
Train Epoch: 539 [20480/90000 (23%)]	Loss: 2.5522	Cost: 12.81s
Train Epoch: 539 [40960/90000 (45%)]	Loss: 2.1556	Cost: 12.93s
Train Epoch: 539 [61440/90000 (68%)]	Loss: 2.4891	Cost: 8.27s
Train Epoch: 539 [81920/90000 (91%)]	Loss: 2.2591	Cost: 6.78s
Train Epoch: 539 	Average Loss: 2.4673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5705

Learning rate: 9.928487935497362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 540 [0/90000 (0%)]	Loss: 3.5397	Cost: 34.51s
Train Epoch: 540 [20480/90000 (23%)]	Loss: 2.4456	Cost: 8.86s
Train Epoch: 540 [40960/90000 (45%)]	Loss: 2.2535	Cost: 9.76s
Train Epoch: 540 [61440/90000 (68%)]	Loss: 2.2535	Cost: 6.91s
Train Epoch: 540 [81920/90000 (91%)]	Loss: 2.2493	Cost: 19.30s
Train Epoch: 540 	Average Loss: 2.4407
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5805

Learning rate: 9.928222975744984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 541 [0/90000 (0%)]	Loss: 3.5265	Cost: 48.10s
Train Epoch: 541 [20480/90000 (23%)]	Loss: 2.4465	Cost: 12.19s
Train Epoch: 541 [40960/90000 (45%)]	Loss: 2.2517	Cost: 12.38s
Train Epoch: 541 [61440/90000 (68%)]	Loss: 2.2574	Cost: 7.82s
Train Epoch: 541 [81920/90000 (91%)]	Loss: 2.2695	Cost: 6.18s
Train Epoch: 541 	Average Loss: 2.4447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4859

Learning rate: 9.927957529596498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 542 [0/90000 (0%)]	Loss: 3.4866	Cost: 29.83s
Train Epoch: 542 [20480/90000 (23%)]	Loss: 2.4810	Cost: 9.23s
Train Epoch: 542 [40960/90000 (45%)]	Loss: 2.3637	Cost: 11.93s
Train Epoch: 542 [61440/90000 (68%)]	Loss: 2.3372	Cost: 8.30s
Train Epoch: 542 [81920/90000 (91%)]	Loss: 2.2875	Cost: 8.27s
Train Epoch: 542 	Average Loss: 2.4426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4964

Learning rate: 9.927691597078101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 543 [0/90000 (0%)]	Loss: 3.5777	Cost: 28.77s
Train Epoch: 543 [20480/90000 (23%)]	Loss: 2.4703	Cost: 8.30s
Train Epoch: 543 [40960/90000 (45%)]	Loss: 2.2821	Cost: 17.69s
Train Epoch: 543 [61440/90000 (68%)]	Loss: 2.2914	Cost: 11.99s
Train Epoch: 543 [81920/90000 (91%)]	Loss: 2.1189	Cost: 11.91s
Train Epoch: 543 	Average Loss: 2.4215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4444

Saving model as e543_model.pt & e543_waveforms_supplementary.hdf5
Learning rate: 9.927425178216043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 544 [0/90000 (0%)]	Loss: 3.4334	Cost: 29.64s
Train Epoch: 544 [20480/90000 (23%)]	Loss: 2.4290	Cost: 6.30s
Train Epoch: 544 [40960/90000 (45%)]	Loss: 2.1407	Cost: 13.74s
Train Epoch: 544 [61440/90000 (68%)]	Loss: 2.3327	Cost: 9.08s
Train Epoch: 544 [81920/90000 (91%)]	Loss: 2.2033	Cost: 11.77s
Train Epoch: 544 	Average Loss: 2.3766
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4328

Saving model as e544_model.pt & e544_waveforms_supplementary.hdf5
Learning rate: 9.927158273036618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 545 [0/90000 (0%)]	Loss: 3.4022	Cost: 36.91s
Train Epoch: 545 [20480/90000 (23%)]	Loss: 2.4370	Cost: 14.74s
Train Epoch: 545 [40960/90000 (45%)]	Loss: 2.1854	Cost: 13.04s
Train Epoch: 545 [61440/90000 (68%)]	Loss: 2.2519	Cost: 12.15s
Train Epoch: 545 [81920/90000 (91%)]	Loss: 2.0796	Cost: 11.83s
Train Epoch: 545 	Average Loss: 2.3441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4084

Saving model as e545_model.pt & e545_waveforms_supplementary.hdf5
Learning rate: 9.926890881566166e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 546 [0/90000 (0%)]	Loss: 3.3917	Cost: 32.52s
Train Epoch: 546 [20480/90000 (23%)]	Loss: 2.3729	Cost: 8.16s
Train Epoch: 546 [40960/90000 (45%)]	Loss: 2.2792	Cost: 13.40s
Train Epoch: 546 [61440/90000 (68%)]	Loss: 2.2381	Cost: 8.68s
Train Epoch: 546 [81920/90000 (91%)]	Loss: 2.2633	Cost: 8.48s
Train Epoch: 546 	Average Loss: 2.4058
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5045

Learning rate: 9.926623003831078e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 547 [0/90000 (0%)]	Loss: 3.5216	Cost: 30.59s
Train Epoch: 547 [20480/90000 (23%)]	Loss: 2.5453	Cost: 12.13s
Train Epoch: 547 [40960/90000 (45%)]	Loss: 2.2790	Cost: 12.40s
Train Epoch: 547 [61440/90000 (68%)]	Loss: 2.3841	Cost: 13.43s
Train Epoch: 547 [81920/90000 (91%)]	Loss: 2.0788	Cost: 12.06s
Train Epoch: 547 	Average Loss: 2.4142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4387

Learning rate: 9.926354639857796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 548 [0/90000 (0%)]	Loss: 3.4380	Cost: 39.42s
Train Epoch: 548 [20480/90000 (23%)]	Loss: 2.3264	Cost: 12.27s
Train Epoch: 548 [40960/90000 (45%)]	Loss: 2.2161	Cost: 10.14s
Train Epoch: 548 [61440/90000 (68%)]	Loss: 2.1197	Cost: 6.03s
Train Epoch: 548 [81920/90000 (91%)]	Loss: 2.1908	Cost: 8.16s
Train Epoch: 548 	Average Loss: 2.3263
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4624

Learning rate: 9.926085789672802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 549 [0/90000 (0%)]	Loss: 3.3646	Cost: 29.39s
Train Epoch: 549 [20480/90000 (23%)]	Loss: 2.4894	Cost: 7.59s
Train Epoch: 549 [40960/90000 (45%)]	Loss: 2.1677	Cost: 12.61s
Train Epoch: 549 [61440/90000 (68%)]	Loss: 2.2231	Cost: 11.12s
Train Epoch: 549 [81920/90000 (91%)]	Loss: 1.9913	Cost: 21.23s
Train Epoch: 549 	Average Loss: 2.3287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4575

Learning rate: 9.92581645330263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 550 [0/90000 (0%)]	Loss: 3.3025	Cost: 39.64s
Train Epoch: 550 [20480/90000 (23%)]	Loss: 2.3596	Cost: 14.44s
Train Epoch: 550 [40960/90000 (45%)]	Loss: 2.2026	Cost: 12.24s
Train Epoch: 550 [61440/90000 (68%)]	Loss: 2.1549	Cost: 10.61s
Train Epoch: 550 [81920/90000 (91%)]	Loss: 2.1095	Cost: 6.16s
Train Epoch: 550 	Average Loss: 2.3282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4713

Learning rate: 9.925546630773865e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 551 [0/90000 (0%)]	Loss: 3.4618	Cost: 32.78s
Train Epoch: 551 [20480/90000 (23%)]	Loss: 2.4061	Cost: 9.27s
Train Epoch: 551 [40960/90000 (45%)]	Loss: 2.2195	Cost: 10.84s
Train Epoch: 551 [61440/90000 (68%)]	Loss: 2.2711	Cost: 8.61s
Train Epoch: 551 [81920/90000 (91%)]	Loss: 2.1899	Cost: 6.62s
Train Epoch: 551 	Average Loss: 2.3019
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4677

Learning rate: 9.925276322113137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 552 [0/90000 (0%)]	Loss: 3.2709	Cost: 32.15s
Train Epoch: 552 [20480/90000 (23%)]	Loss: 2.3537	Cost: 12.73s
Train Epoch: 552 [40960/90000 (45%)]	Loss: 2.1429	Cost: 15.05s
Train Epoch: 552 [61440/90000 (68%)]	Loss: 2.1716	Cost: 12.50s
Train Epoch: 552 [81920/90000 (91%)]	Loss: 2.1901	Cost: 12.20s
Train Epoch: 552 	Average Loss: 2.3050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4462

Learning rate: 9.925005527347125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 553 [0/90000 (0%)]	Loss: 3.2713	Cost: 45.86s
Train Epoch: 553 [20480/90000 (23%)]	Loss: 2.2579	Cost: 7.29s
Train Epoch: 553 [40960/90000 (45%)]	Loss: 2.1861	Cost: 11.87s
Train Epoch: 553 [61440/90000 (68%)]	Loss: 2.1206	Cost: 8.76s
Train Epoch: 553 [81920/90000 (91%)]	Loss: 2.0602	Cost: 9.55s
Train Epoch: 553 	Average Loss: 2.2633
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3795

Saving model as e553_model.pt & e553_waveforms_supplementary.hdf5
Learning rate: 9.924734246502554e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 554 [0/90000 (0%)]	Loss: 3.3567	Cost: 27.65s
Train Epoch: 554 [20480/90000 (23%)]	Loss: 2.2668	Cost: 6.73s
Train Epoch: 554 [40960/90000 (45%)]	Loss: 2.1570	Cost: 17.07s
Train Epoch: 554 [61440/90000 (68%)]	Loss: 2.0986	Cost: 12.63s
Train Epoch: 554 [81920/90000 (91%)]	Loss: 2.0392	Cost: 12.33s
Train Epoch: 554 	Average Loss: 2.2606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4339

Learning rate: 9.9244624796062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 555 [0/90000 (0%)]	Loss: 3.3380	Cost: 33.99s
Train Epoch: 555 [20480/90000 (23%)]	Loss: 2.3382	Cost: 10.90s
Train Epoch: 555 [40960/90000 (45%)]	Loss: 2.1590	Cost: 11.18s
Train Epoch: 555 [61440/90000 (68%)]	Loss: 2.1279	Cost: 8.65s
Train Epoch: 555 [81920/90000 (91%)]	Loss: 2.1262	Cost: 12.70s
Train Epoch: 555 	Average Loss: 2.2747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3777

Saving model as e555_model.pt & e555_waveforms_supplementary.hdf5
Learning rate: 9.924190226684883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 556 [0/90000 (0%)]	Loss: 3.4277	Cost: 35.35s
Train Epoch: 556 [20480/90000 (23%)]	Loss: 2.4554	Cost: 9.96s
Train Epoch: 556 [40960/90000 (45%)]	Loss: 2.1902	Cost: 13.94s
Train Epoch: 556 [61440/90000 (68%)]	Loss: 2.3010	Cost: 12.07s
Train Epoch: 556 [81920/90000 (91%)]	Loss: 2.1510	Cost: 12.23s
Train Epoch: 556 	Average Loss: 2.3319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4307

Learning rate: 9.923917487765477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 557 [0/90000 (0%)]	Loss: 3.3509	Cost: 41.11s
Train Epoch: 557 [20480/90000 (23%)]	Loss: 2.3117	Cost: 9.05s
Train Epoch: 557 [40960/90000 (45%)]	Loss: 2.2318	Cost: 8.83s
Train Epoch: 557 [61440/90000 (68%)]	Loss: 2.0896	Cost: 7.81s
Train Epoch: 557 [81920/90000 (91%)]	Loss: 2.1285	Cost: 12.96s
Train Epoch: 557 	Average Loss: 2.2942
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4626

Learning rate: 9.923644262874898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 558 [0/90000 (0%)]	Loss: 3.4093	Cost: 34.76s
Train Epoch: 558 [20480/90000 (23%)]	Loss: 2.3885	Cost: 6.79s
Train Epoch: 558 [40960/90000 (45%)]	Loss: 2.0667	Cost: 17.74s
Train Epoch: 558 [61440/90000 (68%)]	Loss: 2.1127	Cost: 12.40s
Train Epoch: 558 [81920/90000 (91%)]	Loss: 2.0939	Cost: 11.90s
Train Epoch: 558 	Average Loss: 2.3347
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5020

Learning rate: 9.92337055204011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 559 [0/90000 (0%)]	Loss: 3.4962	Cost: 30.45s
Train Epoch: 559 [20480/90000 (23%)]	Loss: 2.3526	Cost: 12.38s
Train Epoch: 559 [40960/90000 (45%)]	Loss: 2.1377	Cost: 7.16s
Train Epoch: 559 [61440/90000 (68%)]	Loss: 2.2435	Cost: 6.74s
Train Epoch: 559 [81920/90000 (91%)]	Loss: 2.0717	Cost: 12.59s
Train Epoch: 559 	Average Loss: 2.2798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3936

Learning rate: 9.92309635528813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 560 [0/90000 (0%)]	Loss: 3.3822	Cost: 33.23s
Train Epoch: 560 [20480/90000 (23%)]	Loss: 2.3541	Cost: 11.23s
Train Epoch: 560 [40960/90000 (45%)]	Loss: 2.0099	Cost: 16.70s
Train Epoch: 560 [61440/90000 (68%)]	Loss: 2.1044	Cost: 12.53s
Train Epoch: 560 [81920/90000 (91%)]	Loss: 2.0649	Cost: 11.99s
Train Epoch: 560 	Average Loss: 2.2051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3403

Saving model as e560_model.pt & e560_waveforms_supplementary.hdf5
Learning rate: 9.92282167264602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 561 [0/90000 (0%)]	Loss: 3.3971	Cost: 32.16s
Train Epoch: 561 [20480/90000 (23%)]	Loss: 2.1424	Cost: 12.60s
Train Epoch: 561 [40960/90000 (45%)]	Loss: 2.0351	Cost: 11.97s
Train Epoch: 561 [61440/90000 (68%)]	Loss: 2.1808	Cost: 6.19s
Train Epoch: 561 [81920/90000 (91%)]	Loss: 2.0256	Cost: 9.97s
Train Epoch: 561 	Average Loss: 2.1964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4517

Learning rate: 9.92254650414089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 562 [0/90000 (0%)]	Loss: 3.2952	Cost: 31.39s
Train Epoch: 562 [20480/90000 (23%)]	Loss: 2.3384	Cost: 9.83s
Train Epoch: 562 [40960/90000 (45%)]	Loss: 2.2357	Cost: 13.43s
Train Epoch: 562 [61440/90000 (68%)]	Loss: 2.2136	Cost: 13.96s
Train Epoch: 562 [81920/90000 (91%)]	Loss: 2.1362	Cost: 12.11s
Train Epoch: 562 	Average Loss: 2.2952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3987

Learning rate: 9.922270849799896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 563 [0/90000 (0%)]	Loss: 3.4048	Cost: 39.92s
Train Epoch: 563 [20480/90000 (23%)]	Loss: 2.3207	Cost: 12.43s
Train Epoch: 563 [40960/90000 (45%)]	Loss: 2.1539	Cost: 12.07s
Train Epoch: 563 [61440/90000 (68%)]	Loss: 2.1109	Cost: 8.03s
Train Epoch: 563 [81920/90000 (91%)]	Loss: 2.1180	Cost: 6.21s
Train Epoch: 563 	Average Loss: 2.2388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3361

Saving model as e563_model.pt & e563_waveforms_supplementary.hdf5
Learning rate: 9.921994709650246e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 564 [0/90000 (0%)]	Loss: 3.2642	Cost: 30.57s
Train Epoch: 564 [20480/90000 (23%)]	Loss: 2.1394	Cost: 6.65s
Train Epoch: 564 [40960/90000 (45%)]	Loss: 2.1719	Cost: 15.43s
Train Epoch: 564 [61440/90000 (68%)]	Loss: 2.0722	Cost: 10.78s
Train Epoch: 564 [81920/90000 (91%)]	Loss: 2.1152	Cost: 20.04s
Train Epoch: 564 	Average Loss: 2.2117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3120

Saving model as e564_model.pt & e564_waveforms_supplementary.hdf5
Learning rate: 9.921718083719194e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 565 [0/90000 (0%)]	Loss: 3.1253	Cost: 43.84s
Train Epoch: 565 [20480/90000 (23%)]	Loss: 2.3336	Cost: 12.92s
Train Epoch: 565 [40960/90000 (45%)]	Loss: 2.1843	Cost: 12.12s
Train Epoch: 565 [61440/90000 (68%)]	Loss: 2.1051	Cost: 6.32s
Train Epoch: 565 [81920/90000 (91%)]	Loss: 1.9296	Cost: 6.75s
Train Epoch: 565 	Average Loss: 2.1963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3544

Learning rate: 9.921440972034041e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 566 [0/90000 (0%)]	Loss: 3.3104	Cost: 37.20s
Train Epoch: 566 [20480/90000 (23%)]	Loss: 2.3239	Cost: 6.11s
Train Epoch: 566 [40960/90000 (45%)]	Loss: 2.2603	Cost: 16.11s
Train Epoch: 566 [61440/90000 (68%)]	Loss: 2.1002	Cost: 11.94s
Train Epoch: 566 [81920/90000 (91%)]	Loss: 1.9704	Cost: 12.22s
Train Epoch: 566 	Average Loss: 2.2351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2959

Saving model as e566_model.pt & e566_waveforms_supplementary.hdf5
Learning rate: 9.921163374622138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 567 [0/90000 (0%)]	Loss: 3.2641	Cost: 46.91s
Train Epoch: 567 [20480/90000 (23%)]	Loss: 2.2962	Cost: 8.68s
Train Epoch: 567 [40960/90000 (45%)]	Loss: 1.9756	Cost: 10.36s
Train Epoch: 567 [61440/90000 (68%)]	Loss: 2.0273	Cost: 6.22s
Train Epoch: 567 [81920/90000 (91%)]	Loss: 1.9217	Cost: 13.90s
Train Epoch: 567 	Average Loss: 2.1504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2049

Saving model as e567_model.pt & e567_waveforms_supplementary.hdf5
Learning rate: 9.920885291510881e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 568 [0/90000 (0%)]	Loss: 3.2838	Cost: 26.99s
Train Epoch: 568 [20480/90000 (23%)]	Loss: 2.1530	Cost: 6.59s
Train Epoch: 568 [40960/90000 (45%)]	Loss: 2.2534	Cost: 13.97s
Train Epoch: 568 [61440/90000 (68%)]	Loss: 2.2813	Cost: 11.87s
Train Epoch: 568 [81920/90000 (91%)]	Loss: 2.0530	Cost: 15.01s
Train Epoch: 568 	Average Loss: 2.2688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4645

Learning rate: 9.920606722727717e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 569 [0/90000 (0%)]	Loss: 3.3752	Cost: 33.58s
Train Epoch: 569 [20480/90000 (23%)]	Loss: 2.5105	Cost: 12.89s
Train Epoch: 569 [40960/90000 (45%)]	Loss: 2.2097	Cost: 12.59s
Train Epoch: 569 [61440/90000 (68%)]	Loss: 2.2319	Cost: 6.68s
Train Epoch: 569 [81920/90000 (91%)]	Loss: 2.0329	Cost: 7.59s
Train Epoch: 569 	Average Loss: 2.3249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3213

Learning rate: 9.920327668300141e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 570 [0/90000 (0%)]	Loss: 3.2697	Cost: 29.92s
Train Epoch: 570 [20480/90000 (23%)]	Loss: 2.2699	Cost: 8.14s
Train Epoch: 570 [40960/90000 (45%)]	Loss: 2.2285	Cost: 21.50s
Train Epoch: 570 [61440/90000 (68%)]	Loss: 2.3506	Cost: 12.53s
Train Epoch: 570 [81920/90000 (91%)]	Loss: 2.1475	Cost: 12.06s
Train Epoch: 570 	Average Loss: 2.3325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.5081

Learning rate: 9.920048128255691e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 571 [0/90000 (0%)]	Loss: 3.6616	Cost: 43.95s
Train Epoch: 571 [20480/90000 (23%)]	Loss: 2.3525	Cost: 11.88s
Train Epoch: 571 [40960/90000 (45%)]	Loss: 2.0898	Cost: 7.40s
Train Epoch: 571 [61440/90000 (68%)]	Loss: 2.1394	Cost: 6.69s
Train Epoch: 571 [81920/90000 (91%)]	Loss: 1.8192	Cost: 15.25s
Train Epoch: 571 	Average Loss: 2.2465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2446

Learning rate: 9.91976810262196e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 572 [0/90000 (0%)]	Loss: 3.3565	Cost: 28.57s
Train Epoch: 572 [20480/90000 (23%)]	Loss: 2.2530	Cost: 7.31s
Train Epoch: 572 [40960/90000 (45%)]	Loss: 1.9515	Cost: 17.25s
Train Epoch: 572 [61440/90000 (68%)]	Loss: 1.9351	Cost: 12.12s
Train Epoch: 572 [81920/90000 (91%)]	Loss: 1.8960	Cost: 12.07s
Train Epoch: 572 	Average Loss: 2.1404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2510

Learning rate: 9.919487591426583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 573 [0/90000 (0%)]	Loss: 3.3554	Cost: 31.64s
Train Epoch: 573 [20480/90000 (23%)]	Loss: 2.2078	Cost: 12.17s
Train Epoch: 573 [40960/90000 (45%)]	Loss: 1.8761	Cost: 11.98s
Train Epoch: 573 [61440/90000 (68%)]	Loss: 1.8796	Cost: 6.44s
Train Epoch: 573 [81920/90000 (91%)]	Loss: 1.9041	Cost: 8.03s
Train Epoch: 573 	Average Loss: 2.0687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3313

Learning rate: 9.919206594697245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 574 [0/90000 (0%)]	Loss: 3.5478	Cost: 33.89s
Train Epoch: 574 [20480/90000 (23%)]	Loss: 2.1726	Cost: 12.37s
Train Epoch: 574 [40960/90000 (45%)]	Loss: 2.0021	Cost: 19.68s
Train Epoch: 574 [61440/90000 (68%)]	Loss: 1.7730	Cost: 12.43s
Train Epoch: 574 [81920/90000 (91%)]	Loss: 1.8468	Cost: 11.84s
Train Epoch: 574 	Average Loss: 2.0534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2855

Learning rate: 9.918925112461682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 575 [0/90000 (0%)]	Loss: 3.2157	Cost: 34.45s
Train Epoch: 575 [20480/90000 (23%)]	Loss: 2.0389	Cost: 6.92s
Train Epoch: 575 [40960/90000 (45%)]	Loss: 2.1036	Cost: 14.66s
Train Epoch: 575 [61440/90000 (68%)]	Loss: 2.0276	Cost: 8.52s
Train Epoch: 575 [81920/90000 (91%)]	Loss: 1.9047	Cost: 8.67s
Train Epoch: 575 	Average Loss: 2.1105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2662

Learning rate: 9.918643144747673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 576 [0/90000 (0%)]	Loss: 3.1998	Cost: 29.01s
Train Epoch: 576 [20480/90000 (23%)]	Loss: 2.1227	Cost: 6.76s
Train Epoch: 576 [40960/90000 (45%)]	Loss: 2.0317	Cost: 18.49s
Train Epoch: 576 [61440/90000 (68%)]	Loss: 1.9130	Cost: 12.78s
Train Epoch: 576 [81920/90000 (91%)]	Loss: 1.8964	Cost: 12.04s
Train Epoch: 576 	Average Loss: 2.0851
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1892

Saving model as e576_model.pt & e576_waveforms_supplementary.hdf5
Learning rate: 9.918360691583047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 577 [0/90000 (0%)]	Loss: 3.1706	Cost: 42.86s
Train Epoch: 577 [20480/90000 (23%)]	Loss: 2.0488	Cost: 10.60s
Train Epoch: 577 [40960/90000 (45%)]	Loss: 1.8117	Cost: 7.05s
Train Epoch: 577 [61440/90000 (68%)]	Loss: 1.9018	Cost: 7.00s
Train Epoch: 577 [81920/90000 (91%)]	Loss: 1.9340	Cost: 13.19s
Train Epoch: 577 	Average Loss: 2.0294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2374

Learning rate: 9.918077752995681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 578 [0/90000 (0%)]	Loss: 3.0452	Cost: 31.72s
Train Epoch: 578 [20480/90000 (23%)]	Loss: 2.0635	Cost: 6.75s
Train Epoch: 578 [40960/90000 (45%)]	Loss: 1.8885	Cost: 18.82s
Train Epoch: 578 [61440/90000 (68%)]	Loss: 1.9382	Cost: 14.07s
Train Epoch: 578 [81920/90000 (91%)]	Loss: 1.7957	Cost: 12.30s
Train Epoch: 578 	Average Loss: 2.0310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2970

Learning rate: 9.917794329013504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 579 [0/90000 (0%)]	Loss: 3.1686	Cost: 34.10s
Train Epoch: 579 [20480/90000 (23%)]	Loss: 2.1502	Cost: 10.23s
Train Epoch: 579 [40960/90000 (45%)]	Loss: 1.9836	Cost: 14.44s
Train Epoch: 579 [61440/90000 (68%)]	Loss: 2.1927	Cost: 8.92s
Train Epoch: 579 [81920/90000 (91%)]	Loss: 2.0604	Cost: 14.81s
Train Epoch: 579 	Average Loss: 2.1755
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.4139

Learning rate: 9.917510419664483e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 580 [0/90000 (0%)]	Loss: 3.1464	Cost: 35.09s
Train Epoch: 580 [20480/90000 (23%)]	Loss: 2.3054	Cost: 10.50s
Train Epoch: 580 [40960/90000 (45%)]	Loss: 2.1333	Cost: 17.15s
Train Epoch: 580 [61440/90000 (68%)]	Loss: 1.9563	Cost: 12.04s
Train Epoch: 580 [81920/90000 (91%)]	Loss: 1.8720	Cost: 11.89s
Train Epoch: 580 	Average Loss: 2.1617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.3273

Learning rate: 9.91722602497664e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 581 [0/90000 (0%)]	Loss: 3.2380	Cost: 33.06s
Train Epoch: 581 [20480/90000 (23%)]	Loss: 2.2029	Cost: 12.57s
Train Epoch: 581 [40960/90000 (45%)]	Loss: 1.9925	Cost: 7.71s
Train Epoch: 581 [61440/90000 (68%)]	Loss: 1.9651	Cost: 6.43s
Train Epoch: 581 [81920/90000 (91%)]	Loss: 1.8352	Cost: 14.53s
Train Epoch: 581 	Average Loss: 2.0886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2313

Learning rate: 9.916941144978047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 582 [0/90000 (0%)]	Loss: 3.3370	Cost: 34.37s
Train Epoch: 582 [20480/90000 (23%)]	Loss: 2.0623	Cost: 8.05s
Train Epoch: 582 [40960/90000 (45%)]	Loss: 1.9314	Cost: 16.33s
Train Epoch: 582 [61440/90000 (68%)]	Loss: 1.8742	Cost: 12.26s
Train Epoch: 582 [81920/90000 (91%)]	Loss: 1.7910	Cost: 12.12s
Train Epoch: 582 	Average Loss: 2.0170
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1889

Saving model as e582_model.pt & e582_waveforms_supplementary.hdf5
Learning rate: 9.916655779696818e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 583 [0/90000 (0%)]	Loss: 3.0993	Cost: 31.26s
Train Epoch: 583 [20480/90000 (23%)]	Loss: 2.0114	Cost: 12.55s
Train Epoch: 583 [40960/90000 (45%)]	Loss: 1.8451	Cost: 8.93s
Train Epoch: 583 [61440/90000 (68%)]	Loss: 1.9424	Cost: 9.05s
Train Epoch: 583 [81920/90000 (91%)]	Loss: 1.7949	Cost: 16.33s
Train Epoch: 583 	Average Loss: 1.9894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2100

Learning rate: 9.916369929161117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 584 [0/90000 (0%)]	Loss: 3.2566	Cost: 31.17s
Train Epoch: 584 [20480/90000 (23%)]	Loss: 2.0260	Cost: 8.73s
Train Epoch: 584 [40960/90000 (45%)]	Loss: 1.8389	Cost: 17.26s
Train Epoch: 584 [61440/90000 (68%)]	Loss: 1.9800	Cost: 12.45s
Train Epoch: 584 [81920/90000 (91%)]	Loss: 1.7326	Cost: 15.15s
Train Epoch: 584 	Average Loss: 1.9708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2449

Learning rate: 9.916083593399158e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 585 [0/90000 (0%)]	Loss: 3.2523	Cost: 57.73s
Train Epoch: 585 [20480/90000 (23%)]	Loss: 1.9825	Cost: 9.86s
Train Epoch: 585 [40960/90000 (45%)]	Loss: 1.7352	Cost: 6.82s
Train Epoch: 585 [61440/90000 (68%)]	Loss: 1.7625	Cost: 6.69s
Train Epoch: 585 [81920/90000 (91%)]	Loss: 1.6962	Cost: 14.38s
Train Epoch: 585 	Average Loss: 1.9865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1745

Saving model as e585_model.pt & e585_waveforms_supplementary.hdf5
Learning rate: 9.9157967724392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 586 [0/90000 (0%)]	Loss: 3.2134	Cost: 33.96s
Train Epoch: 586 [20480/90000 (23%)]	Loss: 1.9261	Cost: 9.98s
Train Epoch: 586 [40960/90000 (45%)]	Loss: 1.9134	Cost: 16.20s
Train Epoch: 586 [61440/90000 (68%)]	Loss: 2.0402	Cost: 12.72s
Train Epoch: 586 [81920/90000 (91%)]	Loss: 1.8351	Cost: 12.03s
Train Epoch: 586 	Average Loss: 2.0051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.2279

Learning rate: 9.915509466309551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 587 [0/90000 (0%)]	Loss: 3.1280	Cost: 39.06s
Train Epoch: 587 [20480/90000 (23%)]	Loss: 2.0259	Cost: 7.94s
Train Epoch: 587 [40960/90000 (45%)]	Loss: 1.9081	Cost: 11.37s
Train Epoch: 587 [61440/90000 (68%)]	Loss: 1.7523	Cost: 8.68s
Train Epoch: 587 [81920/90000 (91%)]	Loss: 1.6893	Cost: 12.29s
Train Epoch: 587 	Average Loss: 1.9704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1534

Saving model as e587_model.pt & e587_waveforms_supplementary.hdf5
Learning rate: 9.915221675038568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 588 [0/90000 (0%)]	Loss: 2.9635	Cost: 31.38s
Train Epoch: 588 [20480/90000 (23%)]	Loss: 1.8514	Cost: 11.54s
Train Epoch: 588 [40960/90000 (45%)]	Loss: 1.7632	Cost: 19.90s
Train Epoch: 588 [61440/90000 (68%)]	Loss: 1.7421	Cost: 12.27s
Train Epoch: 588 [81920/90000 (91%)]	Loss: 1.7245	Cost: 11.95s
Train Epoch: 588 	Average Loss: 1.9249
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1688

Learning rate: 9.914933398654654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 589 [0/90000 (0%)]	Loss: 3.1145	Cost: 43.47s
Train Epoch: 589 [20480/90000 (23%)]	Loss: 2.0183	Cost: 12.18s
Train Epoch: 589 [40960/90000 (45%)]	Loss: 1.9750	Cost: 9.00s
Train Epoch: 589 [61440/90000 (68%)]	Loss: 1.7942	Cost: 6.28s
Train Epoch: 589 [81920/90000 (91%)]	Loss: 1.7082	Cost: 10.35s
Train Epoch: 589 	Average Loss: 1.9544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1044

Saving model as e589_model.pt & e589_waveforms_supplementary.hdf5
Learning rate: 9.914644637186261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 590 [0/90000 (0%)]	Loss: 3.0116	Cost: 30.04s
Train Epoch: 590 [20480/90000 (23%)]	Loss: 1.8387	Cost: 8.65s
Train Epoch: 590 [40960/90000 (45%)]	Loss: 1.7573	Cost: 10.63s
Train Epoch: 590 [61440/90000 (68%)]	Loss: 1.7379	Cost: 7.93s
Train Epoch: 590 [81920/90000 (91%)]	Loss: 1.6579	Cost: 19.48s
Train Epoch: 590 	Average Loss: 1.9070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0459

Saving model as e590_model.pt & e590_waveforms_supplementary.hdf5
Learning rate: 9.914355390661888e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 591 [0/90000 (0%)]	Loss: 2.8535	Cost: 38.46s
Train Epoch: 591 [20480/90000 (23%)]	Loss: 1.8952	Cost: 12.43s
Train Epoch: 591 [40960/90000 (45%)]	Loss: 1.7495	Cost: 10.91s
Train Epoch: 591 [61440/90000 (68%)]	Loss: 1.8902	Cost: 6.24s
Train Epoch: 591 [81920/90000 (91%)]	Loss: 1.7610	Cost: 11.27s
Train Epoch: 591 	Average Loss: 1.9091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1266

Learning rate: 9.914065659110084e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 592 [0/90000 (0%)]	Loss: 3.1805	Cost: 28.11s
Train Epoch: 592 [20480/90000 (23%)]	Loss: 2.0313	Cost: 7.06s
Train Epoch: 592 [40960/90000 (45%)]	Loss: 1.7984	Cost: 17.25s
Train Epoch: 592 [61440/90000 (68%)]	Loss: 1.8821	Cost: 10.41s
Train Epoch: 592 [81920/90000 (91%)]	Loss: 1.7163	Cost: 13.97s
Train Epoch: 592 	Average Loss: 1.9456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1332

Learning rate: 9.913775442559442e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 593 [0/90000 (0%)]	Loss: 3.2098	Cost: 36.57s
Train Epoch: 593 [20480/90000 (23%)]	Loss: 1.9172	Cost: 12.88s
Train Epoch: 593 [40960/90000 (45%)]	Loss: 1.6110	Cost: 12.37s
Train Epoch: 593 [61440/90000 (68%)]	Loss: 1.7440	Cost: 6.89s
Train Epoch: 593 [81920/90000 (91%)]	Loss: 1.6399	Cost: 7.06s
Train Epoch: 593 	Average Loss: 1.8696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0792

Learning rate: 9.913484741038609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 594 [0/90000 (0%)]	Loss: 3.2074	Cost: 33.34s
Train Epoch: 594 [20480/90000 (23%)]	Loss: 2.0037	Cost: 8.90s
Train Epoch: 594 [40960/90000 (45%)]	Loss: 1.7453	Cost: 10.30s
Train Epoch: 594 [61440/90000 (68%)]	Loss: 1.8391	Cost: 7.25s
Train Epoch: 594 [81920/90000 (91%)]	Loss: 1.6691	Cost: 9.01s
Train Epoch: 594 	Average Loss: 1.9077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1512

Learning rate: 9.913193554576272e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 595 [0/90000 (0%)]	Loss: 3.2303	Cost: 32.58s
Train Epoch: 595 [20480/90000 (23%)]	Loss: 1.8254	Cost: 7.67s
Train Epoch: 595 [40960/90000 (45%)]	Loss: 1.7022	Cost: 17.42s
Train Epoch: 595 [61440/90000 (68%)]	Loss: 1.6815	Cost: 12.61s
Train Epoch: 595 [81920/90000 (91%)]	Loss: 1.6681	Cost: 11.87s
Train Epoch: 595 	Average Loss: 1.8336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0774

Learning rate: 9.912901883201172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 596 [0/90000 (0%)]	Loss: 2.9885	Cost: 29.82s
Train Epoch: 596 [20480/90000 (23%)]	Loss: 1.8573	Cost: 6.25s
Train Epoch: 596 [40960/90000 (45%)]	Loss: 1.5771	Cost: 14.38s
Train Epoch: 596 [61440/90000 (68%)]	Loss: 1.7117	Cost: 9.26s
Train Epoch: 596 [81920/90000 (91%)]	Loss: 1.6567	Cost: 9.91s
Train Epoch: 596 	Average Loss: 1.8277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0779

Learning rate: 9.912609726942096e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 597 [0/90000 (0%)]	Loss: 3.0530	Cost: 31.98s
Train Epoch: 597 [20480/90000 (23%)]	Loss: 1.8117	Cost: 11.28s
Train Epoch: 597 [40960/90000 (45%)]	Loss: 1.6209	Cost: 15.56s
Train Epoch: 597 [61440/90000 (68%)]	Loss: 1.8748	Cost: 12.77s
Train Epoch: 597 [81920/90000 (91%)]	Loss: 1.7194	Cost: 11.93s
Train Epoch: 597 	Average Loss: 1.8701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1230

Learning rate: 9.912317085827877e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 598 [0/90000 (0%)]	Loss: 2.9940	Cost: 36.77s
Train Epoch: 598 [20480/90000 (23%)]	Loss: 1.7930	Cost: 12.32s
Train Epoch: 598 [40960/90000 (45%)]	Loss: 1.7120	Cost: 10.88s
Train Epoch: 598 [61440/90000 (68%)]	Loss: 1.6253	Cost: 6.17s
Train Epoch: 598 [81920/90000 (91%)]	Loss: 1.5583	Cost: 9.45s
Train Epoch: 598 	Average Loss: 1.8127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0970

Learning rate: 9.9120239598874e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 599 [0/90000 (0%)]	Loss: 3.1103	Cost: 39.60s
Train Epoch: 599 [20480/90000 (23%)]	Loss: 1.7681	Cost: 7.57s
Train Epoch: 599 [40960/90000 (45%)]	Loss: 1.6420	Cost: 18.00s
Train Epoch: 599 [61440/90000 (68%)]	Loss: 1.6587	Cost: 12.36s
Train Epoch: 599 [81920/90000 (91%)]	Loss: 1.4987	Cost: 12.00s
Train Epoch: 599 	Average Loss: 1.7819
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1250

Learning rate: 9.911730349149594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 600 [0/90000 (0%)]	Loss: 3.0156	Cost: 35.75s
Train Epoch: 600 [20480/90000 (23%)]	Loss: 1.9668	Cost: 11.07s
Train Epoch: 600 [40960/90000 (45%)]	Loss: 1.5852	Cost: 10.47s
Train Epoch: 600 [61440/90000 (68%)]	Loss: 1.6993	Cost: 6.27s
Train Epoch: 600 [81920/90000 (91%)]	Loss: 1.4950	Cost: 10.73s
Train Epoch: 600 	Average Loss: 1.8012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0941

Learning rate: 9.911436253643436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 601 [0/90000 (0%)]	Loss: 3.0775	Cost: 30.67s
Train Epoch: 601 [20480/90000 (23%)]	Loss: 2.0006	Cost: 10.04s
Train Epoch: 601 [40960/90000 (45%)]	Loss: 1.8910	Cost: 17.80s
Train Epoch: 601 [61440/90000 (68%)]	Loss: 1.8541	Cost: 12.40s
Train Epoch: 601 [81920/90000 (91%)]	Loss: 1.7578	Cost: 12.17s
Train Epoch: 601 	Average Loss: 1.9314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1952

Learning rate: 9.911141673397953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 602 [0/90000 (0%)]	Loss: 2.9056	Cost: 41.88s
Train Epoch: 602 [20480/90000 (23%)]	Loss: 1.9105	Cost: 11.92s
Train Epoch: 602 [40960/90000 (45%)]	Loss: 1.7387	Cost: 9.23s
Train Epoch: 602 [61440/90000 (68%)]	Loss: 1.7476	Cost: 6.42s
Train Epoch: 602 [81920/90000 (91%)]	Loss: 1.6028	Cost: 12.11s
Train Epoch: 602 	Average Loss: 1.8457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0818

Learning rate: 9.91084660844222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 603 [0/90000 (0%)]	Loss: 3.0375	Cost: 33.05s
Train Epoch: 603 [20480/90000 (23%)]	Loss: 1.7667	Cost: 8.37s
Train Epoch: 603 [40960/90000 (45%)]	Loss: 1.6344	Cost: 17.97s
Train Epoch: 603 [61440/90000 (68%)]	Loss: 1.6010	Cost: 12.36s
Train Epoch: 603 [81920/90000 (91%)]	Loss: 1.4560	Cost: 12.17s
Train Epoch: 603 	Average Loss: 1.7596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0307

Saving model as e603_model.pt & e603_waveforms_supplementary.hdf5
Learning rate: 9.910551058805357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 604 [0/90000 (0%)]	Loss: 2.8083	Cost: 33.22s
Train Epoch: 604 [20480/90000 (23%)]	Loss: 1.8468	Cost: 13.11s
Train Epoch: 604 [40960/90000 (45%)]	Loss: 1.6055	Cost: 12.12s
Train Epoch: 604 [61440/90000 (68%)]	Loss: 1.5440	Cost: 7.45s
Train Epoch: 604 [81920/90000 (91%)]	Loss: 1.5814	Cost: 5.87s
Train Epoch: 604 	Average Loss: 1.7541
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0727

Learning rate: 9.910255024516536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 605 [0/90000 (0%)]	Loss: 3.1902	Cost: 29.44s
Train Epoch: 605 [20480/90000 (23%)]	Loss: 1.8468	Cost: 8.38s
Train Epoch: 605 [40960/90000 (45%)]	Loss: 1.5403	Cost: 21.11s
Train Epoch: 605 [61440/90000 (68%)]	Loss: 1.5982	Cost: 14.85s
Train Epoch: 605 [81920/90000 (91%)]	Loss: 1.5076	Cost: 12.72s
Train Epoch: 605 	Average Loss: 1.7384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0773

Learning rate: 9.909958505604974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 606 [0/90000 (0%)]	Loss: 2.9268	Cost: 52.59s
Train Epoch: 606 [20480/90000 (23%)]	Loss: 1.7628	Cost: 10.69s
Train Epoch: 606 [40960/90000 (45%)]	Loss: 1.6999	Cost: 7.44s
Train Epoch: 606 [61440/90000 (68%)]	Loss: 1.5187	Cost: 6.35s
Train Epoch: 606 [81920/90000 (91%)]	Loss: 1.5406	Cost: 13.22s
Train Epoch: 606 	Average Loss: 1.7365
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9922

Saving model as e606_model.pt & e606_waveforms_supplementary.hdf5
Learning rate: 9.909661502099934e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 607 [0/90000 (0%)]	Loss: 2.9000	Cost: 29.69s
Train Epoch: 607 [20480/90000 (23%)]	Loss: 1.5734	Cost: 9.60s
Train Epoch: 607 [40960/90000 (45%)]	Loss: 1.5010	Cost: 18.05s
Train Epoch: 607 [61440/90000 (68%)]	Loss: 1.5250	Cost: 12.10s
Train Epoch: 607 [81920/90000 (91%)]	Loss: 1.4877	Cost: 12.08s
Train Epoch: 607 	Average Loss: 1.6673
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0222

Learning rate: 9.90936401403073e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 608 [0/90000 (0%)]	Loss: 2.7027	Cost: 36.48s
Train Epoch: 608 [20480/90000 (23%)]	Loss: 1.7819	Cost: 12.01s
Train Epoch: 608 [40960/90000 (45%)]	Loss: 1.6436	Cost: 7.46s
Train Epoch: 608 [61440/90000 (68%)]	Loss: 1.6648	Cost: 6.34s
Train Epoch: 608 [81920/90000 (91%)]	Loss: 1.7335	Cost: 13.17s
Train Epoch: 608 	Average Loss: 1.7761
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0893

Learning rate: 9.909066041426725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 609 [0/90000 (0%)]	Loss: 3.1261	Cost: 27.87s
Train Epoch: 609 [20480/90000 (23%)]	Loss: 1.7536	Cost: 7.34s
Train Epoch: 609 [40960/90000 (45%)]	Loss: 1.5434	Cost: 19.25s
Train Epoch: 609 [61440/90000 (68%)]	Loss: 1.7134	Cost: 14.20s
Train Epoch: 609 [81920/90000 (91%)]	Loss: 1.5085	Cost: 12.62s
Train Epoch: 609 	Average Loss: 1.7648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0932

Learning rate: 9.908767584317324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 610 [0/90000 (0%)]	Loss: 2.9539	Cost: 35.62s
Train Epoch: 610 [20480/90000 (23%)]	Loss: 1.7901	Cost: 8.72s
Train Epoch: 610 [40960/90000 (45%)]	Loss: 1.5986	Cost: 12.09s
Train Epoch: 610 [61440/90000 (68%)]	Loss: 1.5389	Cost: 8.27s
Train Epoch: 610 [81920/90000 (91%)]	Loss: 1.3772	Cost: 11.77s
Train Epoch: 610 	Average Loss: 1.7141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0164

Learning rate: 9.908468642731985e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 611 [0/90000 (0%)]	Loss: 2.8507	Cost: 28.20s
Train Epoch: 611 [20480/90000 (23%)]	Loss: 1.6790	Cost: 9.34s
Train Epoch: 611 [40960/90000 (45%)]	Loss: 1.5372	Cost: 24.04s
Train Epoch: 611 [61440/90000 (68%)]	Loss: 1.5750	Cost: 13.56s
Train Epoch: 611 [81920/90000 (91%)]	Loss: 1.4990	Cost: 12.45s
Train Epoch: 611 	Average Loss: 1.7092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0523

Learning rate: 9.908169216700214e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 612 [0/90000 (0%)]	Loss: 3.0555	Cost: 53.88s
Train Epoch: 612 [20480/90000 (23%)]	Loss: 1.5985	Cost: 10.49s
Train Epoch: 612 [40960/90000 (45%)]	Loss: 1.4578	Cost: 9.06s
Train Epoch: 612 [61440/90000 (68%)]	Loss: 1.5222	Cost: 6.08s
Train Epoch: 612 [81920/90000 (91%)]	Loss: 1.5242	Cost: 12.68s
Train Epoch: 612 	Average Loss: 1.6552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9861

Saving model as e612_model.pt & e612_waveforms_supplementary.hdf5
Learning rate: 9.907869306251562e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 613 [0/90000 (0%)]	Loss: 2.7532	Cost: 30.72s
Train Epoch: 613 [20480/90000 (23%)]	Loss: 1.7032	Cost: 10.16s
Train Epoch: 613 [40960/90000 (45%)]	Loss: 1.4141	Cost: 19.42s
Train Epoch: 613 [61440/90000 (68%)]	Loss: 1.4575	Cost: 12.60s
Train Epoch: 613 [81920/90000 (91%)]	Loss: 1.5948	Cost: 12.15s
Train Epoch: 613 	Average Loss: 1.6532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9775

Saving model as e613_model.pt & e613_waveforms_supplementary.hdf5
Learning rate: 9.907568911415629e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 614 [0/90000 (0%)]	Loss: 2.9903	Cost: 45.29s
Train Epoch: 614 [20480/90000 (23%)]	Loss: 1.6933	Cost: 7.12s
Train Epoch: 614 [40960/90000 (45%)]	Loss: 1.5347	Cost: 13.70s
Train Epoch: 614 [61440/90000 (68%)]	Loss: 1.5562	Cost: 8.55s
Train Epoch: 614 [81920/90000 (91%)]	Loss: 1.7006	Cost: 9.04s
Train Epoch: 614 	Average Loss: 1.7287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.1356

Learning rate: 9.907268032222063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 615 [0/90000 (0%)]	Loss: 3.0479	Cost: 31.98s
Train Epoch: 615 [20480/90000 (23%)]	Loss: 1.7272	Cost: 9.28s
Train Epoch: 615 [40960/90000 (45%)]	Loss: 1.4863	Cost: 13.48s
Train Epoch: 615 [61440/90000 (68%)]	Loss: 1.4865	Cost: 12.82s
Train Epoch: 615 [81920/90000 (91%)]	Loss: 1.5021	Cost: 12.16s
Train Epoch: 615 	Average Loss: 1.7010
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0423

Learning rate: 9.906966668700558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 616 [0/90000 (0%)]	Loss: 3.0589	Cost: 46.01s
Train Epoch: 616 [20480/90000 (23%)]	Loss: 1.9338	Cost: 12.16s
Train Epoch: 616 [40960/90000 (45%)]	Loss: 1.3988	Cost: 12.35s
Train Epoch: 616 [61440/90000 (68%)]	Loss: 1.5973	Cost: 6.79s
Train Epoch: 616 [81920/90000 (91%)]	Loss: 1.4909	Cost: 5.96s
Train Epoch: 616 	Average Loss: 1.6719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9932

Learning rate: 9.90666482088086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 617 [0/90000 (0%)]	Loss: 3.2188	Cost: 29.08s
Train Epoch: 617 [20480/90000 (23%)]	Loss: 1.7130	Cost: 8.09s
Train Epoch: 617 [40960/90000 (45%)]	Loss: 1.4231	Cost: 9.86s
Train Epoch: 617 [61440/90000 (68%)]	Loss: 1.5911	Cost: 7.39s
Train Epoch: 617 [81920/90000 (91%)]	Loss: 1.5690	Cost: 21.35s
Train Epoch: 617 	Average Loss: 1.6528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9794

Learning rate: 9.906362488792757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 618 [0/90000 (0%)]	Loss: 2.9138	Cost: 34.35s
Train Epoch: 618 [20480/90000 (23%)]	Loss: 1.6234	Cost: 14.12s
Train Epoch: 618 [40960/90000 (45%)]	Loss: 1.5930	Cost: 11.78s
Train Epoch: 618 [61440/90000 (68%)]	Loss: 1.4640	Cost: 6.16s
Train Epoch: 618 [81920/90000 (91%)]	Loss: 1.4320	Cost: 10.27s
Train Epoch: 618 	Average Loss: 1.6583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0125

Learning rate: 9.906059672466091e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 619 [0/90000 (0%)]	Loss: 2.8661	Cost: 30.42s
Train Epoch: 619 [20480/90000 (23%)]	Loss: 1.8317	Cost: 7.85s
Train Epoch: 619 [40960/90000 (45%)]	Loss: 1.6527	Cost: 16.35s
Train Epoch: 619 [61440/90000 (68%)]	Loss: 1.7245	Cost: 12.80s
Train Epoch: 619 [81920/90000 (91%)]	Loss: 1.3885	Cost: 11.86s
Train Epoch: 619 	Average Loss: 1.7336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 3.0720

Learning rate: 9.905756371930748e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 620 [0/90000 (0%)]	Loss: 3.1874	Cost: 38.77s
Train Epoch: 620 [20480/90000 (23%)]	Loss: 1.8250	Cost: 12.78s
Train Epoch: 620 [40960/90000 (45%)]	Loss: 1.5908	Cost: 11.40s
Train Epoch: 620 [61440/90000 (68%)]	Loss: 1.5046	Cost: 6.72s
Train Epoch: 620 [81920/90000 (91%)]	Loss: 1.5261	Cost: 6.35s
Train Epoch: 620 	Average Loss: 1.6709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9827

Learning rate: 9.905452587216662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 621 [0/90000 (0%)]	Loss: 2.7247	Cost: 36.90s
Train Epoch: 621 [20480/90000 (23%)]	Loss: 1.6176	Cost: 9.12s
Train Epoch: 621 [40960/90000 (45%)]	Loss: 1.5119	Cost: 16.44s
Train Epoch: 621 [61440/90000 (68%)]	Loss: 1.4655	Cost: 12.21s
Train Epoch: 621 [81920/90000 (91%)]	Loss: 1.3900	Cost: 12.08s
Train Epoch: 621 	Average Loss: 1.6068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9032

Saving model as e621_model.pt & e621_waveforms_supplementary.hdf5
Learning rate: 9.905148318353815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 622 [0/90000 (0%)]	Loss: 2.9886	Cost: 33.92s
Train Epoch: 622 [20480/90000 (23%)]	Loss: 1.5228	Cost: 10.91s
Train Epoch: 622 [40960/90000 (45%)]	Loss: 1.3079	Cost: 8.97s
Train Epoch: 622 [61440/90000 (68%)]	Loss: 1.3976	Cost: 7.11s
Train Epoch: 622 [81920/90000 (91%)]	Loss: 1.2945	Cost: 11.91s
Train Epoch: 622 	Average Loss: 1.5498
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8512

Saving model as e622_model.pt & e622_waveforms_supplementary.hdf5
Learning rate: 9.904843565372238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 623 [0/90000 (0%)]	Loss: 2.8789	Cost: 30.12s
Train Epoch: 623 [20480/90000 (23%)]	Loss: 1.5448	Cost: 9.94s
Train Epoch: 623 [40960/90000 (45%)]	Loss: 1.4420	Cost: 18.14s
Train Epoch: 623 [61440/90000 (68%)]	Loss: 1.3476	Cost: 12.76s
Train Epoch: 623 [81920/90000 (91%)]	Loss: 1.3574	Cost: 12.28s
Train Epoch: 623 	Average Loss: 1.5505
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9670

Learning rate: 9.904538328302008e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 624 [0/90000 (0%)]	Loss: 3.0290	Cost: 41.39s
Train Epoch: 624 [20480/90000 (23%)]	Loss: 1.4347	Cost: 11.70s
Train Epoch: 624 [40960/90000 (45%)]	Loss: 1.4103	Cost: 9.00s
Train Epoch: 624 [61440/90000 (68%)]	Loss: 1.4271	Cost: 6.25s
Train Epoch: 624 [81920/90000 (91%)]	Loss: 1.2629	Cost: 11.35s
Train Epoch: 624 	Average Loss: 1.5310
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9426

Learning rate: 9.904232607173254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 625 [0/90000 (0%)]	Loss: 2.8653	Cost: 30.48s
Train Epoch: 625 [20480/90000 (23%)]	Loss: 1.5238	Cost: 7.19s
Train Epoch: 625 [40960/90000 (45%)]	Loss: 1.3756	Cost: 17.63s
Train Epoch: 625 [61440/90000 (68%)]	Loss: 1.3723	Cost: 13.20s
Train Epoch: 625 [81920/90000 (91%)]	Loss: 1.3722	Cost: 12.10s
Train Epoch: 625 	Average Loss: 1.5327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8693

Learning rate: 9.903926402016143e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 626 [0/90000 (0%)]	Loss: 2.8911	Cost: 45.12s
Train Epoch: 626 [20480/90000 (23%)]	Loss: 1.4431	Cost: 10.63s
Train Epoch: 626 [40960/90000 (45%)]	Loss: 1.3854	Cost: 9.09s
Train Epoch: 626 [61440/90000 (68%)]	Loss: 1.3276	Cost: 6.53s
Train Epoch: 626 [81920/90000 (91%)]	Loss: 1.4052	Cost: 11.55s
Train Epoch: 626 	Average Loss: 1.5016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9074

Learning rate: 9.903619712860903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 627 [0/90000 (0%)]	Loss: 2.8250	Cost: 28.78s
Train Epoch: 627 [20480/90000 (23%)]	Loss: 1.5644	Cost: 6.88s
Train Epoch: 627 [40960/90000 (45%)]	Loss: 1.3630	Cost: 17.56s
Train Epoch: 627 [61440/90000 (68%)]	Loss: 1.3910	Cost: 14.96s
Train Epoch: 627 [81920/90000 (91%)]	Loss: 1.2347	Cost: 12.91s
Train Epoch: 627 	Average Loss: 1.5459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8810

Learning rate: 9.903312539737797e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 628 [0/90000 (0%)]	Loss: 2.6917	Cost: 37.08s
Train Epoch: 628 [20480/90000 (23%)]	Loss: 1.6453	Cost: 12.22s
Train Epoch: 628 [40960/90000 (45%)]	Loss: 1.3377	Cost: 10.64s
Train Epoch: 628 [61440/90000 (68%)]	Loss: 1.3298	Cost: 6.44s
Train Epoch: 628 [81920/90000 (91%)]	Loss: 1.2964	Cost: 12.25s
Train Epoch: 628 	Average Loss: 1.5429
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9077

Learning rate: 9.903004882677146e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 629 [0/90000 (0%)]	Loss: 2.6846	Cost: 28.64s
Train Epoch: 629 [20480/90000 (23%)]	Loss: 1.5208	Cost: 8.28s
Train Epoch: 629 [40960/90000 (45%)]	Loss: 1.4375	Cost: 17.55s
Train Epoch: 629 [61440/90000 (68%)]	Loss: 1.4630	Cost: 12.76s
Train Epoch: 629 [81920/90000 (91%)]	Loss: 1.3406	Cost: 11.98s
Train Epoch: 629 	Average Loss: 1.5972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9295

Learning rate: 9.902696741709314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 630 [0/90000 (0%)]	Loss: 2.6711	Cost: 38.06s
Train Epoch: 630 [20480/90000 (23%)]	Loss: 1.6615	Cost: 12.73s
Train Epoch: 630 [40960/90000 (45%)]	Loss: 1.4383	Cost: 13.27s
Train Epoch: 630 [61440/90000 (68%)]	Loss: 1.3250	Cost: 8.94s
Train Epoch: 630 [81920/90000 (91%)]	Loss: 1.4116	Cost: 6.20s
Train Epoch: 630 	Average Loss: 1.6293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9073

Learning rate: 9.902388116864713e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 631 [0/90000 (0%)]	Loss: 2.8006	Cost: 46.45s
Train Epoch: 631 [20480/90000 (23%)]	Loss: 1.5980	Cost: 6.32s
Train Epoch: 631 [40960/90000 (45%)]	Loss: 1.2703	Cost: 13.92s
Train Epoch: 631 [61440/90000 (68%)]	Loss: 1.4427	Cost: 12.16s
Train Epoch: 631 [81920/90000 (91%)]	Loss: 1.2917	Cost: 12.09s
Train Epoch: 631 	Average Loss: 1.5570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9249

Learning rate: 9.902079008173801e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 632 [0/90000 (0%)]	Loss: 2.9143	Cost: 41.14s
Train Epoch: 632 [20480/90000 (23%)]	Loss: 1.5995	Cost: 12.01s
Train Epoch: 632 [40960/90000 (45%)]	Loss: 1.5001	Cost: 12.11s
Train Epoch: 632 [61440/90000 (68%)]	Loss: 1.4429	Cost: 6.67s
Train Epoch: 632 [81920/90000 (91%)]	Loss: 1.3685	Cost: 6.09s
Train Epoch: 632 	Average Loss: 1.5988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9481

Learning rate: 9.90176941566709e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 633 [0/90000 (0%)]	Loss: 2.9600	Cost: 30.85s
Train Epoch: 633 [20480/90000 (23%)]	Loss: 1.4456	Cost: 8.92s
Train Epoch: 633 [40960/90000 (45%)]	Loss: 1.3013	Cost: 12.11s
Train Epoch: 633 [61440/90000 (68%)]	Loss: 1.3377	Cost: 9.33s
Train Epoch: 633 [81920/90000 (91%)]	Loss: 1.2923	Cost: 18.63s
Train Epoch: 633 	Average Loss: 1.5320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.9044

Learning rate: 9.90145933937513e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 634 [0/90000 (0%)]	Loss: 3.0472	Cost: 35.45s
Train Epoch: 634 [20480/90000 (23%)]	Loss: 1.3758	Cost: 11.82s
Train Epoch: 634 [40960/90000 (45%)]	Loss: 1.3485	Cost: 13.06s
Train Epoch: 634 [61440/90000 (68%)]	Loss: 1.4092	Cost: 11.93s
Train Epoch: 634 [81920/90000 (91%)]	Loss: 1.3190	Cost: 9.48s
Train Epoch: 634 	Average Loss: 1.5001
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8354

Saving model as e634_model.pt & e634_waveforms_supplementary.hdf5
Learning rate: 9.901148779328529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 635 [0/90000 (0%)]	Loss: 2.7056	Cost: 28.79s
Train Epoch: 635 [20480/90000 (23%)]	Loss: 1.4031	Cost: 8.42s
Train Epoch: 635 [40960/90000 (45%)]	Loss: 1.3337	Cost: 13.81s
Train Epoch: 635 [61440/90000 (68%)]	Loss: 1.2454	Cost: 9.38s
Train Epoch: 635 [81920/90000 (91%)]	Loss: 1.2239	Cost: 10.90s
Train Epoch: 635 	Average Loss: 1.4312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7806

Saving model as e635_model.pt & e635_waveforms_supplementary.hdf5
Learning rate: 9.900837735557936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 636 [0/90000 (0%)]	Loss: 2.6153	Cost: 46.08s
Train Epoch: 636 [20480/90000 (23%)]	Loss: 1.3468	Cost: 12.54s
Train Epoch: 636 [40960/90000 (45%)]	Loss: 1.2175	Cost: 12.18s
Train Epoch: 636 [61440/90000 (68%)]	Loss: 1.1696	Cost: 12.10s
Train Epoch: 636 [81920/90000 (91%)]	Loss: 1.1615	Cost: 8.21s
Train Epoch: 636 	Average Loss: 1.3765
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8868

Learning rate: 9.90052620809405e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 637 [0/90000 (0%)]	Loss: 2.7926	Cost: 54.18s
Train Epoch: 637 [20480/90000 (23%)]	Loss: 1.3180	Cost: 7.41s
Train Epoch: 637 [40960/90000 (45%)]	Loss: 1.2537	Cost: 11.90s
Train Epoch: 637 [61440/90000 (68%)]	Loss: 1.3537	Cost: 8.53s
Train Epoch: 637 [81920/90000 (91%)]	Loss: 1.2219	Cost: 7.91s
Train Epoch: 637 	Average Loss: 1.4140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7805

Saving model as e637_model.pt & e637_waveforms_supplementary.hdf5
Learning rate: 9.900214196967617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 638 [0/90000 (0%)]	Loss: 3.0263	Cost: 29.73s
Train Epoch: 638 [20480/90000 (23%)]	Loss: 1.2861	Cost: 8.75s
Train Epoch: 638 [40960/90000 (45%)]	Loss: 1.1729	Cost: 17.43s
Train Epoch: 638 [61440/90000 (68%)]	Loss: 1.2603	Cost: 13.50s
Train Epoch: 638 [81920/90000 (91%)]	Loss: 1.2769	Cost: 12.13s
Train Epoch: 638 	Average Loss: 1.4033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7945

Learning rate: 9.899901702209434e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 639 [0/90000 (0%)]	Loss: 2.7219	Cost: 35.83s
Train Epoch: 639 [20480/90000 (23%)]	Loss: 1.4468	Cost: 12.57s
Train Epoch: 639 [40960/90000 (45%)]	Loss: 1.2763	Cost: 9.58s
Train Epoch: 639 [61440/90000 (68%)]	Loss: 1.2972	Cost: 6.27s
Train Epoch: 639 [81920/90000 (91%)]	Loss: 1.1912	Cost: 13.25s
Train Epoch: 639 	Average Loss: 1.4660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7279

Saving model as e639_model.pt & e639_waveforms_supplementary.hdf5
Learning rate: 9.899588723850338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 640 [0/90000 (0%)]	Loss: 2.6559	Cost: 32.86s
Train Epoch: 640 [20480/90000 (23%)]	Loss: 1.3422	Cost: 10.44s
Train Epoch: 640 [40960/90000 (45%)]	Loss: 1.2300	Cost: 14.46s
Train Epoch: 640 [61440/90000 (68%)]	Loss: 1.2439	Cost: 11.79s
Train Epoch: 640 [81920/90000 (91%)]	Loss: 1.2098	Cost: 12.28s
Train Epoch: 640 	Average Loss: 1.3939
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8805

Learning rate: 9.899275261921224e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 641 [0/90000 (0%)]	Loss: 2.9273	Cost: 53.29s
Train Epoch: 641 [20480/90000 (23%)]	Loss: 1.4104	Cost: 6.48s
Train Epoch: 641 [40960/90000 (45%)]	Loss: 1.3098	Cost: 14.51s
Train Epoch: 641 [61440/90000 (68%)]	Loss: 1.3178	Cost: 8.47s
Train Epoch: 641 [81920/90000 (91%)]	Loss: 1.0900	Cost: 8.51s
Train Epoch: 641 	Average Loss: 1.4181
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7658

Learning rate: 9.898961316453026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 642 [0/90000 (0%)]	Loss: 2.3712	Cost: 29.97s
Train Epoch: 642 [20480/90000 (23%)]	Loss: 1.4118	Cost: 8.52s
Train Epoch: 642 [40960/90000 (45%)]	Loss: 1.3876	Cost: 15.69s
Train Epoch: 642 [61440/90000 (68%)]	Loss: 1.5124	Cost: 12.19s
Train Epoch: 642 [81920/90000 (91%)]	Loss: 1.2472	Cost: 12.45s
Train Epoch: 642 	Average Loss: 1.4319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8183

Learning rate: 9.898646887476729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 643 [0/90000 (0%)]	Loss: 2.8028	Cost: 33.20s
Train Epoch: 643 [20480/90000 (23%)]	Loss: 1.4463	Cost: 10.58s
Train Epoch: 643 [40960/90000 (45%)]	Loss: 1.2416	Cost: 10.03s
Train Epoch: 643 [61440/90000 (68%)]	Loss: 1.3015	Cost: 8.31s
Train Epoch: 643 [81920/90000 (91%)]	Loss: 1.0948	Cost: 10.85s
Train Epoch: 643 	Average Loss: 1.3737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7589

Learning rate: 9.898331975023371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 644 [0/90000 (0%)]	Loss: 2.7902	Cost: 36.82s
Train Epoch: 644 [20480/90000 (23%)]	Loss: 1.4179	Cost: 10.39s
Train Epoch: 644 [40960/90000 (45%)]	Loss: 1.2361	Cost: 14.41s
Train Epoch: 644 [61440/90000 (68%)]	Loss: 1.1497	Cost: 12.66s
Train Epoch: 644 [81920/90000 (91%)]	Loss: 1.1224	Cost: 11.71s
Train Epoch: 644 	Average Loss: 1.3834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7158

Saving model as e644_model.pt & e644_waveforms_supplementary.hdf5
Learning rate: 9.898016579124025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 645 [0/90000 (0%)]	Loss: 2.6478	Cost: 43.00s
Train Epoch: 645 [20480/90000 (23%)]	Loss: 1.3423	Cost: 11.60s
Train Epoch: 645 [40960/90000 (45%)]	Loss: 1.1209	Cost: 8.39s
Train Epoch: 645 [61440/90000 (68%)]	Loss: 1.0951	Cost: 6.23s
Train Epoch: 645 [81920/90000 (91%)]	Loss: 1.1307	Cost: 13.00s
Train Epoch: 645 	Average Loss: 1.3401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.8325

Learning rate: 9.897700699809825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 646 [0/90000 (0%)]	Loss: 2.8695	Cost: 29.46s
Train Epoch: 646 [20480/90000 (23%)]	Loss: 1.4600	Cost: 8.05s
Train Epoch: 646 [40960/90000 (45%)]	Loss: 1.2828	Cost: 20.73s
Train Epoch: 646 [61440/90000 (68%)]	Loss: 1.1966	Cost: 12.23s
Train Epoch: 646 [81920/90000 (91%)]	Loss: 1.1069	Cost: 12.18s
Train Epoch: 646 	Average Loss: 1.4145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7662

Learning rate: 9.897384337111944e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 647 [0/90000 (0%)]	Loss: 2.8675	Cost: 33.60s
Train Epoch: 647 [20480/90000 (23%)]	Loss: 1.2719	Cost: 12.05s
Train Epoch: 647 [40960/90000 (45%)]	Loss: 1.1495	Cost: 9.32s
Train Epoch: 647 [61440/90000 (68%)]	Loss: 1.2182	Cost: 7.30s
Train Epoch: 647 [81920/90000 (91%)]	Loss: 1.0429	Cost: 12.17s
Train Epoch: 647 	Average Loss: 1.3147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7281

Learning rate: 9.897067491061608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 648 [0/90000 (0%)]	Loss: 2.7045	Cost: 27.60s
Train Epoch: 648 [20480/90000 (23%)]	Loss: 1.1855	Cost: 8.45s
Train Epoch: 648 [40960/90000 (45%)]	Loss: 1.2465	Cost: 21.44s
Train Epoch: 648 [61440/90000 (68%)]	Loss: 1.2419	Cost: 13.67s
Train Epoch: 648 [81920/90000 (91%)]	Loss: 1.1556	Cost: 12.55s
Train Epoch: 648 	Average Loss: 1.3440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6909

Saving model as e648_model.pt & e648_waveforms_supplementary.hdf5
Learning rate: 9.896750161690087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 649 [0/90000 (0%)]	Loss: 2.5224	Cost: 52.50s
Train Epoch: 649 [20480/90000 (23%)]	Loss: 1.2207	Cost: 9.17s
Train Epoch: 649 [40960/90000 (45%)]	Loss: 1.1398	Cost: 8.50s
Train Epoch: 649 [61440/90000 (68%)]	Loss: 0.9533	Cost: 7.43s
Train Epoch: 649 [81920/90000 (91%)]	Loss: 1.1021	Cost: 13.64s
Train Epoch: 649 	Average Loss: 1.2544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6722

Saving model as e649_model.pt & e649_waveforms_supplementary.hdf5
Learning rate: 9.8964323490287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 650 [0/90000 (0%)]	Loss: 2.5069	Cost: 30.05s
Train Epoch: 650 [20480/90000 (23%)]	Loss: 1.3428	Cost: 11.09s
Train Epoch: 650 [40960/90000 (45%)]	Loss: 1.0952	Cost: 18.85s
Train Epoch: 650 [61440/90000 (68%)]	Loss: 1.0990	Cost: 12.91s
Train Epoch: 650 [81920/90000 (91%)]	Loss: 1.1209	Cost: 12.06s
Train Epoch: 650 	Average Loss: 1.2978
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7296

Learning rate: 9.896114053108814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 651 [0/90000 (0%)]	Loss: 2.6283	Cost: 47.41s
Train Epoch: 651 [20480/90000 (23%)]	Loss: 1.1233	Cost: 8.93s
Train Epoch: 651 [40960/90000 (45%)]	Loss: 1.0860	Cost: 10.50s
Train Epoch: 651 [61440/90000 (68%)]	Loss: 1.0621	Cost: 7.59s
Train Epoch: 651 [81920/90000 (91%)]	Loss: 1.0208	Cost: 12.52s
Train Epoch: 651 	Average Loss: 1.2863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6412

Saving model as e651_model.pt & e651_waveforms_supplementary.hdf5
Learning rate: 9.895795273961846e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 652 [0/90000 (0%)]	Loss: 2.6023	Cost: 34.78s
Train Epoch: 652 [20480/90000 (23%)]	Loss: 1.1918	Cost: 10.72s
Train Epoch: 652 [40960/90000 (45%)]	Loss: 1.1260	Cost: 15.25s
Train Epoch: 652 [61440/90000 (68%)]	Loss: 1.1463	Cost: 12.46s
Train Epoch: 652 [81920/90000 (91%)]	Loss: 0.9994	Cost: 12.17s
Train Epoch: 652 	Average Loss: 1.2329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6282

Saving model as e652_model.pt & e652_waveforms_supplementary.hdf5
Learning rate: 9.895476011619254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 653 [0/90000 (0%)]	Loss: 2.4054	Cost: 48.62s
Train Epoch: 653 [20480/90000 (23%)]	Loss: 1.3110	Cost: 6.24s
Train Epoch: 653 [40960/90000 (45%)]	Loss: 1.0990	Cost: 14.59s
Train Epoch: 653 [61440/90000 (68%)]	Loss: 1.0547	Cost: 8.47s
Train Epoch: 653 [81920/90000 (91%)]	Loss: 0.9981	Cost: 7.62s
Train Epoch: 653 	Average Loss: 1.2344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6656

Learning rate: 9.89515626611255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 654 [0/90000 (0%)]	Loss: 2.6577	Cost: 27.19s
Train Epoch: 654 [20480/90000 (23%)]	Loss: 1.1942	Cost: 8.36s
Train Epoch: 654 [40960/90000 (45%)]	Loss: 1.0557	Cost: 15.58s
Train Epoch: 654 [61440/90000 (68%)]	Loss: 1.0907	Cost: 12.19s
Train Epoch: 654 [81920/90000 (91%)]	Loss: 0.9486	Cost: 12.47s
Train Epoch: 654 	Average Loss: 1.2143
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5793

Saving model as e654_model.pt & e654_waveforms_supplementary.hdf5
Learning rate: 9.894836037473293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 655 [0/90000 (0%)]	Loss: 2.4716	Cost: 32.80s
Train Epoch: 655 [20480/90000 (23%)]	Loss: 1.2112	Cost: 8.31s
Train Epoch: 655 [40960/90000 (45%)]	Loss: 0.9695	Cost: 17.00s
Train Epoch: 655 [61440/90000 (68%)]	Loss: 0.9877	Cost: 8.83s
Train Epoch: 655 [81920/90000 (91%)]	Loss: 0.9541	Cost: 12.01s
Train Epoch: 655 	Average Loss: 1.2118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6099

Learning rate: 9.894515325733087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 656 [0/90000 (0%)]	Loss: 2.5869	Cost: 34.68s
Train Epoch: 656 [20480/90000 (23%)]	Loss: 1.1745	Cost: 9.91s
Train Epoch: 656 [40960/90000 (45%)]	Loss: 1.1125	Cost: 14.91s
Train Epoch: 656 [61440/90000 (68%)]	Loss: 0.9826	Cost: 12.03s
Train Epoch: 656 [81920/90000 (91%)]	Loss: 0.9679	Cost: 12.17s
Train Epoch: 656 	Average Loss: 1.2228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6380

Learning rate: 9.894194130923585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 657 [0/90000 (0%)]	Loss: 2.6524	Cost: 42.95s
Train Epoch: 657 [20480/90000 (23%)]	Loss: 1.1590	Cost: 8.80s
Train Epoch: 657 [40960/90000 (45%)]	Loss: 1.0602	Cost: 10.47s
Train Epoch: 657 [61440/90000 (68%)]	Loss: 1.2405	Cost: 6.26s
Train Epoch: 657 [81920/90000 (91%)]	Loss: 0.9574	Cost: 13.29s
Train Epoch: 657 	Average Loss: 1.1950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6022

Learning rate: 9.893872453076489e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 658 [0/90000 (0%)]	Loss: 2.2367	Cost: 34.22s
Train Epoch: 658 [20480/90000 (23%)]	Loss: 1.2505	Cost: 6.89s
Train Epoch: 658 [40960/90000 (45%)]	Loss: 0.9697	Cost: 18.41s
Train Epoch: 658 [61440/90000 (68%)]	Loss: 1.0659	Cost: 12.14s
Train Epoch: 658 [81920/90000 (91%)]	Loss: 1.0848	Cost: 12.27s
Train Epoch: 658 	Average Loss: 1.2016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5710

Saving model as e658_model.pt & e658_waveforms_supplementary.hdf5
Learning rate: 9.893550292223543e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 659 [0/90000 (0%)]	Loss: 2.5967	Cost: 34.26s
Train Epoch: 659 [20480/90000 (23%)]	Loss: 1.1452	Cost: 11.16s
Train Epoch: 659 [40960/90000 (45%)]	Loss: 1.0283	Cost: 6.60s
Train Epoch: 659 [61440/90000 (68%)]	Loss: 1.0295	Cost: 8.19s
Train Epoch: 659 [81920/90000 (91%)]	Loss: 0.8650	Cost: 14.04s
Train Epoch: 659 	Average Loss: 1.1787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6350

Learning rate: 9.893227648396548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 660 [0/90000 (0%)]	Loss: 2.5035	Cost: 53.87s
Train Epoch: 660 [20480/90000 (23%)]	Loss: 1.1356	Cost: 12.31s
Train Epoch: 660 [40960/90000 (45%)]	Loss: 1.1456	Cost: 12.11s
Train Epoch: 660 [61440/90000 (68%)]	Loss: 1.1341	Cost: 12.11s
Train Epoch: 660 [81920/90000 (91%)]	Loss: 1.1556	Cost: 10.42s
Train Epoch: 660 	Average Loss: 1.2781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7042

Learning rate: 9.892904521627345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 661 [0/90000 (0%)]	Loss: 2.5317	Cost: 29.41s
Train Epoch: 661 [20480/90000 (23%)]	Loss: 1.1620	Cost: 9.67s
Train Epoch: 661 [40960/90000 (45%)]	Loss: 1.1581	Cost: 11.20s
Train Epoch: 661 [61440/90000 (68%)]	Loss: 1.1033	Cost: 8.94s
Train Epoch: 661 [81920/90000 (91%)]	Loss: 0.8507	Cost: 10.25s
Train Epoch: 661 	Average Loss: 1.2024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6334

Learning rate: 9.892580911947826e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 662 [0/90000 (0%)]	Loss: 2.6214	Cost: 39.61s
Train Epoch: 662 [20480/90000 (23%)]	Loss: 1.0749	Cost: 13.13s
Train Epoch: 662 [40960/90000 (45%)]	Loss: 0.9957	Cost: 13.58s
Train Epoch: 662 [61440/90000 (68%)]	Loss: 0.9862	Cost: 12.25s
Train Epoch: 662 [81920/90000 (91%)]	Loss: 0.9091	Cost: 11.91s
Train Epoch: 662 	Average Loss: 1.1253
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5164

Saving model as e662_model.pt & e662_waveforms_supplementary.hdf5
Learning rate: 9.892256819389932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 663 [0/90000 (0%)]	Loss: 2.5833	Cost: 34.19s
Train Epoch: 663 [20480/90000 (23%)]	Loss: 1.0072	Cost: 7.52s
Train Epoch: 663 [40960/90000 (45%)]	Loss: 1.0427	Cost: 13.93s
Train Epoch: 663 [61440/90000 (68%)]	Loss: 1.0985	Cost: 8.47s
Train Epoch: 663 [81920/90000 (91%)]	Loss: 0.9655	Cost: 8.91s
Train Epoch: 663 	Average Loss: 1.1508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6350

Learning rate: 9.891932243985645e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 664 [0/90000 (0%)]	Loss: 2.7536	Cost: 35.74s
Train Epoch: 664 [20480/90000 (23%)]	Loss: 1.2731	Cost: 10.02s
Train Epoch: 664 [40960/90000 (45%)]	Loss: 1.0355	Cost: 17.37s
Train Epoch: 664 [61440/90000 (68%)]	Loss: 1.0817	Cost: 12.28s
Train Epoch: 664 [81920/90000 (91%)]	Loss: 0.9181	Cost: 11.93s
Train Epoch: 664 	Average Loss: 1.1341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6372

Learning rate: 9.891607185767004e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 665 [0/90000 (0%)]	Loss: 2.5451	Cost: 49.10s
Train Epoch: 665 [20480/90000 (23%)]	Loss: 1.1344	Cost: 7.29s
Train Epoch: 665 [40960/90000 (45%)]	Loss: 0.9586	Cost: 10.90s
Train Epoch: 665 [61440/90000 (68%)]	Loss: 1.0115	Cost: 8.86s
Train Epoch: 665 [81920/90000 (91%)]	Loss: 0.9079	Cost: 8.67s
Train Epoch: 665 	Average Loss: 1.1465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5929

Learning rate: 9.891281644766087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 666 [0/90000 (0%)]	Loss: 2.6101	Cost: 27.23s
Train Epoch: 666 [20480/90000 (23%)]	Loss: 1.1466	Cost: 6.72s
Train Epoch: 666 [40960/90000 (45%)]	Loss: 0.8421	Cost: 14.54s
Train Epoch: 666 [61440/90000 (68%)]	Loss: 0.9689	Cost: 12.88s
Train Epoch: 666 [81920/90000 (91%)]	Loss: 0.8148	Cost: 14.55s
Train Epoch: 666 	Average Loss: 1.1355
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6096

Learning rate: 9.890955621015026e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 667 [0/90000 (0%)]	Loss: 2.6036	Cost: 36.79s
Train Epoch: 667 [20480/90000 (23%)]	Loss: 0.9623	Cost: 13.81s
Train Epoch: 667 [40960/90000 (45%)]	Loss: 0.9641	Cost: 10.99s
Train Epoch: 667 [61440/90000 (68%)]	Loss: 0.9889	Cost: 6.64s
Train Epoch: 667 [81920/90000 (91%)]	Loss: 0.8320	Cost: 13.80s
Train Epoch: 667 	Average Loss: 1.0555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4909

Saving model as e667_model.pt & e667_waveforms_supplementary.hdf5
Learning rate: 9.890629114545997e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 668 [0/90000 (0%)]	Loss: 2.4241	Cost: 33.94s
Train Epoch: 668 [20480/90000 (23%)]	Loss: 1.0501	Cost: 8.32s
Train Epoch: 668 [40960/90000 (45%)]	Loss: 0.8169	Cost: 16.76s
Train Epoch: 668 [61440/90000 (68%)]	Loss: 0.8813	Cost: 12.02s
Train Epoch: 668 [81920/90000 (91%)]	Loss: 0.8224	Cost: 12.26s
Train Epoch: 668 	Average Loss: 0.9988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5400

Learning rate: 9.890302125391226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 669 [0/90000 (0%)]	Loss: 2.3814	Cost: 37.01s
Train Epoch: 669 [20480/90000 (23%)]	Loss: 1.0889	Cost: 12.40s
Train Epoch: 669 [40960/90000 (45%)]	Loss: 0.9859	Cost: 8.24s
Train Epoch: 669 [61440/90000 (68%)]	Loss: 0.9091	Cost: 7.02s
Train Epoch: 669 [81920/90000 (91%)]	Loss: 0.8300	Cost: 11.83s
Train Epoch: 669 	Average Loss: 1.0786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5211

Learning rate: 9.889974653582986e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 670 [0/90000 (0%)]	Loss: 2.5580	Cost: 35.16s
Train Epoch: 670 [20480/90000 (23%)]	Loss: 1.1866	Cost: 6.50s
Train Epoch: 670 [40960/90000 (45%)]	Loss: 0.9329	Cost: 18.19s
Train Epoch: 670 [61440/90000 (68%)]	Loss: 0.8041	Cost: 11.89s
Train Epoch: 670 [81920/90000 (91%)]	Loss: 0.8456	Cost: 11.89s
Train Epoch: 670 	Average Loss: 1.0570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4932

Learning rate: 9.889646699153596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 671 [0/90000 (0%)]	Loss: 2.5043	Cost: 31.01s
Train Epoch: 671 [20480/90000 (23%)]	Loss: 0.9253	Cost: 12.15s
Train Epoch: 671 [40960/90000 (45%)]	Loss: 0.8702	Cost: 10.25s
Train Epoch: 671 [61440/90000 (68%)]	Loss: 0.8577	Cost: 6.28s
Train Epoch: 671 [81920/90000 (91%)]	Loss: 0.9199	Cost: 8.91s
Train Epoch: 671 	Average Loss: 1.0193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4781

Saving model as e671_model.pt & e671_waveforms_supplementary.hdf5
Learning rate: 9.889318262135424e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 672 [0/90000 (0%)]	Loss: 2.3779	Cost: 41.38s
Train Epoch: 672 [20480/90000 (23%)]	Loss: 0.9466	Cost: 7.83s
Train Epoch: 672 [40960/90000 (45%)]	Loss: 0.9046	Cost: 17.04s
Train Epoch: 672 [61440/90000 (68%)]	Loss: 0.8510	Cost: 12.00s
Train Epoch: 672 [81920/90000 (91%)]	Loss: 0.7405	Cost: 12.08s
Train Epoch: 672 	Average Loss: 1.0207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7044

Learning rate: 9.888989342560885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 673 [0/90000 (0%)]	Loss: 2.6880	Cost: 39.25s
Train Epoch: 673 [20480/90000 (23%)]	Loss: 1.4269	Cost: 12.01s
Train Epoch: 673 [40960/90000 (45%)]	Loss: 1.1912	Cost: 11.39s
Train Epoch: 673 [61440/90000 (68%)]	Loss: 1.2535	Cost: 6.33s
Train Epoch: 673 [81920/90000 (91%)]	Loss: 1.1288	Cost: 8.83s
Train Epoch: 673 	Average Loss: 1.4178
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.7588

Learning rate: 9.888659940462443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 674 [0/90000 (0%)]	Loss: 2.6208	Cost: 33.32s
Train Epoch: 674 [20480/90000 (23%)]	Loss: 1.1434	Cost: 8.48s
Train Epoch: 674 [40960/90000 (45%)]	Loss: 1.0305	Cost: 16.65s
Train Epoch: 674 [61440/90000 (68%)]	Loss: 0.9737	Cost: 12.81s
Train Epoch: 674 [81920/90000 (91%)]	Loss: 0.8885	Cost: 12.09s
Train Epoch: 674 	Average Loss: 1.1669
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4806

Learning rate: 9.88833005587261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 675 [0/90000 (0%)]	Loss: 2.3913	Cost: 31.03s
Train Epoch: 675 [20480/90000 (23%)]	Loss: 0.9576	Cost: 12.39s
Train Epoch: 675 [40960/90000 (45%)]	Loss: 0.7654	Cost: 11.22s
Train Epoch: 675 [61440/90000 (68%)]	Loss: 0.7520	Cost: 8.24s
Train Epoch: 675 [81920/90000 (91%)]	Loss: 0.6228	Cost: 11.00s
Train Epoch: 675 	Average Loss: 0.9857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5278

Learning rate: 9.887999688823941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 676 [0/90000 (0%)]	Loss: 2.5274	Cost: 36.22s
Train Epoch: 676 [20480/90000 (23%)]	Loss: 0.9016	Cost: 11.40s
Train Epoch: 676 [40960/90000 (45%)]	Loss: 0.8641	Cost: 8.13s
Train Epoch: 676 [61440/90000 (68%)]	Loss: 0.7944	Cost: 6.84s
Train Epoch: 676 [81920/90000 (91%)]	Loss: 0.7656	Cost: 19.29s
Train Epoch: 676 	Average Loss: 0.9709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5386

Learning rate: 9.887668839349044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 677 [0/90000 (0%)]	Loss: 2.7181	Cost: 55.98s
Train Epoch: 677 [20480/90000 (23%)]	Loss: 0.9873	Cost: 11.67s
Train Epoch: 677 [40960/90000 (45%)]	Loss: 0.8701	Cost: 8.61s
Train Epoch: 677 [61440/90000 (68%)]	Loss: 0.8513	Cost: 6.21s
Train Epoch: 677 [81920/90000 (91%)]	Loss: 0.8573	Cost: 10.64s
Train Epoch: 677 	Average Loss: 1.0323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5156

Learning rate: 9.887337507480573e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 678 [0/90000 (0%)]	Loss: 2.4378	Cost: 27.77s
Train Epoch: 678 [20480/90000 (23%)]	Loss: 0.9578	Cost: 9.45s
Train Epoch: 678 [40960/90000 (45%)]	Loss: 0.7615	Cost: 15.20s
Train Epoch: 678 [61440/90000 (68%)]	Loss: 0.8270	Cost: 14.59s
Train Epoch: 678 [81920/90000 (91%)]	Loss: 0.6302	Cost: 13.15s
Train Epoch: 678 	Average Loss: 0.9882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4150

Saving model as e678_model.pt & e678_waveforms_supplementary.hdf5
Learning rate: 9.887005693251226e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 679 [0/90000 (0%)]	Loss: 2.5640	Cost: 49.91s
Train Epoch: 679 [20480/90000 (23%)]	Loss: 1.0027	Cost: 12.17s
Train Epoch: 679 [40960/90000 (45%)]	Loss: 0.8205	Cost: 8.45s
Train Epoch: 679 [61440/90000 (68%)]	Loss: 0.8471	Cost: 6.07s
Train Epoch: 679 [81920/90000 (91%)]	Loss: 0.6376	Cost: 11.69s
Train Epoch: 679 	Average Loss: 0.9573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5725

Learning rate: 9.886673396693755e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 680 [0/90000 (0%)]	Loss: 2.3726	Cost: 31.54s
Train Epoch: 680 [20480/90000 (23%)]	Loss: 1.0062	Cost: 6.64s
Train Epoch: 680 [40960/90000 (45%)]	Loss: 0.9694	Cost: 18.48s
Train Epoch: 680 [61440/90000 (68%)]	Loss: 0.8734	Cost: 12.39s
Train Epoch: 680 [81920/90000 (91%)]	Loss: 0.7235	Cost: 12.16s
Train Epoch: 680 	Average Loss: 0.9784
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4792

Learning rate: 9.886340617840956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 681 [0/90000 (0%)]	Loss: 2.4797	Cost: 41.29s
Train Epoch: 681 [20480/90000 (23%)]	Loss: 1.0258	Cost: 11.72s
Train Epoch: 681 [40960/90000 (45%)]	Loss: 0.8584	Cost: 6.96s
Train Epoch: 681 [61440/90000 (68%)]	Loss: 0.8080	Cost: 6.19s
Train Epoch: 681 [81920/90000 (91%)]	Loss: 0.7381	Cost: 13.35s
Train Epoch: 681 	Average Loss: 0.9822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4245

Learning rate: 9.886007356725671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 682 [0/90000 (0%)]	Loss: 2.4122	Cost: 29.82s
Train Epoch: 682 [20480/90000 (23%)]	Loss: 0.8985	Cost: 6.18s
Train Epoch: 682 [40960/90000 (45%)]	Loss: 0.7944	Cost: 20.75s
Train Epoch: 682 [61440/90000 (68%)]	Loss: 0.6988	Cost: 14.15s
Train Epoch: 682 [81920/90000 (91%)]	Loss: 0.7762	Cost: 12.25s
Train Epoch: 682 	Average Loss: 0.9496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.6031

Learning rate: 9.885673613380794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 683 [0/90000 (0%)]	Loss: 2.3732	Cost: 38.41s
Train Epoch: 683 [20480/90000 (23%)]	Loss: 1.1056	Cost: 12.00s
Train Epoch: 683 [40960/90000 (45%)]	Loss: 0.8003	Cost: 9.37s
Train Epoch: 683 [61440/90000 (68%)]	Loss: 0.8773	Cost: 9.48s
Train Epoch: 683 [81920/90000 (91%)]	Loss: 0.7225	Cost: 11.03s
Train Epoch: 683 	Average Loss: 1.0380
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.5060

Learning rate: 9.885339387839263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 684 [0/90000 (0%)]	Loss: 2.6056	Cost: 33.28s
Train Epoch: 684 [20480/90000 (23%)]	Loss: 1.0267	Cost: 8.42s
Train Epoch: 684 [40960/90000 (45%)]	Loss: 0.9770	Cost: 13.58s
Train Epoch: 684 [61440/90000 (68%)]	Loss: 0.8627	Cost: 7.61s
Train Epoch: 684 [81920/90000 (91%)]	Loss: 0.6863	Cost: 19.30s
Train Epoch: 684 	Average Loss: 1.0436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4074

Saving model as e684_model.pt & e684_waveforms_supplementary.hdf5
Learning rate: 9.885004680134064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 685 [0/90000 (0%)]	Loss: 2.1927	Cost: 37.59s
Train Epoch: 685 [20480/90000 (23%)]	Loss: 0.8959	Cost: 11.83s
Train Epoch: 685 [40960/90000 (45%)]	Loss: 0.7983	Cost: 7.65s
Train Epoch: 685 [61440/90000 (68%)]	Loss: 0.6750	Cost: 6.12s
Train Epoch: 685 [81920/90000 (91%)]	Loss: 0.4895	Cost: 13.88s
Train Epoch: 685 	Average Loss: 0.8640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3719

Saving model as e685_model.pt & e685_waveforms_supplementary.hdf5
Learning rate: 9.884669490298232e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 686 [0/90000 (0%)]	Loss: 2.4163	Cost: 31.60s
Train Epoch: 686 [20480/90000 (23%)]	Loss: 0.7755	Cost: 8.70s
Train Epoch: 686 [40960/90000 (45%)]	Loss: 0.8123	Cost: 16.18s
Train Epoch: 686 [61440/90000 (68%)]	Loss: 0.6223	Cost: 11.95s
Train Epoch: 686 [81920/90000 (91%)]	Loss: 0.5111	Cost: 12.18s
Train Epoch: 686 	Average Loss: 0.8833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3957

Learning rate: 9.884333818364849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 687 [0/90000 (0%)]	Loss: 2.3015	Cost: 32.43s
Train Epoch: 687 [20480/90000 (23%)]	Loss: 0.9527	Cost: 9.32s
Train Epoch: 687 [40960/90000 (45%)]	Loss: 0.7147	Cost: 9.64s
Train Epoch: 687 [61440/90000 (68%)]	Loss: 0.7010	Cost: 8.69s
Train Epoch: 687 [81920/90000 (91%)]	Loss: 0.5069	Cost: 11.56s
Train Epoch: 687 	Average Loss: 0.8670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3155

Saving model as e687_model.pt & e687_waveforms_supplementary.hdf5
Learning rate: 9.883997664367044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 688 [0/90000 (0%)]	Loss: 2.5245	Cost: 28.40s
Train Epoch: 688 [20480/90000 (23%)]	Loss: 0.7886	Cost: 10.59s
Train Epoch: 688 [40960/90000 (45%)]	Loss: 0.6637	Cost: 21.37s
Train Epoch: 688 [61440/90000 (68%)]	Loss: 0.4885	Cost: 13.12s
Train Epoch: 688 [81920/90000 (91%)]	Loss: 0.4711	Cost: 11.98s
Train Epoch: 688 	Average Loss: 0.7807
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3034

Saving model as e688_model.pt & e688_waveforms_supplementary.hdf5
Learning rate: 9.883661028337996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 689 [0/90000 (0%)]	Loss: 2.1842	Cost: 50.83s
Train Epoch: 689 [20480/90000 (23%)]	Loss: 0.8374	Cost: 6.25s
Train Epoch: 689 [40960/90000 (45%)]	Loss: 0.6143	Cost: 14.36s
Train Epoch: 689 [61440/90000 (68%)]	Loss: 0.6384	Cost: 8.60s
Train Epoch: 689 [81920/90000 (91%)]	Loss: 0.5212	Cost: 8.45s
Train Epoch: 689 	Average Loss: 0.7559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2911

Saving model as e689_model.pt & e689_waveforms_supplementary.hdf5
Learning rate: 9.883323910310927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 690 [0/90000 (0%)]	Loss: 2.2560	Cost: 28.57s
Train Epoch: 690 [20480/90000 (23%)]	Loss: 0.6499	Cost: 8.19s
Train Epoch: 690 [40960/90000 (45%)]	Loss: 0.5517	Cost: 19.91s
Train Epoch: 690 [61440/90000 (68%)]	Loss: 0.6782	Cost: 12.16s
Train Epoch: 690 [81920/90000 (91%)]	Loss: 0.6526	Cost: 11.95s
Train Epoch: 690 	Average Loss: 0.7783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2737

Saving model as e690_model.pt & e690_waveforms_supplementary.hdf5
Learning rate: 9.88298631031911e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 691 [0/90000 (0%)]	Loss: 2.2674	Cost: 41.64s
Train Epoch: 691 [20480/90000 (23%)]	Loss: 0.7890	Cost: 6.85s
Train Epoch: 691 [40960/90000 (45%)]	Loss: 0.6417	Cost: 11.67s
Train Epoch: 691 [61440/90000 (68%)]	Loss: 0.5534	Cost: 8.69s
Train Epoch: 691 [81920/90000 (91%)]	Loss: 0.5372	Cost: 9.17s
Train Epoch: 691 	Average Loss: 0.7346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2973

Learning rate: 9.882648228395867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 692 [0/90000 (0%)]	Loss: 2.5019	Cost: 29.08s
Train Epoch: 692 [20480/90000 (23%)]	Loss: 0.6328	Cost: 10.16s
Train Epoch: 692 [40960/90000 (45%)]	Loss: 0.6969	Cost: 22.83s
Train Epoch: 692 [61440/90000 (68%)]	Loss: 0.6527	Cost: 13.34s
Train Epoch: 692 [81920/90000 (91%)]	Loss: 0.5918	Cost: 12.21s
Train Epoch: 692 	Average Loss: 0.8071
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3627

Learning rate: 9.882309664574563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 693 [0/90000 (0%)]	Loss: 2.4027	Cost: 48.36s
Train Epoch: 693 [20480/90000 (23%)]	Loss: 0.7394	Cost: 11.74s
Train Epoch: 693 [40960/90000 (45%)]	Loss: 0.6455	Cost: 8.85s
Train Epoch: 693 [61440/90000 (68%)]	Loss: 0.6853	Cost: 6.16s
Train Epoch: 693 [81920/90000 (91%)]	Loss: 0.4644	Cost: 12.64s
Train Epoch: 693 	Average Loss: 0.7877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2947

Learning rate: 9.881970618888613e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 694 [0/90000 (0%)]	Loss: 2.2036	Cost: 32.58s
Train Epoch: 694 [20480/90000 (23%)]	Loss: 0.6957	Cost: 7.32s
Train Epoch: 694 [40960/90000 (45%)]	Loss: 0.5620	Cost: 17.30s
Train Epoch: 694 [61440/90000 (68%)]	Loss: 0.5793	Cost: 12.46s
Train Epoch: 694 [81920/90000 (91%)]	Loss: 0.5130	Cost: 12.19s
Train Epoch: 694 	Average Loss: 0.6717
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3213

Learning rate: 9.88163109137148e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 695 [0/90000 (0%)]	Loss: 2.0736	Cost: 34.34s
Train Epoch: 695 [20480/90000 (23%)]	Loss: 0.7235	Cost: 11.85s
Train Epoch: 695 [40960/90000 (45%)]	Loss: 0.5476	Cost: 7.85s
Train Epoch: 695 [61440/90000 (68%)]	Loss: 0.6050	Cost: 6.64s
Train Epoch: 695 [81920/90000 (91%)]	Loss: 0.5597	Cost: 13.20s
Train Epoch: 695 	Average Loss: 0.7730
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2770

Learning rate: 9.881291082056673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 696 [0/90000 (0%)]	Loss: 2.4274	Cost: 30.75s
Train Epoch: 696 [20480/90000 (23%)]	Loss: 0.7092	Cost: 8.25s
Train Epoch: 696 [40960/90000 (45%)]	Loss: 0.6423	Cost: 16.99s
Train Epoch: 696 [61440/90000 (68%)]	Loss: 0.6153	Cost: 13.56s
Train Epoch: 696 [81920/90000 (91%)]	Loss: 0.5469	Cost: 12.49s
Train Epoch: 696 	Average Loss: 0.7617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3323

Learning rate: 9.880950590977753e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 697 [0/90000 (0%)]	Loss: 2.1812	Cost: 32.96s
Train Epoch: 697 [20480/90000 (23%)]	Loss: 0.9168	Cost: 12.48s
Train Epoch: 697 [40960/90000 (45%)]	Loss: 0.6084	Cost: 9.71s
Train Epoch: 697 [61440/90000 (68%)]	Loss: 0.6293	Cost: 8.75s
Train Epoch: 697 [81920/90000 (91%)]	Loss: 0.4345	Cost: 13.35s
Train Epoch: 697 	Average Loss: 0.7415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2192

Saving model as e697_model.pt & e697_waveforms_supplementary.hdf5
Learning rate: 9.88060961816832e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 698 [0/90000 (0%)]	Loss: 2.2503	Cost: 50.12s
Train Epoch: 698 [20480/90000 (23%)]	Loss: 0.6604	Cost: 13.31s
Train Epoch: 698 [40960/90000 (45%)]	Loss: 0.5617	Cost: 12.14s
Train Epoch: 698 [61440/90000 (68%)]	Loss: 0.5544	Cost: 12.01s
Train Epoch: 698 [81920/90000 (91%)]	Loss: 0.3894	Cost: 11.05s
Train Epoch: 698 	Average Loss: 0.7154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2583

Learning rate: 9.88026816366203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 699 [0/90000 (0%)]	Loss: 2.2858	Cost: 33.21s
Train Epoch: 699 [20480/90000 (23%)]	Loss: 0.6142	Cost: 6.74s
Train Epoch: 699 [40960/90000 (45%)]	Loss: 0.5159	Cost: 14.15s
Train Epoch: 699 [61440/90000 (68%)]	Loss: 0.4700	Cost: 8.85s
Train Epoch: 699 [81920/90000 (91%)]	Loss: 0.2781	Cost: 8.87s
Train Epoch: 699 	Average Loss: 0.6873
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2597

Learning rate: 9.879926227492583e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 700 [0/90000 (0%)]	Loss: 2.0369	Cost: 33.94s
Train Epoch: 700 [20480/90000 (23%)]	Loss: 0.5959	Cost: 14.54s
Train Epoch: 700 [40960/90000 (45%)]	Loss: 0.3349	Cost: 12.91s
Train Epoch: 700 [61440/90000 (68%)]	Loss: 0.4209	Cost: 12.00s
Train Epoch: 700 [81920/90000 (91%)]	Loss: 0.3323	Cost: 11.78s
Train Epoch: 700 	Average Loss: 0.6387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2648

Learning rate: 9.879583809693725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 701 [0/90000 (0%)]	Loss: 2.2818	Cost: 37.95s
Train Epoch: 701 [20480/90000 (23%)]	Loss: 0.6823	Cost: 6.50s
Train Epoch: 701 [40960/90000 (45%)]	Loss: 0.5958	Cost: 13.63s
Train Epoch: 701 [61440/90000 (68%)]	Loss: 0.6963	Cost: 8.84s
Train Epoch: 701 [81920/90000 (91%)]	Loss: 0.3822	Cost: 9.43s
Train Epoch: 701 	Average Loss: 0.7042
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2550

Learning rate: 9.879240910299253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 702 [0/90000 (0%)]	Loss: 2.3284	Cost: 30.00s
Train Epoch: 702 [20480/90000 (23%)]	Loss: 0.7038	Cost: 14.63s
Train Epoch: 702 [40960/90000 (45%)]	Loss: 0.4903	Cost: 16.21s
Train Epoch: 702 [61440/90000 (68%)]	Loss: 0.5625	Cost: 12.71s
Train Epoch: 702 [81920/90000 (91%)]	Loss: 0.5104	Cost: 11.30s
Train Epoch: 702 	Average Loss: 0.6927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.3458

Learning rate: 9.87889752934301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 703 [0/90000 (0%)]	Loss: 2.4399	Cost: 29.88s
Train Epoch: 703 [20480/90000 (23%)]	Loss: 0.7438	Cost: 10.28s
Train Epoch: 703 [40960/90000 (45%)]	Loss: 0.6435	Cost: 12.35s
Train Epoch: 703 [61440/90000 (68%)]	Loss: 0.6325	Cost: 9.33s
Train Epoch: 703 [81920/90000 (91%)]	Loss: 0.5922	Cost: 11.86s
Train Epoch: 703 	Average Loss: 0.7961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.4110

Learning rate: 9.878553666858885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 704 [0/90000 (0%)]	Loss: 2.4095	Cost: 42.12s
Train Epoch: 704 [20480/90000 (23%)]	Loss: 0.6323	Cost: 9.99s
Train Epoch: 704 [40960/90000 (45%)]	Loss: 0.5551	Cost: 14.33s
Train Epoch: 704 [61440/90000 (68%)]	Loss: 0.4341	Cost: 12.37s
Train Epoch: 704 [81920/90000 (91%)]	Loss: 0.4425	Cost: 11.81s
Train Epoch: 704 	Average Loss: 0.6953
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1835

Saving model as e704_model.pt & e704_waveforms_supplementary.hdf5
Learning rate: 9.878209322880817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 705 [0/90000 (0%)]	Loss: 2.2173	Cost: 39.19s
Train Epoch: 705 [20480/90000 (23%)]	Loss: 0.6595	Cost: 9.68s
Train Epoch: 705 [40960/90000 (45%)]	Loss: 0.5712	Cost: 7.98s
Train Epoch: 705 [61440/90000 (68%)]	Loss: 0.6144	Cost: 6.83s
Train Epoch: 705 [81920/90000 (91%)]	Loss: 0.2594	Cost: 14.04s
Train Epoch: 705 	Average Loss: 0.6517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2133

Learning rate: 9.87786449744279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 706 [0/90000 (0%)]	Loss: 1.9951	Cost: 31.69s
Train Epoch: 706 [20480/90000 (23%)]	Loss: 0.5414	Cost: 9.95s
Train Epoch: 706 [40960/90000 (45%)]	Loss: 0.5142	Cost: 17.38s
Train Epoch: 706 [61440/90000 (68%)]	Loss: 0.5548	Cost: 12.55s
Train Epoch: 706 [81920/90000 (91%)]	Loss: 0.3906	Cost: 12.19s
Train Epoch: 706 	Average Loss: 0.6410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2306

Learning rate: 9.87751919057884e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 707 [0/90000 (0%)]	Loss: 2.4460	Cost: 46.07s
Train Epoch: 707 [20480/90000 (23%)]	Loss: 0.5879	Cost: 10.59s
Train Epoch: 707 [40960/90000 (45%)]	Loss: 0.4826	Cost: 6.50s
Train Epoch: 707 [61440/90000 (68%)]	Loss: 0.5261	Cost: 6.86s
Train Epoch: 707 [81920/90000 (91%)]	Loss: 0.3350	Cost: 14.32s
Train Epoch: 707 	Average Loss: 0.6061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1097

Saving model as e707_model.pt & e707_waveforms_supplementary.hdf5
Learning rate: 9.877173402323044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 708 [0/90000 (0%)]	Loss: 2.0916	Cost: 34.65s
Train Epoch: 708 [20480/90000 (23%)]	Loss: 0.3899	Cost: 13.02s
Train Epoch: 708 [40960/90000 (45%)]	Loss: 0.4613	Cost: 14.83s
Train Epoch: 708 [61440/90000 (68%)]	Loss: 0.4802	Cost: 11.93s
Train Epoch: 708 [81920/90000 (91%)]	Loss: 0.3679	Cost: 11.82s
Train Epoch: 708 	Average Loss: 0.5785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2029

Learning rate: 9.876827132709531e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 709 [0/90000 (0%)]	Loss: 2.1538	Cost: 57.28s
Train Epoch: 709 [20480/90000 (23%)]	Loss: 0.5615	Cost: 7.98s
Train Epoch: 709 [40960/90000 (45%)]	Loss: 0.4219	Cost: 10.44s
Train Epoch: 709 [61440/90000 (68%)]	Loss: 0.5097	Cost: 8.92s
Train Epoch: 709 [81920/90000 (91%)]	Loss: 0.2148	Cost: 8.95s
Train Epoch: 709 	Average Loss: 0.5876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1486

Learning rate: 9.876480381772478e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 710 [0/90000 (0%)]	Loss: 2.0772	Cost: 29.65s
Train Epoch: 710 [20480/90000 (23%)]	Loss: 0.5802	Cost: 8.52s
Train Epoch: 710 [40960/90000 (45%)]	Loss: 0.5920	Cost: 18.32s
Train Epoch: 710 [61440/90000 (68%)]	Loss: 0.4889	Cost: 13.73s
Train Epoch: 710 [81920/90000 (91%)]	Loss: 0.3654	Cost: 12.30s
Train Epoch: 710 	Average Loss: 0.6202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1890

Learning rate: 9.876133149546104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 711 [0/90000 (0%)]	Loss: 2.1343	Cost: 39.68s
Train Epoch: 711 [20480/90000 (23%)]	Loss: 0.4815	Cost: 12.30s
Train Epoch: 711 [40960/90000 (45%)]	Loss: 0.5578	Cost: 12.21s
Train Epoch: 711 [61440/90000 (68%)]	Loss: 0.4065	Cost: 6.24s
Train Epoch: 711 [81920/90000 (91%)]	Loss: 0.2909	Cost: 6.22s
Train Epoch: 711 	Average Loss: 0.5274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1027

Saving model as e711_model.pt & e711_waveforms_supplementary.hdf5
Learning rate: 9.875785436064683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 712 [0/90000 (0%)]	Loss: 1.9162	Cost: 27.51s
Train Epoch: 712 [20480/90000 (23%)]	Loss: 0.6545	Cost: 6.83s
Train Epoch: 712 [40960/90000 (45%)]	Loss: 0.6107	Cost: 24.06s
Train Epoch: 712 [61440/90000 (68%)]	Loss: 0.5249	Cost: 13.13s
Train Epoch: 712 [81920/90000 (91%)]	Loss: 0.3034	Cost: 12.24s
Train Epoch: 712 	Average Loss: 0.6151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1374

Learning rate: 9.875437241362533e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 713 [0/90000 (0%)]	Loss: 2.2254	Cost: 47.00s
Train Epoch: 713 [20480/90000 (23%)]	Loss: 0.5883	Cost: 11.66s
Train Epoch: 713 [40960/90000 (45%)]	Loss: 0.4247	Cost: 8.92s
Train Epoch: 713 [61440/90000 (68%)]	Loss: 0.4540	Cost: 6.13s
Train Epoch: 713 [81920/90000 (91%)]	Loss: 0.3593	Cost: 12.07s
Train Epoch: 713 	Average Loss: 0.5518
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1901

Learning rate: 9.875088565474018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 714 [0/90000 (0%)]	Loss: 2.2015	Cost: 34.51s
Train Epoch: 714 [20480/90000 (23%)]	Loss: 0.5012	Cost: 6.49s
Train Epoch: 714 [40960/90000 (45%)]	Loss: 0.3766	Cost: 16.26s
Train Epoch: 714 [61440/90000 (68%)]	Loss: 0.3420	Cost: 12.06s
Train Epoch: 714 [81920/90000 (91%)]	Loss: 0.1727	Cost: 12.09s
Train Epoch: 714 	Average Loss: 0.5052
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1055

Learning rate: 9.874739408433551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 715 [0/90000 (0%)]	Loss: 2.1616	Cost: 36.05s
Train Epoch: 715 [20480/90000 (23%)]	Loss: 0.4233	Cost: 12.21s
Train Epoch: 715 [40960/90000 (45%)]	Loss: 0.2088	Cost: 11.27s
Train Epoch: 715 [61440/90000 (68%)]	Loss: 0.3358	Cost: 6.20s
Train Epoch: 715 [81920/90000 (91%)]	Loss: 0.2518	Cost: 11.36s
Train Epoch: 715 	Average Loss: 0.4734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0660

Saving model as e715_model.pt & e715_waveforms_supplementary.hdf5
Learning rate: 9.874389770275595e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 716 [0/90000 (0%)]	Loss: 2.0917	Cost: 30.66s
Train Epoch: 716 [20480/90000 (23%)]	Loss: 0.4696	Cost: 8.59s
Train Epoch: 716 [40960/90000 (45%)]	Loss: 0.2396	Cost: 18.22s
Train Epoch: 716 [61440/90000 (68%)]	Loss: 0.2447	Cost: 11.82s
Train Epoch: 716 [81920/90000 (91%)]	Loss: 0.2193	Cost: 12.02s
Train Epoch: 716 	Average Loss: 0.4525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1278

Learning rate: 9.874039651034654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 717 [0/90000 (0%)]	Loss: 2.0764	Cost: 41.24s
Train Epoch: 717 [20480/90000 (23%)]	Loss: 0.4134	Cost: 12.44s
Train Epoch: 717 [40960/90000 (45%)]	Loss: 0.3743	Cost: 7.91s
Train Epoch: 717 [61440/90000 (68%)]	Loss: 0.4849	Cost: 6.28s
Train Epoch: 717 [81920/90000 (91%)]	Loss: 0.2217	Cost: 14.80s
Train Epoch: 717 	Average Loss: 0.4562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0922

Learning rate: 9.873689050745284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 718 [0/90000 (0%)]	Loss: 1.8506	Cost: 34.06s
Train Epoch: 718 [20480/90000 (23%)]	Loss: 0.4169	Cost: 6.47s
Train Epoch: 718 [40960/90000 (45%)]	Loss: 0.2358	Cost: 17.93s
Train Epoch: 718 [61440/90000 (68%)]	Loss: 0.2172	Cost: 12.02s
Train Epoch: 718 [81920/90000 (91%)]	Loss: 0.2471	Cost: 11.83s
Train Epoch: 718 	Average Loss: 0.4337
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1411

Learning rate: 9.873337969442089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 719 [0/90000 (0%)]	Loss: 2.1304	Cost: 31.00s
Train Epoch: 719 [20480/90000 (23%)]	Loss: 0.5528	Cost: 12.30s
Train Epoch: 719 [40960/90000 (45%)]	Loss: 0.2713	Cost: 12.11s
Train Epoch: 719 [61440/90000 (68%)]	Loss: 0.3286	Cost: 6.87s
Train Epoch: 719 [81920/90000 (91%)]	Loss: 0.1221	Cost: 6.23s
Train Epoch: 719 	Average Loss: 0.4900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1176

Learning rate: 9.87298640715972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 720 [0/90000 (0%)]	Loss: 2.0340	Cost: 30.87s
Train Epoch: 720 [20480/90000 (23%)]	Loss: 0.2944	Cost: 10.25s
Train Epoch: 720 [40960/90000 (45%)]	Loss: 0.4713	Cost: 20.45s
Train Epoch: 720 [61440/90000 (68%)]	Loss: 0.4507	Cost: 12.81s
Train Epoch: 720 [81920/90000 (91%)]	Loss: 0.3828	Cost: 11.89s
Train Epoch: 720 	Average Loss: 0.5494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1658

Learning rate: 9.872634363932875e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 721 [0/90000 (0%)]	Loss: 2.0704	Cost: 38.79s
Train Epoch: 721 [20480/90000 (23%)]	Loss: 0.4168	Cost: 12.40s
Train Epoch: 721 [40960/90000 (45%)]	Loss: 0.4303	Cost: 10.18s
Train Epoch: 721 [61440/90000 (68%)]	Loss: 0.3963	Cost: 6.06s
Train Epoch: 721 [81920/90000 (91%)]	Loss: 0.2683	Cost: 10.29s
Train Epoch: 721 	Average Loss: 0.5312
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1113

Learning rate: 9.872281839796297e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 722 [0/90000 (0%)]	Loss: 2.0049	Cost: 32.04s
Train Epoch: 722 [20480/90000 (23%)]	Loss: 0.6692	Cost: 10.23s
Train Epoch: 722 [40960/90000 (45%)]	Loss: 0.4328	Cost: 23.08s
Train Epoch: 722 [61440/90000 (68%)]	Loss: 0.6050	Cost: 12.37s
Train Epoch: 722 [81920/90000 (91%)]	Loss: 0.4474	Cost: 11.78s
Train Epoch: 722 	Average Loss: 0.6353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.2870

Learning rate: 9.87192883478478e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 723 [0/90000 (0%)]	Loss: 2.2477	Cost: 30.59s
Train Epoch: 723 [20480/90000 (23%)]	Loss: 0.6825	Cost: 12.58s
Train Epoch: 723 [40960/90000 (45%)]	Loss: 0.3722	Cost: 7.49s
Train Epoch: 723 [61440/90000 (68%)]	Loss: 0.5462	Cost: 6.59s
Train Epoch: 723 [81920/90000 (91%)]	Loss: 0.2467	Cost: 10.75s
Train Epoch: 723 	Average Loss: 0.6401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0737

Learning rate: 9.871575348933164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 724 [0/90000 (0%)]	Loss: 1.9684	Cost: 26.53s
Train Epoch: 724 [20480/90000 (23%)]	Loss: 0.5621	Cost: 10.04s
Train Epoch: 724 [40960/90000 (45%)]	Loss: 0.3761	Cost: 22.27s
Train Epoch: 724 [61440/90000 (68%)]	Loss: 0.5301	Cost: 14.25s
Train Epoch: 724 [81920/90000 (91%)]	Loss: 0.1883	Cost: 12.14s
Train Epoch: 724 	Average Loss: 0.5441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.1080

Learning rate: 9.871221382276338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 725 [0/90000 (0%)]	Loss: 2.2792	Cost: 48.70s
Train Epoch: 725 [20480/90000 (23%)]	Loss: 0.5057	Cost: 10.80s
Train Epoch: 725 [40960/90000 (45%)]	Loss: 0.3181	Cost: 8.67s
Train Epoch: 725 [61440/90000 (68%)]	Loss: 0.3220	Cost: 7.23s
Train Epoch: 725 [81920/90000 (91%)]	Loss: 0.1461	Cost: 12.54s
Train Epoch: 725 	Average Loss: 0.4607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9984

Saving model as e725_model.pt & e725_waveforms_supplementary.hdf5
Learning rate: 9.870866934849235e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 726 [0/90000 (0%)]	Loss: 2.0871	Cost: 28.98s
Train Epoch: 726 [20480/90000 (23%)]	Loss: 0.5724	Cost: 6.98s
Train Epoch: 726 [40960/90000 (45%)]	Loss: 0.2334	Cost: 19.78s
Train Epoch: 726 [61440/90000 (68%)]	Loss: 0.4085	Cost: 12.47s
Train Epoch: 726 [81920/90000 (91%)]	Loss: 0.3069	Cost: 11.77s
Train Epoch: 726 	Average Loss: 0.4677
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0621

Learning rate: 9.870512006686839e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 727 [0/90000 (0%)]	Loss: 1.9448	Cost: 40.35s
Train Epoch: 727 [20480/90000 (23%)]	Loss: 0.3170	Cost: 7.64s
Train Epoch: 727 [40960/90000 (45%)]	Loss: 0.3047	Cost: 13.20s
Train Epoch: 727 [61440/90000 (68%)]	Loss: 0.3549	Cost: 8.63s
Train Epoch: 727 [81920/90000 (91%)]	Loss: 0.2788	Cost: 8.48s
Train Epoch: 727 	Average Loss: 0.4436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0949

Learning rate: 9.870156597824179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 728 [0/90000 (0%)]	Loss: 1.9506	Cost: 28.62s
Train Epoch: 728 [20480/90000 (23%)]	Loss: 0.2192	Cost: 6.79s
Train Epoch: 728 [40960/90000 (45%)]	Loss: 0.1328	Cost: 17.49s
Train Epoch: 728 [61440/90000 (68%)]	Loss: 0.3164	Cost: 15.35s
Train Epoch: 728 [81920/90000 (91%)]	Loss: 0.0862	Cost: 12.63s
Train Epoch: 728 	Average Loss: 0.3617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9359

Saving model as e728_model.pt & e728_waveforms_supplementary.hdf5
Learning rate: 9.869800708296334e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 729 [0/90000 (0%)]	Loss: 1.8721	Cost: 33.76s
Train Epoch: 729 [20480/90000 (23%)]	Loss: 0.2915	Cost: 6.68s
Train Epoch: 729 [40960/90000 (45%)]	Loss: 0.1557	Cost: 16.41s
Train Epoch: 729 [61440/90000 (68%)]	Loss: 0.2215	Cost: 9.17s
Train Epoch: 729 [81920/90000 (91%)]	Loss: -0.0468	Cost: 12.05s
Train Epoch: 729 	Average Loss: 0.2692
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8686

Saving model as e729_model.pt & e729_waveforms_supplementary.hdf5
Learning rate: 9.869444338138427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 730 [0/90000 (0%)]	Loss: 2.1294	Cost: 38.35s
Train Epoch: 730 [20480/90000 (23%)]	Loss: 0.2032	Cost: 9.99s
Train Epoch: 730 [40960/90000 (45%)]	Loss: 0.1307	Cost: 16.28s
Train Epoch: 730 [61440/90000 (68%)]	Loss: 0.2393	Cost: 12.18s
Train Epoch: 730 [81920/90000 (91%)]	Loss: 0.0569	Cost: 12.03s
Train Epoch: 730 	Average Loss: 0.2364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8916

Learning rate: 9.869087487385631e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 731 [0/90000 (0%)]	Loss: 1.9495	Cost: 36.13s
Train Epoch: 731 [20480/90000 (23%)]	Loss: 0.2910	Cost: 7.55s
Train Epoch: 731 [40960/90000 (45%)]	Loss: 0.0834	Cost: 11.84s
Train Epoch: 731 [61440/90000 (68%)]	Loss: 0.1960	Cost: 9.13s
Train Epoch: 731 [81920/90000 (91%)]	Loss: -0.0285	Cost: 11.49s
Train Epoch: 731 	Average Loss: 0.2732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0326

Learning rate: 9.868730156073167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 732 [0/90000 (0%)]	Loss: 1.8503	Cost: 29.89s
Train Epoch: 732 [20480/90000 (23%)]	Loss: 0.3516	Cost: 10.68s
Train Epoch: 732 [40960/90000 (45%)]	Loss: 0.2702	Cost: 19.83s
Train Epoch: 732 [61440/90000 (68%)]	Loss: 0.1548	Cost: 12.24s
Train Epoch: 732 [81920/90000 (91%)]	Loss: 0.0196	Cost: 12.22s
Train Epoch: 732 	Average Loss: 0.2594
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8521

Saving model as e732_model.pt & e732_waveforms_supplementary.hdf5
Learning rate: 9.8683723442363e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 733 [0/90000 (0%)]	Loss: 1.8485	Cost: 46.35s
Train Epoch: 733 [20480/90000 (23%)]	Loss: 0.1811	Cost: 6.27s
Train Epoch: 733 [40960/90000 (45%)]	Loss: 0.1367	Cost: 14.46s
Train Epoch: 733 [61440/90000 (68%)]	Loss: 0.1080	Cost: 8.71s
Train Epoch: 733 [81920/90000 (91%)]	Loss: -0.0122	Cost: 9.31s
Train Epoch: 733 	Average Loss: 0.2773
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9415

Learning rate: 9.868014051910347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 734 [0/90000 (0%)]	Loss: 1.8505	Cost: 29.56s
Train Epoch: 734 [20480/90000 (23%)]	Loss: 0.1884	Cost: 11.82s
Train Epoch: 734 [40960/90000 (45%)]	Loss: 0.2693	Cost: 17.57s
Train Epoch: 734 [61440/90000 (68%)]	Loss: 0.2512	Cost: 13.36s
Train Epoch: 734 [81920/90000 (91%)]	Loss: -0.0721	Cost: 12.17s
Train Epoch: 734 	Average Loss: 0.3062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0399

Learning rate: 9.86765527913067e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 735 [0/90000 (0%)]	Loss: 1.7423	Cost: 59.45s
Train Epoch: 735 [20480/90000 (23%)]	Loss: 0.3358	Cost: 6.34s
Train Epoch: 735 [40960/90000 (45%)]	Loss: 0.1668	Cost: 13.45s
Train Epoch: 735 [61440/90000 (68%)]	Loss: 0.1460	Cost: 8.69s
Train Epoch: 735 [81920/90000 (91%)]	Loss: 0.0786	Cost: 9.02s
Train Epoch: 735 	Average Loss: 0.3127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9759

Learning rate: 9.867296025932675e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 736 [0/90000 (0%)]	Loss: 1.9547	Cost: 28.69s
Train Epoch: 736 [20480/90000 (23%)]	Loss: 0.2962	Cost: 8.85s
Train Epoch: 736 [40960/90000 (45%)]	Loss: 0.2007	Cost: 16.18s
Train Epoch: 736 [61440/90000 (68%)]	Loss: 0.1414	Cost: 12.66s
Train Epoch: 736 [81920/90000 (91%)]	Loss: 0.0944	Cost: 12.37s
Train Epoch: 736 	Average Loss: 0.2852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9332

Learning rate: 9.866936292351822e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 737 [0/90000 (0%)]	Loss: 1.6813	Cost: 38.54s
Train Epoch: 737 [20480/90000 (23%)]	Loss: 0.2436	Cost: 11.29s
Train Epoch: 737 [40960/90000 (45%)]	Loss: 0.1991	Cost: 8.11s
Train Epoch: 737 [61440/90000 (68%)]	Loss: 0.0654	Cost: 6.44s
Train Epoch: 737 [81920/90000 (91%)]	Loss: -0.0429	Cost: 15.00s
Train Epoch: 737 	Average Loss: 0.2408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9796

Learning rate: 9.866576078423615e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 738 [0/90000 (0%)]	Loss: 1.9606	Cost: 27.60s
Train Epoch: 738 [20480/90000 (23%)]	Loss: 0.0349	Cost: 9.97s
Train Epoch: 738 [40960/90000 (45%)]	Loss: 0.0836	Cost: 18.25s
Train Epoch: 738 [61440/90000 (68%)]	Loss: 0.0232	Cost: 12.16s
Train Epoch: 738 [81920/90000 (91%)]	Loss: -0.0854	Cost: 12.39s
Train Epoch: 738 	Average Loss: 0.1825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9162

Learning rate: 9.866215384183606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 739 [0/90000 (0%)]	Loss: 1.7888	Cost: 42.88s
Train Epoch: 739 [20480/90000 (23%)]	Loss: 0.1504	Cost: 11.85s
Train Epoch: 739 [40960/90000 (45%)]	Loss: 0.0015	Cost: 10.46s
Train Epoch: 739 [61440/90000 (68%)]	Loss: -0.0010	Cost: 6.50s
Train Epoch: 739 [81920/90000 (91%)]	Loss: -0.1623	Cost: 13.31s
Train Epoch: 739 	Average Loss: 0.1276
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8532

Learning rate: 9.865854209667392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 740 [0/90000 (0%)]	Loss: 1.5858	Cost: 38.13s
Train Epoch: 740 [20480/90000 (23%)]	Loss: 0.1514	Cost: 6.76s
Train Epoch: 740 [40960/90000 (45%)]	Loss: -0.0619	Cost: 17.21s
Train Epoch: 740 [61440/90000 (68%)]	Loss: -0.0274	Cost: 12.25s
Train Epoch: 740 [81920/90000 (91%)]	Loss: -0.0708	Cost: 12.12s
Train Epoch: 740 	Average Loss: 0.1286
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8802

Learning rate: 9.865492554910621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 741 [0/90000 (0%)]	Loss: 1.8433	Cost: 31.15s
Train Epoch: 741 [20480/90000 (23%)]	Loss: 0.0979	Cost: 11.36s
Train Epoch: 741 [40960/90000 (45%)]	Loss: -0.0067	Cost: 8.40s
Train Epoch: 741 [61440/90000 (68%)]	Loss: -0.0034	Cost: 6.64s
Train Epoch: 741 [81920/90000 (91%)]	Loss: -0.1474	Cost: 14.91s
Train Epoch: 741 	Average Loss: 0.1459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9720

Learning rate: 9.865130419948984e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 742 [0/90000 (0%)]	Loss: 1.8942	Cost: 31.80s
Train Epoch: 742 [20480/90000 (23%)]	Loss: 0.1565	Cost: 6.81s
Train Epoch: 742 [40960/90000 (45%)]	Loss: -0.0030	Cost: 20.01s
Train Epoch: 742 [61440/90000 (68%)]	Loss: 0.1004	Cost: 12.69s
Train Epoch: 742 [81920/90000 (91%)]	Loss: 0.0291	Cost: 11.91s
Train Epoch: 742 	Average Loss: 0.2125
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8521

Learning rate: 9.864767804818229e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 743 [0/90000 (0%)]	Loss: 1.8245	Cost: 33.12s
Train Epoch: 743 [20480/90000 (23%)]	Loss: 0.2416	Cost: 11.36s
Train Epoch: 743 [40960/90000 (45%)]	Loss: 0.1105	Cost: 10.32s
Train Epoch: 743 [61440/90000 (68%)]	Loss: 0.0417	Cost: 8.61s
Train Epoch: 743 [81920/90000 (91%)]	Loss: -0.0418	Cost: 14.59s
Train Epoch: 743 	Average Loss: 0.2514
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9709

Learning rate: 9.864404709554137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 744 [0/90000 (0%)]	Loss: 1.8904	Cost: 50.11s
Train Epoch: 744 [20480/90000 (23%)]	Loss: 0.2046	Cost: 6.61s
Train Epoch: 744 [40960/90000 (45%)]	Loss: 0.1361	Cost: 18.04s
Train Epoch: 744 [61440/90000 (68%)]	Loss: 0.2332	Cost: 12.26s
Train Epoch: 744 [81920/90000 (91%)]	Loss: -0.0182	Cost: 11.86s
Train Epoch: 744 	Average Loss: 0.3031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 2.0004

Learning rate: 9.864041134192549e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 745 [0/90000 (0%)]	Loss: 2.0908	Cost: 34.26s
Train Epoch: 745 [20480/90000 (23%)]	Loss: 0.3801	Cost: 12.04s
Train Epoch: 745 [40960/90000 (45%)]	Loss: 0.2190	Cost: 6.51s
Train Epoch: 745 [61440/90000 (68%)]	Loss: 0.1429	Cost: 6.38s
Train Epoch: 745 [81920/90000 (91%)]	Loss: -0.0253	Cost: 14.87s
Train Epoch: 745 	Average Loss: 0.3372
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9405

Learning rate: 9.863677078769347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 746 [0/90000 (0%)]	Loss: 1.9051	Cost: 31.72s
Train Epoch: 746 [20480/90000 (23%)]	Loss: 0.2154	Cost: 14.26s
Train Epoch: 746 [40960/90000 (45%)]	Loss: 0.0859	Cost: 17.86s
Train Epoch: 746 [61440/90000 (68%)]	Loss: -0.1029	Cost: 12.33s
Train Epoch: 746 [81920/90000 (91%)]	Loss: 0.0199	Cost: 11.95s
Train Epoch: 746 	Average Loss: 0.2284
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9061

Learning rate: 9.863312543320462e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 747 [0/90000 (0%)]	Loss: 1.7043	Cost: 34.53s
Train Epoch: 747 [20480/90000 (23%)]	Loss: 0.1734	Cost: 9.11s
Train Epoch: 747 [40960/90000 (45%)]	Loss: 0.0505	Cost: 11.40s
Train Epoch: 747 [61440/90000 (68%)]	Loss: 0.0388	Cost: 8.88s
Train Epoch: 747 [81920/90000 (91%)]	Loss: -0.0229	Cost: 9.15s
Train Epoch: 747 	Average Loss: 0.2191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8239

Saving model as e747_model.pt & e747_waveforms_supplementary.hdf5
Learning rate: 9.862947527881872e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 748 [0/90000 (0%)]	Loss: 1.7797	Cost: 35.92s
Train Epoch: 748 [20480/90000 (23%)]	Loss: 0.3232	Cost: 13.11s
Train Epoch: 748 [40960/90000 (45%)]	Loss: -0.1849	Cost: 17.26s
Train Epoch: 748 [61440/90000 (68%)]	Loss: -0.1614	Cost: 12.02s
Train Epoch: 748 [81920/90000 (91%)]	Loss: -0.0465	Cost: 12.19s
Train Epoch: 748 	Average Loss: 0.1183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7808

Saving model as e748_model.pt & e748_waveforms_supplementary.hdf5
Learning rate: 9.862582032489604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 749 [0/90000 (0%)]	Loss: 1.6279	Cost: 40.65s
Train Epoch: 749 [20480/90000 (23%)]	Loss: 0.0129	Cost: 10.27s
Train Epoch: 749 [40960/90000 (45%)]	Loss: -0.1488	Cost: 6.37s
Train Epoch: 749 [61440/90000 (68%)]	Loss: -0.2718	Cost: 6.39s
Train Epoch: 749 [81920/90000 (91%)]	Loss: -0.1743	Cost: 12.92s
Train Epoch: 749 	Average Loss: 0.0400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8220

Learning rate: 9.862216057179729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 750 [0/90000 (0%)]	Loss: 1.6213	Cost: 28.19s
Train Epoch: 750 [20480/90000 (23%)]	Loss: -0.1012	Cost: 7.29s
Train Epoch: 750 [40960/90000 (45%)]	Loss: -0.0766	Cost: 18.59s
Train Epoch: 750 [61440/90000 (68%)]	Loss: -0.2252	Cost: 14.54s
Train Epoch: 750 [81920/90000 (91%)]	Loss: -0.1588	Cost: 13.13s
Train Epoch: 750 	Average Loss: 0.0244
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8689

Learning rate: 9.861849601988368e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 751 [0/90000 (0%)]	Loss: 1.8100	Cost: 39.93s
Train Epoch: 751 [20480/90000 (23%)]	Loss: 0.1472	Cost: 12.03s
Train Epoch: 751 [40960/90000 (45%)]	Loss: -0.0132	Cost: 11.17s
Train Epoch: 751 [61440/90000 (68%)]	Loss: 0.0360	Cost: 6.42s
Train Epoch: 751 [81920/90000 (91%)]	Loss: -0.2188	Cost: 12.64s
Train Epoch: 751 	Average Loss: 0.1590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.9412

Learning rate: 9.86148266695169e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 752 [0/90000 (0%)]	Loss: 2.0890	Cost: 35.79s
Train Epoch: 752 [20480/90000 (23%)]	Loss: -0.0219	Cost: 7.21s
Train Epoch: 752 [40960/90000 (45%)]	Loss: -0.1916	Cost: 17.05s
Train Epoch: 752 [61440/90000 (68%)]	Loss: -0.1257	Cost: 12.38s
Train Epoch: 752 [81920/90000 (91%)]	Loss: -0.2003	Cost: 12.35s
Train Epoch: 752 	Average Loss: 0.0919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8579

Learning rate: 9.861115252105906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 753 [0/90000 (0%)]	Loss: 1.5526	Cost: 43.05s
Train Epoch: 753 [20480/90000 (23%)]	Loss: -0.0360	Cost: 12.20s
Train Epoch: 753 [40960/90000 (45%)]	Loss: -0.2762	Cost: 8.07s
Train Epoch: 753 [61440/90000 (68%)]	Loss: -0.0950	Cost: 6.42s
Train Epoch: 753 [81920/90000 (91%)]	Loss: -0.2251	Cost: 12.86s
Train Epoch: 753 	Average Loss: 0.0574
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8397

Learning rate: 9.860747357487283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 754 [0/90000 (0%)]	Loss: 1.6109	Cost: 27.74s
Train Epoch: 754 [20480/90000 (23%)]	Loss: -0.1007	Cost: 6.03s
Train Epoch: 754 [40960/90000 (45%)]	Loss: 0.0035	Cost: 17.28s
Train Epoch: 754 [61440/90000 (68%)]	Loss: 0.0037	Cost: 12.52s
Train Epoch: 754 [81920/90000 (91%)]	Loss: -0.1739	Cost: 12.19s
Train Epoch: 754 	Average Loss: 0.1136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8848

Learning rate: 9.860378983132128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 755 [0/90000 (0%)]	Loss: 1.6752	Cost: 35.41s
Train Epoch: 755 [20480/90000 (23%)]	Loss: -0.0399	Cost: 11.88s
Train Epoch: 755 [40960/90000 (45%)]	Loss: -0.1210	Cost: 10.49s
Train Epoch: 755 [61440/90000 (68%)]	Loss: -0.1217	Cost: 7.93s
Train Epoch: 755 [81920/90000 (91%)]	Loss: -0.1184	Cost: 8.55s
Train Epoch: 755 	Average Loss: 0.0483
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7248

Saving model as e755_model.pt & e755_waveforms_supplementary.hdf5
Learning rate: 9.860010129076798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 756 [0/90000 (0%)]	Loss: 1.5962	Cost: 36.91s
Train Epoch: 756 [20480/90000 (23%)]	Loss: -0.0674	Cost: 7.26s
Train Epoch: 756 [40960/90000 (45%)]	Loss: -0.2442	Cost: 15.27s
Train Epoch: 756 [61440/90000 (68%)]	Loss: -0.0485	Cost: 12.02s
Train Epoch: 756 [81920/90000 (91%)]	Loss: 0.0645	Cost: 12.97s
Train Epoch: 756 	Average Loss: 0.0571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8629

Learning rate: 9.8596407953577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 757 [0/90000 (0%)]	Loss: 2.0381	Cost: 41.37s
Train Epoch: 757 [20480/90000 (23%)]	Loss: 0.0306	Cost: 12.04s
Train Epoch: 757 [40960/90000 (45%)]	Loss: -0.0016	Cost: 8.46s
Train Epoch: 757 [61440/90000 (68%)]	Loss: 0.0133	Cost: 6.27s
Train Epoch: 757 [81920/90000 (91%)]	Loss: -0.0771	Cost: 12.03s
Train Epoch: 757 	Average Loss: 0.1393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8405

Learning rate: 9.859270982011284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 758 [0/90000 (0%)]	Loss: 1.7178	Cost: 34.91s
Train Epoch: 758 [20480/90000 (23%)]	Loss: -0.0435	Cost: 10.27s
Train Epoch: 758 [40960/90000 (45%)]	Loss: -0.1445	Cost: 20.01s
Train Epoch: 758 [61440/90000 (68%)]	Loss: -0.0871	Cost: 12.27s
Train Epoch: 758 [81920/90000 (91%)]	Loss: -0.1323	Cost: 11.82s
Train Epoch: 758 	Average Loss: 0.0834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.8183

Learning rate: 9.858900689074049e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 759 [0/90000 (0%)]	Loss: 1.8892	Cost: 37.89s
Train Epoch: 759 [20480/90000 (23%)]	Loss: 0.0684	Cost: 11.62s
Train Epoch: 759 [40960/90000 (45%)]	Loss: -0.1706	Cost: 7.49s
Train Epoch: 759 [61440/90000 (68%)]	Loss: -0.1834	Cost: 6.25s
Train Epoch: 759 [81920/90000 (91%)]	Loss: -0.2627	Cost: 13.33s
Train Epoch: 759 	Average Loss: 0.0341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7338

Learning rate: 9.85852991658254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 760 [0/90000 (0%)]	Loss: 1.4781	Cost: 33.17s
Train Epoch: 760 [20480/90000 (23%)]	Loss: -0.0424	Cost: 11.20s
Train Epoch: 760 [40960/90000 (45%)]	Loss: -0.2669	Cost: 15.59s
Train Epoch: 760 [61440/90000 (68%)]	Loss: -0.1735	Cost: 12.25s
Train Epoch: 760 [81920/90000 (91%)]	Loss: -0.2658	Cost: 12.01s
Train Epoch: 760 	Average Loss: -0.0212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7338

Learning rate: 9.858158664573355e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 761 [0/90000 (0%)]	Loss: 1.5388	Cost: 32.92s
Train Epoch: 761 [20480/90000 (23%)]	Loss: -0.1072	Cost: 10.84s
Train Epoch: 761 [40960/90000 (45%)]	Loss: -0.2737	Cost: 6.17s
Train Epoch: 761 [61440/90000 (68%)]	Loss: -0.1707	Cost: 6.12s
Train Epoch: 761 [81920/90000 (91%)]	Loss: -0.3333	Cost: 13.44s
Train Epoch: 761 	Average Loss: -0.0279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7424

Learning rate: 9.857786933083131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 762 [0/90000 (0%)]	Loss: 1.8380	Cost: 27.45s
Train Epoch: 762 [20480/90000 (23%)]	Loss: -0.1962	Cost: 10.70s
Train Epoch: 762 [40960/90000 (45%)]	Loss: -0.3237	Cost: 22.97s
Train Epoch: 762 [61440/90000 (68%)]	Loss: -0.2948	Cost: 13.41s
Train Epoch: 762 [81920/90000 (91%)]	Loss: -0.3273	Cost: 11.96s
Train Epoch: 762 	Average Loss: -0.0618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7967

Learning rate: 9.85741472214856e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 763 [0/90000 (0%)]	Loss: 1.8314	Cost: 47.63s
Train Epoch: 763 [20480/90000 (23%)]	Loss: -0.0620	Cost: 10.67s
Train Epoch: 763 [40960/90000 (45%)]	Loss: -0.3207	Cost: 8.00s
Train Epoch: 763 [61440/90000 (68%)]	Loss: -0.2722	Cost: 6.85s
Train Epoch: 763 [81920/90000 (91%)]	Loss: -0.4387	Cost: 12.07s
Train Epoch: 763 	Average Loss: -0.1116
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.7545

Learning rate: 9.857042031806373e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 764 [0/90000 (0%)]	Loss: 1.7986	Cost: 31.79s
Train Epoch: 764 [20480/90000 (23%)]	Loss: -0.2494	Cost: 6.77s
Train Epoch: 764 [40960/90000 (45%)]	Loss: -0.1532	Cost: 19.40s
Train Epoch: 764 [61440/90000 (68%)]	Loss: -0.3639	Cost: 12.42s
Train Epoch: 764 [81920/90000 (91%)]	Loss: -0.3503	Cost: 12.12s
Train Epoch: 764 	Average Loss: -0.1167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6718

Saving model as e764_model.pt & e764_waveforms_supplementary.hdf5
Learning rate: 9.856668862093358e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 765 [0/90000 (0%)]	Loss: 1.6597	Cost: 43.84s
Train Epoch: 765 [20480/90000 (23%)]	Loss: -0.0796	Cost: 6.45s
Train Epoch: 765 [40960/90000 (45%)]	Loss: -0.2809	Cost: 14.20s
Train Epoch: 765 [61440/90000 (68%)]	Loss: -0.3346	Cost: 8.53s
Train Epoch: 765 [81920/90000 (91%)]	Loss: -0.3879	Cost: 8.69s
Train Epoch: 765 	Average Loss: -0.1592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5826

Saving model as e765_model.pt & e765_waveforms_supplementary.hdf5
Learning rate: 9.856295213046343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 766 [0/90000 (0%)]	Loss: 1.8732	Cost: 30.15s
Train Epoch: 766 [20480/90000 (23%)]	Loss: -0.1926	Cost: 9.01s
Train Epoch: 766 [40960/90000 (45%)]	Loss: -0.4580	Cost: 17.17s
Train Epoch: 766 [61440/90000 (68%)]	Loss: -0.4480	Cost: 13.61s
Train Epoch: 766 [81920/90000 (91%)]	Loss: -0.4884	Cost: 12.28s
Train Epoch: 766 	Average Loss: -0.2093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6452

Learning rate: 9.855921084702205e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 767 [0/90000 (0%)]	Loss: 1.5660	Cost: 34.42s
Train Epoch: 767 [20480/90000 (23%)]	Loss: -0.1625	Cost: 11.46s
Train Epoch: 767 [40960/90000 (45%)]	Loss: -0.3061	Cost: 11.95s
Train Epoch: 767 [61440/90000 (68%)]	Loss: -0.3297	Cost: 8.72s
Train Epoch: 767 [81920/90000 (91%)]	Loss: -0.4101	Cost: 15.17s
Train Epoch: 767 	Average Loss: -0.1660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5819

Saving model as e767_model.pt & e767_waveforms_supplementary.hdf5
Learning rate: 9.85554647709787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 768 [0/90000 (0%)]	Loss: 1.6814	Cost: 30.82s
Train Epoch: 768 [20480/90000 (23%)]	Loss: -0.2143	Cost: 9.02s
Train Epoch: 768 [40960/90000 (45%)]	Loss: -0.5470	Cost: 15.45s
Train Epoch: 768 [61440/90000 (68%)]	Loss: -0.4059	Cost: 12.40s
Train Epoch: 768 [81920/90000 (91%)]	Loss: -0.6124	Cost: 12.24s
Train Epoch: 768 	Average Loss: -0.2167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5393

Saving model as e768_model.pt & e768_waveforms_supplementary.hdf5
Learning rate: 9.85517139027031e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 769 [0/90000 (0%)]	Loss: 1.2265	Cost: 38.60s
Train Epoch: 769 [20480/90000 (23%)]	Loss: -0.3554	Cost: 7.46s
Train Epoch: 769 [40960/90000 (45%)]	Loss: -0.4228	Cost: 14.70s
Train Epoch: 769 [61440/90000 (68%)]	Loss: -0.3119	Cost: 8.71s
Train Epoch: 769 [81920/90000 (91%)]	Loss: -0.4097	Cost: 10.67s
Train Epoch: 769 	Average Loss: -0.2391
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6489

Learning rate: 9.854795824256546e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 770 [0/90000 (0%)]	Loss: 1.6021	Cost: 28.97s
Train Epoch: 770 [20480/90000 (23%)]	Loss: -0.2661	Cost: 8.42s
Train Epoch: 770 [40960/90000 (45%)]	Loss: -0.3316	Cost: 16.44s
Train Epoch: 770 [61440/90000 (68%)]	Loss: -0.4066	Cost: 12.29s
Train Epoch: 770 [81920/90000 (91%)]	Loss: -0.3878	Cost: 12.47s
Train Epoch: 770 	Average Loss: -0.1904
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6243

Learning rate: 9.854419779093642e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 771 [0/90000 (0%)]	Loss: 1.6131	Cost: 32.69s
Train Epoch: 771 [20480/90000 (23%)]	Loss: -0.2468	Cost: 11.92s
Train Epoch: 771 [40960/90000 (45%)]	Loss: -0.4410	Cost: 8.73s
Train Epoch: 771 [61440/90000 (68%)]	Loss: -0.3873	Cost: 8.22s
Train Epoch: 771 [81920/90000 (91%)]	Loss: -0.2086	Cost: 13.31s
Train Epoch: 771 	Average Loss: -0.1841
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6956

Learning rate: 9.854043254818714e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 772 [0/90000 (0%)]	Loss: 1.5133	Cost: 40.96s
Train Epoch: 772 [20480/90000 (23%)]	Loss: -0.2003	Cost: 7.05s
Train Epoch: 772 [40960/90000 (45%)]	Loss: -0.3944	Cost: 18.34s
Train Epoch: 772 [61440/90000 (68%)]	Loss: -0.1527	Cost: 11.88s
Train Epoch: 772 [81920/90000 (91%)]	Loss: -0.3529	Cost: 12.00s
Train Epoch: 772 	Average Loss: -0.0457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6501

Learning rate: 9.853666251468923e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 773 [0/90000 (0%)]	Loss: 1.6221	Cost: 39.00s
Train Epoch: 773 [20480/90000 (23%)]	Loss: -0.1848	Cost: 11.45s
Train Epoch: 773 [40960/90000 (45%)]	Loss: -0.1311	Cost: 8.69s
Train Epoch: 773 [61440/90000 (68%)]	Loss: -0.4774	Cost: 6.42s
Train Epoch: 773 [81920/90000 (91%)]	Loss: -0.5137	Cost: 14.43s
Train Epoch: 773 	Average Loss: -0.1646
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4607

Saving model as e773_model.pt & e773_waveforms_supplementary.hdf5
Learning rate: 9.853288769081479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 774 [0/90000 (0%)]	Loss: 1.6853	Cost: 32.19s
Train Epoch: 774 [20480/90000 (23%)]	Loss: -0.3701	Cost: 6.67s
Train Epoch: 774 [40960/90000 (45%)]	Loss: -0.4509	Cost: 20.61s
Train Epoch: 774 [61440/90000 (68%)]	Loss: -0.4547	Cost: 12.41s
Train Epoch: 774 [81920/90000 (91%)]	Loss: -0.4797	Cost: 12.00s
Train Epoch: 774 	Average Loss: -0.2865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5525

Learning rate: 9.852910807693636e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 775 [0/90000 (0%)]	Loss: 1.4472	Cost: 30.47s
Train Epoch: 775 [20480/90000 (23%)]	Loss: -0.5270	Cost: 8.77s
Train Epoch: 775 [40960/90000 (45%)]	Loss: -0.5425	Cost: 13.81s
Train Epoch: 775 [61440/90000 (68%)]	Loss: -0.5055	Cost: 9.32s
Train Epoch: 775 [81920/90000 (91%)]	Loss: -0.5575	Cost: 11.76s
Train Epoch: 775 	Average Loss: -0.2872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.6154

Learning rate: 9.8525323673427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 776 [0/90000 (0%)]	Loss: 1.6152	Cost: 36.76s
Train Epoch: 776 [20480/90000 (23%)]	Loss: -0.3401	Cost: 11.64s
Train Epoch: 776 [40960/90000 (45%)]	Loss: -0.4507	Cost: 16.56s
Train Epoch: 776 [61440/90000 (68%)]	Loss: -0.3833	Cost: 12.12s
Train Epoch: 776 [81920/90000 (91%)]	Loss: -0.5051	Cost: 11.90s
Train Epoch: 776 	Average Loss: -0.2593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4614

Learning rate: 9.85215344806602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 777 [0/90000 (0%)]	Loss: 1.7471	Cost: 54.94s
Train Epoch: 777 [20480/90000 (23%)]	Loss: -0.4494	Cost: 6.34s
Train Epoch: 777 [40960/90000 (45%)]	Loss: -0.5388	Cost: 13.93s
Train Epoch: 777 [61440/90000 (68%)]	Loss: -0.5757	Cost: 8.59s
Train Epoch: 777 [81920/90000 (91%)]	Loss: -0.4711	Cost: 8.59s
Train Epoch: 777 	Average Loss: -0.3027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5704

Learning rate: 9.851774049900992e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 778 [0/90000 (0%)]	Loss: 1.5083	Cost: 29.22s
Train Epoch: 778 [20480/90000 (23%)]	Loss: -0.3580	Cost: 11.13s
Train Epoch: 778 [40960/90000 (45%)]	Loss: -0.2083	Cost: 18.95s
Train Epoch: 778 [61440/90000 (68%)]	Loss: -0.4820	Cost: 13.76s
Train Epoch: 778 [81920/90000 (91%)]	Loss: -0.5571	Cost: 11.97s
Train Epoch: 778 	Average Loss: -0.2593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5796

Learning rate: 9.851394172885063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 779 [0/90000 (0%)]	Loss: 1.7245	Cost: 48.26s
Train Epoch: 779 [20480/90000 (23%)]	Loss: -0.3964	Cost: 10.53s
Train Epoch: 779 [40960/90000 (45%)]	Loss: -0.3963	Cost: 8.73s
Train Epoch: 779 [61440/90000 (68%)]	Loss: -0.3734	Cost: 7.49s
Train Epoch: 779 [81920/90000 (91%)]	Loss: -0.5142	Cost: 11.68s
Train Epoch: 779 	Average Loss: -0.2678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5961

Learning rate: 9.851013817055725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 780 [0/90000 (0%)]	Loss: 1.5658	Cost: 31.70s
Train Epoch: 780 [20480/90000 (23%)]	Loss: -0.3194	Cost: 9.24s
Train Epoch: 780 [40960/90000 (45%)]	Loss: -0.5256	Cost: 18.93s
Train Epoch: 780 [61440/90000 (68%)]	Loss: -0.5170	Cost: 13.39s
Train Epoch: 780 [81920/90000 (91%)]	Loss: -0.6000	Cost: 12.11s
Train Epoch: 780 	Average Loss: -0.3096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4427

Saving model as e780_model.pt & e780_waveforms_supplementary.hdf5
Learning rate: 9.850632982450517e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 781 [0/90000 (0%)]	Loss: 1.3918	Cost: 50.91s
Train Epoch: 781 [20480/90000 (23%)]	Loss: -0.3432	Cost: 10.40s
Train Epoch: 781 [40960/90000 (45%)]	Loss: -0.2277	Cost: 6.41s
Train Epoch: 781 [61440/90000 (68%)]	Loss: -0.2903	Cost: 6.47s
Train Epoch: 781 [81920/90000 (91%)]	Loss: -0.5021	Cost: 12.46s
Train Epoch: 781 	Average Loss: -0.2481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4915

Learning rate: 9.850251669107029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 782 [0/90000 (0%)]	Loss: 1.6274	Cost: 28.90s
Train Epoch: 782 [20480/90000 (23%)]	Loss: -0.2937	Cost: 7.17s
Train Epoch: 782 [40960/90000 (45%)]	Loss: -0.1193	Cost: 18.04s
Train Epoch: 782 [61440/90000 (68%)]	Loss: -0.2357	Cost: 13.01s
Train Epoch: 782 [81920/90000 (91%)]	Loss: -0.4344	Cost: 12.35s
Train Epoch: 782 	Average Loss: -0.1563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5579

Learning rate: 9.84986987706289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 783 [0/90000 (0%)]	Loss: 1.4987	Cost: 34.47s
Train Epoch: 783 [20480/90000 (23%)]	Loss: -0.2419	Cost: 11.76s
Train Epoch: 783 [40960/90000 (45%)]	Loss: -0.3196	Cost: 8.59s
Train Epoch: 783 [61440/90000 (68%)]	Loss: -0.2706	Cost: 7.48s
Train Epoch: 783 [81920/90000 (91%)]	Loss: -0.3891	Cost: 13.77s
Train Epoch: 783 	Average Loss: -0.1506
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5881

Learning rate: 9.849487606355786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 784 [0/90000 (0%)]	Loss: 1.4017	Cost: 29.43s
Train Epoch: 784 [20480/90000 (23%)]	Loss: -0.3176	Cost: 10.47s
Train Epoch: 784 [40960/90000 (45%)]	Loss: -0.3713	Cost: 21.14s
Train Epoch: 784 [61440/90000 (68%)]	Loss: -0.5855	Cost: 11.98s
Train Epoch: 784 [81920/90000 (91%)]	Loss: -0.5762	Cost: 11.88s
Train Epoch: 784 	Average Loss: -0.2772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.4291

Saving model as e784_model.pt & e784_waveforms_supplementary.hdf5
Learning rate: 9.849104857023443e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 785 [0/90000 (0%)]	Loss: 1.2706	Cost: 42.35s
Train Epoch: 785 [20480/90000 (23%)]	Loss: -0.3461	Cost: 10.20s
Train Epoch: 785 [40960/90000 (45%)]	Loss: -0.3539	Cost: 8.87s
Train Epoch: 785 [61440/90000 (68%)]	Loss: -0.5243	Cost: 7.31s
Train Epoch: 785 [81920/90000 (91%)]	Loss: -0.5411	Cost: 13.92s
Train Epoch: 785 	Average Loss: -0.3392
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3692

Saving model as e785_model.pt & e785_waveforms_supplementary.hdf5
Learning rate: 9.848721629103637e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 786 [0/90000 (0%)]	Loss: 1.3648	Cost: 31.98s
Train Epoch: 786 [20480/90000 (23%)]	Loss: -0.4529	Cost: 7.40s
Train Epoch: 786 [40960/90000 (45%)]	Loss: -0.5921	Cost: 17.85s
Train Epoch: 786 [61440/90000 (68%)]	Loss: -0.6629	Cost: 12.04s
Train Epoch: 786 [81920/90000 (91%)]	Loss: -0.9131	Cost: 11.83s
Train Epoch: 786 	Average Loss: -0.4762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3504

Saving model as e786_model.pt & e786_waveforms_supplementary.hdf5
Learning rate: 9.848337922634192e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 787 [0/90000 (0%)]	Loss: 1.1821	Cost: 31.57s
Train Epoch: 787 [20480/90000 (23%)]	Loss: -0.6221	Cost: 11.68s
Train Epoch: 787 [40960/90000 (45%)]	Loss: -0.6238	Cost: 6.29s
Train Epoch: 787 [61440/90000 (68%)]	Loss: -0.7137	Cost: 6.84s
Train Epoch: 787 [81920/90000 (91%)]	Loss: -0.7872	Cost: 14.68s
Train Epoch: 787 	Average Loss: -0.5236
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3956

Learning rate: 9.847953737652978e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 788 [0/90000 (0%)]	Loss: 1.1724	Cost: 34.25s
Train Epoch: 788 [20480/90000 (23%)]	Loss: -0.5566	Cost: 11.77s
Train Epoch: 788 [40960/90000 (45%)]	Loss: -0.6596	Cost: 16.55s
Train Epoch: 788 [61440/90000 (68%)]	Loss: -0.6592	Cost: 12.40s
Train Epoch: 788 [81920/90000 (91%)]	Loss: -0.7135	Cost: 12.03s
Train Epoch: 788 	Average Loss: -0.5264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3271

Saving model as e788_model.pt & e788_waveforms_supplementary.hdf5
Learning rate: 9.847569074197914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 789 [0/90000 (0%)]	Loss: 1.1177	Cost: 41.95s
Train Epoch: 789 [20480/90000 (23%)]	Loss: -0.5924	Cost: 7.94s
Train Epoch: 789 [40960/90000 (45%)]	Loss: -0.6802	Cost: 10.30s
Train Epoch: 789 [61440/90000 (68%)]	Loss: -0.6159	Cost: 8.75s
Train Epoch: 789 [81920/90000 (91%)]	Loss: -0.7845	Cost: 9.27s
Train Epoch: 789 	Average Loss: -0.5213
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2029

Saving model as e789_model.pt & e789_waveforms_supplementary.hdf5
Learning rate: 9.847183932306961e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 790 [0/90000 (0%)]	Loss: 1.2959	Cost: 29.62s
Train Epoch: 790 [20480/90000 (23%)]	Loss: -0.5636	Cost: 9.60s
Train Epoch: 790 [40960/90000 (45%)]	Loss: -0.7287	Cost: 21.81s
Train Epoch: 790 [61440/90000 (68%)]	Loss: -0.7789	Cost: 12.20s
Train Epoch: 790 [81920/90000 (91%)]	Loss: -0.8151	Cost: 11.82s
Train Epoch: 790 	Average Loss: -0.5587
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2482

Learning rate: 9.846798312018134e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 791 [0/90000 (0%)]	Loss: 1.3328	Cost: 40.15s
Train Epoch: 791 [20480/90000 (23%)]	Loss: -0.7509	Cost: 6.28s
Train Epoch: 791 [40960/90000 (45%)]	Loss: -0.7543	Cost: 14.19s
Train Epoch: 791 [61440/90000 (68%)]	Loss: -0.8147	Cost: 8.52s
Train Epoch: 791 [81920/90000 (91%)]	Loss: -0.7133	Cost: 8.87s
Train Epoch: 791 	Average Loss: -0.5779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3652

Learning rate: 9.846412213369493e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 792 [0/90000 (0%)]	Loss: 1.0881	Cost: 28.37s
Train Epoch: 792 [20480/90000 (23%)]	Loss: -0.5825	Cost: 6.81s
Train Epoch: 792 [40960/90000 (45%)]	Loss: -0.7358	Cost: 21.62s
Train Epoch: 792 [61440/90000 (68%)]	Loss: -0.6768	Cost: 13.27s
Train Epoch: 792 [81920/90000 (91%)]	Loss: -0.7358	Cost: 12.23s
Train Epoch: 792 	Average Loss: -0.5033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3436

Learning rate: 9.84602563639914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 793 [0/90000 (0%)]	Loss: 1.1278	Cost: 36.63s
Train Epoch: 793 [20480/90000 (23%)]	Loss: -0.6321	Cost: 10.76s
Train Epoch: 793 [40960/90000 (45%)]	Loss: -0.5753	Cost: 10.23s
Train Epoch: 793 [61440/90000 (68%)]	Loss: -0.8249	Cost: 9.03s
Train Epoch: 793 [81920/90000 (91%)]	Loss: -0.8105	Cost: 11.84s
Train Epoch: 793 	Average Loss: -0.5353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3005

Learning rate: 9.845638581145233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 794 [0/90000 (0%)]	Loss: 1.4210	Cost: 37.47s
Train Epoch: 794 [20480/90000 (23%)]	Loss: -0.4889	Cost: 8.25s
Train Epoch: 794 [40960/90000 (45%)]	Loss: -0.7067	Cost: 16.16s
Train Epoch: 794 [61440/90000 (68%)]	Loss: -0.7647	Cost: 11.99s
Train Epoch: 794 [81920/90000 (91%)]	Loss: -0.8592	Cost: 12.22s
Train Epoch: 794 	Average Loss: -0.5364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3377

Learning rate: 9.845251047645971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 795 [0/90000 (0%)]	Loss: 1.3862	Cost: 35.05s
Train Epoch: 795 [20480/90000 (23%)]	Loss: -0.6547	Cost: 12.06s
Train Epoch: 795 [40960/90000 (45%)]	Loss: -0.5811	Cost: 8.59s
Train Epoch: 795 [61440/90000 (68%)]	Loss: -0.7714	Cost: 7.04s
Train Epoch: 795 [81920/90000 (91%)]	Loss: -0.8401	Cost: 11.23s
Train Epoch: 795 	Average Loss: -0.5030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3092

Learning rate: 9.844863035939603e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 796 [0/90000 (0%)]	Loss: 1.3210	Cost: 35.95s
Train Epoch: 796 [20480/90000 (23%)]	Loss: -0.7274	Cost: 6.72s
Train Epoch: 796 [40960/90000 (45%)]	Loss: -0.7838	Cost: 18.52s
Train Epoch: 796 [61440/90000 (68%)]	Loss: -0.7534	Cost: 12.00s
Train Epoch: 796 [81920/90000 (91%)]	Loss: -0.9173	Cost: 12.40s
Train Epoch: 796 	Average Loss: -0.5614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1812

Saving model as e796_model.pt & e796_waveforms_supplementary.hdf5
Learning rate: 9.844474546064422e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 797 [0/90000 (0%)]	Loss: 1.4632	Cost: 33.15s
Train Epoch: 797 [20480/90000 (23%)]	Loss: -0.6364	Cost: 12.32s
Train Epoch: 797 [40960/90000 (45%)]	Loss: -0.6728	Cost: 6.52s
Train Epoch: 797 [61440/90000 (68%)]	Loss: -0.7729	Cost: 8.54s
Train Epoch: 797 [81920/90000 (91%)]	Loss: -0.7985	Cost: 10.43s
Train Epoch: 797 	Average Loss: -0.6023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2710

Learning rate: 9.844085578058772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 798 [0/90000 (0%)]	Loss: 1.0125	Cost: 33.14s
Train Epoch: 798 [20480/90000 (23%)]	Loss: -0.6622	Cost: 10.31s
Train Epoch: 798 [40960/90000 (45%)]	Loss: -0.8728	Cost: 24.14s
Train Epoch: 798 [61440/90000 (68%)]	Loss: -0.7913	Cost: 12.12s
Train Epoch: 798 [81920/90000 (91%)]	Loss: -0.8796	Cost: 11.93s
Train Epoch: 798 	Average Loss: -0.5898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2617

Learning rate: 9.843696131961044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 799 [0/90000 (0%)]	Loss: 1.0971	Cost: 36.34s
Train Epoch: 799 [20480/90000 (23%)]	Loss: -0.7560	Cost: 7.52s
Train Epoch: 799 [40960/90000 (45%)]	Loss: -0.7936	Cost: 11.90s
Train Epoch: 799 [61440/90000 (68%)]	Loss: -0.8365	Cost: 8.66s
Train Epoch: 799 [81920/90000 (91%)]	Loss: -0.8730	Cost: 12.27s
Train Epoch: 799 	Average Loss: -0.6583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1894

Learning rate: 9.843306207809673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 800 [0/90000 (0%)]	Loss: 1.2975	Cost: 30.85s
Train Epoch: 800 [20480/90000 (23%)]	Loss: -0.7664	Cost: 9.95s
Train Epoch: 800 [40960/90000 (45%)]	Loss: -0.7516	Cost: 19.36s
Train Epoch: 800 [61440/90000 (68%)]	Loss: -0.7978	Cost: 12.57s
Train Epoch: 800 [81920/90000 (91%)]	Loss: -1.0233	Cost: 11.97s
Train Epoch: 800 	Average Loss: -0.6720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2294

Learning rate: 9.842915805643143e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 801 [0/90000 (0%)]	Loss: 0.7497	Cost: 42.53s
Train Epoch: 801 [20480/90000 (23%)]	Loss: -0.7603	Cost: 12.13s
Train Epoch: 801 [40960/90000 (45%)]	Loss: -0.8114	Cost: 6.79s
Train Epoch: 801 [61440/90000 (68%)]	Loss: -0.7876	Cost: 6.06s
Train Epoch: 801 [81920/90000 (91%)]	Loss: -0.7999	Cost: 14.35s
Train Epoch: 801 	Average Loss: -0.6270
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3707

Learning rate: 9.842524925499985e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 802 [0/90000 (0%)]	Loss: 1.3330	Cost: 32.20s
Train Epoch: 802 [20480/90000 (23%)]	Loss: -0.7500	Cost: 10.36s
Train Epoch: 802 [40960/90000 (45%)]	Loss: -0.7502	Cost: 26.51s
Train Epoch: 802 [61440/90000 (68%)]	Loss: -0.6987	Cost: 11.84s
Train Epoch: 802 [81920/90000 (91%)]	Loss: -0.8021	Cost: 11.84s
Train Epoch: 802 	Average Loss: -0.5732
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2098

Learning rate: 9.842133567418779e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 803 [0/90000 (0%)]	Loss: 0.9479	Cost: 59.34s
Train Epoch: 803 [20480/90000 (23%)]	Loss: -0.7825	Cost: 6.50s
Train Epoch: 803 [40960/90000 (45%)]	Loss: -0.7712	Cost: 14.03s
Train Epoch: 803 [61440/90000 (68%)]	Loss: -0.7580	Cost: 8.81s
Train Epoch: 803 [81920/90000 (91%)]	Loss: -0.6531	Cost: 8.49s
Train Epoch: 803 	Average Loss: -0.5721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3563

Learning rate: 9.841741731438147e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 804 [0/90000 (0%)]	Loss: 1.4004	Cost: 29.94s
Train Epoch: 804 [20480/90000 (23%)]	Loss: -0.5648	Cost: 11.70s
Train Epoch: 804 [40960/90000 (45%)]	Loss: -0.6077	Cost: 22.97s
Train Epoch: 804 [61440/90000 (68%)]	Loss: -0.8167	Cost: 12.82s
Train Epoch: 804 [81920/90000 (91%)]	Loss: -0.8843	Cost: 12.19s
Train Epoch: 804 	Average Loss: -0.5266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3144

Learning rate: 9.841349417596765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 805 [0/90000 (0%)]	Loss: 1.1474	Cost: 44.92s
Train Epoch: 805 [20480/90000 (23%)]	Loss: -0.6356	Cost: 6.80s
Train Epoch: 805 [40960/90000 (45%)]	Loss: -0.7703	Cost: 14.60s
Train Epoch: 805 [61440/90000 (68%)]	Loss: -0.8183	Cost: 8.76s
Train Epoch: 805 [81920/90000 (91%)]	Loss: -0.8484	Cost: 8.87s
Train Epoch: 805 	Average Loss: -0.5986
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2498

Learning rate: 9.840956625933353e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 806 [0/90000 (0%)]	Loss: 1.3973	Cost: 33.06s
Train Epoch: 806 [20480/90000 (23%)]	Loss: -0.8473	Cost: 11.32s
Train Epoch: 806 [40960/90000 (45%)]	Loss: -0.7658	Cost: 17.19s
Train Epoch: 806 [61440/90000 (68%)]	Loss: -0.9858	Cost: 12.92s
Train Epoch: 806 [81920/90000 (91%)]	Loss: -0.9087	Cost: 12.13s
Train Epoch: 806 	Average Loss: -0.6702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1748

Saving model as e806_model.pt & e806_waveforms_supplementary.hdf5
Learning rate: 9.840563356486677e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 807 [0/90000 (0%)]	Loss: 1.1517	Cost: 50.36s
Train Epoch: 807 [20480/90000 (23%)]	Loss: -0.7131	Cost: 6.28s
Train Epoch: 807 [40960/90000 (45%)]	Loss: -0.8359	Cost: 13.56s
Train Epoch: 807 [61440/90000 (68%)]	Loss: -0.8708	Cost: 8.74s
Train Epoch: 807 [81920/90000 (91%)]	Loss: -0.6780	Cost: 7.76s
Train Epoch: 807 	Average Loss: -0.6576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.5039

Learning rate: 9.840169609295549e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 808 [0/90000 (0%)]	Loss: 1.1629	Cost: 29.51s
Train Epoch: 808 [20480/90000 (23%)]	Loss: -0.2742	Cost: 7.80s
Train Epoch: 808 [40960/90000 (45%)]	Loss: -0.5948	Cost: 16.50s
Train Epoch: 808 [61440/90000 (68%)]	Loss: -0.6339	Cost: 11.93s
Train Epoch: 808 [81920/90000 (91%)]	Loss: -0.6530	Cost: 12.43s
Train Epoch: 808 	Average Loss: -0.3816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3138

Learning rate: 9.839775384398833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 809 [0/90000 (0%)]	Loss: 1.3198	Cost: 31.31s
Train Epoch: 809 [20480/90000 (23%)]	Loss: -0.6392	Cost: 12.26s
Train Epoch: 809 [40960/90000 (45%)]	Loss: -0.7350	Cost: 7.00s
Train Epoch: 809 [61440/90000 (68%)]	Loss: -0.7795	Cost: 7.75s
Train Epoch: 809 [81920/90000 (91%)]	Loss: -0.9625	Cost: 14.22s
Train Epoch: 809 	Average Loss: -0.6296
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1905

Learning rate: 9.839380681835437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 810 [0/90000 (0%)]	Loss: 0.9571	Cost: 45.99s
Train Epoch: 810 [20480/90000 (23%)]	Loss: -0.4649	Cost: 12.14s
Train Epoch: 810 [40960/90000 (45%)]	Loss: -0.7693	Cost: 13.21s
Train Epoch: 810 [61440/90000 (68%)]	Loss: -0.8917	Cost: 12.01s
Train Epoch: 810 [81920/90000 (91%)]	Loss: -0.8850	Cost: 11.95s
Train Epoch: 810 	Average Loss: -0.6564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1354

Saving model as e810_model.pt & e810_waveforms_supplementary.hdf5
Learning rate: 9.838985501644315e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 811 [0/90000 (0%)]	Loss: 1.1471	Cost: 33.78s
Train Epoch: 811 [20480/90000 (23%)]	Loss: -0.9533	Cost: 6.25s
Train Epoch: 811 [40960/90000 (45%)]	Loss: -0.9195	Cost: 14.76s
Train Epoch: 811 [61440/90000 (68%)]	Loss: -0.8966	Cost: 8.89s
Train Epoch: 811 [81920/90000 (91%)]	Loss: -0.9958	Cost: 9.46s
Train Epoch: 811 	Average Loss: -0.7691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1718

Learning rate: 9.838589843864472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 812 [0/90000 (0%)]	Loss: 1.0640	Cost: 39.47s
Train Epoch: 812 [20480/90000 (23%)]	Loss: -0.8157	Cost: 12.93s
Train Epoch: 812 [40960/90000 (45%)]	Loss: -1.0463	Cost: 12.31s
Train Epoch: 812 [61440/90000 (68%)]	Loss: -1.1581	Cost: 12.38s
Train Epoch: 812 [81920/90000 (91%)]	Loss: -1.0879	Cost: 12.04s
Train Epoch: 812 	Average Loss: -0.8374
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9866

Saving model as e812_model.pt & e812_waveforms_supplementary.hdf5
Learning rate: 9.838193708534956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 813 [0/90000 (0%)]	Loss: 1.1326	Cost: 34.93s
Train Epoch: 813 [20480/90000 (23%)]	Loss: -0.9628	Cost: 6.41s
Train Epoch: 813 [40960/90000 (45%)]	Loss: -1.1181	Cost: 14.58s
Train Epoch: 813 [61440/90000 (68%)]	Loss: -1.1646	Cost: 9.16s
Train Epoch: 813 [81920/90000 (91%)]	Loss: -1.1260	Cost: 9.92s
Train Epoch: 813 	Average Loss: -0.8675
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2028

Learning rate: 9.837797095694866e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 814 [0/90000 (0%)]	Loss: 0.8014	Cost: 34.60s
Train Epoch: 814 [20480/90000 (23%)]	Loss: -0.8730	Cost: 12.57s
Train Epoch: 814 [40960/90000 (45%)]	Loss: -0.8626	Cost: 20.40s
Train Epoch: 814 [61440/90000 (68%)]	Loss: -1.0105	Cost: 12.12s
Train Epoch: 814 [81920/90000 (91%)]	Loss: -1.1217	Cost: 11.85s
Train Epoch: 814 	Average Loss: -0.8062
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0728

Learning rate: 9.837400005383343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 815 [0/90000 (0%)]	Loss: 0.9738	Cost: 46.42s
Train Epoch: 815 [20480/90000 (23%)]	Loss: -0.8365	Cost: 6.25s
Train Epoch: 815 [40960/90000 (45%)]	Loss: -0.9369	Cost: 15.52s
Train Epoch: 815 [61440/90000 (68%)]	Loss: -1.1309	Cost: 8.48s
Train Epoch: 815 [81920/90000 (91%)]	Loss: -1.1430	Cost: 8.44s
Train Epoch: 815 	Average Loss: -0.8671
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9633

Saving model as e815_model.pt & e815_waveforms_supplementary.hdf5
Learning rate: 9.837002437639581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 816 [0/90000 (0%)]	Loss: 0.9203	Cost: 31.86s
Train Epoch: 816 [20480/90000 (23%)]	Loss: -0.8951	Cost: 9.92s
Train Epoch: 816 [40960/90000 (45%)]	Loss: -1.0393	Cost: 15.74s
Train Epoch: 816 [61440/90000 (68%)]	Loss: -1.0434	Cost: 11.98s
Train Epoch: 816 [81920/90000 (91%)]	Loss: -1.0886	Cost: 12.12s
Train Epoch: 816 	Average Loss: -0.8658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1503

Learning rate: 9.836604392502818e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 817 [0/90000 (0%)]	Loss: 0.8432	Cost: 35.22s
Train Epoch: 817 [20480/90000 (23%)]	Loss: -0.7878	Cost: 11.07s
Train Epoch: 817 [40960/90000 (45%)]	Loss: -1.0689	Cost: 8.42s
Train Epoch: 817 [61440/90000 (68%)]	Loss: -0.9871	Cost: 7.23s
Train Epoch: 817 [81920/90000 (91%)]	Loss: -1.1347	Cost: 12.20s
Train Epoch: 817 	Average Loss: -0.8704
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0647

Learning rate: 9.836205870012337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 818 [0/90000 (0%)]	Loss: 1.2259	Cost: 29.73s
Train Epoch: 818 [20480/90000 (23%)]	Loss: -1.0208	Cost: 7.36s
Train Epoch: 818 [40960/90000 (45%)]	Loss: -1.0246	Cost: 18.61s
Train Epoch: 818 [61440/90000 (68%)]	Loss: -1.0674	Cost: 14.09s
Train Epoch: 818 [81920/90000 (91%)]	Loss: -1.0811	Cost: 12.39s
Train Epoch: 818 	Average Loss: -0.8615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1760

Learning rate: 9.835806870207475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 819 [0/90000 (0%)]	Loss: 0.7302	Cost: 33.27s
Train Epoch: 819 [20480/90000 (23%)]	Loss: -0.9689	Cost: 14.42s
Train Epoch: 819 [40960/90000 (45%)]	Loss: -1.2065	Cost: 11.24s
Train Epoch: 819 [61440/90000 (68%)]	Loss: -1.2636	Cost: 8.93s
Train Epoch: 819 [81920/90000 (91%)]	Loss: -1.0673	Cost: 12.23s
Train Epoch: 819 	Average Loss: -0.9408
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0084

Learning rate: 9.835407393127609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 820 [0/90000 (0%)]	Loss: 0.7298	Cost: 40.23s
Train Epoch: 820 [20480/90000 (23%)]	Loss: -0.9470	Cost: 7.00s
Train Epoch: 820 [40960/90000 (45%)]	Loss: -1.1181	Cost: 16.33s
Train Epoch: 820 [61440/90000 (68%)]	Loss: -1.1266	Cost: 12.42s
Train Epoch: 820 [81920/90000 (91%)]	Loss: -1.1715	Cost: 12.53s
Train Epoch: 820 	Average Loss: -0.9194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0433

Learning rate: 9.835007438812164e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 821 [0/90000 (0%)]	Loss: 0.9787	Cost: 35.78s
Train Epoch: 821 [20480/90000 (23%)]	Loss: -0.9273	Cost: 12.12s
Train Epoch: 821 [40960/90000 (45%)]	Loss: -1.1863	Cost: 9.19s
Train Epoch: 821 [61440/90000 (68%)]	Loss: -1.1726	Cost: 6.53s
Train Epoch: 821 [81920/90000 (91%)]	Loss: -1.2293	Cost: 12.74s
Train Epoch: 821 	Average Loss: -0.8945
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0567

Learning rate: 9.834607007300618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 822 [0/90000 (0%)]	Loss: 1.3775	Cost: 35.43s
Train Epoch: 822 [20480/90000 (23%)]	Loss: -0.9306	Cost: 9.46s
Train Epoch: 822 [40960/90000 (45%)]	Loss: -1.0761	Cost: 21.33s
Train Epoch: 822 [61440/90000 (68%)]	Loss: -1.2376	Cost: 12.51s
Train Epoch: 822 [81920/90000 (91%)]	Loss: -1.3672	Cost: 11.72s
Train Epoch: 822 	Average Loss: -0.9215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9599

Saving model as e822_model.pt & e822_waveforms_supplementary.hdf5
Learning rate: 9.834206098632488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 823 [0/90000 (0%)]	Loss: 0.8999	Cost: 42.24s
Train Epoch: 823 [20480/90000 (23%)]	Loss: -1.1912	Cost: 6.49s
Train Epoch: 823 [40960/90000 (45%)]	Loss: -1.2712	Cost: 14.35s
Train Epoch: 823 [61440/90000 (68%)]	Loss: -1.1154	Cost: 8.84s
Train Epoch: 823 [81920/90000 (91%)]	Loss: -1.0430	Cost: 10.72s
Train Epoch: 823 	Average Loss: -0.9980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9818

Learning rate: 9.833804712847345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 824 [0/90000 (0%)]	Loss: 1.0502	Cost: 40.73s
Train Epoch: 824 [20480/90000 (23%)]	Loss: -0.9042	Cost: 8.07s
Train Epoch: 824 [40960/90000 (45%)]	Loss: -0.9353	Cost: 15.96s
Train Epoch: 824 [61440/90000 (68%)]	Loss: -0.9915	Cost: 12.05s
Train Epoch: 824 [81920/90000 (91%)]	Loss: -1.1059	Cost: 11.70s
Train Epoch: 824 	Average Loss: -0.8282
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1585

Learning rate: 9.833402849984804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 825 [0/90000 (0%)]	Loss: 1.1521	Cost: 31.52s
Train Epoch: 825 [20480/90000 (23%)]	Loss: -0.9196	Cost: 6.54s
Train Epoch: 825 [40960/90000 (45%)]	Loss: -0.9818	Cost: 13.64s
Train Epoch: 825 [61440/90000 (68%)]	Loss: -1.1432	Cost: 8.47s
Train Epoch: 825 [81920/90000 (91%)]	Loss: -1.0713	Cost: 8.90s
Train Epoch: 825 	Average Loss: -0.8324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0761

Learning rate: 9.833000510084526e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 826 [0/90000 (0%)]	Loss: 0.9509	Cost: 32.22s
Train Epoch: 826 [20480/90000 (23%)]	Loss: -1.0681	Cost: 10.36s
Train Epoch: 826 [40960/90000 (45%)]	Loss: -1.0665	Cost: 24.43s
Train Epoch: 826 [61440/90000 (68%)]	Loss: -1.2548	Cost: 12.21s
Train Epoch: 826 [81920/90000 (91%)]	Loss: -1.1875	Cost: 11.91s
Train Epoch: 826 	Average Loss: -0.9192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9681

Learning rate: 9.832597693186221e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 827 [0/90000 (0%)]	Loss: 1.0410	Cost: 40.96s
Train Epoch: 827 [20480/90000 (23%)]	Loss: -1.1090	Cost: 6.47s
Train Epoch: 827 [40960/90000 (45%)]	Loss: -1.2417	Cost: 14.98s
Train Epoch: 827 [61440/90000 (68%)]	Loss: -1.3550	Cost: 8.53s
Train Epoch: 827 [81920/90000 (91%)]	Loss: -1.3258	Cost: 8.90s
Train Epoch: 827 	Average Loss: -1.0489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9673

Learning rate: 9.832194399329644e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 828 [0/90000 (0%)]	Loss: 0.8974	Cost: 32.53s
Train Epoch: 828 [20480/90000 (23%)]	Loss: -1.1242	Cost: 9.58s
Train Epoch: 828 [40960/90000 (45%)]	Loss: -1.2589	Cost: 15.40s
Train Epoch: 828 [61440/90000 (68%)]	Loss: -1.3056	Cost: 13.78s
Train Epoch: 828 [81920/90000 (91%)]	Loss: -1.3177	Cost: 12.29s
Train Epoch: 828 	Average Loss: -1.0955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8773

Saving model as e828_model.pt & e828_waveforms_supplementary.hdf5
Learning rate: 9.831790628554601e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 829 [0/90000 (0%)]	Loss: 0.9381	Cost: 50.80s
Train Epoch: 829 [20480/90000 (23%)]	Loss: -1.1919	Cost: 6.43s
Train Epoch: 829 [40960/90000 (45%)]	Loss: -0.9958	Cost: 13.50s
Train Epoch: 829 [61440/90000 (68%)]	Loss: -1.2498	Cost: 8.57s
Train Epoch: 829 [81920/90000 (91%)]	Loss: -1.2914	Cost: 7.75s
Train Epoch: 829 	Average Loss: -1.0113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9692

Learning rate: 9.831386380900942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 830 [0/90000 (0%)]	Loss: 0.8389	Cost: 26.05s
Train Epoch: 830 [20480/90000 (23%)]	Loss: -1.2496	Cost: 8.12s
Train Epoch: 830 [40960/90000 (45%)]	Loss: -1.1311	Cost: 17.39s
Train Epoch: 830 [61440/90000 (68%)]	Loss: -1.1165	Cost: 12.16s
Train Epoch: 830 [81920/90000 (91%)]	Loss: -1.2656	Cost: 12.18s
Train Epoch: 830 	Average Loss: -1.0231
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.3283

Learning rate: 9.830981656408563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 831 [0/90000 (0%)]	Loss: 1.2418	Cost: 37.72s
Train Epoch: 831 [20480/90000 (23%)]	Loss: -0.6783	Cost: 12.10s
Train Epoch: 831 [40960/90000 (45%)]	Loss: -0.6855	Cost: 10.70s
Train Epoch: 831 [61440/90000 (68%)]	Loss: -0.5509	Cost: 6.31s
Train Epoch: 831 [81920/90000 (91%)]	Loss: -0.7040	Cost: 10.89s
Train Epoch: 831 	Average Loss: -0.4946
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.2663

Learning rate: 9.830576455117411e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 832 [0/90000 (0%)]	Loss: 1.1272	Cost: 30.06s
Train Epoch: 832 [20480/90000 (23%)]	Loss: -0.7197	Cost: 9.33s
Train Epoch: 832 [40960/90000 (45%)]	Loss: -0.9807	Cost: 14.77s
Train Epoch: 832 [61440/90000 (68%)]	Loss: -1.0589	Cost: 13.21s
Train Epoch: 832 [81920/90000 (91%)]	Loss: -0.9778	Cost: 12.14s
Train Epoch: 832 	Average Loss: -0.8565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0889

Learning rate: 9.830170777067474e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 833 [0/90000 (0%)]	Loss: 0.9645	Cost: 39.07s
Train Epoch: 833 [20480/90000 (23%)]	Loss: -1.1190	Cost: 14.26s
Train Epoch: 833 [40960/90000 (45%)]	Loss: -1.1934	Cost: 12.40s
Train Epoch: 833 [61440/90000 (68%)]	Loss: -1.0566	Cost: 7.09s
Train Epoch: 833 [81920/90000 (91%)]	Loss: -0.9895	Cost: 6.84s
Train Epoch: 833 	Average Loss: -0.8905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0724

Learning rate: 9.829764622298796e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 834 [0/90000 (0%)]	Loss: 1.2281	Cost: 34.92s
Train Epoch: 834 [20480/90000 (23%)]	Loss: -0.9641	Cost: 8.50s
Train Epoch: 834 [40960/90000 (45%)]	Loss: -1.0267	Cost: 8.51s
Train Epoch: 834 [61440/90000 (68%)]	Loss: -1.1335	Cost: 6.90s
Train Epoch: 834 [81920/90000 (91%)]	Loss: -1.2172	Cost: 18.23s
Train Epoch: 834 	Average Loss: -0.9233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0441

Learning rate: 9.829357990851458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 835 [0/90000 (0%)]	Loss: 1.2794	Cost: 36.32s
Train Epoch: 835 [20480/90000 (23%)]	Loss: -0.9800	Cost: 12.35s
Train Epoch: 835 [40960/90000 (45%)]	Loss: -1.1401	Cost: 12.16s
Train Epoch: 835 [61440/90000 (68%)]	Loss: -1.2382	Cost: 11.88s
Train Epoch: 835 [81920/90000 (91%)]	Loss: -1.2578	Cost: 8.29s
Train Epoch: 835 	Average Loss: -0.9725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9195

Learning rate: 9.828950882765597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 836 [0/90000 (0%)]	Loss: 1.1845	Cost: 30.70s
Train Epoch: 836 [20480/90000 (23%)]	Loss: -0.8712	Cost: 9.51s
Train Epoch: 836 [40960/90000 (45%)]	Loss: -1.2980	Cost: 12.09s
Train Epoch: 836 [61440/90000 (68%)]	Loss: -1.2223	Cost: 9.07s
Train Epoch: 836 [81920/90000 (91%)]	Loss: -1.2551	Cost: 9.18s
Train Epoch: 836 	Average Loss: -0.9343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.1282

Learning rate: 9.82854329808139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 837 [0/90000 (0%)]	Loss: 1.0024	Cost: 32.27s
Train Epoch: 837 [20480/90000 (23%)]	Loss: -1.0773	Cost: 13.68s
Train Epoch: 837 [40960/90000 (45%)]	Loss: -1.1842	Cost: 14.96s
Train Epoch: 837 [61440/90000 (68%)]	Loss: -1.2395	Cost: 12.24s
Train Epoch: 837 [81920/90000 (91%)]	Loss: -1.3145	Cost: 11.87s
Train Epoch: 837 	Average Loss: -0.9798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0423

Learning rate: 9.828135236839064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 838 [0/90000 (0%)]	Loss: 0.9749	Cost: 34.19s
Train Epoch: 838 [20480/90000 (23%)]	Loss: -1.1373	Cost: 9.47s
Train Epoch: 838 [40960/90000 (45%)]	Loss: -1.3424	Cost: 10.05s
Train Epoch: 838 [61440/90000 (68%)]	Loss: -1.1823	Cost: 8.11s
Train Epoch: 838 [81920/90000 (91%)]	Loss: -1.2622	Cost: 14.32s
Train Epoch: 838 	Average Loss: -1.0644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9596

Learning rate: 9.827726699078896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 839 [0/90000 (0%)]	Loss: 0.8723	Cost: 40.47s
Train Epoch: 839 [20480/90000 (23%)]	Loss: -1.2405	Cost: 9.07s
Train Epoch: 839 [40960/90000 (45%)]	Loss: -1.3997	Cost: 16.87s
Train Epoch: 839 [61440/90000 (68%)]	Loss: -1.2929	Cost: 12.22s
Train Epoch: 839 [81920/90000 (91%)]	Loss: -1.3876	Cost: 11.89s
Train Epoch: 839 	Average Loss: -1.1653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0273

Learning rate: 9.827317684841204e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 840 [0/90000 (0%)]	Loss: 0.8933	Cost: 37.12s
Train Epoch: 840 [20480/90000 (23%)]	Loss: -1.1976	Cost: 6.26s
Train Epoch: 840 [40960/90000 (45%)]	Loss: -1.3734	Cost: 14.34s
Train Epoch: 840 [61440/90000 (68%)]	Loss: -1.4113	Cost: 8.55s
Train Epoch: 840 [81920/90000 (91%)]	Loss: -1.3598	Cost: 8.76s
Train Epoch: 840 	Average Loss: -1.1004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9845

Learning rate: 9.826908194166357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 841 [0/90000 (0%)]	Loss: 0.8293	Cost: 28.81s
Train Epoch: 841 [20480/90000 (23%)]	Loss: -1.1573	Cost: 9.53s
Train Epoch: 841 [40960/90000 (45%)]	Loss: -1.2958	Cost: 23.56s
Train Epoch: 841 [61440/90000 (68%)]	Loss: -1.1822	Cost: 12.55s
Train Epoch: 841 [81920/90000 (91%)]	Loss: -1.4414	Cost: 12.03s
Train Epoch: 841 	Average Loss: -1.0932
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9136

Learning rate: 9.826498227094772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 842 [0/90000 (0%)]	Loss: 0.8057	Cost: 42.79s
Train Epoch: 842 [20480/90000 (23%)]	Loss: -1.2698	Cost: 8.91s
Train Epoch: 842 [40960/90000 (45%)]	Loss: -1.3356	Cost: 10.72s
Train Epoch: 842 [61440/90000 (68%)]	Loss: -1.4674	Cost: 8.74s
Train Epoch: 842 [81920/90000 (91%)]	Loss: -1.4878	Cost: 9.80s
Train Epoch: 842 	Average Loss: -1.2203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8547

Saving model as e842_model.pt & e842_waveforms_supplementary.hdf5
Learning rate: 9.826087783666908e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 843 [0/90000 (0%)]	Loss: 0.6610	Cost: 34.52s
Train Epoch: 843 [20480/90000 (23%)]	Loss: -1.2193	Cost: 10.38s
Train Epoch: 843 [40960/90000 (45%)]	Loss: -1.4112	Cost: 18.50s
Train Epoch: 843 [61440/90000 (68%)]	Loss: -1.2703	Cost: 12.55s
Train Epoch: 843 [81920/90000 (91%)]	Loss: -1.3512	Cost: 12.07s
Train Epoch: 843 	Average Loss: -1.1585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8703

Learning rate: 9.825676863923276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 844 [0/90000 (0%)]	Loss: 0.9843	Cost: 47.62s
Train Epoch: 844 [20480/90000 (23%)]	Loss: -1.2794	Cost: 7.31s
Train Epoch: 844 [40960/90000 (45%)]	Loss: -1.2961	Cost: 12.60s
Train Epoch: 844 [61440/90000 (68%)]	Loss: -1.2892	Cost: 8.58s
Train Epoch: 844 [81920/90000 (91%)]	Loss: -1.2897	Cost: 7.35s
Train Epoch: 844 	Average Loss: -1.0706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8220

Saving model as e844_model.pt & e844_waveforms_supplementary.hdf5
Learning rate: 9.825265467904433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 845 [0/90000 (0%)]	Loss: 0.9852	Cost: 29.12s
Train Epoch: 845 [20480/90000 (23%)]	Loss: -1.3856	Cost: 12.43s
Train Epoch: 845 [40960/90000 (45%)]	Loss: -1.4482	Cost: 12.22s
Train Epoch: 845 [61440/90000 (68%)]	Loss: -1.3152	Cost: 12.27s
Train Epoch: 845 [81920/90000 (91%)]	Loss: -1.3468	Cost: 12.29s
Train Epoch: 845 	Average Loss: -1.1351
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9873

Learning rate: 9.824853595650979e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 846 [0/90000 (0%)]	Loss: 0.7301	Cost: 33.98s
Train Epoch: 846 [20480/90000 (23%)]	Loss: -1.3506	Cost: 9.04s
Train Epoch: 846 [40960/90000 (45%)]	Loss: -1.2746	Cost: 13.15s
Train Epoch: 846 [61440/90000 (68%)]	Loss: -1.1719	Cost: 8.79s
Train Epoch: 846 [81920/90000 (91%)]	Loss: -1.4736	Cost: 10.52s
Train Epoch: 846 	Average Loss: -1.1562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8957

Learning rate: 9.824441247203567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 847 [0/90000 (0%)]	Loss: 0.7871	Cost: 31.82s
Train Epoch: 847 [20480/90000 (23%)]	Loss: -1.2867	Cost: 10.38s
Train Epoch: 847 [40960/90000 (45%)]	Loss: -1.2818	Cost: 18.64s
Train Epoch: 847 [61440/90000 (68%)]	Loss: -1.4215	Cost: 12.27s
Train Epoch: 847 [81920/90000 (91%)]	Loss: -1.4058	Cost: 11.93s
Train Epoch: 847 	Average Loss: -1.1558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8167

Saving model as e847_model.pt & e847_waveforms_supplementary.hdf5
Learning rate: 9.824028422602895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 848 [0/90000 (0%)]	Loss: 0.6448	Cost: 42.87s
Train Epoch: 848 [20480/90000 (23%)]	Loss: -1.3456	Cost: 6.67s
Train Epoch: 848 [40960/90000 (45%)]	Loss: -1.6054	Cost: 16.32s
Train Epoch: 848 [61440/90000 (68%)]	Loss: -1.3595	Cost: 8.75s
Train Epoch: 848 [81920/90000 (91%)]	Loss: -1.3118	Cost: 11.70s
Train Epoch: 848 	Average Loss: -1.2068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.9404

Learning rate: 9.823615121889704e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 849 [0/90000 (0%)]	Loss: 0.8406	Cost: 34.19s
Train Epoch: 849 [20480/90000 (23%)]	Loss: -1.0524	Cost: 6.64s
Train Epoch: 849 [40960/90000 (45%)]	Loss: -0.7223	Cost: 16.37s
Train Epoch: 849 [61440/90000 (68%)]	Loss: -0.7422	Cost: 12.32s
Train Epoch: 849 [81920/90000 (91%)]	Loss: -0.9324	Cost: 12.19s
Train Epoch: 849 	Average Loss: -0.7628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 1.0547

Learning rate: 9.823201345104787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 850 [0/90000 (0%)]	Loss: 1.0735	Cost: 39.88s
Train Epoch: 850 [20480/90000 (23%)]	Loss: -1.0848	Cost: 10.80s
Train Epoch: 850 [40960/90000 (45%)]	Loss: -1.3234	Cost: 6.74s
Train Epoch: 850 [61440/90000 (68%)]	Loss: -1.3147	Cost: 6.81s
Train Epoch: 850 [81920/90000 (91%)]	Loss: -1.5656	Cost: 13.54s
Train Epoch: 850 	Average Loss: -1.0912
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6862

Saving model as e850_model.pt & e850_waveforms_supplementary.hdf5
Learning rate: 9.82278709228898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 851 [0/90000 (0%)]	Loss: 0.7199	Cost: 33.76s
Train Epoch: 851 [20480/90000 (23%)]	Loss: -1.5069	Cost: 10.83s
Train Epoch: 851 [40960/90000 (45%)]	Loss: -1.4695	Cost: 22.13s
Train Epoch: 851 [61440/90000 (68%)]	Loss: -1.3946	Cost: 12.46s
Train Epoch: 851 [81920/90000 (91%)]	Loss: -1.4610	Cost: 11.91s
Train Epoch: 851 	Average Loss: -1.2561
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7486

Learning rate: 9.82237236348317e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 852 [0/90000 (0%)]	Loss: 0.5630	Cost: 38.43s
Train Epoch: 852 [20480/90000 (23%)]	Loss: -1.3776	Cost: 7.93s
Train Epoch: 852 [40960/90000 (45%)]	Loss: -1.2917	Cost: 9.88s
Train Epoch: 852 [61440/90000 (68%)]	Loss: -1.2965	Cost: 8.36s
Train Epoch: 852 [81920/90000 (91%)]	Loss: -1.4218	Cost: 11.93s
Train Epoch: 852 	Average Loss: -1.1552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7059

Learning rate: 9.821957158728289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 853 [0/90000 (0%)]	Loss: 1.0150	Cost: 29.40s
Train Epoch: 853 [20480/90000 (23%)]	Loss: -1.1803	Cost: 10.19s
Train Epoch: 853 [40960/90000 (45%)]	Loss: -1.3534	Cost: 21.71s
Train Epoch: 853 [61440/90000 (68%)]	Loss: -1.4538	Cost: 12.10s
Train Epoch: 853 [81920/90000 (91%)]	Loss: -1.4681	Cost: 11.98s
Train Epoch: 853 	Average Loss: -1.2023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8006

Learning rate: 9.821541478065316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 854 [0/90000 (0%)]	Loss: 0.6222	Cost: 34.44s
Train Epoch: 854 [20480/90000 (23%)]	Loss: -1.3813	Cost: 8.67s
Train Epoch: 854 [40960/90000 (45%)]	Loss: -1.4264	Cost: 9.53s
Train Epoch: 854 [61440/90000 (68%)]	Loss: -1.5342	Cost: 7.76s
Train Epoch: 854 [81920/90000 (91%)]	Loss: -1.5270	Cost: 11.33s
Train Epoch: 854 	Average Loss: -1.2796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7258

Learning rate: 9.821125321535279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 855 [0/90000 (0%)]	Loss: 0.5421	Cost: 26.76s
Train Epoch: 855 [20480/90000 (23%)]	Loss: -1.4982	Cost: 8.92s
Train Epoch: 855 [40960/90000 (45%)]	Loss: -1.3667	Cost: 22.77s
Train Epoch: 855 [61440/90000 (68%)]	Loss: -1.6054	Cost: 14.26s
Train Epoch: 855 [81920/90000 (91%)]	Loss: -1.6384	Cost: 12.35s
Train Epoch: 855 	Average Loss: -1.3605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6856

Saving model as e855_model.pt & e855_waveforms_supplementary.hdf5
Learning rate: 9.820708689179247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 856 [0/90000 (0%)]	Loss: 0.7428	Cost: 54.70s
Train Epoch: 856 [20480/90000 (23%)]	Loss: -1.2989	Cost: 6.87s
Train Epoch: 856 [40960/90000 (45%)]	Loss: -1.1601	Cost: 12.84s
Train Epoch: 856 [61440/90000 (68%)]	Loss: -1.4742	Cost: 8.66s
Train Epoch: 856 [81920/90000 (91%)]	Loss: -1.6888	Cost: 8.45s
Train Epoch: 856 	Average Loss: -1.2635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7071

Learning rate: 9.820291581038343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 857 [0/90000 (0%)]	Loss: 0.5912	Cost: 25.90s
Train Epoch: 857 [20480/90000 (23%)]	Loss: -1.3363	Cost: 9.74s
Train Epoch: 857 [40960/90000 (45%)]	Loss: -1.3380	Cost: 25.06s
Train Epoch: 857 [61440/90000 (68%)]	Loss: -1.4614	Cost: 12.12s
Train Epoch: 857 [81920/90000 (91%)]	Loss: -1.3795	Cost: 11.88s
Train Epoch: 857 	Average Loss: -1.2560
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8038

Learning rate: 9.819873997153732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 858 [0/90000 (0%)]	Loss: 0.6092	Cost: 40.52s
Train Epoch: 858 [20480/90000 (23%)]	Loss: -1.3564	Cost: 6.68s
Train Epoch: 858 [40960/90000 (45%)]	Loss: -1.4843	Cost: 13.51s
Train Epoch: 858 [61440/90000 (68%)]	Loss: -1.5003	Cost: 8.90s
Train Epoch: 858 [81920/90000 (91%)]	Loss: -1.4972	Cost: 9.98s
Train Epoch: 858 	Average Loss: -1.2721
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6970

Learning rate: 9.81945593756663e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 859 [0/90000 (0%)]	Loss: 0.8315	Cost: 34.69s
Train Epoch: 859 [20480/90000 (23%)]	Loss: -1.4119	Cost: 15.20s
Train Epoch: 859 [40960/90000 (45%)]	Loss: -1.5770	Cost: 16.53s
Train Epoch: 859 [61440/90000 (68%)]	Loss: -1.5864	Cost: 12.23s
Train Epoch: 859 [81920/90000 (91%)]	Loss: -1.6731	Cost: 9.91s
Train Epoch: 859 	Average Loss: -1.3893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5725

Saving model as e859_model.pt & e859_waveforms_supplementary.hdf5
Learning rate: 9.819037402318296e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 860 [0/90000 (0%)]	Loss: 0.3349	Cost: 53.43s
Train Epoch: 860 [20480/90000 (23%)]	Loss: -1.6675	Cost: 8.89s
Train Epoch: 860 [40960/90000 (45%)]	Loss: -1.8076	Cost: 11.07s
Train Epoch: 860 [61440/90000 (68%)]	Loss: -1.6349	Cost: 8.67s
Train Epoch: 860 [81920/90000 (91%)]	Loss: -1.7358	Cost: 7.21s
Train Epoch: 860 	Average Loss: -1.4663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5770

Learning rate: 9.818618391450038e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 861 [0/90000 (0%)]	Loss: 0.5799	Cost: 32.09s
Train Epoch: 861 [20480/90000 (23%)]	Loss: -1.4879	Cost: 7.39s
Train Epoch: 861 [40960/90000 (45%)]	Loss: -1.5758	Cost: 18.07s
Train Epoch: 861 [61440/90000 (68%)]	Loss: -1.6745	Cost: 12.37s
Train Epoch: 861 [81920/90000 (91%)]	Loss: -1.7966	Cost: 12.08s
Train Epoch: 861 	Average Loss: -1.4542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5756

Learning rate: 9.81819890500321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 862 [0/90000 (0%)]	Loss: 0.6299	Cost: 49.36s
Train Epoch: 862 [20480/90000 (23%)]	Loss: -1.5865	Cost: 6.22s
Train Epoch: 862 [40960/90000 (45%)]	Loss: -1.6771	Cost: 13.86s
Train Epoch: 862 [61440/90000 (68%)]	Loss: -1.7555	Cost: 8.64s
Train Epoch: 862 [81920/90000 (91%)]	Loss: -1.7713	Cost: 8.80s
Train Epoch: 862 	Average Loss: -1.5366
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5460

Saving model as e862_model.pt & e862_waveforms_supplementary.hdf5
Learning rate: 9.817778943019216e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 863 [0/90000 (0%)]	Loss: 0.8758	Cost: 28.81s
Train Epoch: 863 [20480/90000 (23%)]	Loss: -1.3622	Cost: 7.66s
Train Epoch: 863 [40960/90000 (45%)]	Loss: -1.4733	Cost: 16.97s
Train Epoch: 863 [61440/90000 (68%)]	Loss: -1.4319	Cost: 12.01s
Train Epoch: 863 [81920/90000 (91%)]	Loss: -1.3873	Cost: 12.39s
Train Epoch: 863 	Average Loss: -1.3060
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7233

Learning rate: 9.817358505539504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 864 [0/90000 (0%)]	Loss: 0.6349	Cost: 34.66s
Train Epoch: 864 [20480/90000 (23%)]	Loss: -1.4402	Cost: 9.73s
Train Epoch: 864 [40960/90000 (45%)]	Loss: -1.4744	Cost: 12.93s
Train Epoch: 864 [61440/90000 (68%)]	Loss: -1.5258	Cost: 8.79s
Train Epoch: 864 [81920/90000 (91%)]	Loss: -1.6348	Cost: 13.26s
Train Epoch: 864 	Average Loss: -1.3085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5797

Learning rate: 9.816937592605568e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 865 [0/90000 (0%)]	Loss: 0.7195	Cost: 30.97s
Train Epoch: 865 [20480/90000 (23%)]	Loss: -1.6765	Cost: 11.76s
Train Epoch: 865 [40960/90000 (45%)]	Loss: -1.6320	Cost: 16.40s
Train Epoch: 865 [61440/90000 (68%)]	Loss: -1.7175	Cost: 12.16s
Train Epoch: 865 [81920/90000 (91%)]	Loss: -1.7269	Cost: 12.07s
Train Epoch: 865 	Average Loss: -1.5031
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5936

Learning rate: 9.816516204258952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 866 [0/90000 (0%)]	Loss: 1.0299	Cost: 40.92s
Train Epoch: 866 [20480/90000 (23%)]	Loss: -1.4119	Cost: 12.35s
Train Epoch: 866 [40960/90000 (45%)]	Loss: -1.6728	Cost: 10.70s
Train Epoch: 866 [61440/90000 (68%)]	Loss: -1.7982	Cost: 6.36s
Train Epoch: 866 [81920/90000 (91%)]	Loss: -1.7936	Cost: 6.95s
Train Epoch: 866 	Average Loss: -1.4975
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4641

Saving model as e866_model.pt & e866_waveforms_supplementary.hdf5
Learning rate: 9.816094340541243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 867 [0/90000 (0%)]	Loss: 0.4707	Cost: 35.10s
Train Epoch: 867 [20480/90000 (23%)]	Loss: -1.7260	Cost: 8.30s
Train Epoch: 867 [40960/90000 (45%)]	Loss: -1.7215	Cost: 9.93s
Train Epoch: 867 [61440/90000 (68%)]	Loss: -1.7765	Cost: 6.64s
Train Epoch: 867 [81920/90000 (91%)]	Loss: -1.7560	Cost: 21.02s
Train Epoch: 867 	Average Loss: -1.5526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5011

Learning rate: 9.815672001494079e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 868 [0/90000 (0%)]	Loss: 0.5696	Cost: 32.04s
Train Epoch: 868 [20480/90000 (23%)]	Loss: -1.6347	Cost: 11.88s
Train Epoch: 868 [40960/90000 (45%)]	Loss: -1.7340	Cost: 12.05s
Train Epoch: 868 [61440/90000 (68%)]	Loss: -1.8766	Cost: 8.48s
Train Epoch: 868 [81920/90000 (91%)]	Loss: -1.8848	Cost: 8.70s
Train Epoch: 868 	Average Loss: -1.5592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4544

Saving model as e868_model.pt & e868_waveforms_supplementary.hdf5
Learning rate: 9.815249187159144e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 869 [0/90000 (0%)]	Loss: 0.2972	Cost: 28.43s
Train Epoch: 869 [20480/90000 (23%)]	Loss: -1.7964	Cost: 10.13s
Train Epoch: 869 [40960/90000 (45%)]	Loss: -1.8533	Cost: 21.88s
Train Epoch: 869 [61440/90000 (68%)]	Loss: -1.8009	Cost: 12.70s
Train Epoch: 869 [81920/90000 (91%)]	Loss: -1.7667	Cost: 12.06s
Train Epoch: 869 	Average Loss: -1.6439
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4065

Saving model as e869_model.pt & e869_waveforms_supplementary.hdf5
Learning rate: 9.814825897578167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 870 [0/90000 (0%)]	Loss: 0.3571	Cost: 54.84s
Train Epoch: 870 [20480/90000 (23%)]	Loss: -1.6354	Cost: 6.24s
Train Epoch: 870 [40960/90000 (45%)]	Loss: -1.7004	Cost: 14.25s
Train Epoch: 870 [61440/90000 (68%)]	Loss: -1.8148	Cost: 8.85s
Train Epoch: 870 [81920/90000 (91%)]	Loss: -1.8460	Cost: 9.81s
Train Epoch: 870 	Average Loss: -1.5746
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5052

Learning rate: 9.814402132792926e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 871 [0/90000 (0%)]	Loss: 0.4252	Cost: 28.45s
Train Epoch: 871 [20480/90000 (23%)]	Loss: -1.7830	Cost: 12.29s
Train Epoch: 871 [40960/90000 (45%)]	Loss: -1.7723	Cost: 15.63s
Train Epoch: 871 [61440/90000 (68%)]	Loss: -1.8440	Cost: 12.61s
Train Epoch: 871 [81920/90000 (91%)]	Loss: -1.7120	Cost: 12.00s
Train Epoch: 871 	Average Loss: -1.5503
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.8542

Learning rate: 9.813977892845244e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 872 [0/90000 (0%)]	Loss: 0.8414	Cost: 41.34s
Train Epoch: 872 [20480/90000 (23%)]	Loss: -1.3203	Cost: 10.37s
Train Epoch: 872 [40960/90000 (45%)]	Loss: -1.5583	Cost: 8.42s
Train Epoch: 872 [61440/90000 (68%)]	Loss: -1.6319	Cost: 6.80s
Train Epoch: 872 [81920/90000 (91%)]	Loss: -1.8126	Cost: 12.73s
Train Epoch: 872 	Average Loss: -1.3343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6467

Learning rate: 9.813553177776991e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 873 [0/90000 (0%)]	Loss: 0.3575	Cost: 29.47s
Train Epoch: 873 [20480/90000 (23%)]	Loss: -1.5602	Cost: 6.82s
Train Epoch: 873 [40960/90000 (45%)]	Loss: -1.7636	Cost: 21.42s
Train Epoch: 873 [61440/90000 (68%)]	Loss: -1.8690	Cost: 14.05s
Train Epoch: 873 [81920/90000 (91%)]	Loss: -1.6930	Cost: 12.24s
Train Epoch: 873 	Average Loss: -1.5519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4636

Learning rate: 9.813127987630086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 874 [0/90000 (0%)]	Loss: 0.6195	Cost: 34.23s
Train Epoch: 874 [20480/90000 (23%)]	Loss: -1.6596	Cost: 12.18s
Train Epoch: 874 [40960/90000 (45%)]	Loss: -1.7835	Cost: 11.31s
Train Epoch: 874 [61440/90000 (68%)]	Loss: -1.9295	Cost: 8.26s
Train Epoch: 874 [81920/90000 (91%)]	Loss: -1.7869	Cost: 12.95s
Train Epoch: 874 	Average Loss: -1.5362
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5254

Learning rate: 9.812702322446492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 875 [0/90000 (0%)]	Loss: 0.3968	Cost: 33.08s
Train Epoch: 875 [20480/90000 (23%)]	Loss: -1.7199	Cost: 9.10s
Train Epoch: 875 [40960/90000 (45%)]	Loss: -1.9296	Cost: 15.29s
Train Epoch: 875 [61440/90000 (68%)]	Loss: -1.8038	Cost: 12.19s
Train Epoch: 875 [81920/90000 (91%)]	Loss: -1.8629	Cost: 12.24s
Train Epoch: 875 	Average Loss: -1.5960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4669

Learning rate: 9.812276182268223e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 876 [0/90000 (0%)]	Loss: 0.4734	Cost: 53.15s
Train Epoch: 876 [20480/90000 (23%)]	Loss: -1.7690	Cost: 8.00s
Train Epoch: 876 [40960/90000 (45%)]	Loss: -1.8262	Cost: 12.15s
Train Epoch: 876 [61440/90000 (68%)]	Loss: -2.0065	Cost: 8.53s
Train Epoch: 876 [81920/90000 (91%)]	Loss: -1.8215	Cost: 10.77s
Train Epoch: 876 	Average Loss: -1.6815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4411

Learning rate: 9.811849567137337e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 877 [0/90000 (0%)]	Loss: 0.7881	Cost: 29.05s
Train Epoch: 877 [20480/90000 (23%)]	Loss: -1.7562	Cost: 7.30s
Train Epoch: 877 [40960/90000 (45%)]	Loss: -1.7408	Cost: 17.65s
Train Epoch: 877 [61440/90000 (68%)]	Loss: -1.9272	Cost: 11.98s
Train Epoch: 877 [81920/90000 (91%)]	Loss: -1.8590	Cost: 12.33s
Train Epoch: 877 	Average Loss: -1.5948
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5903

Learning rate: 9.811422477095938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 878 [0/90000 (0%)]	Loss: 0.4578	Cost: 32.71s
Train Epoch: 878 [20480/90000 (23%)]	Loss: -1.7469	Cost: 12.25s
Train Epoch: 878 [40960/90000 (45%)]	Loss: -1.8366	Cost: 7.86s
Train Epoch: 878 [61440/90000 (68%)]	Loss: -1.8455	Cost: 8.21s
Train Epoch: 878 [81920/90000 (91%)]	Loss: -1.7836	Cost: 14.75s
Train Epoch: 878 	Average Loss: -1.5981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5072

Learning rate: 9.810994912186177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 879 [0/90000 (0%)]	Loss: 0.4396	Cost: 41.74s
Train Epoch: 879 [20480/90000 (23%)]	Loss: -1.8030	Cost: 10.07s
Train Epoch: 879 [40960/90000 (45%)]	Loss: -1.1789	Cost: 16.52s
Train Epoch: 879 [61440/90000 (68%)]	Loss: -1.4441	Cost: 12.12s
Train Epoch: 879 [81920/90000 (91%)]	Loss: -1.4659	Cost: 12.13s
Train Epoch: 879 	Average Loss: -1.3208
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.7470

Learning rate: 9.810566872450255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 880 [0/90000 (0%)]	Loss: 0.9105	Cost: 39.88s
Train Epoch: 880 [20480/90000 (23%)]	Loss: -1.4355	Cost: 11.91s
Train Epoch: 880 [40960/90000 (45%)]	Loss: -1.6922	Cost: 7.47s
Train Epoch: 880 [61440/90000 (68%)]	Loss: -1.6246	Cost: 6.12s
Train Epoch: 880 [81920/90000 (91%)]	Loss: -1.7968	Cost: 13.39s
Train Epoch: 880 	Average Loss: -1.4192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4908

Learning rate: 9.810138357930416e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 881 [0/90000 (0%)]	Loss: 0.4474	Cost: 37.50s
Train Epoch: 881 [20480/90000 (23%)]	Loss: -1.6637	Cost: 7.40s
Train Epoch: 881 [40960/90000 (45%)]	Loss: -1.7386	Cost: 17.95s
Train Epoch: 881 [61440/90000 (68%)]	Loss: -1.9401	Cost: 12.42s
Train Epoch: 881 [81920/90000 (91%)]	Loss: -2.0590	Cost: 12.14s
Train Epoch: 881 	Average Loss: -1.6112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3104

Saving model as e881_model.pt & e881_waveforms_supplementary.hdf5
Learning rate: 9.809709368668956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 882 [0/90000 (0%)]	Loss: 0.3614	Cost: 32.58s
Train Epoch: 882 [20480/90000 (23%)]	Loss: -1.7801	Cost: 6.30s
Train Epoch: 882 [40960/90000 (45%)]	Loss: -2.0670	Cost: 15.88s
Train Epoch: 882 [61440/90000 (68%)]	Loss: -2.0079	Cost: 9.40s
Train Epoch: 882 [81920/90000 (91%)]	Loss: -1.9887	Cost: 12.36s
Train Epoch: 882 	Average Loss: -1.7469
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3094

Saving model as e882_model.pt & e882_waveforms_supplementary.hdf5
Learning rate: 9.80927990470821e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 883 [0/90000 (0%)]	Loss: 0.4569	Cost: 33.66s
Train Epoch: 883 [20480/90000 (23%)]	Loss: -1.8742	Cost: 11.85s
Train Epoch: 883 [40960/90000 (45%)]	Loss: -1.9229	Cost: 20.50s
Train Epoch: 883 [61440/90000 (68%)]	Loss: -2.0775	Cost: 11.77s
Train Epoch: 883 [81920/90000 (91%)]	Loss: -1.8318	Cost: 11.89s
Train Epoch: 883 	Average Loss: -1.7432
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4995

Learning rate: 9.80884996609057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 884 [0/90000 (0%)]	Loss: 0.4358	Cost: 51.24s
Train Epoch: 884 [20480/90000 (23%)]	Loss: -1.7245	Cost: 6.33s
Train Epoch: 884 [40960/90000 (45%)]	Loss: -1.9001	Cost: 13.74s
Train Epoch: 884 [61440/90000 (68%)]	Loss: -2.1015	Cost: 8.59s
Train Epoch: 884 [81920/90000 (91%)]	Loss: -1.9509	Cost: 8.72s
Train Epoch: 884 	Average Loss: -1.7023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3079

Saving model as e884_model.pt & e884_waveforms_supplementary.hdf5
Learning rate: 9.808419552858463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 885 [0/90000 (0%)]	Loss: 0.0585	Cost: 33.67s
Train Epoch: 885 [20480/90000 (23%)]	Loss: -1.8139	Cost: 12.88s
Train Epoch: 885 [40960/90000 (45%)]	Loss: -1.9929	Cost: 15.51s
Train Epoch: 885 [61440/90000 (68%)]	Loss: -1.8182	Cost: 12.59s
Train Epoch: 885 [81920/90000 (91%)]	Loss: -1.9419	Cost: 12.21s
Train Epoch: 885 	Average Loss: -1.7590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4164

Learning rate: 9.807988665054374e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 886 [0/90000 (0%)]	Loss: 0.4848	Cost: 40.85s
Train Epoch: 886 [20480/90000 (23%)]	Loss: -1.6882	Cost: 11.48s
Train Epoch: 886 [40960/90000 (45%)]	Loss: -1.9848	Cost: 7.80s
Train Epoch: 886 [61440/90000 (68%)]	Loss: -2.1422	Cost: 6.46s
Train Epoch: 886 [81920/90000 (91%)]	Loss: -1.7980	Cost: 12.15s
Train Epoch: 886 	Average Loss: -1.7552
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4247

Learning rate: 9.807557302720827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 887 [0/90000 (0%)]	Loss: 0.4373	Cost: 28.53s
Train Epoch: 887 [20480/90000 (23%)]	Loss: -1.7690	Cost: 10.96s
Train Epoch: 887 [40960/90000 (45%)]	Loss: -1.6084	Cost: 21.19s
Train Epoch: 887 [61440/90000 (68%)]	Loss: -1.8441	Cost: 13.26s
Train Epoch: 887 [81920/90000 (91%)]	Loss: -1.8709	Cost: 12.10s
Train Epoch: 887 	Average Loss: -1.6061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.6061

Learning rate: 9.807125465900396e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 888 [0/90000 (0%)]	Loss: 0.2322	Cost: 49.33s
Train Epoch: 888 [20480/90000 (23%)]	Loss: -1.6596	Cost: 12.16s
Train Epoch: 888 [40960/90000 (45%)]	Loss: -1.8691	Cost: 7.89s
Train Epoch: 888 [61440/90000 (68%)]	Loss: -1.7777	Cost: 6.36s
Train Epoch: 888 [81920/90000 (91%)]	Loss: -1.9472	Cost: 10.15s
Train Epoch: 888 	Average Loss: -1.6636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4040

Learning rate: 9.806693154635704e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 889 [0/90000 (0%)]	Loss: 0.6186	Cost: 30.95s
Train Epoch: 889 [20480/90000 (23%)]	Loss: -1.7942	Cost: 8.91s
Train Epoch: 889 [40960/90000 (45%)]	Loss: -1.9777	Cost: 9.66s
Train Epoch: 889 [61440/90000 (68%)]	Loss: -1.8604	Cost: 6.01s
Train Epoch: 889 [81920/90000 (91%)]	Loss: -1.9581	Cost: 11.24s
Train Epoch: 889 	Average Loss: -1.6551
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4250

Learning rate: 9.806260368969415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 890 [0/90000 (0%)]	Loss: 0.2019	Cost: 31.89s
Train Epoch: 890 [20480/90000 (23%)]	Loss: -1.7340	Cost: 13.14s
Train Epoch: 890 [40960/90000 (45%)]	Loss: -1.7805	Cost: 12.86s
Train Epoch: 890 [61440/90000 (68%)]	Loss: -1.9443	Cost: 12.16s
Train Epoch: 890 [81920/90000 (91%)]	Loss: -1.9248	Cost: 12.05s
Train Epoch: 890 	Average Loss: -1.6654
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3921

Learning rate: 9.805827108944247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 891 [0/90000 (0%)]	Loss: 0.2287	Cost: 33.77s
Train Epoch: 891 [20480/90000 (23%)]	Loss: -1.8083	Cost: 7.81s
Train Epoch: 891 [40960/90000 (45%)]	Loss: -1.9575	Cost: 13.34s
Train Epoch: 891 [61440/90000 (68%)]	Loss: -2.0454	Cost: 8.54s
Train Epoch: 891 [81920/90000 (91%)]	Loss: -1.9366	Cost: 8.74s
Train Epoch: 891 	Average Loss: -1.7513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4697

Learning rate: 9.805393374602958e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 892 [0/90000 (0%)]	Loss: 0.5448	Cost: 30.92s
Train Epoch: 892 [20480/90000 (23%)]	Loss: -1.9854	Cost: 10.75s
Train Epoch: 892 [40960/90000 (45%)]	Loss: -2.0840	Cost: 15.81s
Train Epoch: 892 [61440/90000 (68%)]	Loss: -2.0371	Cost: 14.10s
Train Epoch: 892 [81920/90000 (91%)]	Loss: -2.2387	Cost: 12.22s
Train Epoch: 892 	Average Loss: -1.8603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2548

Saving model as e892_model.pt & e892_waveforms_supplementary.hdf5
Learning rate: 9.804959165988357e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 893 [0/90000 (0%)]	Loss: 0.0211	Cost: 35.27s
Train Epoch: 893 [20480/90000 (23%)]	Loss: -2.1055	Cost: 13.17s
Train Epoch: 893 [40960/90000 (45%)]	Loss: -2.1015	Cost: 8.90s
Train Epoch: 893 [61440/90000 (68%)]	Loss: -2.0968	Cost: 7.08s
Train Epoch: 893 [81920/90000 (91%)]	Loss: -2.3333	Cost: 14.35s
Train Epoch: 893 	Average Loss: -1.9104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1474

Saving model as e893_model.pt & e893_waveforms_supplementary.hdf5
Learning rate: 9.804524483143299e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 894 [0/90000 (0%)]	Loss: 0.1392	Cost: 33.67s
Train Epoch: 894 [20480/90000 (23%)]	Loss: -1.9951	Cost: 6.68s
Train Epoch: 894 [40960/90000 (45%)]	Loss: -2.0136	Cost: 17.19s
Train Epoch: 894 [61440/90000 (68%)]	Loss: -2.0954	Cost: 11.98s
Train Epoch: 894 [81920/90000 (91%)]	Loss: -2.1561	Cost: 12.09s
Train Epoch: 894 	Average Loss: -1.9214
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2604

Learning rate: 9.804089326110685e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 895 [0/90000 (0%)]	Loss: 0.2104	Cost: 33.84s
Train Epoch: 895 [20480/90000 (23%)]	Loss: -1.9327	Cost: 11.43s
Train Epoch: 895 [40960/90000 (45%)]	Loss: -2.0307	Cost: 10.48s
Train Epoch: 895 [61440/90000 (68%)]	Loss: -2.1398	Cost: 6.50s
Train Epoch: 895 [81920/90000 (91%)]	Loss: -2.0270	Cost: 13.00s
Train Epoch: 895 	Average Loss: -1.8577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2553

Learning rate: 9.803653694933463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 896 [0/90000 (0%)]	Loss: 0.4262	Cost: 29.92s
Train Epoch: 896 [20480/90000 (23%)]	Loss: -1.9499	Cost: 7.38s
Train Epoch: 896 [40960/90000 (45%)]	Loss: -2.0926	Cost: 19.19s
Train Epoch: 896 [61440/90000 (68%)]	Loss: -2.1661	Cost: 13.03s
Train Epoch: 896 [81920/90000 (91%)]	Loss: -1.9759	Cost: 12.10s
Train Epoch: 896 	Average Loss: -1.8525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.5037

Learning rate: 9.803217589654627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 897 [0/90000 (0%)]	Loss: 0.4430	Cost: 36.79s
Train Epoch: 897 [20480/90000 (23%)]	Loss: -1.6888	Cost: 12.83s
Train Epoch: 897 [40960/90000 (45%)]	Loss: -1.8442	Cost: 7.32s
Train Epoch: 897 [61440/90000 (68%)]	Loss: -1.9878	Cost: 6.44s
Train Epoch: 897 [81920/90000 (91%)]	Loss: -1.9826	Cost: 16.16s
Train Epoch: 897 	Average Loss: -1.6492
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4219

Learning rate: 9.802781010317222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 898 [0/90000 (0%)]	Loss: 0.2035	Cost: 37.04s
Train Epoch: 898 [20480/90000 (23%)]	Loss: -1.8307	Cost: 6.90s
Train Epoch: 898 [40960/90000 (45%)]	Loss: -1.8615	Cost: 16.66s
Train Epoch: 898 [61440/90000 (68%)]	Loss: -2.1129	Cost: 12.48s
Train Epoch: 898 [81920/90000 (91%)]	Loss: -2.0719	Cost: 11.99s
Train Epoch: 898 	Average Loss: -1.8309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2315

Learning rate: 9.802343956964335e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 899 [0/90000 (0%)]	Loss: 0.3630	Cost: 36.68s
Train Epoch: 899 [20480/90000 (23%)]	Loss: -1.9910	Cost: 12.27s
Train Epoch: 899 [40960/90000 (45%)]	Loss: -2.1106	Cost: 9.64s
Train Epoch: 899 [61440/90000 (68%)]	Loss: -2.1687	Cost: 6.29s
Train Epoch: 899 [81920/90000 (91%)]	Loss: -2.1657	Cost: 9.89s
Train Epoch: 899 	Average Loss: -1.8825
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1540

Learning rate: 9.8019064296391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 900 [0/90000 (0%)]	Loss: 0.3487	Cost: 29.03s
Train Epoch: 900 [20480/90000 (23%)]	Loss: -2.0325	Cost: 8.82s
Train Epoch: 900 [40960/90000 (45%)]	Loss: -2.0518	Cost: 11.88s
Train Epoch: 900 [61440/90000 (68%)]	Loss: -2.0289	Cost: 10.23s
Train Epoch: 900 [81920/90000 (91%)]	Loss: -2.0843	Cost: 15.81s
Train Epoch: 900 	Average Loss: -1.8831
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1969

Learning rate: 9.801468428384702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 901 [0/90000 (0%)]	Loss: 0.1727	Cost: 46.76s
Train Epoch: 901 [20480/90000 (23%)]	Loss: -1.9826	Cost: 12.72s
Train Epoch: 901 [40960/90000 (45%)]	Loss: -2.0701	Cost: 12.08s
Train Epoch: 901 [61440/90000 (68%)]	Loss: -1.9834	Cost: 9.88s
Train Epoch: 901 [81920/90000 (91%)]	Loss: -2.2355	Cost: 5.87s
Train Epoch: 901 	Average Loss: -1.8916
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2646

Learning rate: 9.80102995324437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 902 [0/90000 (0%)]	Loss: 0.1650	Cost: 31.29s
Train Epoch: 902 [20480/90000 (23%)]	Loss: -2.1096	Cost: 8.83s
Train Epoch: 902 [40960/90000 (45%)]	Loss: -2.1681	Cost: 11.27s
Train Epoch: 902 [61440/90000 (68%)]	Loss: -2.2589	Cost: 6.28s
Train Epoch: 902 [81920/90000 (91%)]	Loss: -2.3728	Cost: 17.65s
Train Epoch: 902 	Average Loss: -1.9862
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1485

Learning rate: 9.800591004261374e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 903 [0/90000 (0%)]	Loss: 0.2800	Cost: 42.33s
Train Epoch: 903 [20480/90000 (23%)]	Loss: -2.0415	Cost: 13.65s
Train Epoch: 903 [40960/90000 (45%)]	Loss: -2.2594	Cost: 12.40s
Train Epoch: 903 [61440/90000 (68%)]	Loss: -2.2920	Cost: 12.22s
Train Epoch: 903 [81920/90000 (91%)]	Loss: -2.2833	Cost: 8.11s
Train Epoch: 903 	Average Loss: -1.9738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1641

Learning rate: 9.800151581479044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 904 [0/90000 (0%)]	Loss: 0.1821	Cost: 30.07s
Train Epoch: 904 [20480/90000 (23%)]	Loss: -2.1302	Cost: 8.28s
Train Epoch: 904 [40960/90000 (45%)]	Loss: -2.1402	Cost: 11.84s
Train Epoch: 904 [61440/90000 (68%)]	Loss: -2.4012	Cost: 8.63s
Train Epoch: 904 [81920/90000 (91%)]	Loss: -2.2675	Cost: 7.23s
Train Epoch: 904 	Average Loss: -1.9973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3024

Learning rate: 9.799711684940746e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 905 [0/90000 (0%)]	Loss: 0.4159	Cost: 29.79s
Train Epoch: 905 [20480/90000 (23%)]	Loss: -2.1028	Cost: 8.78s
Train Epoch: 905 [40960/90000 (45%)]	Loss: -2.0885	Cost: 16.41s
Train Epoch: 905 [61440/90000 (68%)]	Loss: -2.2943	Cost: 12.62s
Train Epoch: 905 [81920/90000 (91%)]	Loss: -2.2979	Cost: 12.29s
Train Epoch: 905 	Average Loss: -1.9913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1441

Saving model as e905_model.pt & e905_waveforms_supplementary.hdf5
Learning rate: 9.799271314689895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 906 [0/90000 (0%)]	Loss: 0.3558	Cost: 44.24s
Train Epoch: 906 [20480/90000 (23%)]	Loss: -2.0597	Cost: 6.58s
Train Epoch: 906 [40960/90000 (45%)]	Loss: -2.1019	Cost: 15.22s
Train Epoch: 906 [61440/90000 (68%)]	Loss: -2.1480	Cost: 8.93s
Train Epoch: 906 [81920/90000 (91%)]	Loss: -2.0706	Cost: 9.79s
Train Epoch: 906 	Average Loss: -1.9173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3949

Learning rate: 9.798830470769955e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 907 [0/90000 (0%)]	Loss: 0.1937	Cost: 27.90s
Train Epoch: 907 [20480/90000 (23%)]	Loss: -1.9687	Cost: 11.75s
Train Epoch: 907 [40960/90000 (45%)]	Loss: -2.0088	Cost: 14.15s
Train Epoch: 907 [61440/90000 (68%)]	Loss: -2.1743	Cost: 12.31s
Train Epoch: 907 [81920/90000 (91%)]	Loss: -1.8629	Cost: 11.99s
Train Epoch: 907 	Average Loss: -1.8360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.4081

Learning rate: 9.798389153224436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 908 [0/90000 (0%)]	Loss: 0.6018	Cost: 35.38s
Train Epoch: 908 [20480/90000 (23%)]	Loss: -1.8450	Cost: 12.60s
Train Epoch: 908 [40960/90000 (45%)]	Loss: -2.0357	Cost: 10.52s
Train Epoch: 908 [61440/90000 (68%)]	Loss: -2.2082	Cost: 6.63s
Train Epoch: 908 [81920/90000 (91%)]	Loss: -2.2775	Cost: 11.64s
Train Epoch: 908 	Average Loss: -1.8621
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1571

Learning rate: 9.797947362096895e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 909 [0/90000 (0%)]	Loss: 0.3388	Cost: 34.71s
Train Epoch: 909 [20480/90000 (23%)]	Loss: -2.1035	Cost: 6.35s
Train Epoch: 909 [40960/90000 (45%)]	Loss: -2.2437	Cost: 16.88s
Train Epoch: 909 [61440/90000 (68%)]	Loss: -2.2834	Cost: 12.45s
Train Epoch: 909 [81920/90000 (91%)]	Loss: -2.1456	Cost: 12.25s
Train Epoch: 909 	Average Loss: -1.9302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2386

Learning rate: 9.797505097430932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 910 [0/90000 (0%)]	Loss: 0.0855	Cost: 31.80s
Train Epoch: 910 [20480/90000 (23%)]	Loss: -2.0040	Cost: 12.23s
Train Epoch: 910 [40960/90000 (45%)]	Loss: -2.2170	Cost: 12.01s
Train Epoch: 910 [61440/90000 (68%)]	Loss: -2.2820	Cost: 12.01s
Train Epoch: 910 [81920/90000 (91%)]	Loss: -2.3554	Cost: 7.93s
Train Epoch: 910 	Average Loss: -2.0221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1140

Saving model as e910_model.pt & e910_waveforms_supplementary.hdf5
Learning rate: 9.797062359270201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 911 [0/90000 (0%)]	Loss: -0.0640	Cost: 32.04s
Train Epoch: 911 [20480/90000 (23%)]	Loss: -2.2413	Cost: 8.32s
Train Epoch: 911 [40960/90000 (45%)]	Loss: -2.3676	Cost: 14.16s
Train Epoch: 911 [61440/90000 (68%)]	Loss: -2.4390	Cost: 10.88s
Train Epoch: 911 [81920/90000 (91%)]	Loss: -2.3385	Cost: 16.53s
Train Epoch: 911 	Average Loss: -2.0965
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0196

Saving model as e911_model.pt & e911_waveforms_supplementary.hdf5
Learning rate: 9.796619147658394e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 912 [0/90000 (0%)]	Loss: 0.0851	Cost: 50.62s
Train Epoch: 912 [20480/90000 (23%)]	Loss: -2.3583	Cost: 10.59s
Train Epoch: 912 [40960/90000 (45%)]	Loss: -2.1855	Cost: 6.51s
Train Epoch: 912 [61440/90000 (68%)]	Loss: -2.2848	Cost: 6.24s
Train Epoch: 912 [81920/90000 (91%)]	Loss: -2.4513	Cost: 14.11s
Train Epoch: 912 	Average Loss: -2.1000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0135

Saving model as e912_model.pt & e912_waveforms_supplementary.hdf5
Learning rate: 9.796175462639258e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 913 [0/90000 (0%)]	Loss: -0.1058	Cost: 29.42s
Train Epoch: 913 [20480/90000 (23%)]	Loss: -2.3364	Cost: 11.29s
Train Epoch: 913 [40960/90000 (45%)]	Loss: -2.2881	Cost: 20.84s
Train Epoch: 913 [61440/90000 (68%)]	Loss: -2.3980	Cost: 11.99s
Train Epoch: 913 [81920/90000 (91%)]	Loss: -2.4586	Cost: 12.07s
Train Epoch: 913 	Average Loss: -2.1535
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0369

Saving model as e913_model.pt & e913_waveforms_supplementary.hdf5
Learning rate: 9.79573130425658e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 914 [0/90000 (0%)]	Loss: 0.0509	Cost: 30.42s
Train Epoch: 914 [20480/90000 (23%)]	Loss: -2.2611	Cost: 6.28s
Train Epoch: 914 [40960/90000 (45%)]	Loss: -2.3750	Cost: 12.68s
Train Epoch: 914 [61440/90000 (68%)]	Loss: -2.4533	Cost: 9.34s
Train Epoch: 914 [81920/90000 (91%)]	Loss: -2.3612	Cost: 8.40s
Train Epoch: 914 	Average Loss: -2.2038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0464

Learning rate: 9.795286672554198e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 915 [0/90000 (0%)]	Loss: 0.2414	Cost: 27.35s
Train Epoch: 915 [20480/90000 (23%)]	Loss: -2.2414	Cost: 10.25s
Train Epoch: 915 [40960/90000 (45%)]	Loss: -2.3925	Cost: 20.32s
Train Epoch: 915 [61440/90000 (68%)]	Loss: -2.4376	Cost: 14.53s
Train Epoch: 915 [81920/90000 (91%)]	Loss: -2.4297	Cost: 12.09s
Train Epoch: 915 	Average Loss: -2.1553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0186

Learning rate: 9.794841567575996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 916 [0/90000 (0%)]	Loss: -0.0954	Cost: 40.90s
Train Epoch: 916 [20480/90000 (23%)]	Loss: -2.3243	Cost: 11.22s
Train Epoch: 916 [40960/90000 (45%)]	Loss: -2.1392	Cost: 9.09s
Train Epoch: 916 [61440/90000 (68%)]	Loss: -2.4100	Cost: 6.42s
Train Epoch: 916 [81920/90000 (91%)]	Loss: -2.4608	Cost: 14.45s
Train Epoch: 916 	Average Loss: -2.1192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0790

Learning rate: 9.794395989365903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 917 [0/90000 (0%)]	Loss: 0.3066	Cost: 28.85s
Train Epoch: 917 [20480/90000 (23%)]	Loss: -2.1477	Cost: 9.53s
Train Epoch: 917 [40960/90000 (45%)]	Loss: -2.3129	Cost: 18.90s
Train Epoch: 917 [61440/90000 (68%)]	Loss: -2.3967	Cost: 12.43s
Train Epoch: 917 [81920/90000 (91%)]	Loss: -2.5844	Cost: 12.10s
Train Epoch: 917 	Average Loss: -2.1802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0327

Learning rate: 9.793949937967896e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 918 [0/90000 (0%)]	Loss: -0.1137	Cost: 51.85s
Train Epoch: 918 [20480/90000 (23%)]	Loss: -2.3572	Cost: 11.14s
Train Epoch: 918 [40960/90000 (45%)]	Loss: -2.3517	Cost: 6.02s
Train Epoch: 918 [61440/90000 (68%)]	Loss: -2.3512	Cost: 6.57s
Train Epoch: 918 [81920/90000 (91%)]	Loss: -2.3341	Cost: 13.64s
Train Epoch: 918 	Average Loss: -2.1706
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0656

Learning rate: 9.793503413425998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 919 [0/90000 (0%)]	Loss: -0.0783	Cost: 26.69s
Train Epoch: 919 [20480/90000 (23%)]	Loss: -2.3750	Cost: 5.96s
Train Epoch: 919 [40960/90000 (45%)]	Loss: -2.2828	Cost: 16.76s
Train Epoch: 919 [61440/90000 (68%)]	Loss: -2.3755	Cost: 12.37s
Train Epoch: 919 [81920/90000 (91%)]	Loss: -2.3172	Cost: 13.49s
Train Epoch: 919 	Average Loss: -2.1756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1022

Learning rate: 9.793056415784282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 920 [0/90000 (0%)]	Loss: 0.0915	Cost: 38.87s
Train Epoch: 920 [20480/90000 (23%)]	Loss: -2.2088	Cost: 13.39s
Train Epoch: 920 [40960/90000 (45%)]	Loss: -2.3092	Cost: 12.95s
Train Epoch: 920 [61440/90000 (68%)]	Loss: -2.3574	Cost: 9.26s
Train Epoch: 920 [81920/90000 (91%)]	Loss: -2.4296	Cost: 6.07s
Train Epoch: 920 	Average Loss: -2.0818
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0134

Learning rate: 9.792608945086863e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 921 [0/90000 (0%)]	Loss: 0.1990	Cost: 29.76s
Train Epoch: 921 [20480/90000 (23%)]	Loss: -2.1609	Cost: 9.02s
Train Epoch: 921 [40960/90000 (45%)]	Loss: -2.5000	Cost: 12.21s
Train Epoch: 921 [61440/90000 (68%)]	Loss: -2.5574	Cost: 8.66s
Train Epoch: 921 [81920/90000 (91%)]	Loss: -2.4487	Cost: 8.20s
Train Epoch: 921 	Average Loss: -2.1840
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1075

Learning rate: 9.792161001377905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 922 [0/90000 (0%)]	Loss: -0.3644	Cost: 32.16s
Train Epoch: 922 [20480/90000 (23%)]	Loss: -2.1061	Cost: 12.12s
Train Epoch: 922 [40960/90000 (45%)]	Loss: -1.4022	Cost: 13.73s
Train Epoch: 922 [61440/90000 (68%)]	Loss: -1.7555	Cost: 11.87s
Train Epoch: 922 [81920/90000 (91%)]	Loss: -2.0369	Cost: 12.01s
Train Epoch: 922 	Average Loss: -1.6931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3287

Learning rate: 9.791712584701618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 923 [0/90000 (0%)]	Loss: 0.2513	Cost: 38.45s
Train Epoch: 923 [20480/90000 (23%)]	Loss: -1.9823	Cost: 9.92s
Train Epoch: 923 [40960/90000 (45%)]	Loss: -2.1965	Cost: 10.64s
Train Epoch: 923 [61440/90000 (68%)]	Loss: -2.3909	Cost: 6.63s
Train Epoch: 923 [81920/90000 (91%)]	Loss: -2.1633	Cost: 14.54s
Train Epoch: 923 	Average Loss: -1.9763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1429

Learning rate: 9.791263695102257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 924 [0/90000 (0%)]	Loss: 0.8191	Cost: 35.61s
Train Epoch: 924 [20480/90000 (23%)]	Loss: -2.2943	Cost: 6.41s
Train Epoch: 924 [40960/90000 (45%)]	Loss: -2.3455	Cost: 18.43s
Train Epoch: 924 [61440/90000 (68%)]	Loss: -2.4216	Cost: 12.13s
Train Epoch: 924 [81920/90000 (91%)]	Loss: -2.4076	Cost: 12.00s
Train Epoch: 924 	Average Loss: -2.0747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2006

Learning rate: 9.790814332624128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 925 [0/90000 (0%)]	Loss: -0.0413	Cost: 31.89s
Train Epoch: 925 [20480/90000 (23%)]	Loss: -2.2209	Cost: 11.90s
Train Epoch: 925 [40960/90000 (45%)]	Loss: -2.2895	Cost: 9.57s
Train Epoch: 925 [61440/90000 (68%)]	Loss: -2.0172	Cost: 6.31s
Train Epoch: 925 [81920/90000 (91%)]	Loss: -2.0785	Cost: 8.55s
Train Epoch: 925 	Average Loss: -1.9702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.3010

Learning rate: 9.790364497311582e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 926 [0/90000 (0%)]	Loss: 0.2140	Cost: 33.57s
Train Epoch: 926 [20480/90000 (23%)]	Loss: -2.0510	Cost: 11.16s
Train Epoch: 926 [40960/90000 (45%)]	Loss: -2.2199	Cost: 20.67s
Train Epoch: 926 [61440/90000 (68%)]	Loss: -2.3467	Cost: 12.17s
Train Epoch: 926 [81920/90000 (91%)]	Loss: -2.4771	Cost: 11.83s
Train Epoch: 926 	Average Loss: -2.0016
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1470

Learning rate: 9.789914189209014e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 927 [0/90000 (0%)]	Loss: 0.2065	Cost: 35.69s
Train Epoch: 927 [20480/90000 (23%)]	Loss: -2.3574	Cost: 10.54s
Train Epoch: 927 [40960/90000 (45%)]	Loss: -2.3382	Cost: 8.97s
Train Epoch: 927 [61440/90000 (68%)]	Loss: -2.3649	Cost: 6.39s
Train Epoch: 927 [81920/90000 (91%)]	Loss: -2.4395	Cost: 13.28s
Train Epoch: 927 	Average Loss: -2.1485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1039

Learning rate: 9.789463408360868e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 928 [0/90000 (0%)]	Loss: 0.1324	Cost: 31.89s
Train Epoch: 928 [20480/90000 (23%)]	Loss: -2.3134	Cost: 10.78s
Train Epoch: 928 [40960/90000 (45%)]	Loss: -2.2530	Cost: 22.89s
Train Epoch: 928 [61440/90000 (68%)]	Loss: -2.5925	Cost: 12.14s
Train Epoch: 928 [81920/90000 (91%)]	Loss: -2.5020	Cost: 11.84s
Train Epoch: 928 	Average Loss: -2.2398
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1092

Saving model as e928_model.pt & e928_waveforms_supplementary.hdf5
Learning rate: 9.789012154811634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 929 [0/90000 (0%)]	Loss: -0.0498	Cost: 40.89s
Train Epoch: 929 [20480/90000 (23%)]	Loss: -2.4963	Cost: 6.16s
Train Epoch: 929 [40960/90000 (45%)]	Loss: -2.3633	Cost: 14.42s
Train Epoch: 929 [61440/90000 (68%)]	Loss: -2.6699	Cost: 8.38s
Train Epoch: 929 [81920/90000 (91%)]	Loss: -2.6290	Cost: 8.39s
Train Epoch: 929 	Average Loss: -2.2884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0314

Learning rate: 9.788560428605849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 930 [0/90000 (0%)]	Loss: 0.1562	Cost: 31.09s
Train Epoch: 930 [20480/90000 (23%)]	Loss: -2.3897	Cost: 9.14s
Train Epoch: 930 [40960/90000 (45%)]	Loss: -2.5725	Cost: 16.23s
Train Epoch: 930 [61440/90000 (68%)]	Loss: -2.8248	Cost: 13.93s
Train Epoch: 930 [81920/90000 (91%)]	Loss: -2.6271	Cost: 12.21s
Train Epoch: 930 	Average Loss: -2.3618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1955

Saving model as e930_model.pt & e930_waveforms_supplementary.hdf5
Learning rate: 9.788108229788097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 931 [0/90000 (0%)]	Loss: 0.0008	Cost: 37.61s
Train Epoch: 931 [20480/90000 (23%)]	Loss: -2.5856	Cost: 12.01s
Train Epoch: 931 [40960/90000 (45%)]	Loss: -2.4963	Cost: 10.83s
Train Epoch: 931 [61440/90000 (68%)]	Loss: -2.6417	Cost: 6.59s
Train Epoch: 931 [81920/90000 (91%)]	Loss: -2.8207	Cost: 11.34s
Train Epoch: 931 	Average Loss: -2.4426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2951

Saving model as e931_model.pt & e931_waveforms_supplementary.hdf5
Learning rate: 9.78765555840301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 932 [0/90000 (0%)]	Loss: -0.2600	Cost: 26.25s
Train Epoch: 932 [20480/90000 (23%)]	Loss: -2.4620	Cost: 9.35s
Train Epoch: 932 [40960/90000 (45%)]	Loss: -2.5302	Cost: 15.28s
Train Epoch: 932 [61440/90000 (68%)]	Loss: -2.7140	Cost: 12.22s
Train Epoch: 932 [81920/90000 (91%)]	Loss: -2.6236	Cost: 13.01s
Train Epoch: 932 	Average Loss: -2.3820
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0002

Learning rate: 9.787202414495261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 933 [0/90000 (0%)]	Loss: -0.2221	Cost: 46.74s
Train Epoch: 933 [20480/90000 (23%)]	Loss: -2.4487	Cost: 13.04s
Train Epoch: 933 [40960/90000 (45%)]	Loss: -2.3562	Cost: 11.16s
Train Epoch: 933 [61440/90000 (68%)]	Loss: -2.6252	Cost: 6.08s
Train Epoch: 933 [81920/90000 (91%)]	Loss: -2.4900	Cost: 11.24s
Train Epoch: 933 	Average Loss: -2.2428
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1504

Learning rate: 9.786748798109577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 934 [0/90000 (0%)]	Loss: 0.0561	Cost: 30.83s
Train Epoch: 934 [20480/90000 (23%)]	Loss: -2.2483	Cost: 7.84s
Train Epoch: 934 [40960/90000 (45%)]	Loss: -2.4296	Cost: 10.75s
Train Epoch: 934 [61440/90000 (68%)]	Loss: -2.5080	Cost: 6.64s
Train Epoch: 934 [81920/90000 (91%)]	Loss: -2.6516	Cost: 19.01s
Train Epoch: 934 	Average Loss: -2.2268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1561

Learning rate: 9.786294709290727e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 935 [0/90000 (0%)]	Loss: -0.0206	Cost: 31.61s
Train Epoch: 935 [20480/90000 (23%)]	Loss: -2.2716	Cost: 12.55s
Train Epoch: 935 [40960/90000 (45%)]	Loss: -2.4965	Cost: 12.38s
Train Epoch: 935 [61440/90000 (68%)]	Loss: -2.5193	Cost: 10.33s
Train Epoch: 935 [81920/90000 (91%)]	Loss: -2.6437	Cost: 9.17s
Train Epoch: 935 	Average Loss: -2.2609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0213

Learning rate: 9.785840148083527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 936 [0/90000 (0%)]	Loss: -0.1529	Cost: 35.00s
Train Epoch: 936 [20480/90000 (23%)]	Loss: -2.3254	Cost: 9.85s
Train Epoch: 936 [40960/90000 (45%)]	Loss: -2.2367	Cost: 9.39s
Train Epoch: 936 [61440/90000 (68%)]	Loss: -2.3315	Cost: 6.73s
Train Epoch: 936 [81920/90000 (91%)]	Loss: -2.4872	Cost: 20.21s
Train Epoch: 936 	Average Loss: -2.2021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0091

Learning rate: 9.785385114532841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 937 [0/90000 (0%)]	Loss: 0.0041	Cost: 37.74s
Train Epoch: 937 [20480/90000 (23%)]	Loss: -2.4104	Cost: 12.73s
Train Epoch: 937 [40960/90000 (45%)]	Loss: -2.5481	Cost: 12.35s
Train Epoch: 937 [61440/90000 (68%)]	Loss: -2.6216	Cost: 12.18s
Train Epoch: 937 [81920/90000 (91%)]	Loss: -2.6379	Cost: 6.78s
Train Epoch: 937 	Average Loss: -2.3495
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0398

Learning rate: 9.78492960868358e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 938 [0/90000 (0%)]	Loss: 0.0109	Cost: 28.84s
Train Epoch: 938 [20480/90000 (23%)]	Loss: -2.3985	Cost: 8.81s
Train Epoch: 938 [40960/90000 (45%)]	Loss: -2.5448	Cost: 11.82s
Train Epoch: 938 [61440/90000 (68%)]	Loss: -2.6522	Cost: 6.87s
Train Epoch: 938 [81920/90000 (91%)]	Loss: -2.6454	Cost: 9.01s
Train Epoch: 938 	Average Loss: -2.3517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0318

Learning rate: 9.784473630580698e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 939 [0/90000 (0%)]	Loss: 0.0057	Cost: 31.26s
Train Epoch: 939 [20480/90000 (23%)]	Loss: -2.1965	Cost: 12.79s
Train Epoch: 939 [40960/90000 (45%)]	Loss: -2.4748	Cost: 12.46s
Train Epoch: 939 [61440/90000 (68%)]	Loss: -2.4147	Cost: 12.50s
Train Epoch: 939 [81920/90000 (91%)]	Loss: -2.7144	Cost: 12.38s
Train Epoch: 939 	Average Loss: -2.2722
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1439

Learning rate: 9.784017180269201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 940 [0/90000 (0%)]	Loss: -0.2776	Cost: 29.03s
Train Epoch: 940 [20480/90000 (23%)]	Loss: -2.4482	Cost: 8.27s
Train Epoch: 940 [40960/90000 (45%)]	Loss: -2.5055	Cost: 17.40s
Train Epoch: 940 [61440/90000 (68%)]	Loss: -2.6636	Cost: 9.48s
Train Epoch: 940 [81920/90000 (91%)]	Loss: -2.6646	Cost: 11.34s
Train Epoch: 940 	Average Loss: -2.3779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1498

Learning rate: 9.783560257794138e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 941 [0/90000 (0%)]	Loss: 0.1473	Cost: 28.43s
Train Epoch: 941 [20480/90000 (23%)]	Loss: -2.4471	Cost: 13.89s
Train Epoch: 941 [40960/90000 (45%)]	Loss: -2.5277	Cost: 14.73s
Train Epoch: 941 [61440/90000 (68%)]	Loss: -2.5542	Cost: 12.87s
Train Epoch: 941 [81920/90000 (91%)]	Loss: -2.4505	Cost: 12.07s
Train Epoch: 941 	Average Loss: -2.2914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0099

Learning rate: 9.783102863200605e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 942 [0/90000 (0%)]	Loss: 0.1007	Cost: 58.26s
Train Epoch: 942 [20480/90000 (23%)]	Loss: -2.2509	Cost: 6.46s
Train Epoch: 942 [40960/90000 (45%)]	Loss: -2.5265	Cost: 13.55s
Train Epoch: 942 [61440/90000 (68%)]	Loss: -2.6512	Cost: 8.63s
Train Epoch: 942 [81920/90000 (91%)]	Loss: -2.4136	Cost: 7.95s
Train Epoch: 942 	Average Loss: -2.2395
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.1043

Learning rate: 9.782644996533745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 943 [0/90000 (0%)]	Loss: -0.1231	Cost: 28.42s
Train Epoch: 943 [20480/90000 (23%)]	Loss: -2.3730	Cost: 7.19s
Train Epoch: 943 [40960/90000 (45%)]	Loss: -2.5787	Cost: 25.37s
Train Epoch: 943 [61440/90000 (68%)]	Loss: -2.4709	Cost: 12.34s
Train Epoch: 943 [81920/90000 (91%)]	Loss: -2.3742	Cost: 12.25s
Train Epoch: 943 	Average Loss: -2.2299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0407

Learning rate: 9.782186657838747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 944 [0/90000 (0%)]	Loss: 0.0449	Cost: 46.83s
Train Epoch: 944 [20480/90000 (23%)]	Loss: -2.3430	Cost: 6.01s
Train Epoch: 944 [40960/90000 (45%)]	Loss: -2.6064	Cost: 15.17s
Train Epoch: 944 [61440/90000 (68%)]	Loss: -2.6009	Cost: 9.06s
Train Epoch: 944 [81920/90000 (91%)]	Loss: -2.8411	Cost: 11.18s
Train Epoch: 944 	Average Loss: -2.3283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1881

Learning rate: 9.781727847160849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 945 [0/90000 (0%)]	Loss: -0.1962	Cost: 33.02s
Train Epoch: 945 [20480/90000 (23%)]	Loss: -2.5333	Cost: 10.24s
Train Epoch: 945 [40960/90000 (45%)]	Loss: -2.6949	Cost: 21.14s
Train Epoch: 945 [61440/90000 (68%)]	Loss: -2.8078	Cost: 12.35s
Train Epoch: 945 [81920/90000 (91%)]	Loss: -2.8978	Cost: 11.87s
Train Epoch: 945 	Average Loss: -2.5070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2155

Learning rate: 9.781268564545331e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 946 [0/90000 (0%)]	Loss: -0.3684	Cost: 47.74s
Train Epoch: 946 [20480/90000 (23%)]	Loss: -2.7257	Cost: 11.94s
Train Epoch: 946 [40960/90000 (45%)]	Loss: -2.6916	Cost: 7.75s
Train Epoch: 946 [61440/90000 (68%)]	Loss: -2.8189	Cost: 6.17s
Train Epoch: 946 [81920/90000 (91%)]	Loss: -2.7666	Cost: 11.87s
Train Epoch: 946 	Average Loss: -2.5098
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1224

Learning rate: 9.780808810037527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 947 [0/90000 (0%)]	Loss: -0.2472	Cost: 29.33s
Train Epoch: 947 [20480/90000 (23%)]	Loss: -2.5965	Cost: 7.82s
Train Epoch: 947 [40960/90000 (45%)]	Loss: -2.6053	Cost: 16.42s
Train Epoch: 947 [61440/90000 (68%)]	Loss: -2.7524	Cost: 12.39s
Train Epoch: 947 [81920/90000 (91%)]	Loss: -2.6323	Cost: 12.27s
Train Epoch: 947 	Average Loss: -2.4203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0496

Learning rate: 9.780348583682808e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 948 [0/90000 (0%)]	Loss: -0.2018	Cost: 34.18s
Train Epoch: 948 [20480/90000 (23%)]	Loss: -2.6915	Cost: 12.41s
Train Epoch: 948 [40960/90000 (45%)]	Loss: -2.6339	Cost: 9.62s
Train Epoch: 948 [61440/90000 (68%)]	Loss: -2.7641	Cost: 6.29s
Train Epoch: 948 [81920/90000 (91%)]	Loss: -2.8347	Cost: 13.32s
Train Epoch: 948 	Average Loss: -2.5045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3513

Saving model as e948_model.pt & e948_waveforms_supplementary.hdf5
Learning rate: 9.779887885526599e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 949 [0/90000 (0%)]	Loss: -0.5178	Cost: 28.15s
Train Epoch: 949 [20480/90000 (23%)]	Loss: -2.6785	Cost: 9.45s
Train Epoch: 949 [40960/90000 (45%)]	Loss: -2.7511	Cost: 19.41s
Train Epoch: 949 [61440/90000 (68%)]	Loss: -2.9073	Cost: 12.22s
Train Epoch: 949 [81920/90000 (91%)]	Loss: -2.9369	Cost: 12.08s
Train Epoch: 949 	Average Loss: -2.5745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2500

Learning rate: 9.77942671561437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 950 [0/90000 (0%)]	Loss: -0.3135	Cost: 40.27s
Train Epoch: 950 [20480/90000 (23%)]	Loss: -2.5337	Cost: 12.89s
Train Epoch: 950 [40960/90000 (45%)]	Loss: -2.5072	Cost: 10.25s
Train Epoch: 950 [61440/90000 (68%)]	Loss: -2.7193	Cost: 6.41s
Train Epoch: 950 [81920/90000 (91%)]	Loss: -2.8641	Cost: 11.29s
Train Epoch: 950 	Average Loss: -2.5063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1879

Learning rate: 9.778965073991635e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 951 [0/90000 (0%)]	Loss: -0.0746	Cost: 31.45s
Train Epoch: 951 [20480/90000 (23%)]	Loss: -2.6173	Cost: 8.86s
Train Epoch: 951 [40960/90000 (45%)]	Loss: -2.8459	Cost: 8.53s
Train Epoch: 951 [61440/90000 (68%)]	Loss: -2.6876	Cost: 6.35s
Train Epoch: 951 [81920/90000 (91%)]	Loss: -2.7376	Cost: 16.86s
Train Epoch: 951 	Average Loss: -2.5423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1979

Learning rate: 9.778502960703957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 952 [0/90000 (0%)]	Loss: -0.3421	Cost: 30.88s
Train Epoch: 952 [20480/90000 (23%)]	Loss: -2.6150	Cost: 13.00s
Train Epoch: 952 [40960/90000 (45%)]	Loss: -2.6440	Cost: 12.06s
Train Epoch: 952 [61440/90000 (68%)]	Loss: -2.9144	Cost: 11.99s
Train Epoch: 952 [81920/90000 (91%)]	Loss: -2.8552	Cost: 7.88s
Train Epoch: 952 	Average Loss: -2.5943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2648

Learning rate: 9.778040375796944e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 953 [0/90000 (0%)]	Loss: -0.2620	Cost: 34.10s
Train Epoch: 953 [20480/90000 (23%)]	Loss: -2.7873	Cost: 9.32s
Train Epoch: 953 [40960/90000 (45%)]	Loss: -2.8672	Cost: 10.22s
Train Epoch: 953 [61440/90000 (68%)]	Loss: -2.8277	Cost: 7.31s
Train Epoch: 953 [81920/90000 (91%)]	Loss: -2.7800	Cost: 17.84s
Train Epoch: 953 	Average Loss: -2.5917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1386

Learning rate: 9.777577319316251e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 954 [0/90000 (0%)]	Loss: -0.0766	Cost: 40.56s
Train Epoch: 954 [20480/90000 (23%)]	Loss: -2.5700	Cost: 12.50s
Train Epoch: 954 [40960/90000 (45%)]	Loss: -2.5462	Cost: 12.19s
Train Epoch: 954 [61440/90000 (68%)]	Loss: -2.8630	Cost: 11.87s
Train Epoch: 954 [81920/90000 (91%)]	Loss: -2.8113	Cost: 8.16s
Train Epoch: 954 	Average Loss: -2.4748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1817

Learning rate: 9.777113791307581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 955 [0/90000 (0%)]	Loss: -0.1991	Cost: 31.36s
Train Epoch: 955 [20480/90000 (23%)]	Loss: -2.6073	Cost: 11.01s
Train Epoch: 955 [40960/90000 (45%)]	Loss: -2.6571	Cost: 11.91s
Train Epoch: 955 [61440/90000 (68%)]	Loss: -2.6440	Cost: 6.22s
Train Epoch: 955 [81920/90000 (91%)]	Loss: -2.5485	Cost: 13.98s
Train Epoch: 955 	Average Loss: -2.4353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0451

Learning rate: 9.776649791816682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 956 [0/90000 (0%)]	Loss: -0.0101	Cost: 37.59s
Train Epoch: 956 [20480/90000 (23%)]	Loss: -2.5022	Cost: 12.98s
Train Epoch: 956 [40960/90000 (45%)]	Loss: -2.6469	Cost: 12.29s
Train Epoch: 956 [61440/90000 (68%)]	Loss: -2.7315	Cost: 12.24s
Train Epoch: 956 [81920/90000 (91%)]	Loss: -2.9303	Cost: 12.04s
Train Epoch: 956 	Average Loss: -2.4914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1923

Learning rate: 9.776185320889348e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 957 [0/90000 (0%)]	Loss: -0.0282	Cost: 42.76s
Train Epoch: 957 [20480/90000 (23%)]	Loss: -2.7428	Cost: 7.33s
Train Epoch: 957 [40960/90000 (45%)]	Loss: -2.7173	Cost: 12.98s
Train Epoch: 957 [61440/90000 (68%)]	Loss: -2.7889	Cost: 8.64s
Train Epoch: 957 [81920/90000 (91%)]	Loss: -2.7554	Cost: 8.98s
Train Epoch: 957 	Average Loss: -2.4804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1305

Learning rate: 9.775720378571423e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 958 [0/90000 (0%)]	Loss: -0.0940	Cost: 31.37s
Train Epoch: 958 [20480/90000 (23%)]	Loss: -2.4937	Cost: 9.79s
Train Epoch: 958 [40960/90000 (45%)]	Loss: -2.7159	Cost: 21.71s
Train Epoch: 958 [61440/90000 (68%)]	Loss: -2.9247	Cost: 12.68s
Train Epoch: 958 [81920/90000 (91%)]	Loss: -2.9237	Cost: 12.29s
Train Epoch: 958 	Average Loss: -2.5648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3597

Saving model as e958_model.pt & e958_waveforms_supplementary.hdf5
Learning rate: 9.775254964908792e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 959 [0/90000 (0%)]	Loss: -0.6741	Cost: 35.49s
Train Epoch: 959 [20480/90000 (23%)]	Loss: -2.6646	Cost: 8.41s
Train Epoch: 959 [40960/90000 (45%)]	Loss: -2.7150	Cost: 12.99s
Train Epoch: 959 [61440/90000 (68%)]	Loss: -2.9276	Cost: 8.57s
Train Epoch: 959 [81920/90000 (91%)]	Loss: -3.0296	Cost: 8.70s
Train Epoch: 959 	Average Loss: -2.6512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4121

Saving model as e959_model.pt & e959_waveforms_supplementary.hdf5
Learning rate: 9.774789079947391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 960 [0/90000 (0%)]	Loss: -0.3949	Cost: 32.44s
Train Epoch: 960 [20480/90000 (23%)]	Loss: -2.2261	Cost: 9.52s
Train Epoch: 960 [40960/90000 (45%)]	Loss: -2.3807	Cost: 23.72s
Train Epoch: 960 [61440/90000 (68%)]	Loss: -2.4350	Cost: 12.23s
Train Epoch: 960 [81920/90000 (91%)]	Loss: -2.4234	Cost: 11.89s
Train Epoch: 960 	Average Loss: -2.2401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0970

Learning rate: 9.774322723733201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 961 [0/90000 (0%)]	Loss: 0.1524	Cost: 38.50s
Train Epoch: 961 [20480/90000 (23%)]	Loss: -2.4709	Cost: 6.72s
Train Epoch: 961 [40960/90000 (45%)]	Loss: -2.6745	Cost: 13.48s
Train Epoch: 961 [61440/90000 (68%)]	Loss: -2.6701	Cost: 8.59s
Train Epoch: 961 [81920/90000 (91%)]	Loss: -2.7676	Cost: 8.33s
Train Epoch: 961 	Average Loss: -2.3863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1658

Learning rate: 9.773855896312248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 962 [0/90000 (0%)]	Loss: -0.2219	Cost: 27.80s
Train Epoch: 962 [20480/90000 (23%)]	Loss: -2.6494	Cost: 6.70s
Train Epoch: 962 [40960/90000 (45%)]	Loss: -2.7085	Cost: 18.20s
Train Epoch: 962 [61440/90000 (68%)]	Loss: -3.1043	Cost: 14.87s
Train Epoch: 962 [81920/90000 (91%)]	Loss: -2.8552	Cost: 12.42s
Train Epoch: 962 	Average Loss: -2.5785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2554

Learning rate: 9.773388597730608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 963 [0/90000 (0%)]	Loss: -0.2134	Cost: 32.77s
Train Epoch: 963 [20480/90000 (23%)]	Loss: -2.6143	Cost: 12.78s
Train Epoch: 963 [40960/90000 (45%)]	Loss: -2.5697	Cost: 13.92s
Train Epoch: 963 [61440/90000 (68%)]	Loss: -2.7921	Cost: 9.04s
Train Epoch: 963 [81920/90000 (91%)]	Loss: -2.8237	Cost: 6.31s
Train Epoch: 963 	Average Loss: -2.5641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3276

Learning rate: 9.772920828034401e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 964 [0/90000 (0%)]	Loss: -0.3052	Cost: 30.38s
Train Epoch: 964 [20480/90000 (23%)]	Loss: -2.6408	Cost: 9.29s
Train Epoch: 964 [40960/90000 (45%)]	Loss: -2.4197	Cost: 11.65s
Train Epoch: 964 [61440/90000 (68%)]	Loss: -2.7668	Cost: 8.64s
Train Epoch: 964 [81920/90000 (91%)]	Loss: -2.5340	Cost: 9.00s
Train Epoch: 964 	Average Loss: -2.4329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0278

Learning rate: 9.772452587269794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 965 [0/90000 (0%)]	Loss: -0.0028	Cost: 27.21s
Train Epoch: 965 [20480/90000 (23%)]	Loss: -2.3375	Cost: 10.23s
Train Epoch: 965 [40960/90000 (45%)]	Loss: -2.4191	Cost: 15.63s
Train Epoch: 965 [61440/90000 (68%)]	Loss: -2.7087	Cost: 12.69s
Train Epoch: 965 [81920/90000 (91%)]	Loss: -2.6621	Cost: 12.04s
Train Epoch: 965 	Average Loss: -2.3011
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1274

Learning rate: 9.771983875482999e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 966 [0/90000 (0%)]	Loss: -0.3073	Cost: 34.14s
Train Epoch: 966 [20480/90000 (23%)]	Loss: -2.5114	Cost: 12.88s
Train Epoch: 966 [40960/90000 (45%)]	Loss: -2.8164	Cost: 11.93s
Train Epoch: 966 [61440/90000 (68%)]	Loss: -2.8789	Cost: 8.05s
Train Epoch: 966 [81920/90000 (91%)]	Loss: -2.8576	Cost: 10.59s
Train Epoch: 966 	Average Loss: -2.5440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3179

Learning rate: 9.771514692720278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 967 [0/90000 (0%)]	Loss: -0.5597	Cost: 45.96s
Train Epoch: 967 [20480/90000 (23%)]	Loss: -2.8207	Cost: 7.99s
Train Epoch: 967 [40960/90000 (45%)]	Loss: -2.9623	Cost: 14.92s
Train Epoch: 967 [61440/90000 (68%)]	Loss: -3.0153	Cost: 12.26s
Train Epoch: 967 [81920/90000 (91%)]	Loss: -2.9205	Cost: 12.83s
Train Epoch: 967 	Average Loss: -2.6815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3073

Learning rate: 9.771045039027936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 968 [0/90000 (0%)]	Loss: -0.1425	Cost: 44.94s
Train Epoch: 968 [20480/90000 (23%)]	Loss: -2.7584	Cost: 11.64s
Train Epoch: 968 [40960/90000 (45%)]	Loss: -2.9015	Cost: 8.63s
Train Epoch: 968 [61440/90000 (68%)]	Loss: -3.0626	Cost: 6.55s
Train Epoch: 968 [81920/90000 (91%)]	Loss: -3.1388	Cost: 14.48s
Train Epoch: 968 	Average Loss: -2.6815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3098

Learning rate: 9.770574914452328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 969 [0/90000 (0%)]	Loss: -0.3560	Cost: 37.49s
Train Epoch: 969 [20480/90000 (23%)]	Loss: -2.8220	Cost: 9.80s
Train Epoch: 969 [40960/90000 (45%)]	Loss: -2.8364	Cost: 17.71s
Train Epoch: 969 [61440/90000 (68%)]	Loss: -2.7654	Cost: 12.47s
Train Epoch: 969 [81920/90000 (91%)]	Loss: -2.7828	Cost: 11.88s
Train Epoch: 969 	Average Loss: -2.6246
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1413

Learning rate: 9.770104319039851e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 970 [0/90000 (0%)]	Loss: -0.4088	Cost: 38.48s
Train Epoch: 970 [20480/90000 (23%)]	Loss: -2.7272	Cost: 12.18s
Train Epoch: 970 [40960/90000 (45%)]	Loss: -2.6411	Cost: 7.92s
Train Epoch: 970 [61440/90000 (68%)]	Loss: -2.7098	Cost: 6.21s
Train Epoch: 970 [81920/90000 (91%)]	Loss: -2.7832	Cost: 10.62s
Train Epoch: 970 	Average Loss: -2.5636
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3343

Learning rate: 9.769633252836953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 971 [0/90000 (0%)]	Loss: -0.2998	Cost: 29.35s
Train Epoch: 971 [20480/90000 (23%)]	Loss: -2.8684	Cost: 6.83s
Train Epoch: 971 [40960/90000 (45%)]	Loss: -2.8691	Cost: 19.24s
Train Epoch: 971 [61440/90000 (68%)]	Loss: -2.8764	Cost: 12.84s
Train Epoch: 971 [81920/90000 (91%)]	Loss: -2.9222	Cost: 12.04s
Train Epoch: 971 	Average Loss: -2.6502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2489

Learning rate: 9.769161715890125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 972 [0/90000 (0%)]	Loss: -0.2160	Cost: 51.33s
Train Epoch: 972 [20480/90000 (23%)]	Loss: -2.7397	Cost: 9.24s
Train Epoch: 972 [40960/90000 (45%)]	Loss: -2.8215	Cost: 7.89s
Train Epoch: 972 [61440/90000 (68%)]	Loss: -2.8496	Cost: 7.52s
Train Epoch: 972 [81920/90000 (91%)]	Loss: -2.8945	Cost: 11.83s
Train Epoch: 972 	Average Loss: -2.5610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2507

Learning rate: 9.768689708245906e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 973 [0/90000 (0%)]	Loss: -0.3146	Cost: 30.27s
Train Epoch: 973 [20480/90000 (23%)]	Loss: -2.9397	Cost: 12.88s
Train Epoch: 973 [40960/90000 (45%)]	Loss: -2.8263	Cost: 15.56s
Train Epoch: 973 [61440/90000 (68%)]	Loss: -2.9873	Cost: 12.34s
Train Epoch: 973 [81920/90000 (91%)]	Loss: -3.0680	Cost: 12.16s
Train Epoch: 973 	Average Loss: -2.6708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3946

Learning rate: 9.768217229950883e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 974 [0/90000 (0%)]	Loss: -0.5344	Cost: 33.16s
Train Epoch: 974 [20480/90000 (23%)]	Loss: -2.9727	Cost: 12.40s
Train Epoch: 974 [40960/90000 (45%)]	Loss: -2.8553	Cost: 11.76s
Train Epoch: 974 [61440/90000 (68%)]	Loss: -3.0464	Cost: 9.17s
Train Epoch: 974 [81920/90000 (91%)]	Loss: -3.1252	Cost: 14.16s
Train Epoch: 974 	Average Loss: -2.7734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4412

Saving model as e974_model.pt & e974_waveforms_supplementary.hdf5
Learning rate: 9.767744281051684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 975 [0/90000 (0%)]	Loss: -0.8848	Cost: 32.54s
Train Epoch: 975 [20480/90000 (23%)]	Loss: -2.8858	Cost: 8.01s
Train Epoch: 975 [40960/90000 (45%)]	Loss: -2.9358	Cost: 16.03s
Train Epoch: 975 [61440/90000 (68%)]	Loss: -3.1113	Cost: 12.12s
Train Epoch: 975 [81920/90000 (91%)]	Loss: -3.0010	Cost: 12.02s
Train Epoch: 975 	Average Loss: -2.8388
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5800

Saving model as e975_model.pt & e975_waveforms_supplementary.hdf5
Learning rate: 9.767270861594989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 976 [0/90000 (0%)]	Loss: -0.6060	Cost: 32.59s
Train Epoch: 976 [20480/90000 (23%)]	Loss: -2.9698	Cost: 9.63s
Train Epoch: 976 [40960/90000 (45%)]	Loss: -2.9966	Cost: 11.31s
Train Epoch: 976 [61440/90000 (68%)]	Loss: -3.2166	Cost: 6.29s
Train Epoch: 976 [81920/90000 (91%)]	Loss: -3.2469	Cost: 13.88s
Train Epoch: 976 	Average Loss: -2.8837
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4696

Learning rate: 9.766796971627527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 977 [0/90000 (0%)]	Loss: -0.0620	Cost: 38.59s
Train Epoch: 977 [20480/90000 (23%)]	Loss: -2.8463	Cost: 11.62s
Train Epoch: 977 [40960/90000 (45%)]	Loss: -2.9922	Cost: 14.84s
Train Epoch: 977 [61440/90000 (68%)]	Loss: -2.9698	Cost: 12.15s
Train Epoch: 977 [81920/90000 (91%)]	Loss: -3.1561	Cost: 11.72s
Train Epoch: 977 	Average Loss: -2.7656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3880

Learning rate: 9.766322611196063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 978 [0/90000 (0%)]	Loss: -0.3556	Cost: 46.98s
Train Epoch: 978 [20480/90000 (23%)]	Loss: -2.8058	Cost: 6.16s
Train Epoch: 978 [40960/90000 (45%)]	Loss: -3.0814	Cost: 14.43s
Train Epoch: 978 [61440/90000 (68%)]	Loss: -3.0876	Cost: 8.94s
Train Epoch: 978 [81920/90000 (91%)]	Loss: -3.1453	Cost: 11.71s
Train Epoch: 978 	Average Loss: -2.8115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4651

Learning rate: 9.765847780347416e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 979 [0/90000 (0%)]	Loss: -0.4631	Cost: 32.39s
Train Epoch: 979 [20480/90000 (23%)]	Loss: -2.9116	Cost: 13.13s
Train Epoch: 979 [40960/90000 (45%)]	Loss: -3.0558	Cost: 16.67s
Train Epoch: 979 [61440/90000 (68%)]	Loss: -2.9351	Cost: 11.91s
Train Epoch: 979 [81920/90000 (91%)]	Loss: -2.9912	Cost: 11.98s
Train Epoch: 979 	Average Loss: -2.7908
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4488

Learning rate: 9.765372479128451e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 980 [0/90000 (0%)]	Loss: -0.7452	Cost: 29.97s
Train Epoch: 980 [20480/90000 (23%)]	Loss: -2.7220	Cost: 6.37s
Train Epoch: 980 [40960/90000 (45%)]	Loss: -2.8719	Cost: 13.75s
Train Epoch: 980 [61440/90000 (68%)]	Loss: -2.8583	Cost: 8.49s
Train Epoch: 980 [81920/90000 (91%)]	Loss: -3.0004	Cost: 8.74s
Train Epoch: 980 	Average Loss: -2.6872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2901

Learning rate: 9.764896707586078e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 981 [0/90000 (0%)]	Loss: -0.5362	Cost: 28.89s
Train Epoch: 981 [20480/90000 (23%)]	Loss: -2.8500	Cost: 9.99s
Train Epoch: 981 [40960/90000 (45%)]	Loss: -3.1587	Cost: 21.64s
Train Epoch: 981 [61440/90000 (68%)]	Loss: -3.2425	Cost: 13.76s
Train Epoch: 981 [81920/90000 (91%)]	Loss: -3.2729	Cost: 12.56s
Train Epoch: 981 	Average Loss: -2.8603
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5287

Learning rate: 9.764420465767253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 982 [0/90000 (0%)]	Loss: -0.4148	Cost: 57.32s
Train Epoch: 982 [20480/90000 (23%)]	Loss: -3.0560	Cost: 6.20s
Train Epoch: 982 [40960/90000 (45%)]	Loss: -3.1084	Cost: 14.46s
Train Epoch: 982 [61440/90000 (68%)]	Loss: -3.1079	Cost: 9.22s
Train Epoch: 982 [81920/90000 (91%)]	Loss: -3.0753	Cost: 7.95s
Train Epoch: 982 	Average Loss: -2.8674
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4868

Learning rate: 9.76394375371898e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 983 [0/90000 (0%)]	Loss: -0.4807	Cost: 28.39s
Train Epoch: 983 [20480/90000 (23%)]	Loss: -2.7258	Cost: 8.52s
Train Epoch: 983 [40960/90000 (45%)]	Loss: -2.9209	Cost: 23.45s
Train Epoch: 983 [61440/90000 (68%)]	Loss: -3.0767	Cost: 12.18s
Train Epoch: 983 [81920/90000 (91%)]	Loss: -3.2677	Cost: 11.98s
Train Epoch: 983 	Average Loss: -2.7735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2333

Learning rate: 9.76346657148831e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 984 [0/90000 (0%)]	Loss: -0.1781	Cost: 33.10s
Train Epoch: 984 [20480/90000 (23%)]	Loss: -2.7783	Cost: 10.14s
Train Epoch: 984 [40960/90000 (45%)]	Loss: -2.7635	Cost: 9.41s
Train Epoch: 984 [61440/90000 (68%)]	Loss: -3.0049	Cost: 7.60s
Train Epoch: 984 [81920/90000 (91%)]	Loss: -3.0974	Cost: 11.35s
Train Epoch: 984 	Average Loss: -2.6886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2998

Learning rate: 9.762988919122336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 985 [0/90000 (0%)]	Loss: -0.5241	Cost: 27.07s
Train Epoch: 985 [20480/90000 (23%)]	Loss: -2.8709	Cost: 8.79s
Train Epoch: 985 [40960/90000 (45%)]	Loss: -2.5608	Cost: 16.37s
Train Epoch: 985 [61440/90000 (68%)]	Loss: -2.6755	Cost: 13.42s
Train Epoch: 985 [81920/90000 (91%)]	Loss: -2.9470	Cost: 12.47s
Train Epoch: 985 	Average Loss: -2.5950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2221

Learning rate: 9.762510796668202e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 986 [0/90000 (0%)]	Loss: -0.3015	Cost: 35.17s
Train Epoch: 986 [20480/90000 (23%)]	Loss: -2.7785	Cost: 10.83s
Train Epoch: 986 [40960/90000 (45%)]	Loss: -3.0608	Cost: 10.13s
Train Epoch: 986 [61440/90000 (68%)]	Loss: -3.1552	Cost: 8.87s
Train Epoch: 986 [81920/90000 (91%)]	Loss: -3.1315	Cost: 8.49s
Train Epoch: 986 	Average Loss: -2.7687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4242

Learning rate: 9.762032204173097e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 987 [0/90000 (0%)]	Loss: -0.6857	Cost: 46.77s
Train Epoch: 987 [20480/90000 (23%)]	Loss: -2.9720	Cost: 10.32s
Train Epoch: 987 [40960/90000 (45%)]	Loss: -3.0411	Cost: 13.50s
Train Epoch: 987 [61440/90000 (68%)]	Loss: -3.1911	Cost: 11.80s
Train Epoch: 987 [81920/90000 (91%)]	Loss: -2.9527	Cost: 12.05s
Train Epoch: 987 	Average Loss: -2.8323
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3709

Learning rate: 9.761553141684257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 988 [0/90000 (0%)]	Loss: -0.3126	Cost: 36.23s
Train Epoch: 988 [20480/90000 (23%)]	Loss: -3.0193	Cost: 7.95s
Train Epoch: 988 [40960/90000 (45%)]	Loss: -3.1274	Cost: 11.56s
Train Epoch: 988 [61440/90000 (68%)]	Loss: -3.1454	Cost: 8.76s
Train Epoch: 988 [81920/90000 (91%)]	Loss: -3.2292	Cost: 13.12s
Train Epoch: 988 	Average Loss: -2.9194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4903

Learning rate: 9.761073609248962e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 989 [0/90000 (0%)]	Loss: -0.3309	Cost: 30.98s
Train Epoch: 989 [20480/90000 (23%)]	Loss: -3.0620	Cost: 7.94s
Train Epoch: 989 [40960/90000 (45%)]	Loss: -3.2168	Cost: 18.58s
Train Epoch: 989 [61440/90000 (68%)]	Loss: -3.3266	Cost: 13.00s
Train Epoch: 989 [81920/90000 (91%)]	Loss: -3.3787	Cost: 12.10s
Train Epoch: 989 	Average Loss: -3.0113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6090

Saving model as e989_model.pt & e989_waveforms_supplementary.hdf5
Learning rate: 9.76059360691454e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 990 [0/90000 (0%)]	Loss: -0.4006	Cost: 33.39s
Train Epoch: 990 [20480/90000 (23%)]	Loss: -3.1377	Cost: 10.88s
Train Epoch: 990 [40960/90000 (45%)]	Loss: -3.1633	Cost: 10.45s
Train Epoch: 990 [61440/90000 (68%)]	Loss: -3.1561	Cost: 7.94s
Train Epoch: 990 [81920/90000 (91%)]	Loss: -3.2381	Cost: 13.61s
Train Epoch: 990 	Average Loss: -2.9628
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4979

Learning rate: 9.760113134728365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 991 [0/90000 (0%)]	Loss: -0.4172	Cost: 45.71s
Train Epoch: 991 [20480/90000 (23%)]	Loss: -3.1438	Cost: 11.58s
Train Epoch: 991 [40960/90000 (45%)]	Loss: -3.0640	Cost: 12.40s
Train Epoch: 991 [61440/90000 (68%)]	Loss: -3.2356	Cost: 12.05s
Train Epoch: 991 [81920/90000 (91%)]	Loss: -3.2341	Cost: 11.85s
Train Epoch: 991 	Average Loss: -2.9424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6025

Learning rate: 9.759632192737859e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 992 [0/90000 (0%)]	Loss: -0.1780	Cost: 36.99s
Train Epoch: 992 [20480/90000 (23%)]	Loss: -3.1850	Cost: 6.67s
Train Epoch: 992 [40960/90000 (45%)]	Loss: -3.1438	Cost: 14.21s
Train Epoch: 992 [61440/90000 (68%)]	Loss: -3.3404	Cost: 8.55s
Train Epoch: 992 [81920/90000 (91%)]	Loss: -3.3877	Cost: 8.52s
Train Epoch: 992 	Average Loss: -3.0197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5233

Learning rate: 9.759150780990488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 993 [0/90000 (0%)]	Loss: -0.7140	Cost: 31.78s
Train Epoch: 993 [20480/90000 (23%)]	Loss: -2.8028	Cost: 10.18s
Train Epoch: 993 [40960/90000 (45%)]	Loss: -2.2375	Cost: 21.18s
Train Epoch: 993 [61440/90000 (68%)]	Loss: -1.8255	Cost: 12.75s
Train Epoch: 993 [81920/90000 (91%)]	Loss: -2.0416	Cost: 12.17s
Train Epoch: 993 	Average Loss: -2.1701
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.2558

Learning rate: 9.758668899533768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 994 [0/90000 (0%)]	Loss: 0.3632	Cost: 42.46s
Train Epoch: 994 [20480/90000 (23%)]	Loss: -2.3856	Cost: 10.71s
Train Epoch: 994 [40960/90000 (45%)]	Loss: -2.6042	Cost: 8.97s
Train Epoch: 994 [61440/90000 (68%)]	Loss: -2.8277	Cost: 6.42s
Train Epoch: 994 [81920/90000 (91%)]	Loss: -2.7397	Cost: 13.56s
Train Epoch: 994 	Average Loss: -2.3547
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1565

Learning rate: 9.758186548415257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 995 [0/90000 (0%)]	Loss: 0.1483	Cost: 31.61s
Train Epoch: 995 [20480/90000 (23%)]	Loss: -2.5281	Cost: 10.27s
Train Epoch: 995 [40960/90000 (45%)]	Loss: -2.6496	Cost: 22.95s
Train Epoch: 995 [61440/90000 (68%)]	Loss: -2.9780	Cost: 11.91s
Train Epoch: 995 [81920/90000 (91%)]	Loss: -2.9477	Cost: 12.09s
Train Epoch: 995 	Average Loss: -2.5787
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3124

Learning rate: 9.757703727682558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 996 [0/90000 (0%)]	Loss: -0.3317	Cost: 44.14s
Train Epoch: 996 [20480/90000 (23%)]	Loss: -2.9737	Cost: 11.24s
Train Epoch: 996 [40960/90000 (45%)]	Loss: -2.8996	Cost: 6.53s
Train Epoch: 996 [61440/90000 (68%)]	Loss: -2.8919	Cost: 6.36s
Train Epoch: 996 [81920/90000 (91%)]	Loss: -3.0426	Cost: 12.85s
Train Epoch: 996 	Average Loss: -2.6668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.3689

Learning rate: 9.757220437383328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 997 [0/90000 (0%)]	Loss: -0.3014	Cost: 29.39s
Train Epoch: 997 [20480/90000 (23%)]	Loss: -2.7967	Cost: 6.45s
Train Epoch: 997 [40960/90000 (45%)]	Loss: -3.0178	Cost: 20.61s
Train Epoch: 997 [61440/90000 (68%)]	Loss: -3.1677	Cost: 14.61s
Train Epoch: 997 [81920/90000 (91%)]	Loss: -3.2982	Cost: 12.24s
Train Epoch: 997 	Average Loss: -2.8482
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5878

Learning rate: 9.756736677565264e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 998 [0/90000 (0%)]	Loss: -0.6352	Cost: 32.41s
Train Epoch: 998 [20480/90000 (23%)]	Loss: -3.1756	Cost: 11.25s
Train Epoch: 998 [40960/90000 (45%)]	Loss: -3.2255	Cost: 9.87s
Train Epoch: 998 [61440/90000 (68%)]	Loss: -3.3809	Cost: 9.07s
Train Epoch: 998 [81920/90000 (91%)]	Loss: -3.3128	Cost: 12.16s
Train Epoch: 998 	Average Loss: -3.0635
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5026

Learning rate: 9.756252448276111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 999 [0/90000 (0%)]	Loss: -0.5798	Cost: 40.84s
Train Epoch: 999 [20480/90000 (23%)]	Loss: -3.2242	Cost: 7.64s
Train Epoch: 999 [40960/90000 (45%)]	Loss: -3.1677	Cost: 16.94s
Train Epoch: 999 [61440/90000 (68%)]	Loss: -3.4229	Cost: 12.03s
Train Epoch: 999 [81920/90000 (91%)]	Loss: -3.4784	Cost: 12.06s
Train Epoch: 999 	Average Loss: -3.0346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7546

Saving model as e999_model.pt & e999_waveforms_supplementary.hdf5
Learning rate: 9.755767749563662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1000 [0/90000 (0%)]	Loss: -0.6133	Cost: 42.48s
Train Epoch: 1000 [20480/90000 (23%)]	Loss: -3.3407	Cost: 9.25s
Train Epoch: 1000 [40960/90000 (45%)]	Loss: -3.3313	Cost: 9.93s
Train Epoch: 1000 [61440/90000 (68%)]	Loss: -3.4283	Cost: 8.29s
Train Epoch: 1000 [81920/90000 (91%)]	Loss: -3.4935	Cost: 12.04s
Train Epoch: 1000 	Average Loss: -3.1155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6747

Learning rate: 9.755282581475752e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1001 [0/90000 (0%)]	Loss: -0.9892	Cost: 29.26s
Train Epoch: 1001 [20480/90000 (23%)]	Loss: -3.2649	Cost: 8.72s
Train Epoch: 1001 [40960/90000 (45%)]	Loss: -3.2890	Cost: 16.26s
Train Epoch: 1001 [61440/90000 (68%)]	Loss: -3.2197	Cost: 12.17s
Train Epoch: 1001 [81920/90000 (91%)]	Loss: -3.3680	Cost: 11.86s
Train Epoch: 1001 	Average Loss: -3.0903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6190

Learning rate: 9.754796944060267e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1002 [0/90000 (0%)]	Loss: -0.7619	Cost: 31.92s
Train Epoch: 1002 [20480/90000 (23%)]	Loss: -3.1536	Cost: 12.34s
Train Epoch: 1002 [40960/90000 (45%)]	Loss: -3.1287	Cost: 10.26s
Train Epoch: 1002 [61440/90000 (68%)]	Loss: -2.9675	Cost: 7.46s
Train Epoch: 1002 [81920/90000 (91%)]	Loss: -2.5985	Cost: 10.09s
Train Epoch: 1002 	Average Loss: -2.7968
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0129

Learning rate: 9.754310837365139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1003 [0/90000 (0%)]	Loss: -0.4321	Cost: 35.66s
Train Epoch: 1003 [20480/90000 (23%)]	Loss: -2.3898	Cost: 7.30s
Train Epoch: 1003 [40960/90000 (45%)]	Loss: -2.5700	Cost: 18.36s
Train Epoch: 1003 [61440/90000 (68%)]	Loss: -2.7660	Cost: 12.41s
Train Epoch: 1003 [81920/90000 (91%)]	Loss: -2.9808	Cost: 12.72s
Train Epoch: 1003 	Average Loss: -2.4725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2498

Learning rate: 9.753824261438342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1004 [0/90000 (0%)]	Loss: -0.2758	Cost: 38.11s
Train Epoch: 1004 [20480/90000 (23%)]	Loss: -2.5795	Cost: 12.49s
Train Epoch: 1004 [40960/90000 (45%)]	Loss: -2.8453	Cost: 9.89s
Train Epoch: 1004 [61440/90000 (68%)]	Loss: -2.7575	Cost: 6.38s
Train Epoch: 1004 [81920/90000 (91%)]	Loss: -2.8360	Cost: 11.84s
Train Epoch: 1004 	Average Loss: -2.5554
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2229

Learning rate: 9.753337216327901e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1005 [0/90000 (0%)]	Loss: -0.2909	Cost: 29.27s
Train Epoch: 1005 [20480/90000 (23%)]	Loss: -2.6304	Cost: 6.36s
Train Epoch: 1005 [40960/90000 (45%)]	Loss: -3.0460	Cost: 19.68s
Train Epoch: 1005 [61440/90000 (68%)]	Loss: -3.1778	Cost: 12.36s
Train Epoch: 1005 [81920/90000 (91%)]	Loss: -3.0565	Cost: 12.14s
Train Epoch: 1005 	Average Loss: -2.7703
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4923

Learning rate: 9.752849702081885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1006 [0/90000 (0%)]	Loss: -0.1277	Cost: 40.44s
Train Epoch: 1006 [20480/90000 (23%)]	Loss: -3.1124	Cost: 9.24s
Train Epoch: 1006 [40960/90000 (45%)]	Loss: -3.2115	Cost: 10.26s
Train Epoch: 1006 [61440/90000 (68%)]	Loss: -3.3607	Cost: 7.64s
Train Epoch: 1006 [81920/90000 (91%)]	Loss: -3.3675	Cost: 14.70s
Train Epoch: 1006 	Average Loss: -3.0007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6171

Learning rate: 9.752361718748408e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1007 [0/90000 (0%)]	Loss: -0.9255	Cost: 33.54s
Train Epoch: 1007 [20480/90000 (23%)]	Loss: -3.2088	Cost: 9.24s
Train Epoch: 1007 [40960/90000 (45%)]	Loss: -3.3865	Cost: 20.54s
Train Epoch: 1007 [61440/90000 (68%)]	Loss: -2.9985	Cost: 12.47s
Train Epoch: 1007 [81920/90000 (91%)]	Loss: -3.2059	Cost: 13.14s
Train Epoch: 1007 	Average Loss: -2.9809
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5228

Learning rate: 9.751873266375635e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1008 [0/90000 (0%)]	Loss: -0.1300	Cost: 57.30s
Train Epoch: 1008 [20480/90000 (23%)]	Loss: -3.1721	Cost: 10.06s
Train Epoch: 1008 [40960/90000 (45%)]	Loss: -3.2628	Cost: 6.55s
Train Epoch: 1008 [61440/90000 (68%)]	Loss: -3.2156	Cost: 6.47s
Train Epoch: 1008 [81920/90000 (91%)]	Loss: -3.0032	Cost: 12.54s
Train Epoch: 1008 	Average Loss: -2.9277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: 0.0007

Learning rate: 9.751384345011772e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1009 [0/90000 (0%)]	Loss: -0.1368	Cost: 30.50s
Train Epoch: 1009 [20480/90000 (23%)]	Loss: -2.4796	Cost: 11.79s
Train Epoch: 1009 [40960/90000 (45%)]	Loss: -2.6327	Cost: 19.10s
Train Epoch: 1009 [61440/90000 (68%)]	Loss: -2.7364	Cost: 12.18s
Train Epoch: 1009 [81920/90000 (91%)]	Loss: -2.9138	Cost: 12.17s
Train Epoch: 1009 	Average Loss: -2.4797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2977

Learning rate: 9.750894954705075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1010 [0/90000 (0%)]	Loss: -0.4774	Cost: 43.48s
Train Epoch: 1010 [20480/90000 (23%)]	Loss: -2.5232	Cost: 11.90s
Train Epoch: 1010 [40960/90000 (45%)]	Loss: -2.6466	Cost: 6.81s
Train Epoch: 1010 [61440/90000 (68%)]	Loss: -2.8390	Cost: 6.27s
Train Epoch: 1010 [81920/90000 (91%)]	Loss: -2.9723	Cost: 13.51s
Train Epoch: 1010 	Average Loss: -2.5527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2245

Learning rate: 9.750405095503843e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1011 [0/90000 (0%)]	Loss: -0.3557	Cost: 34.87s
Train Epoch: 1011 [20480/90000 (23%)]	Loss: -2.9554	Cost: 10.84s
Train Epoch: 1011 [40960/90000 (45%)]	Loss: -2.9503	Cost: 21.92s
Train Epoch: 1011 [61440/90000 (68%)]	Loss: -3.2054	Cost: 11.99s
Train Epoch: 1011 [81920/90000 (91%)]	Loss: -2.6968	Cost: 11.83s
Train Epoch: 1011 	Average Loss: -2.7937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1660

Learning rate: 9.749914767456425e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1012 [0/90000 (0%)]	Loss: 0.0065	Cost: 52.41s
Train Epoch: 1012 [20480/90000 (23%)]	Loss: -2.5757	Cost: 6.26s
Train Epoch: 1012 [40960/90000 (45%)]	Loss: -2.8687	Cost: 13.57s
Train Epoch: 1012 [61440/90000 (68%)]	Loss: -3.1952	Cost: 8.58s
Train Epoch: 1012 [81920/90000 (91%)]	Loss: -3.3625	Cost: 8.38s
Train Epoch: 1012 	Average Loss: -2.7219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6058

Learning rate: 9.749423970611215e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1013 [0/90000 (0%)]	Loss: -0.5949	Cost: 27.43s
Train Epoch: 1013 [20480/90000 (23%)]	Loss: -3.0480	Cost: 8.25s
Train Epoch: 1013 [40960/90000 (45%)]	Loss: -2.8673	Cost: 16.57s
Train Epoch: 1013 [61440/90000 (68%)]	Loss: -3.2396	Cost: 13.11s
Train Epoch: 1013 [81920/90000 (91%)]	Loss: -3.2435	Cost: 12.43s
Train Epoch: 1013 	Average Loss: -2.9067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5482

Learning rate: 9.74893270501665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1014 [0/90000 (0%)]	Loss: -0.5274	Cost: 36.46s
Train Epoch: 1014 [20480/90000 (23%)]	Loss: -3.2859	Cost: 12.54s
Train Epoch: 1014 [40960/90000 (45%)]	Loss: -3.4968	Cost: 7.37s
Train Epoch: 1014 [61440/90000 (68%)]	Loss: -3.2689	Cost: 6.22s
Train Epoch: 1014 [81920/90000 (91%)]	Loss: -2.9151	Cost: 13.87s
Train Epoch: 1014 	Average Loss: -3.0438
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5357

Learning rate: 9.748440970721218e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1015 [0/90000 (0%)]	Loss: -0.3524	Cost: 28.94s
Train Epoch: 1015 [20480/90000 (23%)]	Loss: -2.9782	Cost: 7.43s
Train Epoch: 1015 [40960/90000 (45%)]	Loss: -3.3814	Cost: 23.14s
Train Epoch: 1015 [61440/90000 (68%)]	Loss: -3.3380	Cost: 12.37s
Train Epoch: 1015 [81920/90000 (91%)]	Loss: -3.2935	Cost: 12.05s
Train Epoch: 1015 	Average Loss: -2.9709
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5696

Learning rate: 9.747948767773452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1016 [0/90000 (0%)]	Loss: -0.8179	Cost: 37.70s
Train Epoch: 1016 [20480/90000 (23%)]	Loss: -3.1808	Cost: 13.43s
Train Epoch: 1016 [40960/90000 (45%)]	Loss: -3.1559	Cost: 10.38s
Train Epoch: 1016 [61440/90000 (68%)]	Loss: -3.4081	Cost: 6.72s
Train Epoch: 1016 [81920/90000 (91%)]	Loss: -3.5131	Cost: 11.99s
Train Epoch: 1016 	Average Loss: -3.0327
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6410

Learning rate: 9.747456096221927e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1017 [0/90000 (0%)]	Loss: -0.7826	Cost: 33.56s
Train Epoch: 1017 [20480/90000 (23%)]	Loss: -3.4093	Cost: 6.87s
Train Epoch: 1017 [40960/90000 (45%)]	Loss: -3.4053	Cost: 17.41s
Train Epoch: 1017 [61440/90000 (68%)]	Loss: -3.4763	Cost: 12.52s
Train Epoch: 1017 [81920/90000 (91%)]	Loss: -3.3870	Cost: 11.84s
Train Epoch: 1017 	Average Loss: -3.2120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8713

Saving model as e1017_model.pt & e1017_waveforms_supplementary.hdf5
Learning rate: 9.746962956115272e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1018 [0/90000 (0%)]	Loss: -0.7611	Cost: 31.74s
Train Epoch: 1018 [20480/90000 (23%)]	Loss: -3.2815	Cost: 9.14s
Train Epoch: 1018 [40960/90000 (45%)]	Loss: -3.4139	Cost: 9.77s
Train Epoch: 1018 [61440/90000 (68%)]	Loss: -3.6497	Cost: 8.35s
Train Epoch: 1018 [81920/90000 (91%)]	Loss: -3.6104	Cost: 13.66s
Train Epoch: 1018 	Average Loss: -3.2581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8121

Learning rate: 9.746469347502156e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1019 [0/90000 (0%)]	Loss: -0.9719	Cost: 33.74s
Train Epoch: 1019 [20480/90000 (23%)]	Loss: -3.4510	Cost: 10.89s
Train Epoch: 1019 [40960/90000 (45%)]	Loss: -3.3471	Cost: 19.27s
Train Epoch: 1019 [61440/90000 (68%)]	Loss: -3.4713	Cost: 12.22s
Train Epoch: 1019 [81920/90000 (91%)]	Loss: -3.5613	Cost: 11.88s
Train Epoch: 1019 	Average Loss: -3.2903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8156

Learning rate: 9.745975270431296e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1020 [0/90000 (0%)]	Loss: -0.7590	Cost: 44.22s
Train Epoch: 1020 [20480/90000 (23%)]	Loss: -3.4283	Cost: 9.15s
Train Epoch: 1020 [40960/90000 (45%)]	Loss: -3.4914	Cost: 8.40s
Train Epoch: 1020 [61440/90000 (68%)]	Loss: -3.4635	Cost: 6.94s
Train Epoch: 1020 [81920/90000 (91%)]	Loss: -3.4572	Cost: 14.59s
Train Epoch: 1020 	Average Loss: -3.2419
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8058

Learning rate: 9.745480724951455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1021 [0/90000 (0%)]	Loss: -0.7525	Cost: 31.00s
Train Epoch: 1021 [20480/90000 (23%)]	Loss: -3.2838	Cost: 10.42s
Train Epoch: 1021 [40960/90000 (45%)]	Loss: -3.4052	Cost: 14.61s
Train Epoch: 1021 [61440/90000 (68%)]	Loss: -3.4939	Cost: 12.17s
Train Epoch: 1021 [81920/90000 (91%)]	Loss: -3.4852	Cost: 12.28s
Train Epoch: 1021 	Average Loss: -3.2080
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7536

Learning rate: 9.744985711111445e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1022 [0/90000 (0%)]	Loss: -0.5490	Cost: 46.36s
Train Epoch: 1022 [20480/90000 (23%)]	Loss: -3.4768	Cost: 6.14s
Train Epoch: 1022 [40960/90000 (45%)]	Loss: -3.5290	Cost: 14.19s
Train Epoch: 1022 [61440/90000 (68%)]	Loss: -3.7942	Cost: 8.72s
Train Epoch: 1022 [81920/90000 (91%)]	Loss: -3.8360	Cost: 11.28s
Train Epoch: 1022 	Average Loss: -3.3383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8619

Learning rate: 9.744490228960119e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1023 [0/90000 (0%)]	Loss: -1.0717	Cost: 34.53s
Train Epoch: 1023 [20480/90000 (23%)]	Loss: -3.4988	Cost: 12.80s
Train Epoch: 1023 [40960/90000 (45%)]	Loss: -3.5739	Cost: 18.84s
Train Epoch: 1023 [61440/90000 (68%)]	Loss: -3.4933	Cost: 12.15s
Train Epoch: 1023 [81920/90000 (91%)]	Loss: -3.4674	Cost: 11.90s
Train Epoch: 1023 	Average Loss: -3.2759
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5750

Learning rate: 9.743994278546379e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1024 [0/90000 (0%)]	Loss: -0.4477	Cost: 42.59s
Train Epoch: 1024 [20480/90000 (23%)]	Loss: -2.7139	Cost: 6.14s
Train Epoch: 1024 [40960/90000 (45%)]	Loss: -3.0451	Cost: 15.01s
Train Epoch: 1024 [61440/90000 (68%)]	Loss: -3.2756	Cost: 8.54s
Train Epoch: 1024 [81920/90000 (91%)]	Loss: -3.4753	Cost: 8.59s
Train Epoch: 1024 	Average Loss: -2.8990
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7691

Learning rate: 9.743497859919177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1025 [0/90000 (0%)]	Loss: -0.5110	Cost: 29.56s
Train Epoch: 1025 [20480/90000 (23%)]	Loss: -3.4377	Cost: 7.83s
Train Epoch: 1025 [40960/90000 (45%)]	Loss: -3.4509	Cost: 11.08s
Train Epoch: 1025 [61440/90000 (68%)]	Loss: -3.4911	Cost: 9.83s
Train Epoch: 1025 [81920/90000 (91%)]	Loss: -3.3732	Cost: 17.63s
Train Epoch: 1025 	Average Loss: -3.2015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.1769

Learning rate: 9.743000973127504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1026 [0/90000 (0%)]	Loss: -0.3042	Cost: 40.68s
Train Epoch: 1026 [20480/90000 (23%)]	Loss: -2.6404	Cost: 13.18s
Train Epoch: 1026 [40960/90000 (45%)]	Loss: -3.1565	Cost: 12.21s
Train Epoch: 1026 [61440/90000 (68%)]	Loss: -3.2376	Cost: 9.09s
Train Epoch: 1026 [81920/90000 (91%)]	Loss: -3.2167	Cost: 6.48s
Train Epoch: 1026 	Average Loss: -2.7979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5340

Learning rate: 9.742503618220404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1027 [0/90000 (0%)]	Loss: -0.8594	Cost: 37.68s
Train Epoch: 1027 [20480/90000 (23%)]	Loss: -3.1415	Cost: 7.42s
Train Epoch: 1027 [40960/90000 (45%)]	Loss: -2.7623	Cost: 13.37s
Train Epoch: 1027 [61440/90000 (68%)]	Loss: -2.3586	Cost: 8.69s
Train Epoch: 1027 [81920/90000 (91%)]	Loss: -2.7154	Cost: 9.19s
Train Epoch: 1027 	Average Loss: -2.6149
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2452

Learning rate: 9.742005795246962e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1028 [0/90000 (0%)]	Loss: -0.4406	Cost: 31.29s
Train Epoch: 1028 [20480/90000 (23%)]	Loss: -2.7999	Cost: 11.76s
Train Epoch: 1028 [40960/90000 (45%)]	Loss: -3.1524	Cost: 15.41s
Train Epoch: 1028 [61440/90000 (68%)]	Loss: -3.2242	Cost: 12.87s
Train Epoch: 1028 [81920/90000 (91%)]	Loss: -3.1903	Cost: 11.96s
Train Epoch: 1028 	Average Loss: -2.8233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.4699

Learning rate: 9.74150750425631e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1029 [0/90000 (0%)]	Loss: -0.5173	Cost: 47.86s
Train Epoch: 1029 [20480/90000 (23%)]	Loss: -3.1253	Cost: 7.38s
Train Epoch: 1029 [40960/90000 (45%)]	Loss: -3.4459	Cost: 10.77s
Train Epoch: 1029 [61440/90000 (68%)]	Loss: -3.6365	Cost: 8.70s
Train Epoch: 1029 [81920/90000 (91%)]	Loss: -3.6225	Cost: 10.10s
Train Epoch: 1029 	Average Loss: -3.1867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8216

Learning rate: 9.741008745297627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1030 [0/90000 (0%)]	Loss: -0.9697	Cost: 27.99s
Train Epoch: 1030 [20480/90000 (23%)]	Loss: -3.4224	Cost: 8.45s
Train Epoch: 1030 [40960/90000 (45%)]	Loss: -3.2996	Cost: 16.63s
Train Epoch: 1030 [61440/90000 (68%)]	Loss: -3.3495	Cost: 12.77s
Train Epoch: 1030 [81920/90000 (91%)]	Loss: -3.3050	Cost: 12.13s
Train Epoch: 1030 	Average Loss: -3.2151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7488

Learning rate: 9.740509518420142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1031 [0/90000 (0%)]	Loss: -0.4801	Cost: 33.15s
Train Epoch: 1031 [20480/90000 (23%)]	Loss: -3.4099	Cost: 12.09s
Train Epoch: 1031 [40960/90000 (45%)]	Loss: -3.5867	Cost: 8.37s
Train Epoch: 1031 [61440/90000 (68%)]	Loss: -3.6063	Cost: 6.66s
Train Epoch: 1031 [81920/90000 (91%)]	Loss: -3.6281	Cost: 14.83s
Train Epoch: 1031 	Average Loss: -3.3034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0704

Saving model as e1031_model.pt & e1031_waveforms_supplementary.hdf5
Learning rate: 9.740009823673125e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1032 [0/90000 (0%)]	Loss: -0.8666	Cost: 29.59s
Train Epoch: 1032 [20480/90000 (23%)]	Loss: -3.3444	Cost: 9.90s
Train Epoch: 1032 [40960/90000 (45%)]	Loss: -3.4119	Cost: 20.86s
Train Epoch: 1032 [61440/90000 (68%)]	Loss: -3.5147	Cost: 12.36s
Train Epoch: 1032 [81920/90000 (91%)]	Loss: -3.5128	Cost: 12.21s
Train Epoch: 1032 	Average Loss: -3.2402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7467

Learning rate: 9.739509661105893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1033 [0/90000 (0%)]	Loss: -0.7315	Cost: 37.29s
Train Epoch: 1033 [20480/90000 (23%)]	Loss: -3.4731	Cost: 14.24s
Train Epoch: 1033 [40960/90000 (45%)]	Loss: -3.5362	Cost: 10.39s
Train Epoch: 1033 [61440/90000 (68%)]	Loss: -3.7512	Cost: 6.39s
Train Epoch: 1033 [81920/90000 (91%)]	Loss: -3.9371	Cost: 11.93s
Train Epoch: 1033 	Average Loss: -3.3785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9880

Learning rate: 9.739009030767811e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1034 [0/90000 (0%)]	Loss: -0.8298	Cost: 45.08s
Train Epoch: 1034 [20480/90000 (23%)]	Loss: -3.5564	Cost: 6.62s
Train Epoch: 1034 [40960/90000 (45%)]	Loss: -3.6510	Cost: 17.41s
Train Epoch: 1034 [61440/90000 (68%)]	Loss: -3.8132	Cost: 12.14s
Train Epoch: 1034 [81920/90000 (91%)]	Loss: -3.7158	Cost: 11.95s
Train Epoch: 1034 	Average Loss: -3.4472
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0081

Learning rate: 9.73850793270829e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1035 [0/90000 (0%)]	Loss: -0.7107	Cost: 30.78s
Train Epoch: 1035 [20480/90000 (23%)]	Loss: -3.6820	Cost: 6.28s
Train Epoch: 1035 [40960/90000 (45%)]	Loss: -3.5840	Cost: 14.73s
Train Epoch: 1035 [61440/90000 (68%)]	Loss: -3.7928	Cost: 8.81s
Train Epoch: 1035 [81920/90000 (91%)]	Loss: -3.8381	Cost: 10.47s
Train Epoch: 1035 	Average Loss: -3.4369
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7491

Learning rate: 9.738006366976783e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1036 [0/90000 (0%)]	Loss: -0.4750	Cost: 31.07s
Train Epoch: 1036 [20480/90000 (23%)]	Loss: -3.2886	Cost: 12.72s
Train Epoch: 1036 [40960/90000 (45%)]	Loss: -3.3468	Cost: 16.59s
Train Epoch: 1036 [61440/90000 (68%)]	Loss: -3.5462	Cost: 12.58s
Train Epoch: 1036 [81920/90000 (91%)]	Loss: -3.6281	Cost: 12.07s
Train Epoch: 1036 	Average Loss: -3.2277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9257

Learning rate: 9.737504333622795e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1037 [0/90000 (0%)]	Loss: -0.7867	Cost: 39.56s
Train Epoch: 1037 [20480/90000 (23%)]	Loss: -3.3309	Cost: 11.23s
Train Epoch: 1037 [40960/90000 (45%)]	Loss: -3.5858	Cost: 8.37s
Train Epoch: 1037 [61440/90000 (68%)]	Loss: -3.7198	Cost: 6.67s
Train Epoch: 1037 [81920/90000 (91%)]	Loss: -3.7176	Cost: 14.59s
Train Epoch: 1037 	Average Loss: -3.3522
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8809

Learning rate: 9.737001832695876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1038 [0/90000 (0%)]	Loss: -0.8128	Cost: 35.71s
Train Epoch: 1038 [20480/90000 (23%)]	Loss: -3.5487	Cost: 9.69s
Train Epoch: 1038 [40960/90000 (45%)]	Loss: -3.1583	Cost: 22.21s
Train Epoch: 1038 [61440/90000 (68%)]	Loss: -3.4911	Cost: 12.29s
Train Epoch: 1038 [81920/90000 (91%)]	Loss: -3.6568	Cost: 11.89s
Train Epoch: 1038 	Average Loss: -3.1617
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8685

Learning rate: 9.73649886424562e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1039 [0/90000 (0%)]	Loss: -0.6710	Cost: 44.97s
Train Epoch: 1039 [20480/90000 (23%)]	Loss: -3.3710	Cost: 6.17s
Train Epoch: 1039 [40960/90000 (45%)]	Loss: -3.5030	Cost: 14.18s
Train Epoch: 1039 [61440/90000 (68%)]	Loss: -3.7639	Cost: 8.50s
Train Epoch: 1039 [81920/90000 (91%)]	Loss: -3.8887	Cost: 8.37s
Train Epoch: 1039 	Average Loss: -3.3571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0121

Learning rate: 9.735995428321667e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1040 [0/90000 (0%)]	Loss: -0.6367	Cost: 29.71s
Train Epoch: 1040 [20480/90000 (23%)]	Loss: -3.4548	Cost: 8.14s
Train Epoch: 1040 [40960/90000 (45%)]	Loss: -3.4345	Cost: 20.21s
Train Epoch: 1040 [61440/90000 (68%)]	Loss: -3.6525	Cost: 13.74s
Train Epoch: 1040 [81920/90000 (91%)]	Loss: -3.5362	Cost: 12.16s
Train Epoch: 1040 	Average Loss: -3.2959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8525

Learning rate: 9.735491524973705e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1041 [0/90000 (0%)]	Loss: -0.6225	Cost: 38.67s
Train Epoch: 1041 [20480/90000 (23%)]	Loss: -3.5468	Cost: 11.21s
Train Epoch: 1041 [40960/90000 (45%)]	Loss: -3.3385	Cost: 8.82s
Train Epoch: 1041 [61440/90000 (68%)]	Loss: -3.7006	Cost: 7.64s
Train Epoch: 1041 [81920/90000 (91%)]	Loss: -3.6946	Cost: 14.11s
Train Epoch: 1041 	Average Loss: -3.3418
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8734

Learning rate: 9.734987154251465e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1042 [0/90000 (0%)]	Loss: -1.0454	Cost: 33.73s
Train Epoch: 1042 [20480/90000 (23%)]	Loss: -3.5436	Cost: 10.49s
Train Epoch: 1042 [40960/90000 (45%)]	Loss: -3.4487	Cost: 16.16s
Train Epoch: 1042 [61440/90000 (68%)]	Loss: -3.7684	Cost: 12.33s
Train Epoch: 1042 [81920/90000 (91%)]	Loss: -3.7720	Cost: 11.80s
Train Epoch: 1042 	Average Loss: -3.3991
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9270

Learning rate: 9.73448231620473e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1043 [0/90000 (0%)]	Loss: -1.1334	Cost: 39.98s
Train Epoch: 1043 [20480/90000 (23%)]	Loss: -3.5550	Cost: 11.47s
Train Epoch: 1043 [40960/90000 (45%)]	Loss: -3.5755	Cost: 8.15s
Train Epoch: 1043 [61440/90000 (68%)]	Loss: -3.7808	Cost: 6.57s
Train Epoch: 1043 [81920/90000 (91%)]	Loss: -3.8769	Cost: 14.43s
Train Epoch: 1043 	Average Loss: -3.4979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0058

Learning rate: 9.733977010883324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1044 [0/90000 (0%)]	Loss: -1.1358	Cost: 30.77s
Train Epoch: 1044 [20480/90000 (23%)]	Loss: -3.8258	Cost: 7.27s
Train Epoch: 1044 [40960/90000 (45%)]	Loss: -3.9219	Cost: 17.29s
Train Epoch: 1044 [61440/90000 (68%)]	Loss: -3.7438	Cost: 12.19s
Train Epoch: 1044 [81920/90000 (91%)]	Loss: -3.8158	Cost: 12.39s
Train Epoch: 1044 	Average Loss: -3.5876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0291

Learning rate: 9.733471238337118e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1045 [0/90000 (0%)]	Loss: -0.5851	Cost: 40.67s
Train Epoch: 1045 [20480/90000 (23%)]	Loss: -3.7336	Cost: 7.76s
Train Epoch: 1045 [40960/90000 (45%)]	Loss: -3.5452	Cost: 12.11s
Train Epoch: 1045 [61440/90000 (68%)]	Loss: -3.5088	Cost: 10.00s
Train Epoch: 1045 [81920/90000 (91%)]	Loss: -3.5708	Cost: 11.14s
Train Epoch: 1045 	Average Loss: -3.4049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5934

Learning rate: 9.732964998616029e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1046 [0/90000 (0%)]	Loss: -0.2966	Cost: 42.62s
Train Epoch: 1046 [20480/90000 (23%)]	Loss: -3.2823	Cost: 7.54s
Train Epoch: 1046 [40960/90000 (45%)]	Loss: -3.3778	Cost: 20.38s
Train Epoch: 1046 [61440/90000 (68%)]	Loss: -3.7298	Cost: 11.74s
Train Epoch: 1046 [81920/90000 (91%)]	Loss: -2.7761	Cost: 12.10s
Train Epoch: 1046 	Average Loss: -3.0410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2347

Learning rate: 9.732458291770023e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1047 [0/90000 (0%)]	Loss: 0.0194	Cost: 35.81s
Train Epoch: 1047 [20480/90000 (23%)]	Loss: -2.8601	Cost: 6.37s
Train Epoch: 1047 [40960/90000 (45%)]	Loss: -2.8731	Cost: 14.35s
Train Epoch: 1047 [61440/90000 (68%)]	Loss: -3.1249	Cost: 8.86s
Train Epoch: 1047 [81920/90000 (91%)]	Loss: -3.4585	Cost: 9.87s
Train Epoch: 1047 	Average Loss: -2.7527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.6429

Learning rate: 9.731951117849109e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1048 [0/90000 (0%)]	Loss: -0.6144	Cost: 28.98s
Train Epoch: 1048 [20480/90000 (23%)]	Loss: -2.8477	Cost: 10.71s
Train Epoch: 1048 [40960/90000 (45%)]	Loss: -3.1564	Cost: 20.64s
Train Epoch: 1048 [61440/90000 (68%)]	Loss: -3.1623	Cost: 12.37s
Train Epoch: 1048 [81920/90000 (91%)]	Loss: -3.1769	Cost: 12.21s
Train Epoch: 1048 	Average Loss: -2.8750
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5837

Learning rate: 9.731443476903343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1049 [0/90000 (0%)]	Loss: -0.8144	Cost: 41.26s
Train Epoch: 1049 [20480/90000 (23%)]	Loss: -3.1844	Cost: 10.87s
Train Epoch: 1049 [40960/90000 (45%)]	Loss: -3.1111	Cost: 6.30s
Train Epoch: 1049 [61440/90000 (68%)]	Loss: -3.4641	Cost: 6.40s
Train Epoch: 1049 [81920/90000 (91%)]	Loss: -3.6950	Cost: 15.48s
Train Epoch: 1049 	Average Loss: -3.1600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7543

Learning rate: 9.730935368982828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1050 [0/90000 (0%)]	Loss: -0.6505	Cost: 33.60s
Train Epoch: 1050 [20480/90000 (23%)]	Loss: -3.4462	Cost: 10.28s
Train Epoch: 1050 [40960/90000 (45%)]	Loss: -3.4161	Cost: 23.97s
Train Epoch: 1050 [61440/90000 (68%)]	Loss: -3.7315	Cost: 11.93s
Train Epoch: 1050 [81920/90000 (91%)]	Loss: -3.7306	Cost: 11.94s
Train Epoch: 1050 	Average Loss: -3.3627
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8151

Learning rate: 9.730426794137711e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1051 [0/90000 (0%)]	Loss: -0.8305	Cost: 51.24s
Train Epoch: 1051 [20480/90000 (23%)]	Loss: -3.2596	Cost: 6.36s
Train Epoch: 1051 [40960/90000 (45%)]	Loss: -3.2739	Cost: 13.70s
Train Epoch: 1051 [61440/90000 (68%)]	Loss: -3.1904	Cost: 8.61s
Train Epoch: 1051 [81920/90000 (91%)]	Loss: -3.0803	Cost: 8.16s
Train Epoch: 1051 	Average Loss: -3.0996
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2859

Learning rate: 9.729917752418187e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1052 [0/90000 (0%)]	Loss: -0.3214	Cost: 30.45s
Train Epoch: 1052 [20480/90000 (23%)]	Loss: -2.7351	Cost: 7.82s
Train Epoch: 1052 [40960/90000 (45%)]	Loss: -3.1250	Cost: 17.15s
Train Epoch: 1052 [61440/90000 (68%)]	Loss: -3.2854	Cost: 12.26s
Train Epoch: 1052 [81920/90000 (91%)]	Loss: -3.5060	Cost: 12.45s
Train Epoch: 1052 	Average Loss: -2.9104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.7079

Learning rate: 9.729408243874495e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1053 [0/90000 (0%)]	Loss: -0.7148	Cost: 32.76s
Train Epoch: 1053 [20480/90000 (23%)]	Loss: -3.4682	Cost: 11.27s
Train Epoch: 1053 [40960/90000 (45%)]	Loss: -3.5932	Cost: 11.14s
Train Epoch: 1053 [61440/90000 (68%)]	Loss: -3.8777	Cost: 8.68s
Train Epoch: 1053 [81920/90000 (91%)]	Loss: -3.8086	Cost: 12.33s
Train Epoch: 1053 	Average Loss: -3.4081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9589

Learning rate: 9.728898268556922e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1054 [0/90000 (0%)]	Loss: -1.2725	Cost: 33.04s
Train Epoch: 1054 [20480/90000 (23%)]	Loss: -3.7779	Cost: 10.35s
Train Epoch: 1054 [40960/90000 (45%)]	Loss: -3.9899	Cost: 19.10s
Train Epoch: 1054 [61440/90000 (68%)]	Loss: -3.9243	Cost: 12.04s
Train Epoch: 1054 [81920/90000 (91%)]	Loss: -3.7845	Cost: 11.77s
Train Epoch: 1054 	Average Loss: -3.6000
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9631

Learning rate: 9.728387826515802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1055 [0/90000 (0%)]	Loss: -0.9360	Cost: 39.53s
Train Epoch: 1055 [20480/90000 (23%)]	Loss: -3.5947	Cost: 6.93s
Train Epoch: 1055 [40960/90000 (45%)]	Loss: -3.9549	Cost: 13.97s
Train Epoch: 1055 [61440/90000 (68%)]	Loss: -3.7679	Cost: 8.84s
Train Epoch: 1055 [81920/90000 (91%)]	Loss: -3.8063	Cost: 11.10s
Train Epoch: 1055 	Average Loss: -3.5403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0891

Saving model as e1055_model.pt & e1055_waveforms_supplementary.hdf5
Learning rate: 9.727876917801514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1056 [0/90000 (0%)]	Loss: -0.9397	Cost: 34.32s
Train Epoch: 1056 [20480/90000 (23%)]	Loss: -3.7512	Cost: 7.99s
Train Epoch: 1056 [40960/90000 (45%)]	Loss: -3.7788	Cost: 16.98s
Train Epoch: 1056 [61440/90000 (68%)]	Loss: -3.7833	Cost: 11.88s
Train Epoch: 1056 [81920/90000 (91%)]	Loss: -3.9239	Cost: 12.12s
Train Epoch: 1056 	Average Loss: -3.6123
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1288

Saving model as e1056_model.pt & e1056_waveforms_supplementary.hdf5
Learning rate: 9.727365542464482e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1057 [0/90000 (0%)]	Loss: -0.9403	Cost: 33.08s
Train Epoch: 1057 [20480/90000 (23%)]	Loss: -3.6201	Cost: 7.74s
Train Epoch: 1057 [40960/90000 (45%)]	Loss: -3.6177	Cost: 10.21s
Train Epoch: 1057 [61440/90000 (68%)]	Loss: -3.9023	Cost: 10.09s
Train Epoch: 1057 [81920/90000 (91%)]	Loss: -3.8086	Cost: 11.40s
Train Epoch: 1057 	Average Loss: -3.5215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0160

Learning rate: 9.726853700555175e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1058 [0/90000 (0%)]	Loss: -0.8734	Cost: 36.12s
Train Epoch: 1058 [20480/90000 (23%)]	Loss: -3.7750	Cost: 13.88s
Train Epoch: 1058 [40960/90000 (45%)]	Loss: -3.9867	Cost: 13.96s
Train Epoch: 1058 [61440/90000 (68%)]	Loss: -4.0877	Cost: 12.33s
Train Epoch: 1058 [81920/90000 (91%)]	Loss: -4.0840	Cost: 12.03s
Train Epoch: 1058 	Average Loss: -3.7349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2535

Saving model as e1058_model.pt & e1058_waveforms_supplementary.hdf5
Learning rate: 9.726341392124111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1059 [0/90000 (0%)]	Loss: -0.8567	Cost: 42.73s
Train Epoch: 1059 [20480/90000 (23%)]	Loss: -3.8888	Cost: 6.28s
Train Epoch: 1059 [40960/90000 (45%)]	Loss: -3.9326	Cost: 13.56s
Train Epoch: 1059 [61440/90000 (68%)]	Loss: -3.8276	Cost: 8.77s
Train Epoch: 1059 [81920/90000 (91%)]	Loss: -3.9095	Cost: 9.42s
Train Epoch: 1059 	Average Loss: -3.6446
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1574

Learning rate: 9.725828617221853e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1060 [0/90000 (0%)]	Loss: -1.1453	Cost: 27.07s
Train Epoch: 1060 [20480/90000 (23%)]	Loss: -3.9211	Cost: 9.77s
Train Epoch: 1060 [40960/90000 (45%)]	Loss: -4.0550	Cost: 23.10s
Train Epoch: 1060 [61440/90000 (68%)]	Loss: -4.2215	Cost: 12.32s
Train Epoch: 1060 [81920/90000 (91%)]	Loss: -3.9685	Cost: 11.85s
Train Epoch: 1060 	Average Loss: -3.8037
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0823

Learning rate: 9.725315375899009e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1061 [0/90000 (0%)]	Loss: -0.9461	Cost: 41.53s
Train Epoch: 1061 [20480/90000 (23%)]	Loss: -3.9884	Cost: 6.41s
Train Epoch: 1061 [40960/90000 (45%)]	Loss: -3.9627	Cost: 13.59s
Train Epoch: 1061 [61440/90000 (68%)]	Loss: -4.1438	Cost: 9.02s
Train Epoch: 1061 [81920/90000 (91%)]	Loss: -4.1418	Cost: 9.93s
Train Epoch: 1061 	Average Loss: -3.7800
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2196

Learning rate: 9.724801668206235e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1062 [0/90000 (0%)]	Loss: -0.9138	Cost: 28.42s
Train Epoch: 1062 [20480/90000 (23%)]	Loss: -3.9763	Cost: 13.70s
Train Epoch: 1062 [40960/90000 (45%)]	Loss: -4.0702	Cost: 15.81s
Train Epoch: 1062 [61440/90000 (68%)]	Loss: -4.1677	Cost: 13.15s
Train Epoch: 1062 [81920/90000 (91%)]	Loss: -4.1828	Cost: 12.14s
Train Epoch: 1062 	Average Loss: -3.8513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2142

Learning rate: 9.72428749419423e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1063 [0/90000 (0%)]	Loss: -1.1776	Cost: 34.15s
Train Epoch: 1063 [20480/90000 (23%)]	Loss: -3.8634	Cost: 13.73s
Train Epoch: 1063 [40960/90000 (45%)]	Loss: -4.2044	Cost: 8.74s
Train Epoch: 1063 [61440/90000 (68%)]	Loss: -4.1893	Cost: 8.25s
Train Epoch: 1063 [81920/90000 (91%)]	Loss: -4.1344	Cost: 12.89s
Train Epoch: 1063 	Average Loss: -3.8629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9134

Learning rate: 9.723772853913744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1064 [0/90000 (0%)]	Loss: -0.7814	Cost: 38.55s
Train Epoch: 1064 [20480/90000 (23%)]	Loss: -3.7321	Cost: 7.33s
Train Epoch: 1064 [40960/90000 (45%)]	Loss: -3.7864	Cost: 17.59s
Train Epoch: 1064 [61440/90000 (68%)]	Loss: -4.0955	Cost: 12.05s
Train Epoch: 1064 [81920/90000 (91%)]	Loss: -4.1503	Cost: 12.07s
Train Epoch: 1064 	Average Loss: -3.6173
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1306

Learning rate: 9.723257747415567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1065 [0/90000 (0%)]	Loss: -0.8293	Cost: 32.29s
Train Epoch: 1065 [20480/90000 (23%)]	Loss: -3.7617	Cost: 11.56s
Train Epoch: 1065 [40960/90000 (45%)]	Loss: -3.9106	Cost: 9.28s
Train Epoch: 1065 [61440/90000 (68%)]	Loss: -3.9337	Cost: 6.23s
Train Epoch: 1065 [81920/90000 (91%)]	Loss: -2.6908	Cost: 14.98s
Train Epoch: 1065 	Average Loss: -3.5261
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.2147

Learning rate: 9.722742174750542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1066 [0/90000 (0%)]	Loss: -0.1735	Cost: 32.01s
Train Epoch: 1066 [20480/90000 (23%)]	Loss: -2.8940	Cost: 9.40s
Train Epoch: 1066 [40960/90000 (45%)]	Loss: -3.1346	Cost: 23.54s
Train Epoch: 1066 [61440/90000 (68%)]	Loss: -3.5863	Cost: 12.13s
Train Epoch: 1066 [81920/90000 (91%)]	Loss: -3.6778	Cost: 11.91s
Train Epoch: 1066 	Average Loss: -3.0277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8113

Learning rate: 9.722226135969548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1067 [0/90000 (0%)]	Loss: -0.6998	Cost: 39.22s
Train Epoch: 1067 [20480/90000 (23%)]	Loss: -1.7276	Cost: 11.35s
Train Epoch: 1067 [40960/90000 (45%)]	Loss: -2.5566	Cost: 11.14s
Train Epoch: 1067 [61440/90000 (68%)]	Loss: -2.6236	Cost: 6.63s
Train Epoch: 1067 [81920/90000 (91%)]	Loss: -3.0171	Cost: 14.95s
Train Epoch: 1067 	Average Loss: -2.4690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.5031

Learning rate: 9.72170963112352e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1068 [0/90000 (0%)]	Loss: -0.6766	Cost: 32.14s
Train Epoch: 1068 [20480/90000 (23%)]	Loss: -3.2440	Cost: 6.61s
Train Epoch: 1068 [40960/90000 (45%)]	Loss: -3.6336	Cost: 13.55s
Train Epoch: 1068 [61440/90000 (68%)]	Loss: -3.7973	Cost: 11.98s
Train Epoch: 1068 [81920/90000 (91%)]	Loss: -3.7443	Cost: 13.85s
Train Epoch: 1068 	Average Loss: -3.3405
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9057

Learning rate: 9.721192660263436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1069 [0/90000 (0%)]	Loss: -0.8214	Cost: 35.04s
Train Epoch: 1069 [20480/90000 (23%)]	Loss: -3.6977	Cost: 12.24s
Train Epoch: 1069 [40960/90000 (45%)]	Loss: -3.7398	Cost: 12.22s
Train Epoch: 1069 [61440/90000 (68%)]	Loss: -3.8170	Cost: 10.05s
Train Epoch: 1069 [81920/90000 (91%)]	Loss: -3.9012	Cost: 8.79s
Train Epoch: 1069 	Average Loss: -3.5524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0644

Learning rate: 9.720675223440316e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1070 [0/90000 (0%)]	Loss: -1.3038	Cost: 36.66s
Train Epoch: 1070 [20480/90000 (23%)]	Loss: -3.7972	Cost: 10.70s
Train Epoch: 1070 [40960/90000 (45%)]	Loss: -3.7378	Cost: 11.16s
Train Epoch: 1070 [61440/90000 (68%)]	Loss: -3.8579	Cost: 7.15s
Train Epoch: 1070 [81920/90000 (91%)]	Loss: -3.9753	Cost: 20.13s
Train Epoch: 1070 	Average Loss: -3.6161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1508

Learning rate: 9.720157320705232e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1071 [0/90000 (0%)]	Loss: -0.6745	Cost: 44.50s
Train Epoch: 1071 [20480/90000 (23%)]	Loss: -3.8474	Cost: 12.44s
Train Epoch: 1071 [40960/90000 (45%)]	Loss: -3.9752	Cost: 12.22s
Train Epoch: 1071 [61440/90000 (68%)]	Loss: -3.7087	Cost: 6.74s
Train Epoch: 1071 [81920/90000 (91%)]	Loss: -3.7389	Cost: 6.33s
Train Epoch: 1071 	Average Loss: -3.5546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8432

Learning rate: 9.719638952109295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1072 [0/90000 (0%)]	Loss: -0.8095	Cost: 30.27s
Train Epoch: 1072 [20480/90000 (23%)]	Loss: -3.6750	Cost: 6.55s
Train Epoch: 1072 [40960/90000 (45%)]	Loss: -3.9866	Cost: 14.13s
Train Epoch: 1072 [61440/90000 (68%)]	Loss: -4.0345	Cost: 12.51s
Train Epoch: 1072 [81920/90000 (91%)]	Loss: -4.0782	Cost: 13.05s
Train Epoch: 1072 	Average Loss: -3.6612
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1656

Learning rate: 9.719120117703668e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1073 [0/90000 (0%)]	Loss: -1.1890	Cost: 37.51s
Train Epoch: 1073 [20480/90000 (23%)]	Loss: -3.8891	Cost: 12.30s
Train Epoch: 1073 [40960/90000 (45%)]	Loss: -3.8124	Cost: 12.36s
Train Epoch: 1073 [61440/90000 (68%)]	Loss: -4.0198	Cost: 7.83s
Train Epoch: 1073 [81920/90000 (91%)]	Loss: -4.1448	Cost: 6.13s
Train Epoch: 1073 	Average Loss: -3.7068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1081

Learning rate: 9.71860081753956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1074 [0/90000 (0%)]	Loss: -1.0945	Cost: 32.73s
Train Epoch: 1074 [20480/90000 (23%)]	Loss: -3.8945	Cost: 10.84s
Train Epoch: 1074 [40960/90000 (45%)]	Loss: -4.1472	Cost: 8.48s
Train Epoch: 1074 [61440/90000 (68%)]	Loss: -4.1068	Cost: 7.84s
Train Epoch: 1074 [81920/90000 (91%)]	Loss: -4.1845	Cost: 20.16s
Train Epoch: 1074 	Average Loss: -3.8077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1924

Learning rate: 9.71808105166822e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1075 [0/90000 (0%)]	Loss: -1.2504	Cost: 58.67s
Train Epoch: 1075 [20480/90000 (23%)]	Loss: -3.8105	Cost: 11.17s
Train Epoch: 1075 [40960/90000 (45%)]	Loss: -3.9527	Cost: 6.47s
Train Epoch: 1075 [61440/90000 (68%)]	Loss: -4.1289	Cost: 6.29s
Train Epoch: 1075 [81920/90000 (91%)]	Loss: -4.0803	Cost: 12.15s
Train Epoch: 1075 	Average Loss: -3.7399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1774

Learning rate: 9.71756082014095e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1076 [0/90000 (0%)]	Loss: -1.0307	Cost: 28.77s
Train Epoch: 1076 [20480/90000 (23%)]	Loss: -3.9816	Cost: 6.60s
Train Epoch: 1076 [40960/90000 (45%)]	Loss: -3.9024	Cost: 16.49s
Train Epoch: 1076 [61440/90000 (68%)]	Loss: -4.1572	Cost: 12.31s
Train Epoch: 1076 [81920/90000 (91%)]	Loss: -4.2254	Cost: 14.09s
Train Epoch: 1076 	Average Loss: -3.7782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2308

Learning rate: 9.717040123009093e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1077 [0/90000 (0%)]	Loss: -1.3649	Cost: 43.29s
Train Epoch: 1077 [20480/90000 (23%)]	Loss: -3.8877	Cost: 13.53s
Train Epoch: 1077 [40960/90000 (45%)]	Loss: -4.1214	Cost: 12.44s
Train Epoch: 1077 [61440/90000 (68%)]	Loss: -4.2293	Cost: 9.92s
Train Epoch: 1077 [81920/90000 (91%)]	Loss: -4.2759	Cost: 5.98s
Train Epoch: 1077 	Average Loss: -3.9219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3461

Saving model as e1077_model.pt & e1077_waveforms_supplementary.hdf5
Learning rate: 9.716518960324041e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1078 [0/90000 (0%)]	Loss: -1.0977	Cost: 32.17s
Train Epoch: 1078 [20480/90000 (23%)]	Loss: -3.9452	Cost: 8.70s
Train Epoch: 1078 [40960/90000 (45%)]	Loss: -4.0973	Cost: 9.91s
Train Epoch: 1078 [61440/90000 (68%)]	Loss: -4.2939	Cost: 7.54s
Train Epoch: 1078 [81920/90000 (91%)]	Loss: -4.3212	Cost: 8.22s
Train Epoch: 1078 	Average Loss: -3.9202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3590

Saving model as e1078_model.pt & e1078_waveforms_supplementary.hdf5
Learning rate: 9.71599733213723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1079 [0/90000 (0%)]	Loss: -0.6494	Cost: 30.85s
Train Epoch: 1079 [20480/90000 (23%)]	Loss: -4.0098	Cost: 13.98s
Train Epoch: 1079 [40960/90000 (45%)]	Loss: -4.0354	Cost: 14.74s
Train Epoch: 1079 [61440/90000 (68%)]	Loss: -4.0579	Cost: 12.02s
Train Epoch: 1079 [81920/90000 (91%)]	Loss: -4.0686	Cost: 11.95s
Train Epoch: 1079 	Average Loss: -3.8410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2248

Learning rate: 9.71547523850014e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1080 [0/90000 (0%)]	Loss: -1.1235	Cost: 35.51s
Train Epoch: 1080 [20480/90000 (23%)]	Loss: -3.6370	Cost: 11.33s
Train Epoch: 1080 [40960/90000 (45%)]	Loss: -3.8958	Cost: 8.48s
Train Epoch: 1080 [61440/90000 (68%)]	Loss: -3.9552	Cost: 6.30s
Train Epoch: 1080 [81920/90000 (91%)]	Loss: -3.8331	Cost: 14.96s
Train Epoch: 1080 	Average Loss: -3.6188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9896

Learning rate: 9.714952679464304e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1081 [0/90000 (0%)]	Loss: -1.2154	Cost: 30.60s
Train Epoch: 1081 [20480/90000 (23%)]	Loss: -3.9599	Cost: 9.26s
Train Epoch: 1081 [40960/90000 (45%)]	Loss: -4.0259	Cost: 15.88s
Train Epoch: 1081 [61440/90000 (68%)]	Loss: -4.2184	Cost: 13.89s
Train Epoch: 1081 [81920/90000 (91%)]	Loss: -4.2333	Cost: 13.02s
Train Epoch: 1081 	Average Loss: -3.8232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2797

Learning rate: 9.714429655081295e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1082 [0/90000 (0%)]	Loss: -1.3738	Cost: 33.25s
Train Epoch: 1082 [20480/90000 (23%)]	Loss: -4.1362	Cost: 11.99s
Train Epoch: 1082 [40960/90000 (45%)]	Loss: -4.3031	Cost: 10.76s
Train Epoch: 1082 [61440/90000 (68%)]	Loss: -3.9563	Cost: 8.03s
Train Epoch: 1082 [81920/90000 (91%)]	Loss: -4.1743	Cost: 16.17s
Train Epoch: 1082 	Average Loss: -3.8980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2490

Learning rate: 9.713906165402731e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1083 [0/90000 (0%)]	Loss: -1.1383	Cost: 33.73s
Train Epoch: 1083 [20480/90000 (23%)]	Loss: -3.9683	Cost: 7.24s
Train Epoch: 1083 [40960/90000 (45%)]	Loss: -4.2391	Cost: 16.86s
Train Epoch: 1083 [61440/90000 (68%)]	Loss: -4.4490	Cost: 12.24s
Train Epoch: 1083 [81920/90000 (91%)]	Loss: -4.2343	Cost: 12.04s
Train Epoch: 1083 	Average Loss: -3.9531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2084

Learning rate: 9.713382210480282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1084 [0/90000 (0%)]	Loss: -1.1243	Cost: 34.53s
Train Epoch: 1084 [20480/90000 (23%)]	Loss: -4.1191	Cost: 11.95s
Train Epoch: 1084 [40960/90000 (45%)]	Loss: -4.0659	Cost: 12.29s
Train Epoch: 1084 [61440/90000 (68%)]	Loss: -4.2527	Cost: 6.31s
Train Epoch: 1084 [81920/90000 (91%)]	Loss: -3.9637	Cost: 8.72s
Train Epoch: 1084 	Average Loss: -3.8770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2361

Learning rate: 9.712857790365659e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1085 [0/90000 (0%)]	Loss: -0.9197	Cost: 36.43s
Train Epoch: 1085 [20480/90000 (23%)]	Loss: -4.0008	Cost: 7.20s
Train Epoch: 1085 [40960/90000 (45%)]	Loss: -4.0435	Cost: 10.22s
Train Epoch: 1085 [61440/90000 (68%)]	Loss: -4.1545	Cost: 6.62s
Train Epoch: 1085 [81920/90000 (91%)]	Loss: -4.1337	Cost: 20.16s
Train Epoch: 1085 	Average Loss: -3.8081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2365

Learning rate: 9.712332905110621e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1086 [0/90000 (0%)]	Loss: -1.1251	Cost: 36.21s
Train Epoch: 1086 [20480/90000 (23%)]	Loss: -4.0464	Cost: 12.42s
Train Epoch: 1086 [40960/90000 (45%)]	Loss: -4.0929	Cost: 13.13s
Train Epoch: 1086 [61440/90000 (68%)]	Loss: -4.1687	Cost: 9.71s
Train Epoch: 1086 [81920/90000 (91%)]	Loss: -4.0073	Cost: 7.18s
Train Epoch: 1086 	Average Loss: -3.8460
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1883

Learning rate: 9.711807554766971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1087 [0/90000 (0%)]	Loss: -1.2865	Cost: 28.99s
Train Epoch: 1087 [20480/90000 (23%)]	Loss: -3.9287	Cost: 10.10s
Train Epoch: 1087 [40960/90000 (45%)]	Loss: -3.8561	Cost: 18.51s
Train Epoch: 1087 [61440/90000 (68%)]	Loss: -4.2985	Cost: 12.83s
Train Epoch: 1087 [81920/90000 (91%)]	Loss: -4.1802	Cost: 15.89s
Train Epoch: 1087 	Average Loss: -3.8232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2820

Learning rate: 9.711281739386558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1088 [0/90000 (0%)]	Loss: -1.1870	Cost: 51.94s
Train Epoch: 1088 [20480/90000 (23%)]	Loss: -4.2472	Cost: 10.44s
Train Epoch: 1088 [40960/90000 (45%)]	Loss: -4.0917	Cost: 8.39s
Train Epoch: 1088 [61440/90000 (68%)]	Loss: -4.2566	Cost: 6.21s
Train Epoch: 1088 [81920/90000 (91%)]	Loss: -4.3187	Cost: 15.36s
Train Epoch: 1088 	Average Loss: -4.0140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3752

Saving model as e1088_model.pt & e1088_waveforms_supplementary.hdf5
Learning rate: 9.710755459021279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1089 [0/90000 (0%)]	Loss: -1.7144	Cost: 33.19s
Train Epoch: 1089 [20480/90000 (23%)]	Loss: -4.2038	Cost: 10.20s
Train Epoch: 1089 [40960/90000 (45%)]	Loss: -4.1842	Cost: 18.25s
Train Epoch: 1089 [61440/90000 (68%)]	Loss: -4.4047	Cost: 12.23s
Train Epoch: 1089 [81920/90000 (91%)]	Loss: -4.2340	Cost: 12.34s
Train Epoch: 1089 	Average Loss: -3.9847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1232

Learning rate: 9.710228713723075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1090 [0/90000 (0%)]	Loss: -1.0563	Cost: 41.38s
Train Epoch: 1090 [20480/90000 (23%)]	Loss: -3.9504	Cost: 12.02s
Train Epoch: 1090 [40960/90000 (45%)]	Loss: -4.0414	Cost: 6.75s
Train Epoch: 1090 [61440/90000 (68%)]	Loss: -4.1135	Cost: 7.07s
Train Epoch: 1090 [81920/90000 (91%)]	Loss: -4.1969	Cost: 12.12s
Train Epoch: 1090 	Average Loss: -3.8471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3683

Learning rate: 9.709701503543935e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1091 [0/90000 (0%)]	Loss: -1.5869	Cost: 29.79s
Train Epoch: 1091 [20480/90000 (23%)]	Loss: -4.2815	Cost: 9.25s
Train Epoch: 1091 [40960/90000 (45%)]	Loss: -4.2370	Cost: 18.02s
Train Epoch: 1091 [61440/90000 (68%)]	Loss: -4.2535	Cost: 13.56s
Train Epoch: 1091 [81920/90000 (91%)]	Loss: -4.1696	Cost: 12.09s
Train Epoch: 1091 	Average Loss: -4.0218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2822

Learning rate: 9.709173828535892e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1092 [0/90000 (0%)]	Loss: -1.3865	Cost: 59.97s
Train Epoch: 1092 [20480/90000 (23%)]	Loss: -4.1408	Cost: 8.96s
Train Epoch: 1092 [40960/90000 (45%)]	Loss: -4.2927	Cost: 6.93s
Train Epoch: 1092 [61440/90000 (68%)]	Loss: -4.5663	Cost: 7.05s
Train Epoch: 1092 [81920/90000 (91%)]	Loss: -4.3458	Cost: 13.52s
Train Epoch: 1092 	Average Loss: -4.0400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3411

Learning rate: 9.708645688751025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1093 [0/90000 (0%)]	Loss: -1.3299	Cost: 28.30s
Train Epoch: 1093 [20480/90000 (23%)]	Loss: -4.0571	Cost: 6.35s
Train Epoch: 1093 [40960/90000 (45%)]	Loss: -3.6764	Cost: 18.04s
Train Epoch: 1093 [61440/90000 (68%)]	Loss: -3.4928	Cost: 12.34s
Train Epoch: 1093 [81920/90000 (91%)]	Loss: -3.6871	Cost: 12.32s
Train Epoch: 1093 	Average Loss: -3.5858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9191

Learning rate: 9.70811708424146e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1094 [0/90000 (0%)]	Loss: -1.0327	Cost: 40.64s
Train Epoch: 1094 [20480/90000 (23%)]	Loss: -3.7276	Cost: 12.40s
Train Epoch: 1094 [40960/90000 (45%)]	Loss: -3.7901	Cost: 11.91s
Train Epoch: 1094 [61440/90000 (68%)]	Loss: -3.9437	Cost: 6.21s
Train Epoch: 1094 [81920/90000 (91%)]	Loss: -4.2935	Cost: 8.02s
Train Epoch: 1094 	Average Loss: -3.6434
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2265

Learning rate: 9.707588015059367e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1095 [0/90000 (0%)]	Loss: -1.2955	Cost: 27.87s
Train Epoch: 1095 [20480/90000 (23%)]	Loss: -4.0612	Cost: 9.04s
Train Epoch: 1095 [40960/90000 (45%)]	Loss: -4.0746	Cost: 13.89s
Train Epoch: 1095 [61440/90000 (68%)]	Loss: -4.4454	Cost: 8.18s
Train Epoch: 1095 [81920/90000 (91%)]	Loss: -4.2021	Cost: 19.36s
Train Epoch: 1095 	Average Loss: -3.8847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0656

Learning rate: 9.707058481256966e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1096 [0/90000 (0%)]	Loss: -1.3270	Cost: 37.69s
Train Epoch: 1096 [20480/90000 (23%)]	Loss: -3.9861	Cost: 13.16s
Train Epoch: 1096 [40960/90000 (45%)]	Loss: -3.9195	Cost: 13.07s
Train Epoch: 1096 [61440/90000 (68%)]	Loss: -4.3911	Cost: 6.41s
Train Epoch: 1096 [81920/90000 (91%)]	Loss: -4.2501	Cost: 11.34s
Train Epoch: 1096 	Average Loss: -3.8400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2802

Learning rate: 9.706528482886516e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1097 [0/90000 (0%)]	Loss: -1.1562	Cost: 35.61s
Train Epoch: 1097 [20480/90000 (23%)]	Loss: -4.1220	Cost: 6.22s
Train Epoch: 1097 [40960/90000 (45%)]	Loss: -4.1673	Cost: 12.51s
Train Epoch: 1097 [61440/90000 (68%)]	Loss: -3.6528	Cost: 11.53s
Train Epoch: 1097 [81920/90000 (91%)]	Loss: -2.8532	Cost: 15.19s
Train Epoch: 1097 	Average Loss: -3.5430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.0954

Learning rate: 9.705998020000328e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1098 [0/90000 (0%)]	Loss: -0.4904	Cost: 35.25s
Train Epoch: 1098 [20480/90000 (23%)]	Loss: -2.8846	Cost: 12.83s
Train Epoch: 1098 [40960/90000 (45%)]	Loss: -3.2240	Cost: 12.06s
Train Epoch: 1098 [61440/90000 (68%)]	Loss: -3.6462	Cost: 8.78s
Train Epoch: 1098 [81920/90000 (91%)]	Loss: -3.6364	Cost: 8.46s
Train Epoch: 1098 	Average Loss: -3.0085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8046

Learning rate: 9.705467092650757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1099 [0/90000 (0%)]	Loss: -1.0286	Cost: 34.03s
Train Epoch: 1099 [20480/90000 (23%)]	Loss: -3.5633	Cost: 10.06s
Train Epoch: 1099 [40960/90000 (45%)]	Loss: -3.9694	Cost: 13.60s
Train Epoch: 1099 [61440/90000 (68%)]	Loss: -4.1800	Cost: 10.76s
Train Epoch: 1099 [81920/90000 (91%)]	Loss: -4.2557	Cost: 15.05s
Train Epoch: 1099 	Average Loss: -3.6349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1172

Learning rate: 9.704935700890203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1100 [0/90000 (0%)]	Loss: -0.8694	Cost: 44.50s
Train Epoch: 1100 [20480/90000 (23%)]	Loss: -3.9061	Cost: 11.99s
Train Epoch: 1100 [40960/90000 (45%)]	Loss: -4.0558	Cost: 12.06s
Train Epoch: 1100 [61440/90000 (68%)]	Loss: -4.3718	Cost: 7.23s
Train Epoch: 1100 [81920/90000 (91%)]	Loss: -4.2693	Cost: 6.30s
Train Epoch: 1100 	Average Loss: -3.9108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0747

Learning rate: 9.70440384477111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1101 [0/90000 (0%)]	Loss: -1.4198	Cost: 29.26s
Train Epoch: 1101 [20480/90000 (23%)]	Loss: -3.7406	Cost: 9.47s
Train Epoch: 1101 [40960/90000 (45%)]	Loss: -3.8632	Cost: 10.14s
Train Epoch: 1101 [61440/90000 (68%)]	Loss: -4.2389	Cost: 7.38s
Train Epoch: 1101 [81920/90000 (91%)]	Loss: -4.1582	Cost: 20.46s
Train Epoch: 1101 	Average Loss: -3.7527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3024

Learning rate: 9.703871524345972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1102 [0/90000 (0%)]	Loss: -1.4596	Cost: 37.31s
Train Epoch: 1102 [20480/90000 (23%)]	Loss: -3.8939	Cost: 12.27s
Train Epoch: 1102 [40960/90000 (45%)]	Loss: -4.3106	Cost: 12.02s
Train Epoch: 1102 [61440/90000 (68%)]	Loss: -4.4599	Cost: 9.85s
Train Epoch: 1102 [81920/90000 (91%)]	Loss: -4.3831	Cost: 6.25s
Train Epoch: 1102 	Average Loss: -4.0158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3330

Learning rate: 9.703338739667327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1103 [0/90000 (0%)]	Loss: -1.5144	Cost: 28.32s
Train Epoch: 1103 [20480/90000 (23%)]	Loss: -4.1545	Cost: 9.11s
Train Epoch: 1103 [40960/90000 (45%)]	Loss: -4.0858	Cost: 12.27s
Train Epoch: 1103 [61440/90000 (68%)]	Loss: -4.4636	Cost: 10.06s
Train Epoch: 1103 [81920/90000 (91%)]	Loss: -4.3968	Cost: 17.41s
Train Epoch: 1103 	Average Loss: -4.0313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4092

Saving model as e1103_model.pt & e1103_waveforms_supplementary.hdf5
Learning rate: 9.70280549078776e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1104 [0/90000 (0%)]	Loss: -1.5470	Cost: 56.55s
Train Epoch: 1104 [20480/90000 (23%)]	Loss: -4.1255	Cost: 11.21s
Train Epoch: 1104 [40960/90000 (45%)]	Loss: -4.4653	Cost: 8.48s
Train Epoch: 1104 [61440/90000 (68%)]	Loss: -4.3940	Cost: 6.33s
Train Epoch: 1104 [81920/90000 (91%)]	Loss: -3.9513	Cost: 12.50s
Train Epoch: 1104 	Average Loss: -4.0423
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.9554

Learning rate: 9.702271777759897e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1105 [0/90000 (0%)]	Loss: -1.0486	Cost: 29.24s
Train Epoch: 1105 [20480/90000 (23%)]	Loss: -3.8594	Cost: 7.73s
Train Epoch: 1105 [40960/90000 (45%)]	Loss: -4.0915	Cost: 18.16s
Train Epoch: 1105 [61440/90000 (68%)]	Loss: -4.4416	Cost: 12.82s
Train Epoch: 1105 [81920/90000 (91%)]	Loss: -4.2881	Cost: 12.38s
Train Epoch: 1105 	Average Loss: -3.9206
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3396

Learning rate: 9.701737600636417e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1106 [0/90000 (0%)]	Loss: -1.3271	Cost: 44.96s
Train Epoch: 1106 [20480/90000 (23%)]	Loss: -4.1243	Cost: 12.36s
Train Epoch: 1106 [40960/90000 (45%)]	Loss: -4.3873	Cost: 7.46s
Train Epoch: 1106 [61440/90000 (68%)]	Loss: -4.4878	Cost: 6.68s
Train Epoch: 1106 [81920/90000 (91%)]	Loss: -4.2587	Cost: 14.43s
Train Epoch: 1106 	Average Loss: -4.0109
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2002

Learning rate: 9.701202959470039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1107 [0/90000 (0%)]	Loss: -1.3946	Cost: 27.20s
Train Epoch: 1107 [20480/90000 (23%)]	Loss: -3.6427	Cost: 10.11s
Train Epoch: 1107 [40960/90000 (45%)]	Loss: -3.7468	Cost: 16.35s
Train Epoch: 1107 [61440/90000 (68%)]	Loss: -4.0563	Cost: 12.36s
Train Epoch: 1107 [81920/90000 (91%)]	Loss: -4.2260	Cost: 12.40s
Train Epoch: 1107 	Average Loss: -3.7491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3719

Learning rate: 9.700667854313532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1108 [0/90000 (0%)]	Loss: -1.2817	Cost: 45.01s
Train Epoch: 1108 [20480/90000 (23%)]	Loss: -4.0743	Cost: 12.30s
Train Epoch: 1108 [40960/90000 (45%)]	Loss: -4.3533	Cost: 8.06s
Train Epoch: 1108 [61440/90000 (68%)]	Loss: -4.6352	Cost: 6.47s
Train Epoch: 1108 [81920/90000 (91%)]	Loss: -4.2926	Cost: 13.78s
Train Epoch: 1108 	Average Loss: -4.0313
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2329

Learning rate: 9.700132285219706e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1109 [0/90000 (0%)]	Loss: -1.1573	Cost: 32.09s
Train Epoch: 1109 [20480/90000 (23%)]	Loss: -4.1767	Cost: 6.37s
Train Epoch: 1109 [40960/90000 (45%)]	Loss: -3.6250	Cost: 17.37s
Train Epoch: 1109 [61440/90000 (68%)]	Loss: -3.7090	Cost: 12.47s
Train Epoch: 1109 [81920/90000 (91%)]	Loss: -4.0734	Cost: 11.95s
Train Epoch: 1109 	Average Loss: -3.7311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1803

Learning rate: 9.69959625224142e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1110 [0/90000 (0%)]	Loss: -1.3438	Cost: 33.73s
Train Epoch: 1110 [20480/90000 (23%)]	Loss: -3.9148	Cost: 11.85s
Train Epoch: 1110 [40960/90000 (45%)]	Loss: -4.3023	Cost: 11.57s
Train Epoch: 1110 [61440/90000 (68%)]	Loss: -4.3433	Cost: 6.23s
Train Epoch: 1110 [81920/90000 (91%)]	Loss: -4.1214	Cost: 9.66s
Train Epoch: 1110 	Average Loss: -3.8861
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1444

Learning rate: 9.699059755431581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1111 [0/90000 (0%)]	Loss: -0.9757	Cost: 33.70s
Train Epoch: 1111 [20480/90000 (23%)]	Loss: -4.0596	Cost: 9.99s
Train Epoch: 1111 [40960/90000 (45%)]	Loss: -3.8382	Cost: 14.28s
Train Epoch: 1111 [61440/90000 (68%)]	Loss: -4.2388	Cost: 12.89s
Train Epoch: 1111 [81920/90000 (91%)]	Loss: -4.3307	Cost: 12.01s
Train Epoch: 1111 	Average Loss: -3.8207
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3896

Learning rate: 9.698522794843136e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1112 [0/90000 (0%)]	Loss: -1.3885	Cost: 49.23s
Train Epoch: 1112 [20480/90000 (23%)]	Loss: -4.1198	Cost: 11.81s
Train Epoch: 1112 [40960/90000 (45%)]	Loss: -4.2012	Cost: 7.25s
Train Epoch: 1112 [61440/90000 (68%)]	Loss: -4.6422	Cost: 6.74s
Train Epoch: 1112 [81920/90000 (91%)]	Loss: -4.3877	Cost: 12.75s
Train Epoch: 1112 	Average Loss: -4.1288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4512

Saving model as e1112_model.pt & e1112_waveforms_supplementary.hdf5
Learning rate: 9.697985370529083e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1113 [0/90000 (0%)]	Loss: -1.0958	Cost: 31.68s
Train Epoch: 1113 [20480/90000 (23%)]	Loss: -4.2743	Cost: 8.30s
Train Epoch: 1113 [40960/90000 (45%)]	Loss: -4.4460	Cost: 17.55s
Train Epoch: 1113 [61440/90000 (68%)]	Loss: -4.6106	Cost: 11.15s
Train Epoch: 1113 [81920/90000 (91%)]	Loss: -4.2881	Cost: 11.89s
Train Epoch: 1113 	Average Loss: -4.1445
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3784

Learning rate: 9.697447482542464e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1114 [0/90000 (0%)]	Loss: -1.2113	Cost: 31.80s
Train Epoch: 1114 [20480/90000 (23%)]	Loss: -4.1744	Cost: 6.31s
Train Epoch: 1114 [40960/90000 (45%)]	Loss: -4.4296	Cost: 13.01s
Train Epoch: 1114 [61440/90000 (68%)]	Loss: -4.5501	Cost: 8.82s
Train Epoch: 1114 [81920/90000 (91%)]	Loss: -4.4274	Cost: 9.66s
Train Epoch: 1114 	Average Loss: -4.0686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4425

Learning rate: 9.696909130936366e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1115 [0/90000 (0%)]	Loss: -1.4334	Cost: 28.34s
Train Epoch: 1115 [20480/90000 (23%)]	Loss: -4.3447	Cost: 10.38s
Train Epoch: 1115 [40960/90000 (45%)]	Loss: -4.2223	Cost: 21.84s
Train Epoch: 1115 [61440/90000 (68%)]	Loss: -4.5185	Cost: 13.24s
Train Epoch: 1115 [81920/90000 (91%)]	Loss: -4.5803	Cost: 11.99s
Train Epoch: 1115 	Average Loss: -4.1421
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4876

Saving model as e1115_model.pt & e1115_waveforms_supplementary.hdf5
Learning rate: 9.69637031576392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1116 [0/90000 (0%)]	Loss: -1.3328	Cost: 48.51s
Train Epoch: 1116 [20480/90000 (23%)]	Loss: -4.2778	Cost: 6.25s
Train Epoch: 1116 [40960/90000 (45%)]	Loss: -4.4342	Cost: 13.59s
Train Epoch: 1116 [61440/90000 (68%)]	Loss: -4.5577	Cost: 8.55s
Train Epoch: 1116 [81920/90000 (91%)]	Loss: -4.3422	Cost: 7.69s
Train Epoch: 1116 	Average Loss: -4.1747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2218

Learning rate: 9.695831037078306e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1117 [0/90000 (0%)]	Loss: -1.5176	Cost: 29.53s
Train Epoch: 1117 [20480/90000 (23%)]	Loss: -3.9161	Cost: 7.02s
Train Epoch: 1117 [40960/90000 (45%)]	Loss: -3.9006	Cost: 18.44s
Train Epoch: 1117 [61440/90000 (68%)]	Loss: -4.1604	Cost: 12.87s
Train Epoch: 1117 [81920/90000 (91%)]	Loss: -4.3682	Cost: 12.07s
Train Epoch: 1117 	Average Loss: -3.9067
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4104

Learning rate: 9.695291294932748e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1118 [0/90000 (0%)]	Loss: -1.5148	Cost: 38.24s
Train Epoch: 1118 [20480/90000 (23%)]	Loss: -4.2921	Cost: 10.62s
Train Epoch: 1118 [40960/90000 (45%)]	Loss: -4.4170	Cost: 9.72s
Train Epoch: 1118 [61440/90000 (68%)]	Loss: -4.4250	Cost: 7.94s
Train Epoch: 1118 [81920/90000 (91%)]	Loss: -4.5159	Cost: 10.68s
Train Epoch: 1118 	Average Loss: -4.1353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5873

Saving model as e1118_model.pt & e1118_waveforms_supplementary.hdf5
Learning rate: 9.69475108938052e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1119 [0/90000 (0%)]	Loss: -1.8065	Cost: 28.38s
Train Epoch: 1119 [20480/90000 (23%)]	Loss: -4.3695	Cost: 6.81s
Train Epoch: 1119 [40960/90000 (45%)]	Loss: -4.2859	Cost: 19.74s
Train Epoch: 1119 [61440/90000 (68%)]	Loss: -4.1682	Cost: 14.67s
Train Epoch: 1119 [81920/90000 (91%)]	Loss: -3.8368	Cost: 12.37s
Train Epoch: 1119 	Average Loss: -3.9404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.0145

Learning rate: 9.694210420474934e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1120 [0/90000 (0%)]	Loss: -1.0103	Cost: 34.74s
Train Epoch: 1120 [20480/90000 (23%)]	Loss: -3.4308	Cost: 12.81s
Train Epoch: 1120 [40960/90000 (45%)]	Loss: -3.8370	Cost: 9.45s
Train Epoch: 1120 [61440/90000 (68%)]	Loss: -4.2511	Cost: 9.85s
Train Epoch: 1120 [81920/90000 (91%)]	Loss: -4.4242	Cost: 10.26s
Train Epoch: 1120 	Average Loss: -3.6509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3962

Learning rate: 9.693669288269356e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1121 [0/90000 (0%)]	Loss: -1.4549	Cost: 42.20s
Train Epoch: 1121 [20480/90000 (23%)]	Loss: -4.1695	Cost: 7.32s
Train Epoch: 1121 [40960/90000 (45%)]	Loss: -4.2155	Cost: 19.62s
Train Epoch: 1121 [61440/90000 (68%)]	Loss: -4.5473	Cost: 12.55s
Train Epoch: 1121 [81920/90000 (91%)]	Loss: -4.6118	Cost: 11.83s
Train Epoch: 1121 	Average Loss: -4.1885
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5443

Learning rate: 9.693127692817188e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1122 [0/90000 (0%)]	Loss: -1.9198	Cost: 35.55s
Train Epoch: 1122 [20480/90000 (23%)]	Loss: -4.3036	Cost: 9.57s
Train Epoch: 1122 [40960/90000 (45%)]	Loss: -4.5043	Cost: 10.39s
Train Epoch: 1122 [61440/90000 (68%)]	Loss: -4.5401	Cost: 6.28s
Train Epoch: 1122 [81920/90000 (91%)]	Loss: -4.5895	Cost: 14.92s
Train Epoch: 1122 	Average Loss: -4.2363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5363

Learning rate: 9.692585634171887e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1123 [0/90000 (0%)]	Loss: -1.5333	Cost: 35.04s
Train Epoch: 1123 [20480/90000 (23%)]	Loss: -4.4979	Cost: 6.97s
Train Epoch: 1123 [40960/90000 (45%)]	Loss: -4.6791	Cost: 22.86s
Train Epoch: 1123 [61440/90000 (68%)]	Loss: -4.7165	Cost: 12.29s
Train Epoch: 1123 [81920/90000 (91%)]	Loss: -4.6390	Cost: 11.94s
Train Epoch: 1123 	Average Loss: -4.3436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5246

Learning rate: 9.692043112386951e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1124 [0/90000 (0%)]	Loss: -1.5145	Cost: 33.63s
Train Epoch: 1124 [20480/90000 (23%)]	Loss: -4.5667	Cost: 9.29s
Train Epoch: 1124 [40960/90000 (45%)]	Loss: -4.5629	Cost: 10.05s
Train Epoch: 1124 [61440/90000 (68%)]	Loss: -4.9200	Cost: 7.80s
Train Epoch: 1124 [81920/90000 (91%)]	Loss: -4.9427	Cost: 14.21s
Train Epoch: 1124 	Average Loss: -4.4291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6013

Saving model as e1124_model.pt & e1124_waveforms_supplementary.hdf5
Learning rate: 9.691500127515926e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1125 [0/90000 (0%)]	Loss: -1.7841	Cost: 41.61s
Train Epoch: 1125 [20480/90000 (23%)]	Loss: -4.4708	Cost: 12.70s
Train Epoch: 1125 [40960/90000 (45%)]	Loss: -4.5427	Cost: 12.38s
Train Epoch: 1125 [61440/90000 (68%)]	Loss: -4.7065	Cost: 12.22s
Train Epoch: 1125 [81920/90000 (91%)]	Loss: -4.6375	Cost: 11.78s
Train Epoch: 1125 	Average Loss: -4.3690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5031

Learning rate: 9.690956679612404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1126 [0/90000 (0%)]	Loss: -1.4013	Cost: 34.92s
Train Epoch: 1126 [20480/90000 (23%)]	Loss: -4.4130	Cost: 6.45s
Train Epoch: 1126 [40960/90000 (45%)]	Loss: -4.6222	Cost: 14.01s
Train Epoch: 1126 [61440/90000 (68%)]	Loss: -4.7310	Cost: 8.53s
Train Epoch: 1126 [81920/90000 (91%)]	Loss: -4.7372	Cost: 7.86s
Train Epoch: 1126 	Average Loss: -4.2857
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5333

Learning rate: 9.690412768730017e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1127 [0/90000 (0%)]	Loss: -1.5401	Cost: 30.18s
Train Epoch: 1127 [20480/90000 (23%)]	Loss: -4.3037	Cost: 10.54s
Train Epoch: 1127 [40960/90000 (45%)]	Loss: -4.4393	Cost: 20.47s
Train Epoch: 1127 [61440/90000 (68%)]	Loss: -4.8542	Cost: 12.39s
Train Epoch: 1127 [81920/90000 (91%)]	Loss: -4.8617	Cost: 12.00s
Train Epoch: 1127 	Average Loss: -4.3441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8327

Saving model as e1127_model.pt & e1127_waveforms_supplementary.hdf5
Learning rate: 9.689868394922449e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1128 [0/90000 (0%)]	Loss: -1.7287	Cost: 40.48s
Train Epoch: 1128 [20480/90000 (23%)]	Loss: -4.4474	Cost: 6.40s
Train Epoch: 1128 [40960/90000 (45%)]	Loss: -4.6709	Cost: 13.62s
Train Epoch: 1128 [61440/90000 (68%)]	Loss: -4.8614	Cost: 9.09s
Train Epoch: 1128 [81920/90000 (91%)]	Loss: -4.7437	Cost: 9.85s
Train Epoch: 1128 	Average Loss: -4.4639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6717

Learning rate: 9.689323558243428e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1129 [0/90000 (0%)]	Loss: -1.7095	Cost: 31.19s
Train Epoch: 1129 [20480/90000 (23%)]	Loss: -4.4771	Cost: 8.92s
Train Epoch: 1129 [40960/90000 (45%)]	Loss: -4.6300	Cost: 19.46s
Train Epoch: 1129 [61440/90000 (68%)]	Loss: -4.8873	Cost: 11.88s
Train Epoch: 1129 [81920/90000 (91%)]	Loss: -4.1473	Cost: 12.27s
Train Epoch: 1129 	Average Loss: -4.2687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.1613

Learning rate: 9.688778258746725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1130 [0/90000 (0%)]	Loss: -1.2194	Cost: 38.36s
Train Epoch: 1130 [20480/90000 (23%)]	Loss: -4.0854	Cost: 10.64s
Train Epoch: 1130 [40960/90000 (45%)]	Loss: -4.1299	Cost: 11.42s
Train Epoch: 1130 [61440/90000 (68%)]	Loss: -4.2578	Cost: 8.65s
Train Epoch: 1130 [81920/90000 (91%)]	Loss: -4.5605	Cost: 12.32s
Train Epoch: 1130 	Average Loss: -3.9517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3346

Learning rate: 9.68823249648616e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1131 [0/90000 (0%)]	Loss: -1.3217	Cost: 39.15s
Train Epoch: 1131 [20480/90000 (23%)]	Loss: -3.9753	Cost: 6.73s
Train Epoch: 1131 [40960/90000 (45%)]	Loss: -4.0406	Cost: 16.96s
Train Epoch: 1131 [61440/90000 (68%)]	Loss: -4.2445	Cost: 12.24s
Train Epoch: 1131 [81920/90000 (91%)]	Loss: -4.2555	Cost: 11.99s
Train Epoch: 1131 	Average Loss: -3.8947
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4706

Learning rate: 9.6876862715156e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1132 [0/90000 (0%)]	Loss: -1.6529	Cost: 32.53s
Train Epoch: 1132 [20480/90000 (23%)]	Loss: -4.4896	Cost: 7.72s
Train Epoch: 1132 [40960/90000 (45%)]	Loss: -4.7114	Cost: 12.01s
Train Epoch: 1132 [61440/90000 (68%)]	Loss: -4.5946	Cost: 6.51s
Train Epoch: 1132 [81920/90000 (91%)]	Loss: -4.7770	Cost: 14.10s
Train Epoch: 1132 	Average Loss: -4.3626
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8361

Saving model as e1132_model.pt & e1132_waveforms_supplementary.hdf5
Learning rate: 9.687139583888953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1133 [0/90000 (0%)]	Loss: -1.7052	Cost: 31.46s
Train Epoch: 1133 [20480/90000 (23%)]	Loss: -4.6379	Cost: 10.09s
Train Epoch: 1133 [40960/90000 (45%)]	Loss: -4.7571	Cost: 18.08s
Train Epoch: 1133 [61440/90000 (68%)]	Loss: -4.8296	Cost: 12.32s
Train Epoch: 1133 [81920/90000 (91%)]	Loss: -5.0147	Cost: 12.05s
Train Epoch: 1133 	Average Loss: -4.5579
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8148

Learning rate: 9.686592433660174e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1134 [0/90000 (0%)]	Loss: -1.6166	Cost: 36.29s
Train Epoch: 1134 [20480/90000 (23%)]	Loss: -4.5433	Cost: 12.25s
Train Epoch: 1134 [40960/90000 (45%)]	Loss: -4.3567	Cost: 12.22s
Train Epoch: 1134 [61440/90000 (68%)]	Loss: -4.5880	Cost: 9.73s
Train Epoch: 1134 [81920/90000 (91%)]	Loss: -4.7357	Cost: 6.53s
Train Epoch: 1134 	Average Loss: -4.4142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7299

Learning rate: 9.686044820883267e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1135 [0/90000 (0%)]	Loss: -1.4941	Cost: 37.81s
Train Epoch: 1135 [20480/90000 (23%)]	Loss: -4.6018	Cost: 6.19s
Train Epoch: 1135 [40960/90000 (45%)]	Loss: -4.8503	Cost: 14.18s
Train Epoch: 1135 [61440/90000 (68%)]	Loss: -4.8059	Cost: 11.98s
Train Epoch: 1135 [81920/90000 (91%)]	Loss: -4.7727	Cost: 12.31s
Train Epoch: 1135 	Average Loss: -4.5228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7036

Learning rate: 9.685496745612277e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1136 [0/90000 (0%)]	Loss: -1.4299	Cost: 32.97s
Train Epoch: 1136 [20480/90000 (23%)]	Loss: -4.4231	Cost: 13.43s
Train Epoch: 1136 [40960/90000 (45%)]	Loss: -4.5518	Cost: 12.55s
Train Epoch: 1136 [61440/90000 (68%)]	Loss: -4.8068	Cost: 11.25s
Train Epoch: 1136 [81920/90000 (91%)]	Loss: -4.6602	Cost: 6.19s
Train Epoch: 1136 	Average Loss: -4.4265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7298

Learning rate: 9.684948207901299e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1137 [0/90000 (0%)]	Loss: -1.7082	Cost: 31.04s
Train Epoch: 1137 [20480/90000 (23%)]	Loss: -4.3909	Cost: 10.38s
Train Epoch: 1137 [40960/90000 (45%)]	Loss: -4.1758	Cost: 12.65s
Train Epoch: 1137 [61440/90000 (68%)]	Loss: -4.4372	Cost: 8.33s
Train Epoch: 1137 [81920/90000 (91%)]	Loss: -4.3983	Cost: 8.61s
Train Epoch: 1137 	Average Loss: -4.2274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5856

Learning rate: 9.68439920780447e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1138 [0/90000 (0%)]	Loss: -1.5456	Cost: 33.10s
Train Epoch: 1138 [20480/90000 (23%)]	Loss: -4.5574	Cost: 10.68s
Train Epoch: 1138 [40960/90000 (45%)]	Loss: -4.4968	Cost: 22.12s
Train Epoch: 1138 [61440/90000 (68%)]	Loss: -4.4896	Cost: 12.00s
Train Epoch: 1138 [81920/90000 (91%)]	Loss: -4.6346	Cost: 11.97s
Train Epoch: 1138 	Average Loss: -4.2501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4660

Learning rate: 9.683849745375974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1139 [0/90000 (0%)]	Loss: -1.3359	Cost: 44.34s
Train Epoch: 1139 [20480/90000 (23%)]	Loss: -4.4390	Cost: 9.39s
Train Epoch: 1139 [40960/90000 (45%)]	Loss: -4.5026	Cost: 7.83s
Train Epoch: 1139 [61440/90000 (68%)]	Loss: -4.8611	Cost: 7.64s
Train Epoch: 1139 [81920/90000 (91%)]	Loss: -4.9008	Cost: 11.41s
Train Epoch: 1139 	Average Loss: -4.4056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5939

Learning rate: 9.68329982067004e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1140 [0/90000 (0%)]	Loss: -1.3304	Cost: 29.72s
Train Epoch: 1140 [20480/90000 (23%)]	Loss: -4.5421	Cost: 9.84s
Train Epoch: 1140 [40960/90000 (45%)]	Loss: -4.5798	Cost: 16.95s
Train Epoch: 1140 [61440/90000 (68%)]	Loss: -4.7239	Cost: 13.21s
Train Epoch: 1140 [81920/90000 (91%)]	Loss: -4.8702	Cost: 14.04s
Train Epoch: 1140 	Average Loss: -4.3927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7993

Learning rate: 9.682749433740945e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1141 [0/90000 (0%)]	Loss: -1.4490	Cost: 39.44s
Train Epoch: 1141 [20480/90000 (23%)]	Loss: -4.6985	Cost: 12.49s
Train Epoch: 1141 [40960/90000 (45%)]	Loss: -4.7903	Cost: 11.92s
Train Epoch: 1141 [61440/90000 (68%)]	Loss: -4.8728	Cost: 6.44s
Train Epoch: 1141 [81920/90000 (91%)]	Loss: -4.8662	Cost: 6.86s
Train Epoch: 1141 	Average Loss: -4.5630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6697

Learning rate: 9.682198584643011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1142 [0/90000 (0%)]	Loss: -1.5175	Cost: 29.43s
Train Epoch: 1142 [20480/90000 (23%)]	Loss: -4.7557	Cost: 9.23s
Train Epoch: 1142 [40960/90000 (45%)]	Loss: -4.4255	Cost: 14.53s
Train Epoch: 1142 [61440/90000 (68%)]	Loss: -4.6770	Cost: 9.72s
Train Epoch: 1142 [81920/90000 (91%)]	Loss: -4.6736	Cost: 18.00s
Train Epoch: 1142 	Average Loss: -4.4265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7946

Learning rate: 9.681647273430602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1143 [0/90000 (0%)]	Loss: -1.8951	Cost: 47.37s
Train Epoch: 1143 [20480/90000 (23%)]	Loss: -4.4214	Cost: 12.80s
Train Epoch: 1143 [40960/90000 (45%)]	Loss: -4.6049	Cost: 12.24s
Train Epoch: 1143 [61440/90000 (68%)]	Loss: -4.8035	Cost: 11.65s
Train Epoch: 1143 [81920/90000 (91%)]	Loss: -4.8926	Cost: 6.15s
Train Epoch: 1143 	Average Loss: -4.4277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7915

Learning rate: 9.681095500158132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1144 [0/90000 (0%)]	Loss: -1.8494	Cost: 41.48s
Train Epoch: 1144 [20480/90000 (23%)]	Loss: -4.8035	Cost: 7.61s
Train Epoch: 1144 [40960/90000 (45%)]	Loss: -4.7224	Cost: 11.38s
Train Epoch: 1144 [61440/90000 (68%)]	Loss: -4.8489	Cost: 8.68s
Train Epoch: 1144 [81920/90000 (91%)]	Loss: -4.8928	Cost: 7.81s
Train Epoch: 1144 	Average Loss: -4.5077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7532

Learning rate: 9.68054326488006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1145 [0/90000 (0%)]	Loss: -1.5262	Cost: 28.44s
Train Epoch: 1145 [20480/90000 (23%)]	Loss: -4.8336	Cost: 9.60s
Train Epoch: 1145 [40960/90000 (45%)]	Loss: -4.8106	Cost: 19.52s
Train Epoch: 1145 [61440/90000 (68%)]	Loss: -4.6517	Cost: 12.24s
Train Epoch: 1145 [81920/90000 (91%)]	Loss: -4.6740	Cost: 12.02s
Train Epoch: 1145 	Average Loss: -4.5507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7536

Learning rate: 9.679990567650885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1146 [0/90000 (0%)]	Loss: -1.4320	Cost: 31.97s
Train Epoch: 1146 [20480/90000 (23%)]	Loss: -4.7286	Cost: 8.89s
Train Epoch: 1146 [40960/90000 (45%)]	Loss: -4.4952	Cost: 12.67s
Train Epoch: 1146 [61440/90000 (68%)]	Loss: -4.7638	Cost: 8.68s
Train Epoch: 1146 [81920/90000 (91%)]	Loss: -4.6697	Cost: 8.97s
Train Epoch: 1146 	Average Loss: -4.4292
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6646

Learning rate: 9.67943740852516e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1147 [0/90000 (0%)]	Loss: -1.6568	Cost: 32.77s
Train Epoch: 1147 [20480/90000 (23%)]	Loss: -4.7709	Cost: 6.40s
Train Epoch: 1147 [40960/90000 (45%)]	Loss: -4.3455	Cost: 18.84s
Train Epoch: 1147 [61440/90000 (68%)]	Loss: -4.5239	Cost: 12.28s
Train Epoch: 1147 [81920/90000 (91%)]	Loss: -4.6967	Cost: 12.22s
Train Epoch: 1147 	Average Loss: -4.3402
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6148

Learning rate: 9.678883787557477e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1148 [0/90000 (0%)]	Loss: -1.5446	Cost: 32.27s
Train Epoch: 1148 [20480/90000 (23%)]	Loss: -4.4947	Cost: 9.54s
Train Epoch: 1148 [40960/90000 (45%)]	Loss: -4.7685	Cost: 18.17s
Train Epoch: 1148 [61440/90000 (68%)]	Loss: -5.0641	Cost: 8.94s
Train Epoch: 1148 [81920/90000 (91%)]	Loss: -4.9526	Cost: 10.30s
Train Epoch: 1148 	Average Loss: -4.5068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7792

Learning rate: 9.67832970480248e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1149 [0/90000 (0%)]	Loss: -1.9584	Cost: 30.79s
Train Epoch: 1149 [20480/90000 (23%)]	Loss: -4.3151	Cost: 10.01s
Train Epoch: 1149 [40960/90000 (45%)]	Loss: -4.2624	Cost: 21.20s
Train Epoch: 1149 [61440/90000 (68%)]	Loss: -4.5393	Cost: 12.78s
Train Epoch: 1149 [81920/90000 (91%)]	Loss: -4.4236	Cost: 12.49s
Train Epoch: 1149 	Average Loss: -4.1741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5713

Learning rate: 9.67777516031485e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1150 [0/90000 (0%)]	Loss: -1.4711	Cost: 53.37s
Train Epoch: 1150 [20480/90000 (23%)]	Loss: -4.3799	Cost: 6.53s
Train Epoch: 1150 [40960/90000 (45%)]	Loss: -4.6822	Cost: 13.19s
Train Epoch: 1150 [61440/90000 (68%)]	Loss: -4.7169	Cost: 8.61s
Train Epoch: 1150 [81920/90000 (91%)]	Loss: -4.6923	Cost: 8.70s
Train Epoch: 1150 	Average Loss: -4.2926
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2204

Learning rate: 9.677220154149323e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1151 [0/90000 (0%)]	Loss: -1.3338	Cost: 34.82s
Train Epoch: 1151 [20480/90000 (23%)]	Loss: -4.3259	Cost: 10.28s
Train Epoch: 1151 [40960/90000 (45%)]	Loss: -3.7739	Cost: 15.40s
Train Epoch: 1151 [61440/90000 (68%)]	Loss: -4.1616	Cost: 12.45s
Train Epoch: 1151 [81920/90000 (91%)]	Loss: -4.3729	Cost: 12.29s
Train Epoch: 1151 	Average Loss: -3.9298
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.3885

Learning rate: 9.676664686360671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1152 [0/90000 (0%)]	Loss: -1.1253	Cost: 52.72s
Train Epoch: 1152 [20480/90000 (23%)]	Loss: -4.5236	Cost: 7.57s
Train Epoch: 1152 [40960/90000 (45%)]	Loss: -4.3797	Cost: 13.23s
Train Epoch: 1152 [61440/90000 (68%)]	Loss: -4.6377	Cost: 8.53s
Train Epoch: 1152 [81920/90000 (91%)]	Loss: -4.6939	Cost: 8.61s
Train Epoch: 1152 	Average Loss: -4.2866
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6874

Learning rate: 9.67610875700372e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1153 [0/90000 (0%)]	Loss: -1.5655	Cost: 34.07s
Train Epoch: 1153 [20480/90000 (23%)]	Loss: -4.6208	Cost: 6.91s
Train Epoch: 1153 [40960/90000 (45%)]	Loss: -4.3089	Cost: 19.55s
Train Epoch: 1153 [61440/90000 (68%)]	Loss: -4.4912	Cost: 12.49s
Train Epoch: 1153 [81920/90000 (91%)]	Loss: -4.7007	Cost: 12.08s
Train Epoch: 1153 	Average Loss: -4.2786
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.4819

Learning rate: 9.675552366133338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1154 [0/90000 (0%)]	Loss: -1.4086	Cost: 50.16s
Train Epoch: 1154 [20480/90000 (23%)]	Loss: -4.3063	Cost: 6.21s
Train Epoch: 1154 [40960/90000 (45%)]	Loss: -4.2800	Cost: 13.72s
Train Epoch: 1154 [61440/90000 (68%)]	Loss: -4.7808	Cost: 8.47s
Train Epoch: 1154 [81920/90000 (91%)]	Loss: -4.6478	Cost: 8.40s
Train Epoch: 1154 	Average Loss: -4.3035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6657

Learning rate: 9.674995513804436e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1155 [0/90000 (0%)]	Loss: -1.4474	Cost: 28.77s
Train Epoch: 1155 [20480/90000 (23%)]	Loss: -4.4876	Cost: 6.75s
Train Epoch: 1155 [40960/90000 (45%)]	Loss: -4.6951	Cost: 17.21s
Train Epoch: 1155 [61440/90000 (68%)]	Loss: -4.8695	Cost: 13.18s
Train Epoch: 1155 [81920/90000 (91%)]	Loss: -4.9609	Cost: 12.38s
Train Epoch: 1155 	Average Loss: -4.4832
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9120

Saving model as e1155_model.pt & e1155_waveforms_supplementary.hdf5
Learning rate: 9.674438200071975e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1156 [0/90000 (0%)]	Loss: -2.0474	Cost: 31.73s
Train Epoch: 1156 [20480/90000 (23%)]	Loss: -4.7147	Cost: 8.26s
Train Epoch: 1156 [40960/90000 (45%)]	Loss: -4.7785	Cost: 16.23s
Train Epoch: 1156 [61440/90000 (68%)]	Loss: -4.9934	Cost: 9.07s
Train Epoch: 1156 [81920/90000 (91%)]	Loss: -4.8827	Cost: 10.36s
Train Epoch: 1156 	Average Loss: -4.6491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7768

Learning rate: 9.673880424990961e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1157 [0/90000 (0%)]	Loss: -1.5093	Cost: 32.55s
Train Epoch: 1157 [20480/90000 (23%)]	Loss: -4.6179	Cost: 9.43s
Train Epoch: 1157 [40960/90000 (45%)]	Loss: -4.7807	Cost: 15.76s
Train Epoch: 1157 [61440/90000 (68%)]	Loss: -4.9233	Cost: 12.17s
Train Epoch: 1157 [81920/90000 (91%)]	Loss: -5.0395	Cost: 11.96s
Train Epoch: 1157 	Average Loss: -4.5748
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8067

Learning rate: 9.673322188616441e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1158 [0/90000 (0%)]	Loss: -1.5981	Cost: 38.69s
Train Epoch: 1158 [20480/90000 (23%)]	Loss: -4.8929	Cost: 11.45s
Train Epoch: 1158 [40960/90000 (45%)]	Loss: -4.9307	Cost: 7.78s
Train Epoch: 1158 [61440/90000 (68%)]	Loss: -5.0221	Cost: 7.18s
Train Epoch: 1158 [81920/90000 (91%)]	Loss: -5.0327	Cost: 14.09s
Train Epoch: 1158 	Average Loss: -4.6526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8309

Learning rate: 9.672763491003515e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1159 [0/90000 (0%)]	Loss: -1.8094	Cost: 30.37s
Train Epoch: 1159 [20480/90000 (23%)]	Loss: -4.8887	Cost: 10.68s
Train Epoch: 1159 [40960/90000 (45%)]	Loss: -5.0545	Cost: 22.17s
Train Epoch: 1159 [61440/90000 (68%)]	Loss: -4.7812	Cost: 12.25s
Train Epoch: 1159 [81920/90000 (91%)]	Loss: -4.5517	Cost: 11.81s
Train Epoch: 1159 	Average Loss: -4.6024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6779

Learning rate: 9.67220433220732e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1160 [0/90000 (0%)]	Loss: -1.4881	Cost: 30.27s
Train Epoch: 1160 [20480/90000 (23%)]	Loss: -4.5648	Cost: 8.94s
Train Epoch: 1160 [40960/90000 (45%)]	Loss: -4.6404	Cost: 12.33s
Train Epoch: 1160 [61440/90000 (68%)]	Loss: -4.8038	Cost: 9.08s
Train Epoch: 1160 [81920/90000 (91%)]	Loss: -4.9295	Cost: 11.47s
Train Epoch: 1160 	Average Loss: -4.4485
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8515

Learning rate: 9.671644712283045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1161 [0/90000 (0%)]	Loss: -1.5476	Cost: 33.01s
Train Epoch: 1161 [20480/90000 (23%)]	Loss: -4.7176	Cost: 8.25s
Train Epoch: 1161 [40960/90000 (45%)]	Loss: -4.8229	Cost: 18.70s
Train Epoch: 1161 [61440/90000 (68%)]	Loss: -4.9660	Cost: 12.39s
Train Epoch: 1161 [81920/90000 (91%)]	Loss: -4.9278	Cost: 12.25s
Train Epoch: 1161 	Average Loss: -4.5938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8681

Learning rate: 9.67108463128592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1162 [0/90000 (0%)]	Loss: -1.7085	Cost: 39.85s
Train Epoch: 1162 [20480/90000 (23%)]	Loss: -4.3379	Cost: 11.61s
Train Epoch: 1162 [40960/90000 (45%)]	Loss: -3.8932	Cost: 7.03s
Train Epoch: 1162 [61440/90000 (68%)]	Loss: -4.1812	Cost: 6.41s
Train Epoch: 1162 [81920/90000 (91%)]	Loss: -4.5148	Cost: 12.61s
Train Epoch: 1162 	Average Loss: -4.0575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5990

Learning rate: 9.670524089271225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1163 [0/90000 (0%)]	Loss: -1.5021	Cost: 36.87s
Train Epoch: 1163 [20480/90000 (23%)]	Loss: -4.4791	Cost: 14.08s
Train Epoch: 1163 [40960/90000 (45%)]	Loss: -4.4057	Cost: 16.32s
Train Epoch: 1163 [61440/90000 (68%)]	Loss: -4.6607	Cost: 12.20s
Train Epoch: 1163 [81920/90000 (91%)]	Loss: -4.8720	Cost: 11.92s
Train Epoch: 1163 	Average Loss: -4.3570
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8098

Learning rate: 9.669963086294282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1164 [0/90000 (0%)]	Loss: -1.6626	Cost: 36.64s
Train Epoch: 1164 [20480/90000 (23%)]	Loss: -4.8563	Cost: 7.95s
Train Epoch: 1164 [40960/90000 (45%)]	Loss: -5.0154	Cost: 13.58s
Train Epoch: 1164 [61440/90000 (68%)]	Loss: -5.3284	Cost: 8.57s
Train Epoch: 1164 [81920/90000 (91%)]	Loss: -5.0877	Cost: 8.55s
Train Epoch: 1164 	Average Loss: -4.7783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9550

Saving model as e1164_model.pt & e1164_waveforms_supplementary.hdf5
Learning rate: 9.669401622410463e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1165 [0/90000 (0%)]	Loss: -1.9562	Cost: 30.07s
Train Epoch: 1165 [20480/90000 (23%)]	Loss: -4.7994	Cost: 9.04s
Train Epoch: 1165 [40960/90000 (45%)]	Loss: -4.9132	Cost: 19.57s
Train Epoch: 1165 [61440/90000 (68%)]	Loss: -5.2811	Cost: 12.84s
Train Epoch: 1165 [81920/90000 (91%)]	Loss: -5.0775	Cost: 11.89s
Train Epoch: 1165 	Average Loss: -4.7856
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9346

Learning rate: 9.668839697675178e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1166 [0/90000 (0%)]	Loss: -1.7931	Cost: 49.10s
Train Epoch: 1166 [20480/90000 (23%)]	Loss: -4.7766	Cost: 7.32s
Train Epoch: 1166 [40960/90000 (45%)]	Loss: -4.8910	Cost: 10.16s
Train Epoch: 1166 [61440/90000 (68%)]	Loss: -5.0083	Cost: 8.06s
Train Epoch: 1166 [81920/90000 (91%)]	Loss: -5.1129	Cost: 9.71s
Train Epoch: 1166 	Average Loss: -4.7481
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8514

Learning rate: 9.668277312143889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1167 [0/90000 (0%)]	Loss: -2.0461	Cost: 27.89s
Train Epoch: 1167 [20480/90000 (23%)]	Loss: -4.6633	Cost: 6.89s
Train Epoch: 1167 [40960/90000 (45%)]	Loss: -4.7961	Cost: 18.37s
Train Epoch: 1167 [61440/90000 (68%)]	Loss: -5.0087	Cost: 14.67s
Train Epoch: 1167 [81920/90000 (91%)]	Loss: -5.1506	Cost: 12.16s
Train Epoch: 1167 	Average Loss: -4.6443
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9093

Learning rate: 9.667714465872102e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1168 [0/90000 (0%)]	Loss: -1.9114	Cost: 33.80s
Train Epoch: 1168 [20480/90000 (23%)]	Loss: -5.0616	Cost: 12.44s
Train Epoch: 1168 [40960/90000 (45%)]	Loss: -4.7531	Cost: 11.76s
Train Epoch: 1168 [61440/90000 (68%)]	Loss: -5.1999	Cost: 6.68s
Train Epoch: 1168 [81920/90000 (91%)]	Loss: -4.8274	Cost: 14.62s
Train Epoch: 1168 	Average Loss: -4.6940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7362

Learning rate: 9.667151158915365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1169 [0/90000 (0%)]	Loss: -1.7980	Cost: 31.42s
Train Epoch: 1169 [20480/90000 (23%)]	Loss: -4.7963	Cost: 8.87s
Train Epoch: 1169 [40960/90000 (45%)]	Loss: -4.7259	Cost: 15.11s
Train Epoch: 1169 [61440/90000 (68%)]	Loss: -5.1418	Cost: 12.21s
Train Epoch: 1169 [81920/90000 (91%)]	Loss: -5.2072	Cost: 12.18s
Train Epoch: 1169 	Average Loss: -4.6233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0072

Saving model as e1169_model.pt & e1169_waveforms_supplementary.hdf5
Learning rate: 9.666587391329276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1170 [0/90000 (0%)]	Loss: -1.5215	Cost: 39.09s
Train Epoch: 1170 [20480/90000 (23%)]	Loss: -4.7745	Cost: 12.67s
Train Epoch: 1170 [40960/90000 (45%)]	Loss: -5.0115	Cost: 10.81s
Train Epoch: 1170 [61440/90000 (68%)]	Loss: -5.1890	Cost: 6.38s
Train Epoch: 1170 [81920/90000 (91%)]	Loss: -5.0755	Cost: 10.00s
Train Epoch: 1170 	Average Loss: -4.7086
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7482

Learning rate: 9.666023163169475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1171 [0/90000 (0%)]	Loss: -1.6763	Cost: 30.40s
Train Epoch: 1171 [20480/90000 (23%)]	Loss: -4.7416	Cost: 8.66s
Train Epoch: 1171 [40960/90000 (45%)]	Loss: -4.9446	Cost: 8.95s
Train Epoch: 1171 [61440/90000 (68%)]	Loss: -5.1000	Cost: 6.60s
Train Epoch: 1171 [81920/90000 (91%)]	Loss: -5.0862	Cost: 18.34s
Train Epoch: 1171 	Average Loss: -4.6898
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8388

Learning rate: 9.665458474491652e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1172 [0/90000 (0%)]	Loss: -1.6636	Cost: 38.71s
Train Epoch: 1172 [20480/90000 (23%)]	Loss: -4.7241	Cost: 11.41s
Train Epoch: 1172 [40960/90000 (45%)]	Loss: -4.8552	Cost: 10.34s
Train Epoch: 1172 [61440/90000 (68%)]	Loss: -5.0721	Cost: 9.73s
Train Epoch: 1172 [81920/90000 (91%)]	Loss: -4.3374	Cost: 12.19s
Train Epoch: 1172 	Average Loss: -4.5960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -0.8479

Learning rate: 9.664893325351537e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1173 [0/90000 (0%)]	Loss: -0.6947	Cost: 39.90s
Train Epoch: 1173 [20480/90000 (23%)]	Loss: -3.6701	Cost: 7.99s
Train Epoch: 1173 [40960/90000 (45%)]	Loss: -4.0103	Cost: 18.77s
Train Epoch: 1173 [61440/90000 (68%)]	Loss: -4.5446	Cost: 11.98s
Train Epoch: 1173 [81920/90000 (91%)]	Loss: -4.8777	Cost: 12.11s
Train Epoch: 1173 	Average Loss: -3.9430
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6706

Learning rate: 9.664327715804909e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1174 [0/90000 (0%)]	Loss: -1.4844	Cost: 34.40s
Train Epoch: 1174 [20480/90000 (23%)]	Loss: -4.3809	Cost: 10.70s
Train Epoch: 1174 [40960/90000 (45%)]	Loss: -4.5645	Cost: 8.37s
Train Epoch: 1174 [61440/90000 (68%)]	Loss: -4.7539	Cost: 6.19s
Train Epoch: 1174 [81920/90000 (91%)]	Loss: -4.7004	Cost: 14.95s
Train Epoch: 1174 	Average Loss: -4.3454
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6862

Learning rate: 9.663761645907591e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1175 [0/90000 (0%)]	Loss: -1.5655	Cost: 33.61s
Train Epoch: 1175 [20480/90000 (23%)]	Loss: -4.4301	Cost: 7.57s
Train Epoch: 1175 [40960/90000 (45%)]	Loss: -4.1634	Cost: 17.68s
Train Epoch: 1175 [61440/90000 (68%)]	Loss: -4.3397	Cost: 13.04s
Train Epoch: 1175 [81920/90000 (91%)]	Loss: -4.6253	Cost: 12.10s
Train Epoch: 1175 	Average Loss: -4.2159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6936

Learning rate: 9.663195115715452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1176 [0/90000 (0%)]	Loss: -1.8000	Cost: 31.25s
Train Epoch: 1176 [20480/90000 (23%)]	Loss: -4.5529	Cost: 11.25s
Train Epoch: 1176 [40960/90000 (45%)]	Loss: -4.6428	Cost: 9.70s
Train Epoch: 1176 [61440/90000 (68%)]	Loss: -4.8783	Cost: 8.19s
Train Epoch: 1176 [81920/90000 (91%)]	Loss: -4.9505	Cost: 13.41s
Train Epoch: 1176 	Average Loss: -4.4663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8137

Learning rate: 9.662628125284406e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1177 [0/90000 (0%)]	Loss: -2.0582	Cost: 48.96s
Train Epoch: 1177 [20480/90000 (23%)]	Loss: -4.9884	Cost: 9.69s
Train Epoch: 1177 [40960/90000 (45%)]	Loss: -4.9563	Cost: 14.11s
Train Epoch: 1177 [61440/90000 (68%)]	Loss: -5.2229	Cost: 12.18s
Train Epoch: 1177 [81920/90000 (91%)]	Loss: -5.2716	Cost: 11.82s
Train Epoch: 1177 	Average Loss: -4.7653
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0420

Saving model as e1177_model.pt & e1177_waveforms_supplementary.hdf5
Learning rate: 9.662060674670414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1178 [0/90000 (0%)]	Loss: -1.8779	Cost: 40.02s
Train Epoch: 1178 [20480/90000 (23%)]	Loss: -5.0663	Cost: 6.22s
Train Epoch: 1178 [40960/90000 (45%)]	Loss: -5.0992	Cost: 14.31s
Train Epoch: 1178 [61440/90000 (68%)]	Loss: -5.3932	Cost: 8.53s
Train Epoch: 1178 [81920/90000 (91%)]	Loss: -5.2394	Cost: 8.79s
Train Epoch: 1178 	Average Loss: -4.9161
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1225

Saving model as e1178_model.pt & e1178_waveforms_supplementary.hdf5
Learning rate: 9.66149276392948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1179 [0/90000 (0%)]	Loss: -1.4672	Cost: 30.01s
Train Epoch: 1179 [20480/90000 (23%)]	Loss: -5.0267	Cost: 10.54s
Train Epoch: 1179 [40960/90000 (45%)]	Loss: -5.2433	Cost: 18.35s
Train Epoch: 1179 [61440/90000 (68%)]	Loss: -5.4434	Cost: 13.15s
Train Epoch: 1179 [81920/90000 (91%)]	Loss: -5.2249	Cost: 12.08s
Train Epoch: 1179 	Average Loss: -4.9488
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.5730

Learning rate: 9.660924393117656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1180 [0/90000 (0%)]	Loss: -1.6593	Cost: 43.21s
Train Epoch: 1180 [20480/90000 (23%)]	Loss: -4.1419	Cost: 9.40s
Train Epoch: 1180 [40960/90000 (45%)]	Loss: -4.3312	Cost: 10.89s
Train Epoch: 1180 [61440/90000 (68%)]	Loss: -5.0249	Cost: 6.08s
Train Epoch: 1180 [81920/90000 (91%)]	Loss: -4.9235	Cost: 14.61s
Train Epoch: 1180 	Average Loss: -4.3137
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9233

Learning rate: 9.660355562291035e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1181 [0/90000 (0%)]	Loss: -1.8633	Cost: 38.12s
Train Epoch: 1181 [20480/90000 (23%)]	Loss: -4.9934	Cost: 11.74s
Train Epoch: 1181 [40960/90000 (45%)]	Loss: -5.0153	Cost: 20.67s
Train Epoch: 1181 [61440/90000 (68%)]	Loss: -4.9987	Cost: 12.09s
Train Epoch: 1181 [81920/90000 (91%)]	Loss: -4.9365	Cost: 11.88s
Train Epoch: 1181 	Average Loss: -4.7288
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9235

Learning rate: 9.659786271505762e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1182 [0/90000 (0%)]	Loss: -2.0585	Cost: 46.20s
Train Epoch: 1182 [20480/90000 (23%)]	Loss: -4.8630	Cost: 11.08s
Train Epoch: 1182 [40960/90000 (45%)]	Loss: -5.0513	Cost: 6.38s
Train Epoch: 1182 [61440/90000 (68%)]	Loss: -5.1765	Cost: 6.43s
Train Epoch: 1182 [81920/90000 (91%)]	Loss: -5.0472	Cost: 11.97s
Train Epoch: 1182 	Average Loss: -4.8009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8750

Learning rate: 9.65921652081802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1183 [0/90000 (0%)]	Loss: -1.8634	Cost: 27.65s
Train Epoch: 1183 [20480/90000 (23%)]	Loss: -4.9597	Cost: 6.88s
Train Epoch: 1183 [40960/90000 (45%)]	Loss: -5.1061	Cost: 18.14s
Train Epoch: 1183 [61440/90000 (68%)]	Loss: -5.3338	Cost: 13.85s
Train Epoch: 1183 [81920/90000 (91%)]	Loss: -5.2133	Cost: 13.54s
Train Epoch: 1183 	Average Loss: -4.8907
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0875

Learning rate: 9.658646310284045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1184 [0/90000 (0%)]	Loss: -2.2738	Cost: 39.75s
Train Epoch: 1184 [20480/90000 (23%)]	Loss: -4.7911	Cost: 12.37s
Train Epoch: 1184 [40960/90000 (45%)]	Loss: -4.7392	Cost: 9.02s
Train Epoch: 1184 [61440/90000 (68%)]	Loss: -5.0799	Cost: 6.54s
Train Epoch: 1184 [81920/90000 (91%)]	Loss: -5.0848	Cost: 10.65s
Train Epoch: 1184 	Average Loss: -4.7416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9814

Learning rate: 9.65807563996011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1185 [0/90000 (0%)]	Loss: -1.7987	Cost: 28.27s
Train Epoch: 1185 [20480/90000 (23%)]	Loss: -5.0051	Cost: 6.88s
Train Epoch: 1185 [40960/90000 (45%)]	Loss: -5.1849	Cost: 16.02s
Train Epoch: 1185 [61440/90000 (68%)]	Loss: -5.4188	Cost: 13.45s
Train Epoch: 1185 [81920/90000 (91%)]	Loss: -5.4492	Cost: 12.38s
Train Epoch: 1185 	Average Loss: -4.9798
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1509

Saving model as e1185_model.pt & e1185_waveforms_supplementary.hdf5
Learning rate: 9.657504509902543e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1186 [0/90000 (0%)]	Loss: -2.2928	Cost: 53.98s
Train Epoch: 1186 [20480/90000 (23%)]	Loss: -5.1044	Cost: 11.21s
Train Epoch: 1186 [40960/90000 (45%)]	Loss: -5.1896	Cost: 7.20s
Train Epoch: 1186 [61440/90000 (68%)]	Loss: -5.5048	Cost: 6.31s
Train Epoch: 1186 [81920/90000 (91%)]	Loss: -5.4314	Cost: 13.05s
Train Epoch: 1186 	Average Loss: -5.0607
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1267

Learning rate: 9.656932920167708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1187 [0/90000 (0%)]	Loss: -2.1466	Cost: 32.26s
Train Epoch: 1187 [20480/90000 (23%)]	Loss: -5.0570	Cost: 6.80s
Train Epoch: 1187 [40960/90000 (45%)]	Loss: -4.9543	Cost: 17.73s
Train Epoch: 1187 [61440/90000 (68%)]	Loss: -5.3156	Cost: 12.21s
Train Epoch: 1187 [81920/90000 (91%)]	Loss: -5.2279	Cost: 12.06s
Train Epoch: 1187 	Average Loss: -4.9346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1792

Saving model as e1187_model.pt & e1187_waveforms_supplementary.hdf5
Learning rate: 9.656360870812022e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1188 [0/90000 (0%)]	Loss: -1.7352	Cost: 35.32s
Train Epoch: 1188 [20480/90000 (23%)]	Loss: -5.2912	Cost: 15.12s
Train Epoch: 1188 [40960/90000 (45%)]	Loss: -5.0283	Cost: 12.63s
Train Epoch: 1188 [61440/90000 (68%)]	Loss: -5.4097	Cost: 9.43s
Train Epoch: 1188 [81920/90000 (91%)]	Loss: -5.2544	Cost: 7.73s
Train Epoch: 1188 	Average Loss: -4.9477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0274

Learning rate: 9.655788361891943e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1189 [0/90000 (0%)]	Loss: -2.2674	Cost: 42.61s
Train Epoch: 1189 [20480/90000 (23%)]	Loss: -4.9469	Cost: 8.84s
Train Epoch: 1189 [40960/90000 (45%)]	Loss: -5.1900	Cost: 17.20s
Train Epoch: 1189 [61440/90000 (68%)]	Loss: -5.2518	Cost: 12.13s
Train Epoch: 1189 [81920/90000 (91%)]	Loss: -5.4789	Cost: 12.04s
Train Epoch: 1189 	Average Loss: -4.9279
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2331

Saving model as e1189_model.pt & e1189_waveforms_supplementary.hdf5
Learning rate: 9.655215393463971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1190 [0/90000 (0%)]	Loss: -1.9594	Cost: 31.91s
Train Epoch: 1190 [20480/90000 (23%)]	Loss: -4.9841	Cost: 7.38s
Train Epoch: 1190 [40960/90000 (45%)]	Loss: -5.1031	Cost: 14.23s
Train Epoch: 1190 [61440/90000 (68%)]	Loss: -5.4308	Cost: 8.63s
Train Epoch: 1190 [81920/90000 (91%)]	Loss: -5.1462	Cost: 11.13s
Train Epoch: 1190 	Average Loss: -4.9065
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8689

Learning rate: 9.65464196558466e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1191 [0/90000 (0%)]	Loss: -1.5939	Cost: 33.24s
Train Epoch: 1191 [20480/90000 (23%)]	Loss: -5.0904	Cost: 9.95s
Train Epoch: 1191 [40960/90000 (45%)]	Loss: -5.0837	Cost: 16.99s
Train Epoch: 1191 [61440/90000 (68%)]	Loss: -5.2856	Cost: 12.17s
Train Epoch: 1191 [81920/90000 (91%)]	Loss: -4.8879	Cost: 12.24s
Train Epoch: 1191 	Average Loss: -4.7346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7796

Learning rate: 9.654068078310607e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1192 [0/90000 (0%)]	Loss: -1.6103	Cost: 35.73s
Train Epoch: 1192 [20480/90000 (23%)]	Loss: -4.7111	Cost: 11.87s
Train Epoch: 1192 [40960/90000 (45%)]	Loss: -4.6524	Cost: 6.59s
Train Epoch: 1192 [61440/90000 (68%)]	Loss: -4.9532	Cost: 6.29s
Train Epoch: 1192 [81920/90000 (91%)]	Loss: -4.7893	Cost: 15.75s
Train Epoch: 1192 	Average Loss: -4.5614
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7334

Learning rate: 9.653493731698448e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1193 [0/90000 (0%)]	Loss: -1.7968	Cost: 28.96s
Train Epoch: 1193 [20480/90000 (23%)]	Loss: -4.9606	Cost: 8.77s
Train Epoch: 1193 [40960/90000 (45%)]	Loss: -4.9415	Cost: 17.91s
Train Epoch: 1193 [61440/90000 (68%)]	Loss: -5.1882	Cost: 12.56s
Train Epoch: 1193 [81920/90000 (91%)]	Loss: -5.0996	Cost: 15.71s
Train Epoch: 1193 	Average Loss: -4.7779
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9331

Learning rate: 9.652918925804872e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1194 [0/90000 (0%)]	Loss: -1.9318	Cost: 62.17s
Train Epoch: 1194 [20480/90000 (23%)]	Loss: -4.9956	Cost: 6.09s
Train Epoch: 1194 [40960/90000 (45%)]	Loss: -4.9509	Cost: 13.46s
Train Epoch: 1194 [61440/90000 (68%)]	Loss: -5.2008	Cost: 8.68s
Train Epoch: 1194 [81920/90000 (91%)]	Loss: -4.9346	Cost: 8.74s
Train Epoch: 1194 	Average Loss: -4.7763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9551

Learning rate: 9.652343660686608e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1195 [0/90000 (0%)]	Loss: -2.2724	Cost: 29.89s
Train Epoch: 1195 [20480/90000 (23%)]	Loss: -4.6620	Cost: 6.50s
Train Epoch: 1195 [40960/90000 (45%)]	Loss: -4.9708	Cost: 20.04s
Train Epoch: 1195 [61440/90000 (68%)]	Loss: -5.1374	Cost: 12.55s
Train Epoch: 1195 [81920/90000 (91%)]	Loss: -5.1744	Cost: 12.20s
Train Epoch: 1195 	Average Loss: -4.8195
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9788

Learning rate: 9.651767936400433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1196 [0/90000 (0%)]	Loss: -1.9436	Cost: 48.23s
Train Epoch: 1196 [20480/90000 (23%)]	Loss: -4.9298	Cost: 9.68s
Train Epoch: 1196 [40960/90000 (45%)]	Loss: -4.9522	Cost: 10.38s
Train Epoch: 1196 [61440/90000 (68%)]	Loss: -4.9808	Cost: 6.16s
Train Epoch: 1196 [81920/90000 (91%)]	Loss: -5.0563	Cost: 14.87s
Train Epoch: 1196 	Average Loss: -4.8219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0592

Learning rate: 9.651191753003167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1197 [0/90000 (0%)]	Loss: -2.2357	Cost: 32.35s
Train Epoch: 1197 [20480/90000 (23%)]	Loss: -5.0433	Cost: 6.54s
Train Epoch: 1197 [40960/90000 (45%)]	Loss: -5.3000	Cost: 17.52s
Train Epoch: 1197 [61440/90000 (68%)]	Loss: -5.5166	Cost: 12.64s
Train Epoch: 1197 [81920/90000 (91%)]	Loss: -5.4292	Cost: 12.13s
Train Epoch: 1197 	Average Loss: -5.0562
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2442

Saving model as e1197_model.pt & e1197_waveforms_supplementary.hdf5
Learning rate: 9.650615110551681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1198 [0/90000 (0%)]	Loss: -2.2732	Cost: 42.10s
Train Epoch: 1198 [20480/90000 (23%)]	Loss: -5.0486	Cost: 11.96s
Train Epoch: 1198 [40960/90000 (45%)]	Loss: -5.0965	Cost: 7.21s
Train Epoch: 1198 [61440/90000 (68%)]	Loss: -5.3290	Cost: 6.36s
Train Epoch: 1198 [81920/90000 (91%)]	Loss: -5.3366	Cost: 13.10s
Train Epoch: 1198 	Average Loss: -5.0002
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2374

Learning rate: 9.650038009102886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1199 [0/90000 (0%)]	Loss: -2.0861	Cost: 28.01s
Train Epoch: 1199 [20480/90000 (23%)]	Loss: -5.2952	Cost: 6.62s
Train Epoch: 1199 [40960/90000 (45%)]	Loss: -5.3969	Cost: 14.87s
Train Epoch: 1199 [61440/90000 (68%)]	Loss: -5.4685	Cost: 13.04s
Train Epoch: 1199 [81920/90000 (91%)]	Loss: -5.3326	Cost: 13.94s
Train Epoch: 1199 	Average Loss: -5.1100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3350

Saving model as e1199_model.pt & e1199_waveforms_supplementary.hdf5
Learning rate: 9.649460448713736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1200 [0/90000 (0%)]	Loss: -2.1649	Cost: 32.94s
Train Epoch: 1200 [20480/90000 (23%)]	Loss: -5.3527	Cost: 11.99s
Train Epoch: 1200 [40960/90000 (45%)]	Loss: -5.3468	Cost: 14.10s
Train Epoch: 1200 [61440/90000 (68%)]	Loss: -5.4053	Cost: 7.19s
Train Epoch: 1200 [81920/90000 (91%)]	Loss: -5.4436	Cost: 8.45s
Train Epoch: 1200 	Average Loss: -5.1672
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2060

Learning rate: 9.648882429441238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1201 [0/90000 (0%)]	Loss: -1.6008	Cost: 30.80s
Train Epoch: 1201 [20480/90000 (23%)]	Loss: -5.4300	Cost: 10.00s
Train Epoch: 1201 [40960/90000 (45%)]	Loss: -5.2530	Cost: 9.00s
Train Epoch: 1201 [61440/90000 (68%)]	Loss: -5.5721	Cost: 7.14s
Train Epoch: 1201 [81920/90000 (91%)]	Loss: -5.6550	Cost: 19.14s
Train Epoch: 1201 	Average Loss: -5.1555
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2934

Learning rate: 9.64830395134244e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1202 [0/90000 (0%)]	Loss: -1.8842	Cost: 46.42s
Train Epoch: 1202 [20480/90000 (23%)]	Loss: -5.3192	Cost: 12.29s
Train Epoch: 1202 [40960/90000 (45%)]	Loss: -5.2989	Cost: 12.29s
Train Epoch: 1202 [61440/90000 (68%)]	Loss: -5.1792	Cost: 9.76s
Train Epoch: 1202 [81920/90000 (91%)]	Loss: -5.1894	Cost: 6.46s
Train Epoch: 1202 	Average Loss: -5.0448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1829

Learning rate: 9.647725014474433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1203 [0/90000 (0%)]	Loss: -1.8120	Cost: 32.77s
Train Epoch: 1203 [20480/90000 (23%)]	Loss: -5.0711	Cost: 8.64s
Train Epoch: 1203 [40960/90000 (45%)]	Loss: -5.4413	Cost: 12.43s
Train Epoch: 1203 [61440/90000 (68%)]	Loss: -5.4587	Cost: 8.75s
Train Epoch: 1203 [81920/90000 (91%)]	Loss: -5.0720	Cost: 6.42s
Train Epoch: 1203 	Average Loss: -4.9927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8443

Learning rate: 9.647145618894359e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1204 [0/90000 (0%)]	Loss: -1.9733	Cost: 27.98s
Train Epoch: 1204 [20480/90000 (23%)]	Loss: -4.8326	Cost: 7.95s
Train Epoch: 1204 [40960/90000 (45%)]	Loss: -5.1061	Cost: 17.19s
Train Epoch: 1204 [61440/90000 (68%)]	Loss: -5.4371	Cost: 12.12s
Train Epoch: 1204 [81920/90000 (91%)]	Loss: -5.5274	Cost: 12.18s
Train Epoch: 1204 	Average Loss: -4.9608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3126

Learning rate: 9.646565764659398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1205 [0/90000 (0%)]	Loss: -2.3588	Cost: 32.25s
Train Epoch: 1205 [20480/90000 (23%)]	Loss: -5.2452	Cost: 12.07s
Train Epoch: 1205 [40960/90000 (45%)]	Loss: -5.2528	Cost: 9.00s
Train Epoch: 1205 [61440/90000 (68%)]	Loss: -5.5082	Cost: 6.95s
Train Epoch: 1205 [81920/90000 (91%)]	Loss: -5.4753	Cost: 11.08s
Train Epoch: 1205 	Average Loss: -5.1262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3236

Learning rate: 9.645985451826784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1206 [0/90000 (0%)]	Loss: -2.3380	Cost: 33.54s
Train Epoch: 1206 [20480/90000 (23%)]	Loss: -5.3180	Cost: 12.06s
Train Epoch: 1206 [40960/90000 (45%)]	Loss: -5.4641	Cost: 18.82s
Train Epoch: 1206 [61440/90000 (68%)]	Loss: -5.5543	Cost: 12.32s
Train Epoch: 1206 [81920/90000 (91%)]	Loss: -5.4016	Cost: 12.02s
Train Epoch: 1206 	Average Loss: -5.2111
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1413

Learning rate: 9.645404680453786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1207 [0/90000 (0%)]	Loss: -1.7688	Cost: 44.00s
Train Epoch: 1207 [20480/90000 (23%)]	Loss: -5.1118	Cost: 6.24s
Train Epoch: 1207 [40960/90000 (45%)]	Loss: -4.9306	Cost: 13.17s
Train Epoch: 1207 [61440/90000 (68%)]	Loss: -5.1971	Cost: 8.69s
Train Epoch: 1207 [81920/90000 (91%)]	Loss: -5.3019	Cost: 10.03s
Train Epoch: 1207 	Average Loss: -4.8884
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1124

Learning rate: 9.64482345059773e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1208 [0/90000 (0%)]	Loss: -1.7337	Cost: 28.91s
Train Epoch: 1208 [20480/90000 (23%)]	Loss: -5.1197	Cost: 10.27s
Train Epoch: 1208 [40960/90000 (45%)]	Loss: -5.1976	Cost: 23.94s
Train Epoch: 1208 [61440/90000 (68%)]	Loss: -5.3753	Cost: 12.17s
Train Epoch: 1208 [81920/90000 (91%)]	Loss: -5.1599	Cost: 11.96s
Train Epoch: 1208 	Average Loss: -4.9814
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9512

Learning rate: 9.644241762315976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1209 [0/90000 (0%)]	Loss: -1.7804	Cost: 36.37s
Train Epoch: 1209 [20480/90000 (23%)]	Loss: -5.0647	Cost: 6.48s
Train Epoch: 1209 [40960/90000 (45%)]	Loss: -5.2361	Cost: 13.75s
Train Epoch: 1209 [61440/90000 (68%)]	Loss: -5.3656	Cost: 8.55s
Train Epoch: 1209 [81920/90000 (91%)]	Loss: -5.4214	Cost: 9.44s
Train Epoch: 1209 	Average Loss: -4.9691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1907

Learning rate: 9.643659615665937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1210 [0/90000 (0%)]	Loss: -1.9881	Cost: 28.61s
Train Epoch: 1210 [20480/90000 (23%)]	Loss: -5.3367	Cost: 7.10s
Train Epoch: 1210 [40960/90000 (45%)]	Loss: -4.9952	Cost: 23.50s
Train Epoch: 1210 [61440/90000 (68%)]	Loss: -5.2220	Cost: 12.46s
Train Epoch: 1210 [81920/90000 (91%)]	Loss: -5.4426	Cost: 12.25s
Train Epoch: 1210 	Average Loss: -4.9345
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2402

Learning rate: 9.643077010705068e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1211 [0/90000 (0%)]	Loss: -2.2305	Cost: 38.00s
Train Epoch: 1211 [20480/90000 (23%)]	Loss: -5.2920	Cost: 12.37s
Train Epoch: 1211 [40960/90000 (45%)]	Loss: -5.3577	Cost: 11.74s
Train Epoch: 1211 [61440/90000 (68%)]	Loss: -5.6428	Cost: 6.52s
Train Epoch: 1211 [81920/90000 (91%)]	Loss: -5.5019	Cost: 11.54s
Train Epoch: 1211 	Average Loss: -5.1486
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2397

Learning rate: 9.64249394749087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1212 [0/90000 (0%)]	Loss: -1.5102	Cost: 33.63s
Train Epoch: 1212 [20480/90000 (23%)]	Loss: -5.2708	Cost: 7.47s
Train Epoch: 1212 [40960/90000 (45%)]	Loss: -5.3526	Cost: 16.48s
Train Epoch: 1212 [61440/90000 (68%)]	Loss: -5.3303	Cost: 11.92s
Train Epoch: 1212 [81920/90000 (91%)]	Loss: -5.4727	Cost: 12.74s
Train Epoch: 1212 	Average Loss: -5.0294
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0431

Learning rate: 9.641910426080889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1213 [0/90000 (0%)]	Loss: -1.6298	Cost: 39.57s
Train Epoch: 1213 [20480/90000 (23%)]	Loss: -5.1582	Cost: 13.33s
Train Epoch: 1213 [40960/90000 (45%)]	Loss: -5.3802	Cost: 12.20s
Train Epoch: 1213 [61440/90000 (68%)]	Loss: -5.5986	Cost: 8.84s
Train Epoch: 1213 [81920/90000 (91%)]	Loss: -5.5853	Cost: 6.12s
Train Epoch: 1213 	Average Loss: -5.1413
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3087

Learning rate: 9.641326446532716e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1214 [0/90000 (0%)]	Loss: -2.2780	Cost: 33.40s
Train Epoch: 1214 [20480/90000 (23%)]	Loss: -5.5833	Cost: 8.82s
Train Epoch: 1214 [40960/90000 (45%)]	Loss: -4.6337	Cost: 9.96s
Train Epoch: 1214 [61440/90000 (68%)]	Loss: -4.9166	Cost: 7.76s
Train Epoch: 1214 [81920/90000 (91%)]	Loss: -5.0313	Cost: 9.20s
Train Epoch: 1214 	Average Loss: -4.8592
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.7918

Learning rate: 9.640742008903988e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1215 [0/90000 (0%)]	Loss: -1.2802	Cost: 33.09s
Train Epoch: 1215 [20480/90000 (23%)]	Loss: -4.7811	Cost: 11.40s
Train Epoch: 1215 [40960/90000 (45%)]	Loss: -4.9791	Cost: 14.15s
Train Epoch: 1215 [61440/90000 (68%)]	Loss: -5.2367	Cost: 11.90s
Train Epoch: 1215 [81920/90000 (91%)]	Loss: -5.3766	Cost: 12.08s
Train Epoch: 1215 	Average Loss: -4.7794
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2732

Learning rate: 9.640157113252386e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1216 [0/90000 (0%)]	Loss: -2.2564	Cost: 32.98s
Train Epoch: 1216 [20480/90000 (23%)]	Loss: -5.2488	Cost: 7.71s
Train Epoch: 1216 [40960/90000 (45%)]	Loss: -5.2767	Cost: 17.36s
Train Epoch: 1216 [61440/90000 (68%)]	Loss: -5.7343	Cost: 8.79s
Train Epoch: 1216 [81920/90000 (91%)]	Loss: -5.2596	Cost: 10.47s
Train Epoch: 1216 	Average Loss: -5.1194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0875

Learning rate: 9.639571759635636e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1217 [0/90000 (0%)]	Loss: -1.9575	Cost: 33.60s
Train Epoch: 1217 [20480/90000 (23%)]	Loss: -5.0135	Cost: 10.15s
Train Epoch: 1217 [40960/90000 (45%)]	Loss: -5.0841	Cost: 20.22s
Train Epoch: 1217 [61440/90000 (68%)]	Loss: -5.1810	Cost: 12.11s
Train Epoch: 1217 [81920/90000 (91%)]	Loss: -5.2258	Cost: 11.91s
Train Epoch: 1217 	Average Loss: -4.8651
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0755

Learning rate: 9.638985948111512e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1218 [0/90000 (0%)]	Loss: -2.3143	Cost: 38.35s
Train Epoch: 1218 [20480/90000 (23%)]	Loss: -5.1661	Cost: 11.40s
Train Epoch: 1218 [40960/90000 (45%)]	Loss: -5.2134	Cost: 6.26s
Train Epoch: 1218 [61440/90000 (68%)]	Loss: -5.4675	Cost: 6.24s
Train Epoch: 1218 [81920/90000 (91%)]	Loss: -5.5641	Cost: 14.31s
Train Epoch: 1218 	Average Loss: -5.0198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3837

Saving model as e1218_model.pt & e1218_waveforms_supplementary.hdf5
Learning rate: 9.638399678737831e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1219 [0/90000 (0%)]	Loss: -1.9819	Cost: 32.32s
Train Epoch: 1219 [20480/90000 (23%)]	Loss: -4.8467	Cost: 11.17s
Train Epoch: 1219 [40960/90000 (45%)]	Loss: -4.7428	Cost: 14.27s
Train Epoch: 1219 [61440/90000 (68%)]	Loss: -4.8748	Cost: 12.11s
Train Epoch: 1219 [81920/90000 (91%)]	Loss: -5.2078	Cost: 11.99s
Train Epoch: 1219 	Average Loss: -4.7601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1529

Learning rate: 9.637812951572454e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1220 [0/90000 (0%)]	Loss: -2.0403	Cost: 31.80s
Train Epoch: 1220 [20480/90000 (23%)]	Loss: -5.1807	Cost: 11.98s
Train Epoch: 1220 [40960/90000 (45%)]	Loss: -5.2688	Cost: 9.42s
Train Epoch: 1220 [61440/90000 (68%)]	Loss: -5.6652	Cost: 6.05s
Train Epoch: 1220 [81920/90000 (91%)]	Loss: -5.4454	Cost: 10.79s
Train Epoch: 1220 	Average Loss: -5.1092
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2059

Learning rate: 9.63722576667329e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1221 [0/90000 (0%)]	Loss: -2.1384	Cost: 26.96s
Train Epoch: 1221 [20480/90000 (23%)]	Loss: -5.1466	Cost: 9.43s
Train Epoch: 1221 [40960/90000 (45%)]	Loss: -5.2134	Cost: 27.28s
Train Epoch: 1221 [61440/90000 (68%)]	Loss: -5.3355	Cost: 12.72s
Train Epoch: 1221 [81920/90000 (91%)]	Loss: -5.3859	Cost: 11.87s
Train Epoch: 1221 	Average Loss: -4.9952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2148

Learning rate: 9.636638124098291e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1222 [0/90000 (0%)]	Loss: -2.3281	Cost: 54.44s
Train Epoch: 1222 [20480/90000 (23%)]	Loss: -5.3067	Cost: 6.25s
Train Epoch: 1222 [40960/90000 (45%)]	Loss: -5.3484	Cost: 13.28s
Train Epoch: 1222 [61440/90000 (68%)]	Loss: -5.7108	Cost: 9.09s
Train Epoch: 1222 [81920/90000 (91%)]	Loss: -5.6963	Cost: 7.69s
Train Epoch: 1222 	Average Loss: -5.2256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4393

Saving model as e1222_model.pt & e1222_waveforms_supplementary.hdf5
Learning rate: 9.636050023905454e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1223 [0/90000 (0%)]	Loss: -2.1044	Cost: 27.90s
Train Epoch: 1223 [20480/90000 (23%)]	Loss: -5.5103	Cost: 11.67s
Train Epoch: 1223 [40960/90000 (45%)]	Loss: -5.2193	Cost: 21.14s
Train Epoch: 1223 [61440/90000 (68%)]	Loss: -5.3386	Cost: 12.38s
Train Epoch: 1223 [81920/90000 (91%)]	Loss: -5.3964	Cost: 11.72s
Train Epoch: 1223 	Average Loss: -5.1240
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1776

Learning rate: 9.635461466152825e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1224 [0/90000 (0%)]	Loss: -2.0693	Cost: 41.62s
Train Epoch: 1224 [20480/90000 (23%)]	Loss: -5.3386	Cost: 6.27s
Train Epoch: 1224 [40960/90000 (45%)]	Loss: -5.3103	Cost: 13.27s
Train Epoch: 1224 [61440/90000 (68%)]	Loss: -5.3229	Cost: 8.87s
Train Epoch: 1224 [81920/90000 (91%)]	Loss: -5.3046	Cost: 8.71s
Train Epoch: 1224 	Average Loss: -5.0609
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0972

Learning rate: 9.634872450898492e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1225 [0/90000 (0%)]	Loss: -1.3266	Cost: 29.49s
Train Epoch: 1225 [20480/90000 (23%)]	Loss: -4.8160	Cost: 12.14s
Train Epoch: 1225 [40960/90000 (45%)]	Loss: -4.9937	Cost: 17.17s
Train Epoch: 1225 [61440/90000 (68%)]	Loss: -5.4797	Cost: 13.32s
Train Epoch: 1225 [81920/90000 (91%)]	Loss: -5.3264	Cost: 12.09s
Train Epoch: 1225 	Average Loss: -4.9228
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1509

Learning rate: 9.634282978200585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1226 [0/90000 (0%)]	Loss: -1.7231	Cost: 32.89s
Train Epoch: 1226 [20480/90000 (23%)]	Loss: -5.3169	Cost: 11.99s
Train Epoch: 1226 [40960/90000 (45%)]	Loss: -5.3342	Cost: 10.66s
Train Epoch: 1226 [61440/90000 (68%)]	Loss: -5.4813	Cost: 8.09s
Train Epoch: 1226 [81920/90000 (91%)]	Loss: -5.5039	Cost: 12.95s
Train Epoch: 1226 	Average Loss: -5.1414
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3383

Learning rate: 9.633693048117287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1227 [0/90000 (0%)]	Loss: -2.2086	Cost: 37.33s
Train Epoch: 1227 [20480/90000 (23%)]	Loss: -5.3821	Cost: 7.29s
Train Epoch: 1227 [40960/90000 (45%)]	Loss: -4.8393	Cost: 17.66s
Train Epoch: 1227 [61440/90000 (68%)]	Loss: -5.2303	Cost: 12.35s
Train Epoch: 1227 [81920/90000 (91%)]	Loss: -5.2202	Cost: 12.17s
Train Epoch: 1227 	Average Loss: -5.0082
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1553

Learning rate: 9.63310266070682e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1228 [0/90000 (0%)]	Loss: -1.8708	Cost: 46.59s
Train Epoch: 1228 [20480/90000 (23%)]	Loss: -5.3844	Cost: 8.76s
Train Epoch: 1228 [40960/90000 (45%)]	Loss: -5.2213	Cost: 8.05s
Train Epoch: 1228 [61440/90000 (68%)]	Loss: -5.6319	Cost: 7.29s
Train Epoch: 1228 [81920/90000 (91%)]	Loss: -5.2795	Cost: 13.61s
Train Epoch: 1228 	Average Loss: -5.1193
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.8197

Learning rate: 9.632511816027452e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1229 [0/90000 (0%)]	Loss: -2.0328	Cost: 30.86s
Train Epoch: 1229 [20480/90000 (23%)]	Loss: -5.1147	Cost: 7.53s
Train Epoch: 1229 [40960/90000 (45%)]	Loss: -5.2684	Cost: 16.47s
Train Epoch: 1229 [61440/90000 (68%)]	Loss: -5.5976	Cost: 12.20s
Train Epoch: 1229 [81920/90000 (91%)]	Loss: -5.5419	Cost: 12.07s
Train Epoch: 1229 	Average Loss: -5.0590
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3963

Learning rate: 9.631920514137498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1230 [0/90000 (0%)]	Loss: -1.8096	Cost: 33.20s
Train Epoch: 1230 [20480/90000 (23%)]	Loss: -5.4288	Cost: 12.22s
Train Epoch: 1230 [40960/90000 (45%)]	Loss: -5.1532	Cost: 9.12s
Train Epoch: 1230 [61440/90000 (68%)]	Loss: -5.6737	Cost: 6.60s
Train Epoch: 1230 [81920/90000 (91%)]	Loss: -5.6296	Cost: 9.54s
Train Epoch: 1230 	Average Loss: -5.1539
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2932

Learning rate: 9.631328755095315e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1231 [0/90000 (0%)]	Loss: -2.0791	Cost: 30.01s
Train Epoch: 1231 [20480/90000 (23%)]	Loss: -5.2840	Cost: 10.17s
Train Epoch: 1231 [40960/90000 (45%)]	Loss: -5.3413	Cost: 17.94s
Train Epoch: 1231 [61440/90000 (68%)]	Loss: -5.5654	Cost: 12.93s
Train Epoch: 1231 [81920/90000 (91%)]	Loss: -5.5274	Cost: 12.19s
Train Epoch: 1231 	Average Loss: -5.1990
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3035

Learning rate: 9.630736538959309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1232 [0/90000 (0%)]	Loss: -1.9255	Cost: 42.02s
Train Epoch: 1232 [20480/90000 (23%)]	Loss: -5.4829	Cost: 12.44s
Train Epoch: 1232 [40960/90000 (45%)]	Loss: -5.3666	Cost: 12.11s
Train Epoch: 1232 [61440/90000 (68%)]	Loss: -5.7210	Cost: 7.83s
Train Epoch: 1232 [81920/90000 (91%)]	Loss: -5.7432	Cost: 6.06s
Train Epoch: 1232 	Average Loss: -5.2875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4609

Saving model as e1232_model.pt & e1232_waveforms_supplementary.hdf5
Learning rate: 9.630143865787932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1233 [0/90000 (0%)]	Loss: -2.4175	Cost: 28.78s
Train Epoch: 1233 [20480/90000 (23%)]	Loss: -5.3978	Cost: 6.10s
Train Epoch: 1233 [40960/90000 (45%)]	Loss: -5.6810	Cost: 22.82s
Train Epoch: 1233 [61440/90000 (68%)]	Loss: -5.9212	Cost: 12.55s
Train Epoch: 1233 [81920/90000 (91%)]	Loss: -5.6919	Cost: 12.02s
Train Epoch: 1233 	Average Loss: -5.4399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5372

Saving model as e1233_model.pt & e1233_waveforms_supplementary.hdf5
Learning rate: 9.629550735639675e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1234 [0/90000 (0%)]	Loss: -2.3768	Cost: 51.39s
Train Epoch: 1234 [20480/90000 (23%)]	Loss: -5.6932	Cost: 9.54s
Train Epoch: 1234 [40960/90000 (45%)]	Loss: -5.5467	Cost: 7.01s
Train Epoch: 1234 [61440/90000 (68%)]	Loss: -5.6333	Cost: 6.30s
Train Epoch: 1234 [81920/90000 (91%)]	Loss: -5.7686	Cost: 16.12s
Train Epoch: 1234 	Average Loss: -5.3806
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5090

Learning rate: 9.628957148573078e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1235 [0/90000 (0%)]	Loss: -1.7518	Cost: 25.48s
Train Epoch: 1235 [20480/90000 (23%)]	Loss: -5.2284	Cost: 9.33s
Train Epoch: 1235 [40960/90000 (45%)]	Loss: -5.5818	Cost: 24.74s
Train Epoch: 1235 [61440/90000 (68%)]	Loss: -5.6650	Cost: 13.70s
Train Epoch: 1235 [81920/90000 (91%)]	Loss: -5.6336	Cost: 12.13s
Train Epoch: 1235 	Average Loss: -5.2548
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3676

Learning rate: 9.628363104646728e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1236 [0/90000 (0%)]	Loss: -2.0670	Cost: 35.54s
Train Epoch: 1236 [20480/90000 (23%)]	Loss: -5.1608	Cost: 14.37s
Train Epoch: 1236 [40960/90000 (45%)]	Loss: -5.1849	Cost: 10.50s
Train Epoch: 1236 [61440/90000 (68%)]	Loss: -5.4667	Cost: 6.29s
Train Epoch: 1236 [81920/90000 (91%)]	Loss: -5.4368	Cost: 13.54s
Train Epoch: 1236 	Average Loss: -5.1175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2994

Learning rate: 9.627768603919251e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1237 [0/90000 (0%)]	Loss: -2.0956	Cost: 32.19s
Train Epoch: 1237 [20480/90000 (23%)]	Loss: -5.4094	Cost: 9.43s
Train Epoch: 1237 [40960/90000 (45%)]	Loss: -5.1517	Cost: 18.19s
Train Epoch: 1237 [61440/90000 (68%)]	Loss: -5.5501	Cost: 12.09s
Train Epoch: 1237 [81920/90000 (91%)]	Loss: -5.4288	Cost: 12.17s
Train Epoch: 1237 	Average Loss: -5.1772
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2016

Learning rate: 9.627173646449324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1238 [0/90000 (0%)]	Loss: -2.1847	Cost: 44.89s
Train Epoch: 1238 [20480/90000 (23%)]	Loss: -5.2166	Cost: 7.82s
Train Epoch: 1238 [40960/90000 (45%)]	Loss: -5.5722	Cost: 14.16s
Train Epoch: 1238 [61440/90000 (68%)]	Loss: -5.9204	Cost: 8.62s
Train Epoch: 1238 [81920/90000 (91%)]	Loss: -5.3912	Cost: 10.00s
Train Epoch: 1238 	Average Loss: -5.2203
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2325

Learning rate: 9.626578232295669e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1239 [0/90000 (0%)]	Loss: -1.9936	Cost: 30.65s
Train Epoch: 1239 [20480/90000 (23%)]	Loss: -5.3386	Cost: 7.56s
Train Epoch: 1239 [40960/90000 (45%)]	Loss: -5.5321	Cost: 17.71s
Train Epoch: 1239 [61440/90000 (68%)]	Loss: -5.5760	Cost: 12.22s
Train Epoch: 1239 [81920/90000 (91%)]	Loss: -5.5568	Cost: 11.99s
Train Epoch: 1239 	Average Loss: -5.2591
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.1611

Learning rate: 9.625982361517048e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1240 [0/90000 (0%)]	Loss: -2.0014	Cost: 32.62s
Train Epoch: 1240 [20480/90000 (23%)]	Loss: -5.4654	Cost: 12.57s
Train Epoch: 1240 [40960/90000 (45%)]	Loss: -5.5542	Cost: 12.14s
Train Epoch: 1240 [61440/90000 (68%)]	Loss: -5.6659	Cost: 6.31s
Train Epoch: 1240 [81920/90000 (91%)]	Loss: -5.7543	Cost: 8.13s
Train Epoch: 1240 	Average Loss: -5.3026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4314

Learning rate: 9.625386034172271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1241 [0/90000 (0%)]	Loss: -2.2889	Cost: 34.27s
Train Epoch: 1241 [20480/90000 (23%)]	Loss: -5.5578	Cost: 10.55s
Train Epoch: 1241 [40960/90000 (45%)]	Loss: -5.4470	Cost: 19.68s
Train Epoch: 1241 [61440/90000 (68%)]	Loss: -5.7687	Cost: 12.52s
Train Epoch: 1241 [81920/90000 (91%)]	Loss: -5.7474	Cost: 12.12s
Train Epoch: 1241 	Average Loss: -5.3936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2788

Learning rate: 9.624789250320195e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1242 [0/90000 (0%)]	Loss: -2.0015	Cost: 43.78s
Train Epoch: 1242 [20480/90000 (23%)]	Loss: -5.5348	Cost: 10.23s
Train Epoch: 1242 [40960/90000 (45%)]	Loss: -5.5775	Cost: 9.96s
Train Epoch: 1242 [61440/90000 (68%)]	Loss: -5.9472	Cost: 6.54s
Train Epoch: 1242 [81920/90000 (91%)]	Loss: -5.9481	Cost: 10.82s
Train Epoch: 1242 	Average Loss: -5.4462
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5458

Saving model as e1242_model.pt & e1242_waveforms_supplementary.hdf5
Learning rate: 9.62419201001972e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1243 [0/90000 (0%)]	Loss: -2.5248	Cost: 30.52s
Train Epoch: 1243 [20480/90000 (23%)]	Loss: -5.6036	Cost: 9.84s
Train Epoch: 1243 [40960/90000 (45%)]	Loss: -5.7602	Cost: 15.04s
Train Epoch: 1243 [61440/90000 (68%)]	Loss: -5.7457	Cost: 13.57s
Train Epoch: 1243 [81920/90000 (91%)]	Loss: -5.7989	Cost: 12.26s
Train Epoch: 1243 	Average Loss: -5.4921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4240

Learning rate: 9.62359431332979e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1244 [0/90000 (0%)]	Loss: -2.2390	Cost: 35.15s
Train Epoch: 1244 [20480/90000 (23%)]	Loss: -5.7270	Cost: 9.35s
Train Epoch: 1244 [40960/90000 (45%)]	Loss: -5.3970	Cost: 10.77s
Train Epoch: 1244 [61440/90000 (68%)]	Loss: -5.7810	Cost: 6.22s
Train Epoch: 1244 [81920/90000 (91%)]	Loss: -5.6018	Cost: 15.87s
Train Epoch: 1244 	Average Loss: -5.3126
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3751

Learning rate: 9.622996160309395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1245 [0/90000 (0%)]	Loss: -2.3848	Cost: 44.80s
Train Epoch: 1245 [20480/90000 (23%)]	Loss: -5.3437	Cost: 8.46s
Train Epoch: 1245 [40960/90000 (45%)]	Loss: -5.6829	Cost: 17.02s
Train Epoch: 1245 [61440/90000 (68%)]	Loss: -5.9020	Cost: 12.14s
Train Epoch: 1245 [81920/90000 (91%)]	Loss: -5.9693	Cost: 12.12s
Train Epoch: 1245 	Average Loss: -5.4191
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6248

Saving model as e1245_model.pt & e1245_waveforms_supplementary.hdf5
Learning rate: 9.622397551017573e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1246 [0/90000 (0%)]	Loss: -2.4052	Cost: 39.79s
Train Epoch: 1246 [20480/90000 (23%)]	Loss: -5.6339	Cost: 8.88s
Train Epoch: 1246 [40960/90000 (45%)]	Loss: -5.7185	Cost: 8.02s
Train Epoch: 1246 [61440/90000 (68%)]	Loss: -5.9753	Cost: 7.59s
Train Epoch: 1246 [81920/90000 (91%)]	Loss: -5.9727	Cost: 12.04s
Train Epoch: 1246 	Average Loss: -5.6160
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7021

Saving model as e1246_model.pt & e1246_waveforms_supplementary.hdf5
Learning rate: 9.621798485513401e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1247 [0/90000 (0%)]	Loss: -2.8082	Cost: 28.43s
Train Epoch: 1247 [20480/90000 (23%)]	Loss: -5.6095	Cost: 7.13s
Train Epoch: 1247 [40960/90000 (45%)]	Loss: -5.7347	Cost: 17.57s
Train Epoch: 1247 [61440/90000 (68%)]	Loss: -5.9007	Cost: 12.79s
Train Epoch: 1247 [81920/90000 (91%)]	Loss: -4.9592	Cost: 12.30s
Train Epoch: 1247 	Average Loss: -5.3377
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.6679

Learning rate: 9.621198963856007e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1248 [0/90000 (0%)]	Loss: -1.7485	Cost: 37.49s
Train Epoch: 1248 [20480/90000 (23%)]	Loss: -5.0432	Cost: 8.68s
Train Epoch: 1248 [40960/90000 (45%)]	Loss: -5.3295	Cost: 10.82s
Train Epoch: 1248 [61440/90000 (68%)]	Loss: -5.6923	Cost: 9.31s
Train Epoch: 1248 [81920/90000 (91%)]	Loss: -4.2013	Cost: 12.86s
Train Epoch: 1248 	Average Loss: -4.7536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.2619

Learning rate: 9.620598986104559e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1249 [0/90000 (0%)]	Loss: -1.4721	Cost: 28.89s
Train Epoch: 1249 [20480/90000 (23%)]	Loss: -3.9792	Cost: 8.44s
Train Epoch: 1249 [40960/90000 (45%)]	Loss: -4.7049	Cost: 21.19s
Train Epoch: 1249 [61440/90000 (68%)]	Loss: -4.9497	Cost: 11.98s
Train Epoch: 1249 [81920/90000 (91%)]	Loss: -5.1600	Cost: 12.33s
Train Epoch: 1249 	Average Loss: -4.3349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -1.9965

Learning rate: 9.619998552318275e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1250 [0/90000 (0%)]	Loss: -1.8348	Cost: 32.91s
Train Epoch: 1250 [20480/90000 (23%)]	Loss: -5.1099	Cost: 13.63s
Train Epoch: 1250 [40960/90000 (45%)]	Loss: -5.4488	Cost: 11.58s
Train Epoch: 1250 [61440/90000 (68%)]	Loss: -5.7708	Cost: 7.08s
Train Epoch: 1250 [81920/90000 (91%)]	Loss: -5.5134	Cost: 9.61s
Train Epoch: 1250 	Average Loss: -5.1822
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4031

Learning rate: 9.619397662556414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1251 [0/90000 (0%)]	Loss: -2.0728	Cost: 43.34s
Train Epoch: 1251 [20480/90000 (23%)]	Loss: -5.3954	Cost: 8.84s
Train Epoch: 1251 [40960/90000 (45%)]	Loss: -5.3042	Cost: 9.15s
Train Epoch: 1251 [61440/90000 (68%)]	Loss: -5.8335	Cost: 6.34s
Train Epoch: 1251 [81920/90000 (91%)]	Loss: -5.8294	Cost: 18.28s
Train Epoch: 1251 	Average Loss: -5.3081
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4315

Learning rate: 9.618796316878283e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1252 [0/90000 (0%)]	Loss: -2.5412	Cost: 59.57s
Train Epoch: 1252 [20480/90000 (23%)]	Loss: -5.3670	Cost: 11.95s
Train Epoch: 1252 [40960/90000 (45%)]	Loss: -5.5885	Cost: 9.92s
Train Epoch: 1252 [61440/90000 (68%)]	Loss: -5.7841	Cost: 6.18s
Train Epoch: 1252 [81920/90000 (91%)]	Loss: -5.7464	Cost: 8.59s
Train Epoch: 1252 	Average Loss: -5.3992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4399

Learning rate: 9.618194515343229e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1253 [0/90000 (0%)]	Loss: -2.4921	Cost: 28.63s
Train Epoch: 1253 [20480/90000 (23%)]	Loss: -5.5764	Cost: 9.49s
Train Epoch: 1253 [40960/90000 (45%)]	Loss: -5.8772	Cost: 23.73s
Train Epoch: 1253 [61440/90000 (68%)]	Loss: -6.0621	Cost: 14.61s
Train Epoch: 1253 [81920/90000 (91%)]	Loss: -5.8531	Cost: 12.01s
Train Epoch: 1253 	Average Loss: -5.4960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2757

Learning rate: 9.61759225801065e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1254 [0/90000 (0%)]	Loss: -2.2316	Cost: 45.74s
Train Epoch: 1254 [20480/90000 (23%)]	Loss: -5.4864	Cost: 12.37s
Train Epoch: 1254 [40960/90000 (45%)]	Loss: -5.6592	Cost: 9.53s
Train Epoch: 1254 [61440/90000 (68%)]	Loss: -5.8121	Cost: 6.40s
Train Epoch: 1254 [81920/90000 (91%)]	Loss: -5.8386	Cost: 10.94s
Train Epoch: 1254 	Average Loss: -5.4455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5277

Learning rate: 9.616989544939987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1255 [0/90000 (0%)]	Loss: -2.9179	Cost: 31.00s
Train Epoch: 1255 [20480/90000 (23%)]	Loss: -5.3604	Cost: 6.34s
Train Epoch: 1255 [40960/90000 (45%)]	Loss: -5.4618	Cost: 14.02s
Train Epoch: 1255 [61440/90000 (68%)]	Loss: -5.6951	Cost: 13.52s
Train Epoch: 1255 [81920/90000 (91%)]	Loss: -5.6635	Cost: 13.55s
Train Epoch: 1255 	Average Loss: -5.3237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2762

Learning rate: 9.616386376190724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1256 [0/90000 (0%)]	Loss: -2.0396	Cost: 59.45s
Train Epoch: 1256 [20480/90000 (23%)]	Loss: -5.1484	Cost: 9.20s
Train Epoch: 1256 [40960/90000 (45%)]	Loss: -5.2335	Cost: 8.99s
Train Epoch: 1256 [61440/90000 (68%)]	Loss: -5.5461	Cost: 7.37s
Train Epoch: 1256 [81920/90000 (91%)]	Loss: -5.7711	Cost: 13.15s
Train Epoch: 1256 	Average Loss: -5.1652
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3568

Learning rate: 9.615782751822392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1257 [0/90000 (0%)]	Loss: -2.1182	Cost: 27.65s
Train Epoch: 1257 [20480/90000 (23%)]	Loss: -5.5357	Cost: 10.34s
Train Epoch: 1257 [40960/90000 (45%)]	Loss: -5.6785	Cost: 20.41s
Train Epoch: 1257 [61440/90000 (68%)]	Loss: -6.0545	Cost: 12.79s
Train Epoch: 1257 [81920/90000 (91%)]	Loss: -6.0827	Cost: 12.17s
Train Epoch: 1257 	Average Loss: -5.5212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7067

Saving model as e1257_model.pt & e1257_waveforms_supplementary.hdf5
Learning rate: 9.615178671894565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1258 [0/90000 (0%)]	Loss: -2.5176	Cost: 34.10s
Train Epoch: 1258 [20480/90000 (23%)]	Loss: -5.7735	Cost: 13.32s
Train Epoch: 1258 [40960/90000 (45%)]	Loss: -5.6031	Cost: 10.66s
Train Epoch: 1258 [61440/90000 (68%)]	Loss: -5.9273	Cost: 7.19s
Train Epoch: 1258 [81920/90000 (91%)]	Loss: -5.9405	Cost: 11.83s
Train Epoch: 1258 	Average Loss: -5.5536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5835

Learning rate: 9.614574136466867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1259 [0/90000 (0%)]	Loss: -2.5841	Cost: 40.35s
Train Epoch: 1259 [20480/90000 (23%)]	Loss: -5.9019	Cost: 6.66s
Train Epoch: 1259 [40960/90000 (45%)]	Loss: -5.8482	Cost: 17.61s
Train Epoch: 1259 [61440/90000 (68%)]	Loss: -6.0813	Cost: 11.95s
Train Epoch: 1259 [81920/90000 (91%)]	Loss: -5.9836	Cost: 12.27s
Train Epoch: 1259 	Average Loss: -5.6847
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6460

Learning rate: 9.613969145598959e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1260 [0/90000 (0%)]	Loss: -2.6206	Cost: 32.55s
Train Epoch: 1260 [20480/90000 (23%)]	Loss: -5.7937	Cost: 12.64s
Train Epoch: 1260 [40960/90000 (45%)]	Loss: -6.0626	Cost: 10.07s
Train Epoch: 1260 [61440/90000 (68%)]	Loss: -6.2234	Cost: 6.29s
Train Epoch: 1260 [81920/90000 (91%)]	Loss: -6.2746	Cost: 12.04s
Train Epoch: 1260 	Average Loss: -5.7629
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7264

Saving model as e1260_model.pt & e1260_waveforms_supplementary.hdf5
Learning rate: 9.613363699350553e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1261 [0/90000 (0%)]	Loss: -2.6492	Cost: 31.50s
Train Epoch: 1261 [20480/90000 (23%)]	Loss: -5.9573	Cost: 6.96s
Train Epoch: 1261 [40960/90000 (45%)]	Loss: -6.0423	Cost: 17.99s
Train Epoch: 1261 [61440/90000 (68%)]	Loss: -6.2956	Cost: 12.56s
Train Epoch: 1261 [81920/90000 (91%)]	Loss: -6.1606	Cost: 12.09s
Train Epoch: 1261 	Average Loss: -5.8165
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7245

Learning rate: 9.612757797781404e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1262 [0/90000 (0%)]	Loss: -2.5522	Cost: 33.77s
Train Epoch: 1262 [20480/90000 (23%)]	Loss: -5.9524	Cost: 9.16s
Train Epoch: 1262 [40960/90000 (45%)]	Loss: -5.7946	Cost: 15.39s
Train Epoch: 1262 [61440/90000 (68%)]	Loss: -5.7120	Cost: 9.13s
Train Epoch: 1262 [81920/90000 (91%)]	Loss: -5.6103	Cost: 12.19s
Train Epoch: 1262 	Average Loss: -5.5108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4111

Learning rate: 9.612151440951311e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1263 [0/90000 (0%)]	Loss: -2.3973	Cost: 39.69s
Train Epoch: 1263 [20480/90000 (23%)]	Loss: -5.7016	Cost: 8.88s
Train Epoch: 1263 [40960/90000 (45%)]	Loss: -5.8537	Cost: 21.48s
Train Epoch: 1263 [61440/90000 (68%)]	Loss: -6.1020	Cost: 11.85s
Train Epoch: 1263 [81920/90000 (91%)]	Loss: -5.9783	Cost: 11.99s
Train Epoch: 1263 	Average Loss: -5.5821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5470

Learning rate: 9.611544628920122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1264 [0/90000 (0%)]	Loss: -2.2598	Cost: 38.13s
Train Epoch: 1264 [20480/90000 (23%)]	Loss: -5.9864	Cost: 6.49s
Train Epoch: 1264 [40960/90000 (45%)]	Loss: -5.8939	Cost: 13.76s
Train Epoch: 1264 [61440/90000 (68%)]	Loss: -6.0500	Cost: 8.95s
Train Epoch: 1264 [81920/90000 (91%)]	Loss: -5.9577	Cost: 10.75s
Train Epoch: 1264 	Average Loss: -5.6564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5579

Learning rate: 9.610937361747725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1265 [0/90000 (0%)]	Loss: -2.4679	Cost: 29.37s
Train Epoch: 1265 [20480/90000 (23%)]	Loss: -5.8903	Cost: 10.10s
Train Epoch: 1265 [40960/90000 (45%)]	Loss: -5.4121	Cost: 14.74s
Train Epoch: 1265 [61440/90000 (68%)]	Loss: -5.8793	Cost: 12.28s
Train Epoch: 1265 [81920/90000 (91%)]	Loss: -5.9020	Cost: 12.15s
Train Epoch: 1265 	Average Loss: -5.5283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4518

Learning rate: 9.610329639494054e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1266 [0/90000 (0%)]	Loss: -2.5833	Cost: 44.09s
Train Epoch: 1266 [20480/90000 (23%)]	Loss: -5.8258	Cost: 11.30s
Train Epoch: 1266 [40960/90000 (45%)]	Loss: -5.8823	Cost: 6.26s
Train Epoch: 1266 [61440/90000 (68%)]	Loss: -5.5535	Cost: 6.04s
Train Epoch: 1266 [81920/90000 (91%)]	Loss: -5.3148	Cost: 15.87s
Train Epoch: 1266 	Average Loss: -5.4075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0165

Learning rate: 9.60972146221909e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1267 [0/90000 (0%)]	Loss: -1.8656	Cost: 33.65s
Train Epoch: 1267 [20480/90000 (23%)]	Loss: -5.2521	Cost: 10.13s
Train Epoch: 1267 [40960/90000 (45%)]	Loss: -5.7893	Cost: 21.31s
Train Epoch: 1267 [61440/90000 (68%)]	Loss: -5.9439	Cost: 12.46s
Train Epoch: 1267 [81920/90000 (91%)]	Loss: -5.9019	Cost: 13.07s
Train Epoch: 1267 	Average Loss: -5.4319
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5635

Learning rate: 9.609112829982858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1268 [0/90000 (0%)]	Loss: -2.5030	Cost: 55.44s
Train Epoch: 1268 [20480/90000 (23%)]	Loss: -5.7862	Cost: 7.77s
Train Epoch: 1268 [40960/90000 (45%)]	Loss: -5.8230	Cost: 9.35s
Train Epoch: 1268 [61440/90000 (68%)]	Loss: -5.9076	Cost: 8.22s
Train Epoch: 1268 [81920/90000 (91%)]	Loss: -5.8979	Cost: 11.02s
Train Epoch: 1268 	Average Loss: -5.5903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5416

Learning rate: 9.608503742845427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1269 [0/90000 (0%)]	Loss: -2.2714	Cost: 28.88s
Train Epoch: 1269 [20480/90000 (23%)]	Loss: -5.6955	Cost: 8.21s
Train Epoch: 1269 [40960/90000 (45%)]	Loss: -5.7384	Cost: 13.99s
Train Epoch: 1269 [61440/90000 (68%)]	Loss: -6.0047	Cost: 11.90s
Train Epoch: 1269 [81920/90000 (91%)]	Loss: -6.2425	Cost: 12.29s
Train Epoch: 1269 	Average Loss: -5.6265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7714

Saving model as e1269_model.pt & e1269_waveforms_supplementary.hdf5
Learning rate: 9.607894200866912e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1270 [0/90000 (0%)]	Loss: -2.6858	Cost: 42.70s
Train Epoch: 1270 [20480/90000 (23%)]	Loss: -6.0627	Cost: 11.31s
Train Epoch: 1270 [40960/90000 (45%)]	Loss: -5.9552	Cost: 8.35s
Train Epoch: 1270 [61440/90000 (68%)]	Loss: -6.2619	Cost: 6.19s
Train Epoch: 1270 [81920/90000 (91%)]	Loss: -6.1076	Cost: 15.49s
Train Epoch: 1270 	Average Loss: -5.7845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6689

Learning rate: 9.607284204107471e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1271 [0/90000 (0%)]	Loss: -2.3508	Cost: 27.20s
Train Epoch: 1271 [20480/90000 (23%)]	Loss: -5.9023	Cost: 9.10s
Train Epoch: 1271 [40960/90000 (45%)]	Loss: -5.9898	Cost: 24.72s
Train Epoch: 1271 [61440/90000 (68%)]	Loss: -6.0867	Cost: 13.40s
Train Epoch: 1271 [81920/90000 (91%)]	Loss: -6.1438	Cost: 12.10s
Train Epoch: 1271 	Average Loss: -5.7093
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6844

Learning rate: 9.606673752627308e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1272 [0/90000 (0%)]	Loss: -2.2493	Cost: 60.32s
Train Epoch: 1272 [20480/90000 (23%)]	Loss: -5.8051	Cost: 6.31s
Train Epoch: 1272 [40960/90000 (45%)]	Loss: -5.8459	Cost: 13.01s
Train Epoch: 1272 [61440/90000 (68%)]	Loss: -6.2184	Cost: 8.75s
Train Epoch: 1272 [81920/90000 (91%)]	Loss: -6.2281	Cost: 8.79s
Train Epoch: 1272 	Average Loss: -5.7816
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7406

Learning rate: 9.606062846486675e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1273 [0/90000 (0%)]	Loss: -2.8905	Cost: 31.98s
Train Epoch: 1273 [20480/90000 (23%)]	Loss: -6.1402	Cost: 7.12s
Train Epoch: 1273 [40960/90000 (45%)]	Loss: -5.8579	Cost: 18.50s
Train Epoch: 1273 [61440/90000 (68%)]	Loss: -6.3982	Cost: 12.12s
Train Epoch: 1273 [81920/90000 (91%)]	Loss: -6.1243	Cost: 12.19s
Train Epoch: 1273 	Average Loss: -5.8919
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7584

Learning rate: 9.605451485745864e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1274 [0/90000 (0%)]	Loss: -2.5192	Cost: 32.68s
Train Epoch: 1274 [20480/90000 (23%)]	Loss: -5.9582	Cost: 11.80s
Train Epoch: 1274 [40960/90000 (45%)]	Loss: -6.0941	Cost: 8.77s
Train Epoch: 1274 [61440/90000 (68%)]	Loss: -6.3273	Cost: 7.74s
Train Epoch: 1274 [81920/90000 (91%)]	Loss: -6.1684	Cost: 14.46s
Train Epoch: 1274 	Average Loss: -5.8696
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6854

Learning rate: 9.604839670465215e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1275 [0/90000 (0%)]	Loss: -2.3419	Cost: 30.07s
Train Epoch: 1275 [20480/90000 (23%)]	Loss: -5.8769	Cost: 11.58s
Train Epoch: 1275 [40960/90000 (45%)]	Loss: -6.1229	Cost: 20.42s
Train Epoch: 1275 [61440/90000 (68%)]	Loss: -6.1449	Cost: 12.30s
Train Epoch: 1275 [81920/90000 (91%)]	Loss: -5.9802	Cost: 11.86s
Train Epoch: 1275 	Average Loss: -5.7789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5455

Learning rate: 9.604227400705111e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1276 [0/90000 (0%)]	Loss: -2.0986	Cost: 35.65s
Train Epoch: 1276 [20480/90000 (23%)]	Loss: -5.7965	Cost: 11.90s
Train Epoch: 1276 [40960/90000 (45%)]	Loss: -5.9143	Cost: 7.69s
Train Epoch: 1276 [61440/90000 (68%)]	Loss: -6.1159	Cost: 6.34s
Train Epoch: 1276 [81920/90000 (91%)]	Loss: -5.9242	Cost: 14.93s
Train Epoch: 1276 	Average Loss: -5.6845
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5220

Learning rate: 9.603614676525979e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1277 [0/90000 (0%)]	Loss: -2.3795	Cost: 34.55s
Train Epoch: 1277 [20480/90000 (23%)]	Loss: -5.8022	Cost: 8.04s
Train Epoch: 1277 [40960/90000 (45%)]	Loss: -6.0759	Cost: 18.94s
Train Epoch: 1277 [61440/90000 (68%)]	Loss: -6.4567	Cost: 12.18s
Train Epoch: 1277 [81920/90000 (91%)]	Loss: -5.9670	Cost: 11.92s
Train Epoch: 1277 	Average Loss: -5.8190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4297

Learning rate: 9.603001497988294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1278 [0/90000 (0%)]	Loss: -2.2919	Cost: 32.10s
Train Epoch: 1278 [20480/90000 (23%)]	Loss: -5.5360	Cost: 9.97s
Train Epoch: 1278 [40960/90000 (45%)]	Loss: -5.8351	Cost: 8.39s
Train Epoch: 1278 [61440/90000 (68%)]	Loss: -5.7912	Cost: 6.40s
Train Epoch: 1278 [81920/90000 (91%)]	Loss: -5.6204	Cost: 13.00s
Train Epoch: 1278 	Average Loss: -5.4910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0398

Learning rate: 9.602387865152576e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1279 [0/90000 (0%)]	Loss: -2.0260	Cost: 26.83s
Train Epoch: 1279 [20480/90000 (23%)]	Loss: -5.0952	Cost: 10.64s
Train Epoch: 1279 [40960/90000 (45%)]	Loss: -5.4511	Cost: 23.32s
Train Epoch: 1279 [61440/90000 (68%)]	Loss: -5.7520	Cost: 13.03s
Train Epoch: 1279 [81920/90000 (91%)]	Loss: -5.8220	Cost: 11.88s
Train Epoch: 1279 	Average Loss: -5.2248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2954

Learning rate: 9.601773778079384e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1280 [0/90000 (0%)]	Loss: -2.0153	Cost: 53.06s
Train Epoch: 1280 [20480/90000 (23%)]	Loss: -5.5124	Cost: 6.25s
Train Epoch: 1280 [40960/90000 (45%)]	Loss: -5.5894	Cost: 13.74s
Train Epoch: 1280 [61440/90000 (68%)]	Loss: -5.6061	Cost: 8.61s
Train Epoch: 1280 [81920/90000 (91%)]	Loss: -5.6654	Cost: 8.14s
Train Epoch: 1280 	Average Loss: -5.3363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4591

Learning rate: 9.60115923682933e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1281 [0/90000 (0%)]	Loss: -2.1675	Cost: 26.76s
Train Epoch: 1281 [20480/90000 (23%)]	Loss: -5.5273	Cost: 9.15s
Train Epoch: 1281 [40960/90000 (45%)]	Loss: -5.7181	Cost: 22.85s
Train Epoch: 1281 [61440/90000 (68%)]	Loss: -5.9946	Cost: 12.30s
Train Epoch: 1281 [81920/90000 (91%)]	Loss: -5.8022	Cost: 11.96s
Train Epoch: 1281 	Average Loss: -5.4334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3856

Learning rate: 9.600544241463066e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1282 [0/90000 (0%)]	Loss: -2.4896	Cost: 43.39s
Train Epoch: 1282 [20480/90000 (23%)]	Loss: -5.2502	Cost: 7.60s
Train Epoch: 1282 [40960/90000 (45%)]	Loss: -5.5362	Cost: 10.91s
Train Epoch: 1282 [61440/90000 (68%)]	Loss: -5.7776	Cost: 9.39s
Train Epoch: 1282 [81920/90000 (91%)]	Loss: -5.9445	Cost: 12.89s
Train Epoch: 1282 	Average Loss: -5.3618
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5661

Learning rate: 9.599928792041287e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1283 [0/90000 (0%)]	Loss: -2.2441	Cost: 28.09s
Train Epoch: 1283 [20480/90000 (23%)]	Loss: -5.7963	Cost: 10.28s
Train Epoch: 1283 [40960/90000 (45%)]	Loss: -5.8619	Cost: 17.54s
Train Epoch: 1283 [61440/90000 (68%)]	Loss: -6.1481	Cost: 12.87s
Train Epoch: 1283 [81920/90000 (91%)]	Loss: -5.9754	Cost: 12.26s
Train Epoch: 1283 	Average Loss: -5.7219
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5460

Learning rate: 9.599312888624739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1284 [0/90000 (0%)]	Loss: -2.3348	Cost: 55.66s
Train Epoch: 1284 [20480/90000 (23%)]	Loss: -5.8673	Cost: 9.30s
Train Epoch: 1284 [40960/90000 (45%)]	Loss: -6.1109	Cost: 8.23s
Train Epoch: 1284 [61440/90000 (68%)]	Loss: -6.3707	Cost: 7.26s
Train Epoch: 1284 [81920/90000 (91%)]	Loss: -6.4429	Cost: 13.18s
Train Epoch: 1284 	Average Loss: -5.8686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9114

Saving model as e1284_model.pt & e1284_waveforms_supplementary.hdf5
Learning rate: 9.598696531274207e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1285 [0/90000 (0%)]	Loss: -2.6750	Cost: 27.59s
Train Epoch: 1285 [20480/90000 (23%)]	Loss: -5.8153	Cost: 7.63s
Train Epoch: 1285 [40960/90000 (45%)]	Loss: -5.8175	Cost: 17.23s
Train Epoch: 1285 [61440/90000 (68%)]	Loss: -5.6475	Cost: 12.01s
Train Epoch: 1285 [81920/90000 (91%)]	Loss: -5.6996	Cost: 12.13s
Train Epoch: 1285 	Average Loss: -5.5714
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5884

Learning rate: 9.598079720050523e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1286 [0/90000 (0%)]	Loss: -2.6122	Cost: 32.28s
Train Epoch: 1286 [20480/90000 (23%)]	Loss: -5.1303	Cost: 10.93s
Train Epoch: 1286 [40960/90000 (45%)]	Loss: -5.3217	Cost: 8.86s
Train Epoch: 1286 [61440/90000 (68%)]	Loss: -5.5865	Cost: 8.28s
Train Epoch: 1286 [81920/90000 (91%)]	Loss: -5.9012	Cost: 15.14s
Train Epoch: 1286 	Average Loss: -5.2425
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4026

Learning rate: 9.597462455014565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1287 [0/90000 (0%)]	Loss: -1.8452	Cost: 43.30s
Train Epoch: 1287 [20480/90000 (23%)]	Loss: -5.3890	Cost: 8.12s
Train Epoch: 1287 [40960/90000 (45%)]	Loss: -5.6344	Cost: 17.61s
Train Epoch: 1287 [61440/90000 (68%)]	Loss: -5.9434	Cost: 12.26s
Train Epoch: 1287 [81920/90000 (91%)]	Loss: -6.0634	Cost: 12.41s
Train Epoch: 1287 	Average Loss: -5.4738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7100

Learning rate: 9.596844736227252e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1288 [0/90000 (0%)]	Loss: -2.8172	Cost: 38.81s
Train Epoch: 1288 [20480/90000 (23%)]	Loss: -5.9285	Cost: 7.06s
Train Epoch: 1288 [40960/90000 (45%)]	Loss: -5.6279	Cost: 13.43s
Train Epoch: 1288 [61440/90000 (68%)]	Loss: -5.7535	Cost: 8.64s
Train Epoch: 1288 [81920/90000 (91%)]	Loss: -5.3783	Cost: 10.95s
Train Epoch: 1288 	Average Loss: -5.4601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2277

Learning rate: 9.596226563749555e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1289 [0/90000 (0%)]	Loss: -1.9386	Cost: 30.77s
Train Epoch: 1289 [20480/90000 (23%)]	Loss: -5.3196	Cost: 7.04s
Train Epoch: 1289 [40960/90000 (45%)]	Loss: -5.3898	Cost: 17.67s
Train Epoch: 1289 [61440/90000 (68%)]	Loss: -5.5755	Cost: 12.68s
Train Epoch: 1289 [81920/90000 (91%)]	Loss: -5.8742	Cost: 12.10s
Train Epoch: 1289 	Average Loss: -5.2255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6405

Learning rate: 9.595607937642481e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1290 [0/90000 (0%)]	Loss: -2.8977	Cost: 32.23s
Train Epoch: 1290 [20480/90000 (23%)]	Loss: -6.0182	Cost: 11.30s
Train Epoch: 1290 [40960/90000 (45%)]	Loss: -5.8338	Cost: 9.08s
Train Epoch: 1290 [61440/90000 (68%)]	Loss: -6.2153	Cost: 8.94s
Train Epoch: 1290 [81920/90000 (91%)]	Loss: -6.3522	Cost: 13.22s
Train Epoch: 1290 	Average Loss: -5.8245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9337

Saving model as e1290_model.pt & e1290_waveforms_supplementary.hdf5
Learning rate: 9.594988857967086e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1291 [0/90000 (0%)]	Loss: -3.0695	Cost: 39.80s
Train Epoch: 1291 [20480/90000 (23%)]	Loss: -5.8949	Cost: 7.99s
Train Epoch: 1291 [40960/90000 (45%)]	Loss: -6.0576	Cost: 18.23s
Train Epoch: 1291 [61440/90000 (68%)]	Loss: -6.3532	Cost: 12.36s
Train Epoch: 1291 [81920/90000 (91%)]	Loss: -6.2703	Cost: 11.88s
Train Epoch: 1291 	Average Loss: -5.9004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9722

Saving model as e1291_model.pt & e1291_waveforms_supplementary.hdf5
Learning rate: 9.594369324784475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1292 [0/90000 (0%)]	Loss: -2.4150	Cost: 37.29s
Train Epoch: 1292 [20480/90000 (23%)]	Loss: -6.1976	Cost: 6.20s
Train Epoch: 1292 [40960/90000 (45%)]	Loss: -6.1362	Cost: 14.48s
Train Epoch: 1292 [61440/90000 (68%)]	Loss: -6.2008	Cost: 8.58s
Train Epoch: 1292 [81920/90000 (91%)]	Loss: -6.1673	Cost: 8.77s
Train Epoch: 1292 	Average Loss: -5.8874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4228

Learning rate: 9.593749338155789e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1293 [0/90000 (0%)]	Loss: -2.3301	Cost: 32.95s
Train Epoch: 1293 [20480/90000 (23%)]	Loss: -5.8760	Cost: 12.60s
Train Epoch: 1293 [40960/90000 (45%)]	Loss: -5.8206	Cost: 19.58s
Train Epoch: 1293 [61440/90000 (68%)]	Loss: -6.1215	Cost: 12.11s
Train Epoch: 1293 [81920/90000 (91%)]	Loss: -6.2656	Cost: 12.09s
Train Epoch: 1293 	Average Loss: -5.6874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6657

Learning rate: 9.59312889814222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1294 [0/90000 (0%)]	Loss: -2.8473	Cost: 48.27s
Train Epoch: 1294 [20480/90000 (23%)]	Loss: -5.4191	Cost: 6.47s
Train Epoch: 1294 [40960/90000 (45%)]	Loss: -5.4889	Cost: 14.39s
Train Epoch: 1294 [61440/90000 (68%)]	Loss: -5.7491	Cost: 8.55s
Train Epoch: 1294 [81920/90000 (91%)]	Loss: -5.9812	Cost: 7.46s
Train Epoch: 1294 	Average Loss: -5.3639
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4430

Learning rate: 9.592508004805003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1295 [0/90000 (0%)]	Loss: -2.6236	Cost: 32.45s
Train Epoch: 1295 [20480/90000 (23%)]	Loss: -5.7435	Cost: 11.06s
Train Epoch: 1295 [40960/90000 (45%)]	Loss: -5.9202	Cost: 21.50s
Train Epoch: 1295 [61440/90000 (68%)]	Loss: -6.2602	Cost: 11.84s
Train Epoch: 1295 [81920/90000 (91%)]	Loss: -6.0299	Cost: 11.87s
Train Epoch: 1295 	Average Loss: -5.6781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5658

Learning rate: 9.591886658205417e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1296 [0/90000 (0%)]	Loss: -2.3991	Cost: 53.90s
Train Epoch: 1296 [20480/90000 (23%)]	Loss: -5.4972	Cost: 7.43s
Train Epoch: 1296 [40960/90000 (45%)]	Loss: -5.3327	Cost: 9.47s
Train Epoch: 1296 [61440/90000 (68%)]	Loss: -5.8458	Cost: 8.67s
Train Epoch: 1296 [81920/90000 (91%)]	Loss: -5.6575	Cost: 10.41s
Train Epoch: 1296 	Average Loss: -5.3387
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3394

Learning rate: 9.591264858404789e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1297 [0/90000 (0%)]	Loss: -2.5049	Cost: 29.30s
Train Epoch: 1297 [20480/90000 (23%)]	Loss: -5.7751	Cost: 6.09s
Train Epoch: 1297 [40960/90000 (45%)]	Loss: -5.8476	Cost: 16.46s
Train Epoch: 1297 [61440/90000 (68%)]	Loss: -6.2901	Cost: 12.54s
Train Epoch: 1297 [81920/90000 (91%)]	Loss: -6.2571	Cost: 12.22s
Train Epoch: 1297 	Average Loss: -5.6741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6651

Learning rate: 9.590642605464485e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1298 [0/90000 (0%)]	Loss: -2.5838	Cost: 36.22s
Train Epoch: 1298 [20480/90000 (23%)]	Loss: -5.8738	Cost: 12.83s
Train Epoch: 1298 [40960/90000 (45%)]	Loss: -5.8249	Cost: 12.07s
Train Epoch: 1298 [61440/90000 (68%)]	Loss: -6.0338	Cost: 9.09s
Train Epoch: 1298 [81920/90000 (91%)]	Loss: -5.8784	Cost: 6.25s
Train Epoch: 1298 	Average Loss: -5.6317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3737

Learning rate: 9.59001989944592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1299 [0/90000 (0%)]	Loss: -2.7321	Cost: 29.85s
Train Epoch: 1299 [20480/90000 (23%)]	Loss: -5.8107	Cost: 8.79s
Train Epoch: 1299 [40960/90000 (45%)]	Loss: -6.0405	Cost: 10.75s
Train Epoch: 1299 [61440/90000 (68%)]	Loss: -6.1990	Cost: 6.83s
Train Epoch: 1299 [81920/90000 (91%)]	Loss: -6.1523	Cost: 10.52s
Train Epoch: 1299 	Average Loss: -5.7373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7157

Learning rate: 9.589396740410552e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1300 [0/90000 (0%)]	Loss: -2.8617	Cost: 31.64s
Train Epoch: 1300 [20480/90000 (23%)]	Loss: -6.0510	Cost: 14.75s
Train Epoch: 1300 [40960/90000 (45%)]	Loss: -6.0648	Cost: 14.50s
Train Epoch: 1300 [61440/90000 (68%)]	Loss: -6.2361	Cost: 12.19s
Train Epoch: 1300 [81920/90000 (91%)]	Loss: -6.1575	Cost: 8.97s
Train Epoch: 1300 	Average Loss: -5.8457
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7811

Learning rate: 9.588773128419886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1301 [0/90000 (0%)]	Loss: -2.7799	Cost: 30.31s
Train Epoch: 1301 [20480/90000 (23%)]	Loss: -6.1788	Cost: 10.70s
Train Epoch: 1301 [40960/90000 (45%)]	Loss: -6.1939	Cost: 9.73s
Train Epoch: 1301 [61440/90000 (68%)]	Loss: -5.5797	Cost: 9.30s
Train Epoch: 1301 [81920/90000 (91%)]	Loss: -5.4198	Cost: 13.26s
Train Epoch: 1301 	Average Loss: -5.6638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.0184

Learning rate: 9.588149063535469e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1302 [0/90000 (0%)]	Loss: -2.2229	Cost: 52.38s
Train Epoch: 1302 [20480/90000 (23%)]	Loss: -4.5061	Cost: 12.38s
Train Epoch: 1302 [40960/90000 (45%)]	Loss: -5.1966	Cost: 12.21s
Train Epoch: 1302 [61440/90000 (68%)]	Loss: -5.4433	Cost: 11.99s
Train Epoch: 1302 [81920/90000 (91%)]	Loss: -5.6809	Cost: 11.71s
Train Epoch: 1302 	Average Loss: -4.9132
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2640

Learning rate: 9.587524545818893e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1303 [0/90000 (0%)]	Loss: -2.0401	Cost: 30.20s
Train Epoch: 1303 [20480/90000 (23%)]	Loss: -5.6832	Cost: 8.87s
Train Epoch: 1303 [40960/90000 (45%)]	Loss: -5.8689	Cost: 11.42s
Train Epoch: 1303 [61440/90000 (68%)]	Loss: -5.9741	Cost: 8.81s
Train Epoch: 1303 [81920/90000 (91%)]	Loss: -5.5563	Cost: 10.31s
Train Epoch: 1303 	Average Loss: -5.4757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.2763

Learning rate: 9.586899575331797e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1304 [0/90000 (0%)]	Loss: -2.6722	Cost: 38.14s
Train Epoch: 1304 [20480/90000 (23%)]	Loss: -5.6066	Cost: 14.78s
Train Epoch: 1304 [40960/90000 (45%)]	Loss: -5.7360	Cost: 14.06s
Train Epoch: 1304 [61440/90000 (68%)]	Loss: -5.9580	Cost: 12.23s
Train Epoch: 1304 [81920/90000 (91%)]	Loss: -6.0532	Cost: 11.92s
Train Epoch: 1304 	Average Loss: -5.4641
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7406

Learning rate: 9.586274152135862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1305 [0/90000 (0%)]	Loss: -2.2952	Cost: 34.63s
Train Epoch: 1305 [20480/90000 (23%)]	Loss: -6.1602	Cost: 7.10s
Train Epoch: 1305 [40960/90000 (45%)]	Loss: -6.0437	Cost: 13.81s
Train Epoch: 1305 [61440/90000 (68%)]	Loss: -6.2899	Cost: 8.67s
Train Epoch: 1305 [81920/90000 (91%)]	Loss: -6.2928	Cost: 9.81s
Train Epoch: 1305 	Average Loss: -5.8897
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8498

Learning rate: 9.585648276292814e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1306 [0/90000 (0%)]	Loss: -2.9339	Cost: 36.11s
Train Epoch: 1306 [20480/90000 (23%)]	Loss: -6.0949	Cost: 10.55s
Train Epoch: 1306 [40960/90000 (45%)]	Loss: -5.9672	Cost: 21.20s
Train Epoch: 1306 [61440/90000 (68%)]	Loss: -6.2161	Cost: 12.11s
Train Epoch: 1306 [81920/90000 (91%)]	Loss: -6.0614	Cost: 11.97s
Train Epoch: 1306 	Average Loss: -5.8285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4425

Learning rate: 9.585021947864428e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1307 [0/90000 (0%)]	Loss: -2.2463	Cost: 40.32s
Train Epoch: 1307 [20480/90000 (23%)]	Loss: -5.6216	Cost: 11.93s
Train Epoch: 1307 [40960/90000 (45%)]	Loss: -6.1130	Cost: 6.09s
Train Epoch: 1307 [61440/90000 (68%)]	Loss: -5.8602	Cost: 6.43s
Train Epoch: 1307 [81920/90000 (91%)]	Loss: -5.6728	Cost: 13.01s
Train Epoch: 1307 	Average Loss: -5.5896
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5248

Learning rate: 9.584395166912516e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1308 [0/90000 (0%)]	Loss: -2.4906	Cost: 28.89s
Train Epoch: 1308 [20480/90000 (23%)]	Loss: -5.9236	Cost: 6.72s
Train Epoch: 1308 [40960/90000 (45%)]	Loss: -5.9704	Cost: 21.08s
Train Epoch: 1308 [61440/90000 (68%)]	Loss: -5.9493	Cost: 14.00s
Train Epoch: 1308 [81920/90000 (91%)]	Loss: -5.8102	Cost: 12.03s
Train Epoch: 1308 	Average Loss: -5.6557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5475

Learning rate: 9.583767933498941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1309 [0/90000 (0%)]	Loss: -2.5376	Cost: 38.77s
Train Epoch: 1309 [20480/90000 (23%)]	Loss: -5.7817	Cost: 12.90s
Train Epoch: 1309 [40960/90000 (45%)]	Loss: -6.0020	Cost: 8.94s
Train Epoch: 1309 [61440/90000 (68%)]	Loss: -6.1664	Cost: 6.39s
Train Epoch: 1309 [81920/90000 (91%)]	Loss: -6.2344	Cost: 14.54s
Train Epoch: 1309 	Average Loss: -5.7511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8426

Learning rate: 9.58314024768561e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1310 [0/90000 (0%)]	Loss: -2.7376	Cost: 34.74s
Train Epoch: 1310 [20480/90000 (23%)]	Loss: -6.2009	Cost: 9.13s
Train Epoch: 1310 [40960/90000 (45%)]	Loss: -6.3099	Cost: 16.19s
Train Epoch: 1310 [61440/90000 (68%)]	Loss: -6.5504	Cost: 12.18s
Train Epoch: 1310 [81920/90000 (91%)]	Loss: -6.2472	Cost: 12.21s
Train Epoch: 1310 	Average Loss: -6.0441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9337

Learning rate: 9.582512109534469e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1311 [0/90000 (0%)]	Loss: -2.7125	Cost: 41.42s
Train Epoch: 1311 [20480/90000 (23%)]	Loss: -6.2071	Cost: 10.99s
Train Epoch: 1311 [40960/90000 (45%)]	Loss: -6.3290	Cost: 7.71s
Train Epoch: 1311 [61440/90000 (68%)]	Loss: -6.4171	Cost: 6.35s
Train Epoch: 1311 [81920/90000 (91%)]	Loss: -6.2891	Cost: 15.26s
Train Epoch: 1311 	Average Loss: -6.0867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8540

Learning rate: 9.581883519107515e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1312 [0/90000 (0%)]	Loss: -2.8129	Cost: 32.70s
Train Epoch: 1312 [20480/90000 (23%)]	Loss: -6.2682	Cost: 6.81s
Train Epoch: 1312 [40960/90000 (45%)]	Loss: -6.2969	Cost: 17.79s
Train Epoch: 1312 [61440/90000 (68%)]	Loss: -6.7049	Cost: 12.19s
Train Epoch: 1312 [81920/90000 (91%)]	Loss: -6.5803	Cost: 12.31s
Train Epoch: 1312 	Average Loss: -6.1367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0807

Saving model as e1312_model.pt & e1312_waveforms_supplementary.hdf5
Learning rate: 9.581254476466788e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1313 [0/90000 (0%)]	Loss: -3.0198	Cost: 36.14s
Train Epoch: 1313 [20480/90000 (23%)]	Loss: -6.5036	Cost: 12.20s
Train Epoch: 1313 [40960/90000 (45%)]	Loss: -6.5519	Cost: 7.99s
Train Epoch: 1313 [61440/90000 (68%)]	Loss: -6.6480	Cost: 8.85s
Train Epoch: 1313 [81920/90000 (91%)]	Loss: -6.5724	Cost: 10.58s
Train Epoch: 1313 	Average Loss: -6.2248
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8944

Learning rate: 9.58062498167437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1314 [0/90000 (0%)]	Loss: -3.3885	Cost: 50.56s
Train Epoch: 1314 [20480/90000 (23%)]	Loss: -6.3350	Cost: 12.67s
Train Epoch: 1314 [40960/90000 (45%)]	Loss: -6.0531	Cost: 12.29s
Train Epoch: 1314 [61440/90000 (68%)]	Loss: -6.4445	Cost: 12.21s
Train Epoch: 1314 [81920/90000 (91%)]	Loss: -6.2309	Cost: 11.59s
Train Epoch: 1314 	Average Loss: -5.9595
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7121

Learning rate: 9.579995034792391e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1315 [0/90000 (0%)]	Loss: -2.8329	Cost: 33.76s
Train Epoch: 1315 [20480/90000 (23%)]	Loss: -5.7715	Cost: 7.17s
Train Epoch: 1315 [40960/90000 (45%)]	Loss: -5.9753	Cost: 14.05s
Train Epoch: 1315 [61440/90000 (68%)]	Loss: -6.3006	Cost: 8.81s
Train Epoch: 1315 [81920/90000 (91%)]	Loss: -6.3231	Cost: 11.33s
Train Epoch: 1315 	Average Loss: -5.8187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8761

Learning rate: 9.579364635883025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1316 [0/90000 (0%)]	Loss: -2.0794	Cost: 31.16s
Train Epoch: 1316 [20480/90000 (23%)]	Loss: -6.0461	Cost: 7.03s
Train Epoch: 1316 [40960/90000 (45%)]	Loss: -6.3927	Cost: 18.03s
Train Epoch: 1316 [61440/90000 (68%)]	Loss: -6.5407	Cost: 13.63s
Train Epoch: 1316 [81920/90000 (91%)]	Loss: -6.1799	Cost: 11.83s
Train Epoch: 1316 	Average Loss: -5.9463
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7104

Learning rate: 9.57873378500849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1317 [0/90000 (0%)]	Loss: -2.8151	Cost: 40.93s
Train Epoch: 1317 [20480/90000 (23%)]	Loss: -6.1690	Cost: 10.11s
Train Epoch: 1317 [40960/90000 (45%)]	Loss: -6.0971	Cost: 9.58s
Train Epoch: 1317 [61440/90000 (68%)]	Loss: -6.5736	Cost: 6.43s
Train Epoch: 1317 [81920/90000 (91%)]	Loss: -5.9934	Cost: 14.38s
Train Epoch: 1317 	Average Loss: -5.9024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5683

Learning rate: 9.578102482231046e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1318 [0/90000 (0%)]	Loss: -2.1334	Cost: 45.70s
Train Epoch: 1318 [20480/90000 (23%)]	Loss: -5.7755	Cost: 11.98s
Train Epoch: 1318 [40960/90000 (45%)]	Loss: -6.0738	Cost: 13.00s
Train Epoch: 1318 [61440/90000 (68%)]	Loss: -5.9348	Cost: 11.87s
Train Epoch: 1318 [81920/90000 (91%)]	Loss: -5.8249	Cost: 12.09s
Train Epoch: 1318 	Average Loss: -5.5823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5098

Learning rate: 9.577470727613003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1319 [0/90000 (0%)]	Loss: -2.3931	Cost: 50.40s
Train Epoch: 1319 [20480/90000 (23%)]	Loss: -5.5438	Cost: 11.27s
Train Epoch: 1319 [40960/90000 (45%)]	Loss: -5.7328	Cost: 6.27s
Train Epoch: 1319 [61440/90000 (68%)]	Loss: -5.6607	Cost: 6.33s
Train Epoch: 1319 [81920/90000 (91%)]	Loss: -5.6401	Cost: 11.71s
Train Epoch: 1319 	Average Loss: -5.4091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5601

Learning rate: 9.576838521216712e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1320 [0/90000 (0%)]	Loss: -2.0613	Cost: 28.02s
Train Epoch: 1320 [20480/90000 (23%)]	Loss: -5.8122	Cost: 8.53s
Train Epoch: 1320 [40960/90000 (45%)]	Loss: -5.8424	Cost: 11.22s
Train Epoch: 1320 [61440/90000 (68%)]	Loss: -6.3040	Cost: 9.58s
Train Epoch: 1320 [81920/90000 (91%)]	Loss: -6.2970	Cost: 17.03s
Train Epoch: 1320 	Average Loss: -5.7581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8268

Learning rate: 9.576205863104567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1321 [0/90000 (0%)]	Loss: -3.0630	Cost: 53.67s
Train Epoch: 1321 [20480/90000 (23%)]	Loss: -6.3413	Cost: 11.76s
Train Epoch: 1321 [40960/90000 (45%)]	Loss: -6.3190	Cost: 7.11s
Train Epoch: 1321 [61440/90000 (68%)]	Loss: -6.6226	Cost: 6.14s
Train Epoch: 1321 [81920/90000 (91%)]	Loss: -6.6466	Cost: 11.52s
Train Epoch: 1321 	Average Loss: -6.1496
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1090

Saving model as e1321_model.pt & e1321_waveforms_supplementary.hdf5
Learning rate: 9.575572753339011e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1322 [0/90000 (0%)]	Loss: -3.1232	Cost: 31.98s
Train Epoch: 1322 [20480/90000 (23%)]	Loss: -6.6050	Cost: 11.02s
Train Epoch: 1322 [40960/90000 (45%)]	Loss: -6.6328	Cost: 22.29s
Train Epoch: 1322 [61440/90000 (68%)]	Loss: -6.7597	Cost: 12.48s
Train Epoch: 1322 [81920/90000 (91%)]	Loss: -6.5761	Cost: 12.12s
Train Epoch: 1322 	Average Loss: -6.3215
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2136

Saving model as e1322_model.pt & e1322_waveforms_supplementary.hdf5
Learning rate: 9.574939191982527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1323 [0/90000 (0%)]	Loss: -3.0682	Cost: 39.90s
Train Epoch: 1323 [20480/90000 (23%)]	Loss: -6.3396	Cost: 10.31s
Train Epoch: 1323 [40960/90000 (45%)]	Loss: -6.3968	Cost: 7.00s
Train Epoch: 1323 [61440/90000 (68%)]	Loss: -6.5611	Cost: 6.82s
Train Epoch: 1323 [81920/90000 (91%)]	Loss: -6.4584	Cost: 12.86s
Train Epoch: 1323 	Average Loss: -6.1988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9372

Learning rate: 9.574305179097649e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1324 [0/90000 (0%)]	Loss: -2.9068	Cost: 28.70s
Train Epoch: 1324 [20480/90000 (23%)]	Loss: -6.4532	Cost: 6.74s
Train Epoch: 1324 [40960/90000 (45%)]	Loss: -6.7260	Cost: 14.27s
Train Epoch: 1324 [61440/90000 (68%)]	Loss: -6.6144	Cost: 12.91s
Train Epoch: 1324 [81920/90000 (91%)]	Loss: -6.5908	Cost: 13.66s
Train Epoch: 1324 	Average Loss: -6.2164
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8241

Learning rate: 9.573670714746948e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1325 [0/90000 (0%)]	Loss: -2.1382	Cost: 36.58s
Train Epoch: 1325 [20480/90000 (23%)]	Loss: -5.2211	Cost: 12.72s
Train Epoch: 1325 [40960/90000 (45%)]	Loss: -5.4111	Cost: 11.49s
Train Epoch: 1325 [61440/90000 (68%)]	Loss: -6.1130	Cost: 6.30s
Train Epoch: 1325 [81920/90000 (91%)]	Loss: -6.0893	Cost: 11.42s
Train Epoch: 1325 	Average Loss: -5.4147
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7439

Learning rate: 9.573035798993046e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1326 [0/90000 (0%)]	Loss: -2.2469	Cost: 32.94s
Train Epoch: 1326 [20480/90000 (23%)]	Loss: -6.0657	Cost: 8.60s
Train Epoch: 1326 [40960/90000 (45%)]	Loss: -5.8407	Cost: 16.67s
Train Epoch: 1326 [61440/90000 (68%)]	Loss: -6.1742	Cost: 12.31s
Train Epoch: 1326 [81920/90000 (91%)]	Loss: -6.2259	Cost: 12.19s
Train Epoch: 1326 	Average Loss: -5.7921
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9047

Learning rate: 9.572400431898604e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1327 [0/90000 (0%)]	Loss: -2.6821	Cost: 45.67s
Train Epoch: 1327 [20480/90000 (23%)]	Loss: -6.3189	Cost: 11.27s
Train Epoch: 1327 [40960/90000 (45%)]	Loss: -6.3100	Cost: 8.97s
Train Epoch: 1327 [61440/90000 (68%)]	Loss: -6.5305	Cost: 6.59s
Train Epoch: 1327 [81920/90000 (91%)]	Loss: -6.5645	Cost: 13.06s
Train Epoch: 1327 	Average Loss: -6.1336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0858

Learning rate: 9.571764613526331e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1328 [0/90000 (0%)]	Loss: -2.9005	Cost: 32.74s
Train Epoch: 1328 [20480/90000 (23%)]	Loss: -6.5363	Cost: 8.86s
Train Epoch: 1328 [40960/90000 (45%)]	Loss: -6.5379	Cost: 8.98s
Train Epoch: 1328 [61440/90000 (68%)]	Loss: -6.8543	Cost: 6.82s
Train Epoch: 1328 [81920/90000 (91%)]	Loss: -6.8141	Cost: 18.18s
Train Epoch: 1328 	Average Loss: -6.3142
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1297

Learning rate: 9.571128343938982e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1329 [0/90000 (0%)]	Loss: -3.2603	Cost: 33.89s
Train Epoch: 1329 [20480/90000 (23%)]	Loss: -6.1255	Cost: 12.17s
Train Epoch: 1329 [40960/90000 (45%)]	Loss: -6.2402	Cost: 12.47s
Train Epoch: 1329 [61440/90000 (68%)]	Loss: -6.5959	Cost: 9.45s
Train Epoch: 1329 [81920/90000 (91%)]	Loss: -6.2987	Cost: 8.40s
Train Epoch: 1329 	Average Loss: -6.0317
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9813

Learning rate: 9.570491623199352e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1330 [0/90000 (0%)]	Loss: -2.8482	Cost: 28.96s
Train Epoch: 1330 [20480/90000 (23%)]	Loss: -6.2908	Cost: 9.14s
Train Epoch: 1330 [40960/90000 (45%)]	Loss: -6.2507	Cost: 23.72s
Train Epoch: 1330 [61440/90000 (68%)]	Loss: -6.3968	Cost: 13.36s
Train Epoch: 1330 [81920/90000 (91%)]	Loss: -6.2702	Cost: 11.96s
Train Epoch: 1330 	Average Loss: -6.0610
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8764

Learning rate: 9.569854451370282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1331 [0/90000 (0%)]	Loss: -2.4318	Cost: 55.84s
Train Epoch: 1331 [20480/90000 (23%)]	Loss: -6.0404	Cost: 9.72s
Train Epoch: 1331 [40960/90000 (45%)]	Loss: -6.0150	Cost: 7.64s
Train Epoch: 1331 [61440/90000 (68%)]	Loss: -6.2366	Cost: 6.44s
Train Epoch: 1331 [81920/90000 (91%)]	Loss: -6.3132	Cost: 13.71s
Train Epoch: 1331 	Average Loss: -5.8363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8597

Learning rate: 9.569216828514662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1332 [0/90000 (0%)]	Loss: -2.5106	Cost: 29.53s
Train Epoch: 1332 [20480/90000 (23%)]	Loss: -6.2628	Cost: 10.94s
Train Epoch: 1332 [40960/90000 (45%)]	Loss: -6.2536	Cost: 17.93s
Train Epoch: 1332 [61440/90000 (68%)]	Loss: -6.5975	Cost: 12.56s
Train Epoch: 1332 [81920/90000 (91%)]	Loss: -6.7173	Cost: 12.31s
Train Epoch: 1332 	Average Loss: -6.1490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0506

Learning rate: 9.56857875469542e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1333 [0/90000 (0%)]	Loss: -2.8593	Cost: 46.50s
Train Epoch: 1333 [20480/90000 (23%)]	Loss: -6.3782	Cost: 7.94s
Train Epoch: 1333 [40960/90000 (45%)]	Loss: -6.1944	Cost: 10.65s
Train Epoch: 1333 [61440/90000 (68%)]	Loss: -6.8169	Cost: 8.58s
Train Epoch: 1333 [81920/90000 (91%)]	Loss: -6.6307	Cost: 12.72s
Train Epoch: 1333 	Average Loss: -6.2487
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1358

Learning rate: 9.567940229975531e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1334 [0/90000 (0%)]	Loss: -3.0113	Cost: 27.39s
Train Epoch: 1334 [20480/90000 (23%)]	Loss: -6.2730	Cost: 10.53s
Train Epoch: 1334 [40960/90000 (45%)]	Loss: -6.6335	Cost: 18.27s
Train Epoch: 1334 [61440/90000 (68%)]	Loss: -6.6251	Cost: 13.53s
Train Epoch: 1334 [81920/90000 (91%)]	Loss: -6.4942	Cost: 12.20s
Train Epoch: 1334 	Average Loss: -6.1527
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9638

Learning rate: 9.567301254418016e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1335 [0/90000 (0%)]	Loss: -3.1173	Cost: 42.32s
Train Epoch: 1335 [20480/90000 (23%)]	Loss: -6.5533	Cost: 12.43s
Train Epoch: 1335 [40960/90000 (45%)]	Loss: -6.2358	Cost: 9.08s
Train Epoch: 1335 [61440/90000 (68%)]	Loss: -6.6617	Cost: 6.27s
Train Epoch: 1335 [81920/90000 (91%)]	Loss: -6.5346	Cost: 13.46s
Train Epoch: 1335 	Average Loss: -6.2051
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9945

Learning rate: 9.566661828085939e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1336 [0/90000 (0%)]	Loss: -3.1988	Cost: 34.75s
Train Epoch: 1336 [20480/90000 (23%)]	Loss: -6.0972	Cost: 7.65s
Train Epoch: 1336 [40960/90000 (45%)]	Loss: -6.2610	Cost: 15.92s
Train Epoch: 1336 [61440/90000 (68%)]	Loss: -6.5053	Cost: 12.22s
Train Epoch: 1336 [81920/90000 (91%)]	Loss: -6.5376	Cost: 12.05s
Train Epoch: 1336 	Average Loss: -6.0999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9768

Learning rate: 9.56602195104241e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1337 [0/90000 (0%)]	Loss: -2.8155	Cost: 39.51s
Train Epoch: 1337 [20480/90000 (23%)]	Loss: -6.4313	Cost: 11.52s
Train Epoch: 1337 [40960/90000 (45%)]	Loss: -6.5659	Cost: 9.12s
Train Epoch: 1337 [61440/90000 (68%)]	Loss: -6.2150	Cost: 7.02s
Train Epoch: 1337 [81920/90000 (91%)]	Loss: -5.5777	Cost: 12.04s
Train Epoch: 1337 	Average Loss: -5.9890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3806

Learning rate: 9.56538162335058e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1338 [0/90000 (0%)]	Loss: -2.0354	Cost: 34.49s
Train Epoch: 1338 [20480/90000 (23%)]	Loss: -5.8893	Cost: 10.63s
Train Epoch: 1338 [40960/90000 (45%)]	Loss: -5.7327	Cost: 15.75s
Train Epoch: 1338 [61440/90000 (68%)]	Loss: -6.2709	Cost: 13.36s
Train Epoch: 1338 [81920/90000 (91%)]	Loss: -6.1986	Cost: 12.21s
Train Epoch: 1338 	Average Loss: -5.6887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8268

Learning rate: 9.564740845073646e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1339 [0/90000 (0%)]	Loss: -2.8751	Cost: 35.87s
Train Epoch: 1339 [20480/90000 (23%)]	Loss: -6.1953	Cost: 12.38s
Train Epoch: 1339 [40960/90000 (45%)]	Loss: -6.4462	Cost: 7.87s
Train Epoch: 1339 [61440/90000 (68%)]	Loss: -6.5472	Cost: 6.37s
Train Epoch: 1339 [81920/90000 (91%)]	Loss: -6.5960	Cost: 12.27s
Train Epoch: 1339 	Average Loss: -6.1271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1345

Learning rate: 9.564099616274855e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1340 [0/90000 (0%)]	Loss: -2.6666	Cost: 33.87s
Train Epoch: 1340 [20480/90000 (23%)]	Loss: -6.4116	Cost: 6.73s
Train Epoch: 1340 [40960/90000 (45%)]	Loss: -6.5954	Cost: 14.39s
Train Epoch: 1340 [61440/90000 (68%)]	Loss: -6.4010	Cost: 11.49s
Train Epoch: 1340 [81920/90000 (91%)]	Loss: -6.5631	Cost: 14.44s
Train Epoch: 1340 	Average Loss: -6.1737
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0512

Learning rate: 9.563457937017491e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1341 [0/90000 (0%)]	Loss: -2.6107	Cost: 38.58s
Train Epoch: 1341 [20480/90000 (23%)]	Loss: -5.1725	Cost: 11.97s
Train Epoch: 1341 [40960/90000 (45%)]	Loss: -5.4599	Cost: 9.01s
Train Epoch: 1341 [61440/90000 (68%)]	Loss: -5.9338	Cost: 6.14s
Train Epoch: 1341 [81920/90000 (91%)]	Loss: -6.0151	Cost: 9.48s
Train Epoch: 1341 	Average Loss: -5.5436
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5476

Learning rate: 9.562815807364884e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1342 [0/90000 (0%)]	Loss: -2.4791	Cost: 29.02s
Train Epoch: 1342 [20480/90000 (23%)]	Loss: -6.0572	Cost: 9.78s
Train Epoch: 1342 [40960/90000 (45%)]	Loss: -6.4207	Cost: 17.34s
Train Epoch: 1342 [61440/90000 (68%)]	Loss: -6.4818	Cost: 14.26s
Train Epoch: 1342 [81920/90000 (91%)]	Loss: -6.5729	Cost: 12.10s
Train Epoch: 1342 	Average Loss: -6.0416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9632

Learning rate: 9.562173227380412e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1343 [0/90000 (0%)]	Loss: -3.1241	Cost: 55.97s
Train Epoch: 1343 [20480/90000 (23%)]	Loss: -6.4085	Cost: 6.60s
Train Epoch: 1343 [40960/90000 (45%)]	Loss: -6.5547	Cost: 13.92s
Train Epoch: 1343 [61440/90000 (68%)]	Loss: -6.8435	Cost: 8.52s
Train Epoch: 1343 [81920/90000 (91%)]	Loss: -6.8537	Cost: 8.52s
Train Epoch: 1343 	Average Loss: -6.3252
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2031

Learning rate: 9.561530197127494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1344 [0/90000 (0%)]	Loss: -3.6715	Cost: 27.39s
Train Epoch: 1344 [20480/90000 (23%)]	Loss: -6.4683	Cost: 8.60s
Train Epoch: 1344 [40960/90000 (45%)]	Loss: -6.6040	Cost: 22.13s
Train Epoch: 1344 [61440/90000 (68%)]	Loss: -6.9230	Cost: 12.65s
Train Epoch: 1344 [81920/90000 (91%)]	Loss: -6.1986	Cost: 12.09s
Train Epoch: 1344 	Average Loss: -6.3797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7396

Learning rate: 9.560886716669594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1345 [0/90000 (0%)]	Loss: -2.7926	Cost: 42.19s
Train Epoch: 1345 [20480/90000 (23%)]	Loss: -6.0975	Cost: 7.73s
Train Epoch: 1345 [40960/90000 (45%)]	Loss: -6.0851	Cost: 11.48s
Train Epoch: 1345 [61440/90000 (68%)]	Loss: -6.5044	Cost: 8.64s
Train Epoch: 1345 [81920/90000 (91%)]	Loss: -6.4821	Cost: 9.03s
Train Epoch: 1345 	Average Loss: -5.9943
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9089

Learning rate: 9.560242786070223e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1346 [0/90000 (0%)]	Loss: -2.5519	Cost: 27.06s
Train Epoch: 1346 [20480/90000 (23%)]	Loss: -6.2175	Cost: 9.69s
Train Epoch: 1346 [40960/90000 (45%)]	Loss: -6.5312	Cost: 23.46s
Train Epoch: 1346 [61440/90000 (68%)]	Loss: -6.8165	Cost: 13.23s
Train Epoch: 1346 [81920/90000 (91%)]	Loss: -6.4341	Cost: 12.12s
Train Epoch: 1346 	Average Loss: -6.2489
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7869

Learning rate: 9.559598405392933e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1347 [0/90000 (0%)]	Loss: -2.9049	Cost: 50.40s
Train Epoch: 1347 [20480/90000 (23%)]	Loss: -6.2940	Cost: 11.35s
Train Epoch: 1347 [40960/90000 (45%)]	Loss: -6.2511	Cost: 9.52s
Train Epoch: 1347 [61440/90000 (68%)]	Loss: -6.5939	Cost: 6.05s
Train Epoch: 1347 [81920/90000 (91%)]	Loss: -6.5587	Cost: 7.99s
Train Epoch: 1347 	Average Loss: -6.1293
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0590

Learning rate: 9.55895357470132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1348 [0/90000 (0%)]	Loss: -2.6926	Cost: 35.53s
Train Epoch: 1348 [20480/90000 (23%)]	Loss: -6.3543	Cost: 8.52s
Train Epoch: 1348 [40960/90000 (45%)]	Loss: -6.4175	Cost: 9.35s
Train Epoch: 1348 [61440/90000 (68%)]	Loss: -6.5757	Cost: 5.96s
Train Epoch: 1348 [81920/90000 (91%)]	Loss: -6.4849	Cost: 14.11s
Train Epoch: 1348 	Average Loss: -6.1985
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9514

Learning rate: 9.55830829405903e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1349 [0/90000 (0%)]	Loss: -2.8011	Cost: 34.09s
Train Epoch: 1349 [20480/90000 (23%)]	Loss: -5.9909	Cost: 13.71s
Train Epoch: 1349 [40960/90000 (45%)]	Loss: -5.9934	Cost: 12.54s
Train Epoch: 1349 [61440/90000 (68%)]	Loss: -6.2725	Cost: 12.22s
Train Epoch: 1349 [81920/90000 (91%)]	Loss: -6.3398	Cost: 7.35s
Train Epoch: 1349 	Average Loss: -5.8032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8501

Learning rate: 9.557662563529747e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1350 [0/90000 (0%)]	Loss: -3.3471	Cost: 30.68s
Train Epoch: 1350 [20480/90000 (23%)]	Loss: -6.3743	Cost: 8.35s
Train Epoch: 1350 [40960/90000 (45%)]	Loss: -6.2529	Cost: 12.58s
Train Epoch: 1350 [61440/90000 (68%)]	Loss: -6.6241	Cost: 8.90s
Train Epoch: 1350 [81920/90000 (91%)]	Loss: -6.4950	Cost: 10.05s
Train Epoch: 1350 	Average Loss: -6.2197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1195

Learning rate: 9.557016383177202e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1351 [0/90000 (0%)]	Loss: -3.0545	Cost: 28.75s
Train Epoch: 1351 [20480/90000 (23%)]	Loss: -6.6099	Cost: 9.95s
Train Epoch: 1351 [40960/90000 (45%)]	Loss: -6.5670	Cost: 21.00s
Train Epoch: 1351 [61440/90000 (68%)]	Loss: -6.6015	Cost: 12.14s
Train Epoch: 1351 [81920/90000 (91%)]	Loss: -6.6035	Cost: 11.85s
Train Epoch: 1351 	Average Loss: -6.3340
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0681

Learning rate: 9.556369753065172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1352 [0/90000 (0%)]	Loss: -3.3978	Cost: 35.17s
Train Epoch: 1352 [20480/90000 (23%)]	Loss: -5.7101	Cost: 12.65s
Train Epoch: 1352 [40960/90000 (45%)]	Loss: -5.8100	Cost: 7.60s
Train Epoch: 1352 [61440/90000 (68%)]	Loss: -6.3416	Cost: 6.49s
Train Epoch: 1352 [81920/90000 (91%)]	Loss: -6.2646	Cost: 14.30s
Train Epoch: 1352 	Average Loss: -5.7791
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8310

Learning rate: 9.555722673257475e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1353 [0/90000 (0%)]	Loss: -2.5780	Cost: 33.25s
Train Epoch: 1353 [20480/90000 (23%)]	Loss: -6.0702	Cost: 9.14s
Train Epoch: 1353 [40960/90000 (45%)]	Loss: -6.2971	Cost: 15.60s
Train Epoch: 1353 [61440/90000 (68%)]	Loss: -6.6756	Cost: 12.24s
Train Epoch: 1353 [81920/90000 (91%)]	Loss: -6.6421	Cost: 12.00s
Train Epoch: 1353 	Average Loss: -6.1589
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1239

Learning rate: 9.555075143817977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1354 [0/90000 (0%)]	Loss: -3.0436	Cost: 31.45s
Train Epoch: 1354 [20480/90000 (23%)]	Loss: -6.7067	Cost: 12.21s
Train Epoch: 1354 [40960/90000 (45%)]	Loss: -6.3709	Cost: 10.76s
Train Epoch: 1354 [61440/90000 (68%)]	Loss: -6.7554	Cost: 6.03s
Train Epoch: 1354 [81920/90000 (91%)]	Loss: -6.4731	Cost: 7.44s
Train Epoch: 1354 	Average Loss: -6.2813
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0183

Learning rate: 9.554427164810586e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1355 [0/90000 (0%)]	Loss: -2.9355	Cost: 28.80s
Train Epoch: 1355 [20480/90000 (23%)]	Loss: -6.5929	Cost: 10.45s
Train Epoch: 1355 [40960/90000 (45%)]	Loss: -6.6110	Cost: 23.67s
Train Epoch: 1355 [61440/90000 (68%)]	Loss: -6.7079	Cost: 13.00s
Train Epoch: 1355 [81920/90000 (91%)]	Loss: -6.7679	Cost: 12.06s
Train Epoch: 1355 	Average Loss: -6.3577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1737

Learning rate: 9.553778736299254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1356 [0/90000 (0%)]	Loss: -3.4637	Cost: 55.42s
Train Epoch: 1356 [20480/90000 (23%)]	Loss: -6.5254	Cost: 6.31s
Train Epoch: 1356 [40960/90000 (45%)]	Loss: -6.1977	Cost: 13.38s
Train Epoch: 1356 [61440/90000 (68%)]	Loss: -6.6233	Cost: 8.59s
Train Epoch: 1356 [81920/90000 (91%)]	Loss: -6.6919	Cost: 8.97s
Train Epoch: 1356 	Average Loss: -6.1836
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9386

Learning rate: 9.55312985834798e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1357 [0/90000 (0%)]	Loss: -2.9554	Cost: 27.35s
Train Epoch: 1357 [20480/90000 (23%)]	Loss: -6.4693	Cost: 10.42s
Train Epoch: 1357 [40960/90000 (45%)]	Loss: -6.7834	Cost: 15.32s
Train Epoch: 1357 [61440/90000 (68%)]	Loss: -6.9101	Cost: 14.39s
Train Epoch: 1357 [81920/90000 (91%)]	Loss: -6.9445	Cost: 12.38s
Train Epoch: 1357 	Average Loss: -6.4014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3202

Saving model as e1357_model.pt & e1357_waveforms_supplementary.hdf5
Learning rate: 9.552480531020806e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1358 [0/90000 (0%)]	Loss: -3.3187	Cost: 39.50s
Train Epoch: 1358 [20480/90000 (23%)]	Loss: -6.6118	Cost: 10.09s
Train Epoch: 1358 [40960/90000 (45%)]	Loss: -6.5486	Cost: 10.94s
Train Epoch: 1358 [61440/90000 (68%)]	Loss: -6.7792	Cost: 7.16s
Train Epoch: 1358 [81920/90000 (91%)]	Loss: -6.8851	Cost: 11.31s
Train Epoch: 1358 	Average Loss: -6.4789
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4232

Saving model as e1358_model.pt & e1358_waveforms_supplementary.hdf5
Learning rate: 9.551830754381815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1359 [0/90000 (0%)]	Loss: -3.3396	Cost: 26.13s
Train Epoch: 1359 [20480/90000 (23%)]	Loss: -6.8113	Cost: 8.23s
Train Epoch: 1359 [40960/90000 (45%)]	Loss: -6.7765	Cost: 18.94s
Train Epoch: 1359 [61440/90000 (68%)]	Loss: -7.0893	Cost: 12.36s
Train Epoch: 1359 [81920/90000 (91%)]	Loss: -6.9778	Cost: 12.77s
Train Epoch: 1359 	Average Loss: -6.5951
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2142

Learning rate: 9.55118052849514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1360 [0/90000 (0%)]	Loss: -3.4821	Cost: 34.90s
Train Epoch: 1360 [20480/90000 (23%)]	Loss: -6.6579	Cost: 13.04s
Train Epoch: 1360 [40960/90000 (45%)]	Loss: -6.5899	Cost: 13.62s
Train Epoch: 1360 [61440/90000 (68%)]	Loss: -7.0372	Cost: 6.38s
Train Epoch: 1360 [81920/90000 (91%)]	Loss: -6.7015	Cost: 7.07s
Train Epoch: 1360 	Average Loss: -6.4484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0628

Learning rate: 9.550529853424953e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1361 [0/90000 (0%)]	Loss: -2.9917	Cost: 37.87s
Train Epoch: 1361 [20480/90000 (23%)]	Loss: -6.5885	Cost: 9.49s
Train Epoch: 1361 [40960/90000 (45%)]	Loss: -6.8244	Cost: 12.15s
Train Epoch: 1361 [61440/90000 (68%)]	Loss: -7.0974	Cost: 7.72s
Train Epoch: 1361 [81920/90000 (91%)]	Loss: -7.1349	Cost: 19.24s
Train Epoch: 1361 	Average Loss: -6.5959
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4451

Saving model as e1361_model.pt & e1361_waveforms_supplementary.hdf5
Learning rate: 9.549878729235476e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1362 [0/90000 (0%)]	Loss: -3.1556	Cost: 36.84s
Train Epoch: 1362 [20480/90000 (23%)]	Loss: -6.8875	Cost: 12.36s
Train Epoch: 1362 [40960/90000 (45%)]	Loss: -6.8790	Cost: 12.12s
Train Epoch: 1362 [61440/90000 (68%)]	Loss: -7.2420	Cost: 6.61s
Train Epoch: 1362 [81920/90000 (91%)]	Loss: -6.7741	Cost: 6.46s
Train Epoch: 1362 	Average Loss: -6.6291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1909

Learning rate: 9.549227155990973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1363 [0/90000 (0%)]	Loss: -3.2499	Cost: 33.66s
Train Epoch: 1363 [20480/90000 (23%)]	Loss: -6.5839	Cost: 7.99s
Train Epoch: 1363 [40960/90000 (45%)]	Loss: -6.5387	Cost: 17.14s
Train Epoch: 1363 [61440/90000 (68%)]	Loss: -6.9739	Cost: 13.25s
Train Epoch: 1363 [81920/90000 (91%)]	Loss: -7.0039	Cost: 12.08s
Train Epoch: 1363 	Average Loss: -6.4883
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3006

Learning rate: 9.54857513375575e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1364 [0/90000 (0%)]	Loss: -2.6794	Cost: 36.76s
Train Epoch: 1364 [20480/90000 (23%)]	Loss: -6.8327	Cost: 12.39s
Train Epoch: 1364 [40960/90000 (45%)]	Loss: -6.7598	Cost: 11.46s
Train Epoch: 1364 [61440/90000 (68%)]	Loss: -6.8944	Cost: 6.19s
Train Epoch: 1364 [81920/90000 (91%)]	Loss: -7.0118	Cost: 10.85s
Train Epoch: 1364 	Average Loss: -6.5314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2422

Learning rate: 9.547922662594159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1365 [0/90000 (0%)]	Loss: -2.9177	Cost: 38.87s
Train Epoch: 1365 [20480/90000 (23%)]	Loss: -6.8388	Cost: 8.73s
Train Epoch: 1365 [40960/90000 (45%)]	Loss: -7.0054	Cost: 23.51s
Train Epoch: 1365 [61440/90000 (68%)]	Loss: -6.7445	Cost: 12.11s
Train Epoch: 1365 [81920/90000 (91%)]	Loss: -6.6239	Cost: 11.90s
Train Epoch: 1365 	Average Loss: -6.5035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9769

Learning rate: 9.547269742570596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1366 [0/90000 (0%)]	Loss: -2.4524	Cost: 36.16s
Train Epoch: 1366 [20480/90000 (23%)]	Loss: -6.4531	Cost: 10.78s
Train Epoch: 1366 [40960/90000 (45%)]	Loss: -6.6135	Cost: 6.79s
Train Epoch: 1366 [61440/90000 (68%)]	Loss: -6.9494	Cost: 6.18s
Train Epoch: 1366 [81920/90000 (91%)]	Loss: -6.9209	Cost: 12.64s
Train Epoch: 1366 	Average Loss: -6.3390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9964

Learning rate: 9.546616373749502e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1367 [0/90000 (0%)]	Loss: -3.2609	Cost: 29.35s
Train Epoch: 1367 [20480/90000 (23%)]	Loss: -6.5807	Cost: 8.18s
Train Epoch: 1367 [40960/90000 (45%)]	Loss: -6.5930	Cost: 10.38s
Train Epoch: 1367 [61440/90000 (68%)]	Loss: -6.7740	Cost: 7.74s
Train Epoch: 1367 [81920/90000 (91%)]	Loss: -6.6108	Cost: 21.00s
Train Epoch: 1367 	Average Loss: -6.3336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0674

Learning rate: 9.545962556195362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1368 [0/90000 (0%)]	Loss: -2.7026	Cost: 36.34s
Train Epoch: 1368 [20480/90000 (23%)]	Loss: -6.6489	Cost: 14.57s
Train Epoch: 1368 [40960/90000 (45%)]	Loss: -6.1300	Cost: 12.58s
Train Epoch: 1368 [61440/90000 (68%)]	Loss: -6.6231	Cost: 10.20s
Train Epoch: 1368 [81920/90000 (91%)]	Loss: -6.6099	Cost: 6.18s
Train Epoch: 1368 	Average Loss: -6.2117
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0191

Learning rate: 9.545308289972705e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1369 [0/90000 (0%)]	Loss: -2.5036	Cost: 33.99s
Train Epoch: 1369 [20480/90000 (23%)]	Loss: -6.5193	Cost: 9.02s
Train Epoch: 1369 [40960/90000 (45%)]	Loss: -6.8500	Cost: 11.40s
Train Epoch: 1369 [61440/90000 (68%)]	Loss: -7.0790	Cost: 7.34s
Train Epoch: 1369 [81920/90000 (91%)]	Loss: -7.0259	Cost: 10.36s
Train Epoch: 1369 	Average Loss: -6.5120
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3166

Learning rate: 9.544653575146105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1370 [0/90000 (0%)]	Loss: -3.2621	Cost: 29.15s
Train Epoch: 1370 [20480/90000 (23%)]	Loss: -6.8426	Cost: 14.21s
Train Epoch: 1370 [40960/90000 (45%)]	Loss: -7.1010	Cost: 14.05s
Train Epoch: 1370 [61440/90000 (68%)]	Loss: -6.9073	Cost: 12.21s
Train Epoch: 1370 [81920/90000 (91%)]	Loss: -6.3474	Cost: 12.19s
Train Epoch: 1370 	Average Loss: -6.5477
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0230

Learning rate: 9.54399841178018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1371 [0/90000 (0%)]	Loss: -2.8104	Cost: 36.39s
Train Epoch: 1371 [20480/90000 (23%)]	Loss: -6.5063	Cost: 11.31s
Train Epoch: 1371 [40960/90000 (45%)]	Loss: -6.6505	Cost: 10.67s
Train Epoch: 1371 [61440/90000 (68%)]	Loss: -7.1920	Cost: 7.82s
Train Epoch: 1371 [81920/90000 (91%)]	Loss: -7.1416	Cost: 13.16s
Train Epoch: 1371 	Average Loss: -6.5034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3733

Learning rate: 9.54334279993959e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1372 [0/90000 (0%)]	Loss: -3.0829	Cost: 38.33s
Train Epoch: 1372 [20480/90000 (23%)]	Loss: -6.6199	Cost: 6.78s
Train Epoch: 1372 [40960/90000 (45%)]	Loss: -6.3826	Cost: 18.42s
Train Epoch: 1372 [61440/90000 (68%)]	Loss: -6.4690	Cost: 12.08s
Train Epoch: 1372 [81920/90000 (91%)]	Loss: -6.3106	Cost: 11.93s
Train Epoch: 1372 	Average Loss: -6.2855
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7987

Learning rate: 9.542686739689042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1373 [0/90000 (0%)]	Loss: -2.5812	Cost: 40.13s
Train Epoch: 1373 [20480/90000 (23%)]	Loss: -6.3502	Cost: 8.42s
Train Epoch: 1373 [40960/90000 (45%)]	Loss: -6.6312	Cost: 9.73s
Train Epoch: 1373 [61440/90000 (68%)]	Loss: -6.4081	Cost: 8.26s
Train Epoch: 1373 [81920/90000 (91%)]	Loss: -6.4031	Cost: 10.38s
Train Epoch: 1373 	Average Loss: -6.1526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9765

Learning rate: 9.542030231093288e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1374 [0/90000 (0%)]	Loss: -3.1941	Cost: 33.05s
Train Epoch: 1374 [20480/90000 (23%)]	Loss: -6.4955	Cost: 10.77s
Train Epoch: 1374 [40960/90000 (45%)]	Loss: -6.7377	Cost: 18.14s
Train Epoch: 1374 [61440/90000 (68%)]	Loss: -7.0792	Cost: 12.62s
Train Epoch: 1374 [81920/90000 (91%)]	Loss: -6.9257	Cost: 12.03s
Train Epoch: 1374 	Average Loss: -6.4384
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2603

Learning rate: 9.541373274217122e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1375 [0/90000 (0%)]	Loss: -3.1774	Cost: 39.19s
Train Epoch: 1375 [20480/90000 (23%)]	Loss: -6.8096	Cost: 9.76s
Train Epoch: 1375 [40960/90000 (45%)]	Loss: -6.7092	Cost: 10.83s
Train Epoch: 1375 [61440/90000 (68%)]	Loss: -7.0257	Cost: 6.37s
Train Epoch: 1375 [81920/90000 (91%)]	Loss: -6.8035	Cost: 11.63s
Train Epoch: 1375 	Average Loss: -6.5490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2484

Learning rate: 9.540715869125385e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1376 [0/90000 (0%)]	Loss: -2.8929	Cost: 31.55s
Train Epoch: 1376 [20480/90000 (23%)]	Loss: -6.6264	Cost: 7.15s
Train Epoch: 1376 [40960/90000 (45%)]	Loss: -6.5135	Cost: 20.41s
Train Epoch: 1376 [61440/90000 (68%)]	Loss: -6.8340	Cost: 12.69s
Train Epoch: 1376 [81920/90000 (91%)]	Loss: -6.9115	Cost: 12.07s
Train Epoch: 1376 	Average Loss: -6.4785
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2226

Learning rate: 9.540058015882956e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1377 [0/90000 (0%)]	Loss: -3.0526	Cost: 39.56s
Train Epoch: 1377 [20480/90000 (23%)]	Loss: -6.8128	Cost: 12.93s
Train Epoch: 1377 [40960/90000 (45%)]	Loss: -6.8096	Cost: 12.12s
Train Epoch: 1377 [61440/90000 (68%)]	Loss: -7.3034	Cost: 8.69s
Train Epoch: 1377 [81920/90000 (91%)]	Loss: -7.0591	Cost: 6.23s
Train Epoch: 1377 	Average Loss: -6.6983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5051

Saving model as e1377_model.pt & e1377_waveforms_supplementary.hdf5
Learning rate: 9.539399714554766e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1378 [0/90000 (0%)]	Loss: -3.4389	Cost: 29.76s
Train Epoch: 1378 [20480/90000 (23%)]	Loss: -6.7993	Cost: 6.13s
Train Epoch: 1378 [40960/90000 (45%)]	Loss: -6.4651	Cost: 18.06s
Train Epoch: 1378 [61440/90000 (68%)]	Loss: -6.5493	Cost: 14.95s
Train Epoch: 1378 [81920/90000 (91%)]	Loss: -6.6706	Cost: 13.54s
Train Epoch: 1378 	Average Loss: -6.3563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1107

Learning rate: 9.538740965205785e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1379 [0/90000 (0%)]	Loss: -2.5367	Cost: 39.63s
Train Epoch: 1379 [20480/90000 (23%)]	Loss: -6.7373	Cost: 12.40s
Train Epoch: 1379 [40960/90000 (45%)]	Loss: -4.9482	Cost: 12.41s
Train Epoch: 1379 [61440/90000 (68%)]	Loss: -5.7026	Cost: 6.82s
Train Epoch: 1379 [81920/90000 (91%)]	Loss: -5.9205	Cost: 12.52s
Train Epoch: 1379 	Average Loss: -5.6601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.4785

Learning rate: 9.538081767901031e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1380 [0/90000 (0%)]	Loss: -2.1080	Cost: 33.90s
Train Epoch: 1380 [20480/90000 (23%)]	Loss: -5.6517	Cost: 6.62s
Train Epoch: 1380 [40960/90000 (45%)]	Loss: -6.0180	Cost: 17.68s
Train Epoch: 1380 [61440/90000 (68%)]	Loss: -6.4221	Cost: 12.42s
Train Epoch: 1380 [81920/90000 (91%)]	Loss: -6.4636	Cost: 12.16s
Train Epoch: 1380 	Average Loss: -5.8580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.5446

Learning rate: 9.537422122705562e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1381 [0/90000 (0%)]	Loss: -2.3130	Cost: 37.45s
Train Epoch: 1381 [20480/90000 (23%)]	Loss: -5.8599	Cost: 11.86s
Train Epoch: 1381 [40960/90000 (45%)]	Loss: -5.8354	Cost: 8.19s
Train Epoch: 1381 [61440/90000 (68%)]	Loss: -6.4088	Cost: 6.15s
Train Epoch: 1381 [81920/90000 (91%)]	Loss: -6.5366	Cost: 13.81s
Train Epoch: 1381 	Average Loss: -5.8647
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.0484

Learning rate: 9.536762029684484e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1382 [0/90000 (0%)]	Loss: -2.9930	Cost: 28.23s
Train Epoch: 1382 [20480/90000 (23%)]	Loss: -6.4622	Cost: 8.29s
Train Epoch: 1382 [40960/90000 (45%)]	Loss: -6.6833	Cost: 17.69s
Train Epoch: 1382 [61440/90000 (68%)]	Loss: -7.2211	Cost: 11.97s
Train Epoch: 1382 [81920/90000 (91%)]	Loss: -7.0858	Cost: 12.34s
Train Epoch: 1382 	Average Loss: -6.5022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5098

Saving model as e1382_model.pt & e1382_waveforms_supplementary.hdf5
Learning rate: 9.536101488902943e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1383 [0/90000 (0%)]	Loss: -2.9438	Cost: 34.82s
Train Epoch: 1383 [20480/90000 (23%)]	Loss: -6.7144	Cost: 9.38s
Train Epoch: 1383 [40960/90000 (45%)]	Loss: -6.8468	Cost: 10.02s
Train Epoch: 1383 [61440/90000 (68%)]	Loss: -7.2763	Cost: 10.00s
Train Epoch: 1383 [81920/90000 (91%)]	Loss: -7.2859	Cost: 11.90s
Train Epoch: 1383 	Average Loss: -6.7581
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6019

Saving model as e1383_model.pt & e1383_waveforms_supplementary.hdf5
Learning rate: 9.535440500426135e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1384 [0/90000 (0%)]	Loss: -2.9292	Cost: 44.12s
Train Epoch: 1384 [20480/90000 (23%)]	Loss: -7.0209	Cost: 12.32s
Train Epoch: 1384 [40960/90000 (45%)]	Loss: -6.8134	Cost: 12.50s
Train Epoch: 1384 [61440/90000 (68%)]	Loss: -7.0026	Cost: 11.93s
Train Epoch: 1384 [81920/90000 (91%)]	Loss: -7.0994	Cost: 11.93s
Train Epoch: 1384 	Average Loss: -6.6586
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4273

Learning rate: 9.534779064319296e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1385 [0/90000 (0%)]	Loss: -3.7682	Cost: 35.50s
Train Epoch: 1385 [20480/90000 (23%)]	Loss: -7.0818	Cost: 6.90s
Train Epoch: 1385 [40960/90000 (45%)]	Loss: -6.9793	Cost: 14.93s
Train Epoch: 1385 [61440/90000 (68%)]	Loss: -7.2450	Cost: 8.70s
Train Epoch: 1385 [81920/90000 (91%)]	Loss: -7.0570	Cost: 10.61s
Train Epoch: 1385 	Average Loss: -6.8055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4810

Learning rate: 9.534117180647705e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1386 [0/90000 (0%)]	Loss: -2.9474	Cost: 30.80s
Train Epoch: 1386 [20480/90000 (23%)]	Loss: -6.9083	Cost: 9.94s
Train Epoch: 1386 [40960/90000 (45%)]	Loss: -6.9014	Cost: 16.00s
Train Epoch: 1386 [61440/90000 (68%)]	Loss: -7.3200	Cost: 12.63s
Train Epoch: 1386 [81920/90000 (91%)]	Loss: -7.1282	Cost: 12.16s
Train Epoch: 1386 	Average Loss: -6.7349
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4326

Learning rate: 9.533454849476689e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1387 [0/90000 (0%)]	Loss: -3.1996	Cost: 39.37s
Train Epoch: 1387 [20480/90000 (23%)]	Loss: -7.1542	Cost: 11.70s
Train Epoch: 1387 [40960/90000 (45%)]	Loss: -7.1096	Cost: 7.20s
Train Epoch: 1387 [61440/90000 (68%)]	Loss: -7.4091	Cost: 6.32s
Train Epoch: 1387 [81920/90000 (91%)]	Loss: -7.1490	Cost: 14.29s
Train Epoch: 1387 	Average Loss: -6.8799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2382

Learning rate: 9.53279207087162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1388 [0/90000 (0%)]	Loss: -2.4959	Cost: 28.01s
Train Epoch: 1388 [20480/90000 (23%)]	Loss: -6.4580	Cost: 8.62s
Train Epoch: 1388 [40960/90000 (45%)]	Loss: -6.4468	Cost: 22.42s
Train Epoch: 1388 [61440/90000 (68%)]	Loss: -6.7221	Cost: 13.24s
Train Epoch: 1388 [81920/90000 (91%)]	Loss: -6.3271	Cost: 12.01s
Train Epoch: 1388 	Average Loss: -6.2343
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.8444

Learning rate: 9.532128844897905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1389 [0/90000 (0%)]	Loss: -2.0944	Cost: 61.07s
Train Epoch: 1389 [20480/90000 (23%)]	Loss: -5.2229	Cost: 7.59s
Train Epoch: 1389 [40960/90000 (45%)]	Loss: -4.9612	Cost: 9.92s
Train Epoch: 1389 [61440/90000 (68%)]	Loss: -5.4323	Cost: 9.08s
Train Epoch: 1389 [81920/90000 (91%)]	Loss: -5.7113	Cost: 11.11s
Train Epoch: 1389 	Average Loss: -5.2238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.6485

Learning rate: 9.531465171621007e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1390 [0/90000 (0%)]	Loss: -2.6760	Cost: 28.55s
Train Epoch: 1390 [20480/90000 (23%)]	Loss: -6.1022	Cost: 8.34s
Train Epoch: 1390 [40960/90000 (45%)]	Loss: -6.4273	Cost: 17.48s
Train Epoch: 1390 [61440/90000 (68%)]	Loss: -6.7130	Cost: 14.46s
Train Epoch: 1390 [81920/90000 (91%)]	Loss: -6.7676	Cost: 12.48s
Train Epoch: 1390 	Average Loss: -6.0778
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2009

Learning rate: 9.530801051106427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1391 [0/90000 (0%)]	Loss: -2.9700	Cost: 46.16s
Train Epoch: 1391 [20480/90000 (23%)]	Loss: -6.3980	Cost: 10.13s
Train Epoch: 1391 [40960/90000 (45%)]	Loss: -6.7182	Cost: 9.55s
Train Epoch: 1391 [61440/90000 (68%)]	Loss: -7.0177	Cost: 7.81s
Train Epoch: 1391 [81920/90000 (91%)]	Loss: -6.9946	Cost: 14.03s
Train Epoch: 1391 	Average Loss: -6.4875
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5276

Learning rate: 9.53013648341971e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1392 [0/90000 (0%)]	Loss: -2.7018	Cost: 28.65s
Train Epoch: 1392 [20480/90000 (23%)]	Loss: -7.0177	Cost: 10.79s
Train Epoch: 1392 [40960/90000 (45%)]	Loss: -6.9514	Cost: 14.37s
Train Epoch: 1392 [61440/90000 (68%)]	Loss: -7.2669	Cost: 12.47s
Train Epoch: 1392 [81920/90000 (91%)]	Loss: -6.6273	Cost: 12.34s
Train Epoch: 1392 	Average Loss: -6.5580
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9829

Learning rate: 9.529471468626449e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1393 [0/90000 (0%)]	Loss: -3.0444	Cost: 41.65s
Train Epoch: 1393 [20480/90000 (23%)]	Loss: -6.6388	Cost: 11.40s
Train Epoch: 1393 [40960/90000 (45%)]	Loss: -6.7458	Cost: 10.10s
Train Epoch: 1393 [61440/90000 (68%)]	Loss: -6.9956	Cost: 6.34s
Train Epoch: 1393 [81920/90000 (91%)]	Loss: -6.8988	Cost: 12.74s
Train Epoch: 1393 	Average Loss: -6.5100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4453

Learning rate: 9.528806006792274e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1394 [0/90000 (0%)]	Loss: -3.4696	Cost: 27.00s
Train Epoch: 1394 [20480/90000 (23%)]	Loss: -6.7636	Cost: 7.25s
Train Epoch: 1394 [40960/90000 (45%)]	Loss: -6.8945	Cost: 19.26s
Train Epoch: 1394 [61440/90000 (68%)]	Loss: -7.3068	Cost: 12.04s
Train Epoch: 1394 [81920/90000 (91%)]	Loss: -7.0023	Cost: 12.02s
Train Epoch: 1394 	Average Loss: -6.6158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4276

Learning rate: 9.528140097982867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1395 [0/90000 (0%)]	Loss: -3.4329	Cost: 39.48s
Train Epoch: 1395 [20480/90000 (23%)]	Loss: -7.1109	Cost: 12.21s
Train Epoch: 1395 [40960/90000 (45%)]	Loss: -6.9843	Cost: 11.99s
Train Epoch: 1395 [61440/90000 (68%)]	Loss: -7.4865	Cost: 9.38s
Train Epoch: 1395 [81920/90000 (91%)]	Loss: -7.3243	Cost: 7.16s
Train Epoch: 1395 	Average Loss: -6.8894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6490

Saving model as e1395_model.pt & e1395_waveforms_supplementary.hdf5
Learning rate: 9.52747374226395e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1396 [0/90000 (0%)]	Loss: -3.4599	Cost: 43.00s
Train Epoch: 1396 [20480/90000 (23%)]	Loss: -7.1089	Cost: 7.66s
Train Epoch: 1396 [40960/90000 (45%)]	Loss: -7.1979	Cost: 20.64s
Train Epoch: 1396 [61440/90000 (68%)]	Loss: -7.3628	Cost: 12.03s
Train Epoch: 1396 [81920/90000 (91%)]	Loss: -7.2860	Cost: 12.06s
Train Epoch: 1396 	Average Loss: -6.9256
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3741

Learning rate: 9.526806939701286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1397 [0/90000 (0%)]	Loss: -3.2288	Cost: 39.71s
Train Epoch: 1397 [20480/90000 (23%)]	Loss: -6.9848	Cost: 8.62s
Train Epoch: 1397 [40960/90000 (45%)]	Loss: -7.0076	Cost: 10.12s
Train Epoch: 1397 [61440/90000 (68%)]	Loss: -7.2441	Cost: 8.48s
Train Epoch: 1397 [81920/90000 (91%)]	Loss: -6.6170	Cost: 12.69s
Train Epoch: 1397 	Average Loss: -6.6593
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1355

Learning rate: 9.526139690360691e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1398 [0/90000 (0%)]	Loss: -3.0165	Cost: 31.03s
Train Epoch: 1398 [20480/90000 (23%)]	Loss: -6.4708	Cost: 7.09s
Train Epoch: 1398 [40960/90000 (45%)]	Loss: -6.6195	Cost: 18.28s
Train Epoch: 1398 [61440/90000 (68%)]	Loss: -6.8634	Cost: 13.05s
Train Epoch: 1398 [81920/90000 (91%)]	Loss: -7.0438	Cost: 11.98s
Train Epoch: 1398 	Average Loss: -6.3900
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4825

Learning rate: 9.525471994308019e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1399 [0/90000 (0%)]	Loss: -3.4949	Cost: 32.40s
Train Epoch: 1399 [20480/90000 (23%)]	Loss: -7.0766	Cost: 11.56s
Train Epoch: 1399 [40960/90000 (45%)]	Loss: -6.9607	Cost: 9.68s
Train Epoch: 1399 [61440/90000 (68%)]	Loss: -7.2308	Cost: 9.07s
Train Epoch: 1399 [81920/90000 (91%)]	Loss: -7.2663	Cost: 12.30s
Train Epoch: 1399 	Average Loss: -6.8168
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3519

Learning rate: 9.524803851609165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1400 [0/90000 (0%)]	Loss: -2.9794	Cost: 38.58s
Train Epoch: 1400 [20480/90000 (23%)]	Loss: -6.7295	Cost: 8.55s
Train Epoch: 1400 [40960/90000 (45%)]	Loss: -6.7879	Cost: 19.63s
Train Epoch: 1400 [61440/90000 (68%)]	Loss: -7.2158	Cost: 12.20s
Train Epoch: 1400 [81920/90000 (91%)]	Loss: -7.0531	Cost: 12.15s
Train Epoch: 1400 	Average Loss: -6.5960
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3312

Learning rate: 9.524135262330076e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1401 [0/90000 (0%)]	Loss: -3.2347	Cost: 48.36s
Train Epoch: 1401 [20480/90000 (23%)]	Loss: -6.6500	Cost: 11.95s
Train Epoch: 1401 [40960/90000 (45%)]	Loss: -6.6542	Cost: 6.87s
Train Epoch: 1401 [61440/90000 (68%)]	Loss: -7.1052	Cost: 6.37s
Train Epoch: 1401 [81920/90000 (91%)]	Loss: -7.0959	Cost: 12.18s
Train Epoch: 1401 	Average Loss: -6.5780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5349

Learning rate: 9.523466226536737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1402 [0/90000 (0%)]	Loss: -3.0776	Cost: 29.73s
Train Epoch: 1402 [20480/90000 (23%)]	Loss: -7.2663	Cost: 10.10s
Train Epoch: 1402 [40960/90000 (45%)]	Loss: -7.1202	Cost: 21.70s
Train Epoch: 1402 [61440/90000 (68%)]	Loss: -7.5702	Cost: 12.69s
Train Epoch: 1402 [81920/90000 (91%)]	Loss: -7.4221	Cost: 12.91s
Train Epoch: 1402 	Average Loss: -6.9354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6742

Saving model as e1402_model.pt & e1402_waveforms_supplementary.hdf5
Learning rate: 9.52279674429518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1403 [0/90000 (0%)]	Loss: -3.6311	Cost: 44.18s
Train Epoch: 1403 [20480/90000 (23%)]	Loss: -7.1681	Cost: 6.93s
Train Epoch: 1403 [40960/90000 (45%)]	Loss: -6.9339	Cost: 14.01s
Train Epoch: 1403 [61440/90000 (68%)]	Loss: -7.1580	Cost: 8.55s
Train Epoch: 1403 [81920/90000 (91%)]	Loss: -7.4215	Cost: 8.43s
Train Epoch: 1403 	Average Loss: -6.8526
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3849

Learning rate: 9.522126815671481e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1404 [0/90000 (0%)]	Loss: -3.6542	Cost: 30.84s
Train Epoch: 1404 [20480/90000 (23%)]	Loss: -6.7846	Cost: 9.48s
Train Epoch: 1404 [40960/90000 (45%)]	Loss: -6.7688	Cost: 15.21s
Train Epoch: 1404 [61440/90000 (68%)]	Loss: -7.4258	Cost: 13.31s
Train Epoch: 1404 [81920/90000 (91%)]	Loss: -6.9752	Cost: 12.13s
Train Epoch: 1404 	Average Loss: -6.6309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4045

Learning rate: 9.521456440731758e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1405 [0/90000 (0%)]	Loss: -3.0907	Cost: 42.75s
Train Epoch: 1405 [20480/90000 (23%)]	Loss: -7.2021	Cost: 12.10s
Train Epoch: 1405 [40960/90000 (45%)]	Loss: -7.0458	Cost: 10.08s
Train Epoch: 1405 [61440/90000 (68%)]	Loss: -7.2264	Cost: 6.08s
Train Epoch: 1405 [81920/90000 (91%)]	Loss: -7.1423	Cost: 7.77s
Train Epoch: 1405 	Average Loss: -6.9032
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7119

Saving model as e1405_model.pt & e1405_waveforms_supplementary.hdf5
Learning rate: 9.520785619542176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1406 [0/90000 (0%)]	Loss: -3.6589	Cost: 28.47s
Train Epoch: 1406 [20480/90000 (23%)]	Loss: -7.0748	Cost: 8.21s
Train Epoch: 1406 [40960/90000 (45%)]	Loss: -7.0243	Cost: 21.02s
Train Epoch: 1406 [61440/90000 (68%)]	Loss: -7.4002	Cost: 14.68s
Train Epoch: 1406 [81920/90000 (91%)]	Loss: -7.4446	Cost: 12.36s
Train Epoch: 1406 	Average Loss: -6.9516
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6854

Learning rate: 9.520114352168938e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1407 [0/90000 (0%)]	Loss: -3.1352	Cost: 60.15s
Train Epoch: 1407 [20480/90000 (23%)]	Loss: -7.0656	Cost: 7.77s
Train Epoch: 1407 [40960/90000 (45%)]	Loss: -6.8173	Cost: 11.36s
Train Epoch: 1407 [61440/90000 (68%)]	Loss: -6.6921	Cost: 8.78s
Train Epoch: 1407 [81920/90000 (91%)]	Loss: -6.4278	Cost: 8.93s
Train Epoch: 1407 	Average Loss: -6.5400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.3705

Learning rate: 9.519442638678302e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1408 [0/90000 (0%)]	Loss: -2.4346	Cost: 27.82s
Train Epoch: 1408 [20480/90000 (23%)]	Loss: -5.7857	Cost: 9.68s
Train Epoch: 1408 [40960/90000 (45%)]	Loss: -6.1859	Cost: 16.93s
Train Epoch: 1408 [61440/90000 (68%)]	Loss: -6.1229	Cost: 12.47s
Train Epoch: 1408 [81920/90000 (91%)]	Loss: -6.0232	Cost: 12.15s
Train Epoch: 1408 	Average Loss: -5.7441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7658

Learning rate: 9.518770479136558e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1409 [0/90000 (0%)]	Loss: -2.4437	Cost: 38.66s
Train Epoch: 1409 [20480/90000 (23%)]	Loss: -6.3116	Cost: 12.73s
Train Epoch: 1409 [40960/90000 (45%)]	Loss: -6.3465	Cost: 11.96s
Train Epoch: 1409 [61440/90000 (68%)]	Loss: -6.1957	Cost: 9.22s
Train Epoch: 1409 [81920/90000 (91%)]	Loss: -6.2856	Cost: 6.46s
Train Epoch: 1409 	Average Loss: -5.9096
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.9567

Learning rate: 9.518097873610047e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1410 [0/90000 (0%)]	Loss: -2.6940	Cost: 28.84s
Train Epoch: 1410 [20480/90000 (23%)]	Loss: -6.3845	Cost: 8.78s
Train Epoch: 1410 [40960/90000 (45%)]	Loss: -6.4087	Cost: 9.17s
Train Epoch: 1410 [61440/90000 (68%)]	Loss: -6.8502	Cost: 7.14s
Train Epoch: 1410 [81920/90000 (91%)]	Loss: -6.8884	Cost: 17.83s
Train Epoch: 1410 	Average Loss: -6.3118
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3702

Learning rate: 9.517424822165155e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1411 [0/90000 (0%)]	Loss: -3.2505	Cost: 36.73s
Train Epoch: 1411 [20480/90000 (23%)]	Loss: -6.8181	Cost: 9.57s
Train Epoch: 1411 [40960/90000 (45%)]	Loss: -6.7348	Cost: 18.71s
Train Epoch: 1411 [61440/90000 (68%)]	Loss: -6.9757	Cost: 12.13s
Train Epoch: 1411 [81920/90000 (91%)]	Loss: -6.8918	Cost: 6.47s
Train Epoch: 1411 	Average Loss: -6.5747
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2423

Learning rate: 9.516751324868306e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1412 [0/90000 (0%)]	Loss: -2.2466	Cost: 35.62s
Train Epoch: 1412 [20480/90000 (23%)]	Loss: -6.2465	Cost: 9.70s
Train Epoch: 1412 [40960/90000 (45%)]	Loss: -6.5979	Cost: 10.78s
Train Epoch: 1412 [61440/90000 (68%)]	Loss: -7.0211	Cost: 8.60s
Train Epoch: 1412 [81920/90000 (91%)]	Loss: -6.7841	Cost: 6.75s
Train Epoch: 1412 	Average Loss: -6.3682
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3528

Learning rate: 9.516077381785973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1413 [0/90000 (0%)]	Loss: -2.9324	Cost: 37.12s
Train Epoch: 1413 [20480/90000 (23%)]	Loss: -6.8910	Cost: 7.18s
Train Epoch: 1413 [40960/90000 (45%)]	Loss: -7.0135	Cost: 17.59s
Train Epoch: 1413 [61440/90000 (68%)]	Loss: -7.3334	Cost: 12.20s
Train Epoch: 1413 [81920/90000 (91%)]	Loss: -7.4124	Cost: 12.22s
Train Epoch: 1413 	Average Loss: -6.8009
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6531

Learning rate: 9.515402992984673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1414 [0/90000 (0%)]	Loss: -3.5097	Cost: 32.24s
Train Epoch: 1414 [20480/90000 (23%)]	Loss: -7.0740	Cost: 9.90s
Train Epoch: 1414 [40960/90000 (45%)]	Loss: -7.1422	Cost: 9.61s
Train Epoch: 1414 [61440/90000 (68%)]	Loss: -7.4757	Cost: 7.95s
Train Epoch: 1414 [81920/90000 (91%)]	Loss: -7.5173	Cost: 12.81s
Train Epoch: 1414 	Average Loss: -7.0303
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7746

Saving model as e1414_model.pt & e1414_waveforms_supplementary.hdf5
Learning rate: 9.514728158530964e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1415 [0/90000 (0%)]	Loss: -3.3552	Cost: 32.20s
Train Epoch: 1415 [20480/90000 (23%)]	Loss: -7.2356	Cost: 8.34s
Train Epoch: 1415 [40960/90000 (45%)]	Loss: -7.0427	Cost: 16.04s
Train Epoch: 1415 [61440/90000 (68%)]	Loss: -7.5536	Cost: 12.73s
Train Epoch: 1415 [81920/90000 (91%)]	Loss: -7.4432	Cost: 12.13s
Train Epoch: 1415 	Average Loss: -7.0027
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5703

Learning rate: 9.514052878491448e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1416 [0/90000 (0%)]	Loss: -3.2912	Cost: 32.58s
Train Epoch: 1416 [20480/90000 (23%)]	Loss: -6.4258	Cost: 11.80s
Train Epoch: 1416 [40960/90000 (45%)]	Loss: -6.8187	Cost: 9.87s
Train Epoch: 1416 [61440/90000 (68%)]	Loss: -7.1159	Cost: 8.32s
Train Epoch: 1416 [81920/90000 (91%)]	Loss: -6.8580	Cost: 12.46s
Train Epoch: 1416 	Average Loss: -6.4823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4715

Learning rate: 9.513377152932777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1417 [0/90000 (0%)]	Loss: -3.3481	Cost: 54.54s
Train Epoch: 1417 [20480/90000 (23%)]	Loss: -6.8292	Cost: 12.48s
Train Epoch: 1417 [40960/90000 (45%)]	Loss: -6.9519	Cost: 12.12s
Train Epoch: 1417 [61440/90000 (68%)]	Loss: -7.1079	Cost: 12.11s
Train Epoch: 1417 [81920/90000 (91%)]	Loss: -6.9488	Cost: 11.86s
Train Epoch: 1417 	Average Loss: -6.7101
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4229

Learning rate: 9.512700981921638e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1418 [0/90000 (0%)]	Loss: -3.0583	Cost: 41.31s
Train Epoch: 1418 [20480/90000 (23%)]	Loss: -7.1170	Cost: 6.32s
Train Epoch: 1418 [40960/90000 (45%)]	Loss: -7.2372	Cost: 14.56s
Train Epoch: 1418 [61440/90000 (68%)]	Loss: -7.5776	Cost: 8.56s
Train Epoch: 1418 [81920/90000 (91%)]	Loss: -7.4477	Cost: 9.06s
Train Epoch: 1418 	Average Loss: -6.9783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6383

Learning rate: 9.512024365524768e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1419 [0/90000 (0%)]	Loss: -3.4334	Cost: 31.06s
Train Epoch: 1419 [20480/90000 (23%)]	Loss: -7.3893	Cost: 13.26s
Train Epoch: 1419 [40960/90000 (45%)]	Loss: -7.4604	Cost: 15.03s
Train Epoch: 1419 [61440/90000 (68%)]	Loss: -7.6051	Cost: 13.13s
Train Epoch: 1419 [81920/90000 (91%)]	Loss: -7.5284	Cost: 12.05s
Train Epoch: 1419 	Average Loss: -7.1433
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6543

Learning rate: 9.511347303808946e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1420 [0/90000 (0%)]	Loss: -3.7921	Cost: 47.05s
Train Epoch: 1420 [20480/90000 (23%)]	Loss: -7.2778	Cost: 11.02s
Train Epoch: 1420 [40960/90000 (45%)]	Loss: -7.0118	Cost: 8.41s
Train Epoch: 1420 [61440/90000 (68%)]	Loss: -7.0379	Cost: 6.81s
Train Epoch: 1420 [81920/90000 (91%)]	Loss: -6.5668	Cost: 12.66s
Train Epoch: 1420 	Average Loss: -6.7220
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1777

Learning rate: 9.510669796840995e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1421 [0/90000 (0%)]	Loss: -3.1112	Cost: 31.35s
Train Epoch: 1421 [20480/90000 (23%)]	Loss: -6.8181	Cost: 8.83s
Train Epoch: 1421 [40960/90000 (45%)]	Loss: -7.0481	Cost: 18.39s
Train Epoch: 1421 [61440/90000 (68%)]	Loss: -7.3502	Cost: 12.99s
Train Epoch: 1421 [81920/90000 (91%)]	Loss: -7.3683	Cost: 11.87s
Train Epoch: 1421 	Average Loss: -6.7783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7089

Learning rate: 9.509991844687784e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1422 [0/90000 (0%)]	Loss: -2.9219	Cost: 51.97s
Train Epoch: 1422 [20480/90000 (23%)]	Loss: -7.2736	Cost: 9.01s
Train Epoch: 1422 [40960/90000 (45%)]	Loss: -7.4314	Cost: 7.77s
Train Epoch: 1422 [61440/90000 (68%)]	Loss: -7.6593	Cost: 7.08s
Train Epoch: 1422 [81920/90000 (91%)]	Loss: -7.5089	Cost: 12.78s
Train Epoch: 1422 	Average Loss: -7.0981
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8846

Saving model as e1422_model.pt & e1422_waveforms_supplementary.hdf5
Learning rate: 9.509313447416221e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1423 [0/90000 (0%)]	Loss: -3.6746	Cost: 27.43s
Train Epoch: 1423 [20480/90000 (23%)]	Loss: -7.2116	Cost: 10.55s
Train Epoch: 1423 [40960/90000 (45%)]	Loss: -7.4664	Cost: 21.70s
Train Epoch: 1423 [61440/90000 (68%)]	Loss: -7.7512	Cost: 13.64s
Train Epoch: 1423 [81920/90000 (91%)]	Loss: -7.4963	Cost: 12.15s
Train Epoch: 1423 	Average Loss: -7.1738
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7862

Learning rate: 9.508634605093264e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1424 [0/90000 (0%)]	Loss: -3.1237	Cost: 40.84s
Train Epoch: 1424 [20480/90000 (23%)]	Loss: -7.3560	Cost: 12.02s
Train Epoch: 1424 [40960/90000 (45%)]	Loss: -7.4503	Cost: 10.97s
Train Epoch: 1424 [61440/90000 (68%)]	Loss: -7.5681	Cost: 6.57s
Train Epoch: 1424 [81920/90000 (91%)]	Loss: -7.3021	Cost: 15.01s
Train Epoch: 1424 	Average Loss: -7.1631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7366

Learning rate: 9.507955317785911e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1425 [0/90000 (0%)]	Loss: -3.9314	Cost: 31.77s
Train Epoch: 1425 [20480/90000 (23%)]	Loss: -6.8516	Cost: 8.63s
Train Epoch: 1425 [40960/90000 (45%)]	Loss: -6.7391	Cost: 15.59s
Train Epoch: 1425 [61440/90000 (68%)]	Loss: -6.1758	Cost: 12.27s
Train Epoch: 1425 [81920/90000 (91%)]	Loss: -6.0159	Cost: 12.28s
Train Epoch: 1425 	Average Loss: -6.3163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -2.7953

Learning rate: 9.507275585561206e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1426 [0/90000 (0%)]	Loss: -2.5491	Cost: 52.22s
Train Epoch: 1426 [20480/90000 (23%)]	Loss: -6.3285	Cost: 9.25s
Train Epoch: 1426 [40960/90000 (45%)]	Loss: -6.5680	Cost: 9.98s
Train Epoch: 1426 [61440/90000 (68%)]	Loss: -6.9323	Cost: 8.14s
Train Epoch: 1426 [81920/90000 (91%)]	Loss: -6.9169	Cost: 10.85s
Train Epoch: 1426 	Average Loss: -6.3227
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.2936

Learning rate: 9.506595408486236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1427 [0/90000 (0%)]	Loss: -2.4122	Cost: 29.04s
Train Epoch: 1427 [20480/90000 (23%)]	Loss: -6.7594	Cost: 6.99s
Train Epoch: 1427 [40960/90000 (45%)]	Loss: -6.9865	Cost: 17.54s
Train Epoch: 1427 [61440/90000 (68%)]	Loss: -7.5410	Cost: 12.14s
Train Epoch: 1427 [81920/90000 (91%)]	Loss: -7.4844	Cost: 12.35s
Train Epoch: 1427 	Average Loss: -6.8070
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7391

Learning rate: 9.505914786628128e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1428 [0/90000 (0%)]	Loss: -3.3287	Cost: 33.69s
Train Epoch: 1428 [20480/90000 (23%)]	Loss: -7.4485	Cost: 11.33s
Train Epoch: 1428 [40960/90000 (45%)]	Loss: -7.5515	Cost: 9.87s
Train Epoch: 1428 [61440/90000 (68%)]	Loss: -8.0032	Cost: 7.65s
Train Epoch: 1428 [81920/90000 (91%)]	Loss: -7.8153	Cost: 15.76s
Train Epoch: 1428 	Average Loss: -7.3063
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9740

Saving model as e1428_model.pt & e1428_waveforms_supplementary.hdf5
Learning rate: 9.505233720054063e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1429 [0/90000 (0%)]	Loss: -3.5327	Cost: 36.82s
Train Epoch: 1429 [20480/90000 (23%)]	Loss: -7.2861	Cost: 10.14s
Train Epoch: 1429 [40960/90000 (45%)]	Loss: -7.2036	Cost: 15.31s
Train Epoch: 1429 [61440/90000 (68%)]	Loss: -7.2585	Cost: 12.14s
Train Epoch: 1429 [81920/90000 (91%)]	Loss: -7.3743	Cost: 12.01s
Train Epoch: 1429 	Average Loss: -6.9967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6722

Learning rate: 9.504552208831255e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1430 [0/90000 (0%)]	Loss: -3.8670	Cost: 35.45s
Train Epoch: 1430 [20480/90000 (23%)]	Loss: -7.1283	Cost: 11.84s
Train Epoch: 1430 [40960/90000 (45%)]	Loss: -6.9611	Cost: 8.50s
Train Epoch: 1430 [61440/90000 (68%)]	Loss: -7.2491	Cost: 6.43s
Train Epoch: 1430 [81920/90000 (91%)]	Loss: -6.9992	Cost: 14.16s
Train Epoch: 1430 	Average Loss: -6.8502
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4101

Learning rate: 9.503870253026966e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1431 [0/90000 (0%)]	Loss: -3.0509	Cost: 36.37s
Train Epoch: 1431 [20480/90000 (23%)]	Loss: -7.0214	Cost: 10.89s
Train Epoch: 1431 [40960/90000 (45%)]	Loss: -7.2324	Cost: 20.47s
Train Epoch: 1431 [61440/90000 (68%)]	Loss: -7.5393	Cost: 12.01s
Train Epoch: 1431 [81920/90000 (91%)]	Loss: -7.5646	Cost: 12.02s
Train Epoch: 1431 	Average Loss: -7.0447
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8254

Learning rate: 9.503187852708506e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1432 [0/90000 (0%)]	Loss: -4.1042	Cost: 41.91s
Train Epoch: 1432 [20480/90000 (23%)]	Loss: -7.4886	Cost: 6.31s
Train Epoch: 1432 [40960/90000 (45%)]	Loss: -7.5397	Cost: 13.79s
Train Epoch: 1432 [61440/90000 (68%)]	Loss: -7.8940	Cost: 9.00s
Train Epoch: 1432 [81920/90000 (91%)]	Loss: -7.6881	Cost: 11.22s
Train Epoch: 1432 	Average Loss: -7.3524
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9239

Learning rate: 9.502505007943222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1433 [0/90000 (0%)]	Loss: -3.0740	Cost: 31.38s
Train Epoch: 1433 [20480/90000 (23%)]	Loss: -7.6648	Cost: 10.91s
Train Epoch: 1433 [40960/90000 (45%)]	Loss: -7.5558	Cost: 17.33s
Train Epoch: 1433 [61440/90000 (68%)]	Loss: -7.7698	Cost: 12.27s
Train Epoch: 1433 [81920/90000 (91%)]	Loss: -7.4116	Cost: 12.07s
Train Epoch: 1433 	Average Loss: -7.2508
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6589

Learning rate: 9.50182171879851e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1434 [0/90000 (0%)]	Loss: -3.5671	Cost: 34.44s
Train Epoch: 1434 [20480/90000 (23%)]	Loss: -7.3867	Cost: 9.56s
Train Epoch: 1434 [40960/90000 (45%)]	Loss: -7.4647	Cost: 10.19s
Train Epoch: 1434 [61440/90000 (68%)]	Loss: -7.4638	Cost: 6.55s
Train Epoch: 1434 [81920/90000 (91%)]	Loss: -7.4871	Cost: 13.48s
Train Epoch: 1434 	Average Loss: -7.1882
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7760

Learning rate: 9.501137985341808e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1435 [0/90000 (0%)]	Loss: -3.1295	Cost: 25.35s
Train Epoch: 1435 [20480/90000 (23%)]	Loss: -7.0476	Cost: 9.31s
Train Epoch: 1435 [40960/90000 (45%)]	Loss: -6.5309	Cost: 16.39s
Train Epoch: 1435 [61440/90000 (68%)]	Loss: -6.7190	Cost: 14.30s
Train Epoch: 1435 [81920/90000 (91%)]	Loss: -7.0668	Cost: 14.91s
Train Epoch: 1435 	Average Loss: -6.6218
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3047

Learning rate: 9.500453807640594e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1436 [0/90000 (0%)]	Loss: -2.4846	Cost: 51.72s
Train Epoch: 1436 [20480/90000 (23%)]	Loss: -6.6490	Cost: 12.30s
Train Epoch: 1436 [40960/90000 (45%)]	Loss: -7.0015	Cost: 7.15s
Train Epoch: 1436 [61440/90000 (68%)]	Loss: -7.3665	Cost: 6.33s
Train Epoch: 1436 [81920/90000 (91%)]	Loss: -7.3133	Cost: 12.81s
Train Epoch: 1436 	Average Loss: -6.6751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7347

Learning rate: 9.4997691857624e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1437 [0/90000 (0%)]	Loss: -3.6335	Cost: 29.28s
Train Epoch: 1437 [20480/90000 (23%)]	Loss: -7.4790	Cost: 6.92s
Train Epoch: 1437 [40960/90000 (45%)]	Loss: -7.1855	Cost: 18.45s
Train Epoch: 1437 [61440/90000 (68%)]	Loss: -7.2649	Cost: 12.64s
Train Epoch: 1437 [81920/90000 (91%)]	Loss: -6.8858	Cost: 12.08s
Train Epoch: 1437 	Average Loss: -6.9935
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4244

Learning rate: 9.49908411977479e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1438 [0/90000 (0%)]	Loss: -3.2142	Cost: 33.40s
Train Epoch: 1438 [20480/90000 (23%)]	Loss: -7.1268	Cost: 12.30s
Train Epoch: 1438 [40960/90000 (45%)]	Loss: -7.0709	Cost: 7.59s
Train Epoch: 1438 [61440/90000 (68%)]	Loss: -7.6419	Cost: 6.44s
Train Epoch: 1438 [81920/90000 (91%)]	Loss: -7.5921	Cost: 13.74s
Train Epoch: 1438 	Average Loss: -6.9802
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8535

Learning rate: 9.49839860974538e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1439 [0/90000 (0%)]	Loss: -3.6827	Cost: 29.75s
Train Epoch: 1439 [20480/90000 (23%)]	Loss: -7.4956	Cost: 7.72s
Train Epoch: 1439 [40960/90000 (45%)]	Loss: -7.5717	Cost: 23.31s
Train Epoch: 1439 [61440/90000 (68%)]	Loss: -7.8820	Cost: 12.32s
Train Epoch: 1439 [81920/90000 (91%)]	Loss: -7.8183	Cost: 12.23s
Train Epoch: 1439 	Average Loss: -7.3061
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9894

Saving model as e1439_model.pt & e1439_waveforms_supplementary.hdf5
Learning rate: 9.497712655741827e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1440 [0/90000 (0%)]	Loss: -3.7113	Cost: 40.61s
Train Epoch: 1440 [20480/90000 (23%)]	Loss: -7.6452	Cost: 9.43s
Train Epoch: 1440 [40960/90000 (45%)]	Loss: -7.6408	Cost: 11.75s
Train Epoch: 1440 [61440/90000 (68%)]	Loss: -7.6507	Cost: 8.16s
Train Epoch: 1440 [81920/90000 (91%)]	Loss: -7.6552	Cost: 10.64s
Train Epoch: 1440 	Average Loss: -7.3346
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8773

Learning rate: 9.497026257831831e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1441 [0/90000 (0%)]	Loss: -3.3793	Cost: 42.14s
Train Epoch: 1441 [20480/90000 (23%)]	Loss: -7.4182	Cost: 6.56s
Train Epoch: 1441 [40960/90000 (45%)]	Loss: -7.6634	Cost: 17.90s
Train Epoch: 1441 [61440/90000 (68%)]	Loss: -7.8605	Cost: 11.97s
Train Epoch: 1441 [81920/90000 (91%)]	Loss: -7.7654	Cost: 12.07s
Train Epoch: 1441 	Average Loss: -7.3534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0500

Saving model as e1441_model.pt & e1441_waveforms_supplementary.hdf5
Learning rate: 9.496339416083137e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1442 [0/90000 (0%)]	Loss: -3.5103	Cost: 31.78s
Train Epoch: 1442 [20480/90000 (23%)]	Loss: -7.5399	Cost: 6.92s
Train Epoch: 1442 [40960/90000 (45%)]	Loss: -7.5908	Cost: 16.51s
Train Epoch: 1442 [61440/90000 (68%)]	Loss: -7.9581	Cost: 8.80s
Train Epoch: 1442 [81920/90000 (91%)]	Loss: -7.8430	Cost: 9.38s
Train Epoch: 1442 	Average Loss: -7.3542
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0020

Learning rate: 9.495652130563534e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1443 [0/90000 (0%)]	Loss: -3.5966	Cost: 30.29s
Train Epoch: 1443 [20480/90000 (23%)]	Loss: -7.5799	Cost: 7.75s
Train Epoch: 1443 [40960/90000 (45%)]	Loss: -7.6545	Cost: 17.94s
Train Epoch: 1443 [61440/90000 (68%)]	Loss: -7.9124	Cost: 13.36s
Train Epoch: 1443 [81920/90000 (91%)]	Loss: -7.7242	Cost: 12.04s
Train Epoch: 1443 	Average Loss: -7.4375
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9586

Learning rate: 9.494964401340855e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1444 [0/90000 (0%)]	Loss: -3.8578	Cost: 35.18s
Train Epoch: 1444 [20480/90000 (23%)]	Loss: -7.6004	Cost: 10.31s
Train Epoch: 1444 [40960/90000 (45%)]	Loss: -7.7936	Cost: 9.69s
Train Epoch: 1444 [61440/90000 (68%)]	Loss: -7.9806	Cost: 6.32s
Train Epoch: 1444 [81920/90000 (91%)]	Loss: -7.8533	Cost: 14.37s
Train Epoch: 1444 	Average Loss: -7.4751
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1305

Saving model as e1444_model.pt & e1444_waveforms_supplementary.hdf5
Learning rate: 9.494276228482974e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1445 [0/90000 (0%)]	Loss: -3.8668	Cost: 34.31s
Train Epoch: 1445 [20480/90000 (23%)]	Loss: -7.5654	Cost: 7.55s
Train Epoch: 1445 [40960/90000 (45%)]	Loss: -7.5708	Cost: 18.30s
Train Epoch: 1445 [61440/90000 (68%)]	Loss: -8.0390	Cost: 12.04s
Train Epoch: 1445 [81920/90000 (91%)]	Loss: -7.5627	Cost: 12.11s
Train Epoch: 1445 	Average Loss: -7.3745
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6557

Learning rate: 9.493587612057813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1446 [0/90000 (0%)]	Loss: -2.9859	Cost: 41.04s
Train Epoch: 1446 [20480/90000 (23%)]	Loss: -7.2959	Cost: 11.99s
Train Epoch: 1446 [40960/90000 (45%)]	Loss: -7.3066	Cost: 11.96s
Train Epoch: 1446 [61440/90000 (68%)]	Loss: -7.6860	Cost: 5.99s
Train Epoch: 1446 [81920/90000 (91%)]	Loss: -7.6449	Cost: 6.80s
Train Epoch: 1446 	Average Loss: -7.0956
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9976

Learning rate: 9.492898552133333e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1447 [0/90000 (0%)]	Loss: -3.5803	Cost: 29.14s
Train Epoch: 1447 [20480/90000 (23%)]	Loss: -7.5367	Cost: 11.02s
Train Epoch: 1447 [40960/90000 (45%)]	Loss: -7.2964	Cost: 22.91s
Train Epoch: 1447 [61440/90000 (68%)]	Loss: -7.4585	Cost: 14.13s
Train Epoch: 1447 [81920/90000 (91%)]	Loss: -7.4839	Cost: 11.87s
Train Epoch: 1447 	Average Loss: -7.1863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9357

Learning rate: 9.492209048777545e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1448 [0/90000 (0%)]	Loss: -3.3195	Cost: 53.14s
Train Epoch: 1448 [20480/90000 (23%)]	Loss: -7.1789	Cost: 6.25s
Train Epoch: 1448 [40960/90000 (45%)]	Loss: -7.4570	Cost: 14.69s
Train Epoch: 1448 [61440/90000 (68%)]	Loss: -7.8479	Cost: 8.68s
Train Epoch: 1448 [81920/90000 (91%)]	Loss: -7.7997	Cost: 9.42s
Train Epoch: 1448 	Average Loss: -7.2260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0978

Learning rate: 9.491519102058499e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1449 [0/90000 (0%)]	Loss: -3.8963	Cost: 30.61s
Train Epoch: 1449 [20480/90000 (23%)]	Loss: -7.4169	Cost: 12.94s
Train Epoch: 1449 [40960/90000 (45%)]	Loss: -7.5796	Cost: 15.30s
Train Epoch: 1449 [61440/90000 (68%)]	Loss: -7.6636	Cost: 12.34s
Train Epoch: 1449 [81920/90000 (91%)]	Loss: -7.6326	Cost: 12.40s
Train Epoch: 1449 	Average Loss: -7.3190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8374

Learning rate: 9.490828712044288e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1450 [0/90000 (0%)]	Loss: -3.3910	Cost: 41.71s
Train Epoch: 1450 [20480/90000 (23%)]	Loss: -7.4815	Cost: 12.12s
Train Epoch: 1450 [40960/90000 (45%)]	Loss: -7.5514	Cost: 7.11s
Train Epoch: 1450 [61440/90000 (68%)]	Loss: -7.8487	Cost: 6.18s
Train Epoch: 1450 [81920/90000 (91%)]	Loss: -7.8959	Cost: 14.52s
Train Epoch: 1450 	Average Loss: -7.4336
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1178

Learning rate: 9.490137878803053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1451 [0/90000 (0%)]	Loss: -3.7960	Cost: 26.30s
Train Epoch: 1451 [20480/90000 (23%)]	Loss: -7.8380	Cost: 10.09s
Train Epoch: 1451 [40960/90000 (45%)]	Loss: -7.7129	Cost: 15.64s
Train Epoch: 1451 [61440/90000 (68%)]	Loss: -7.8029	Cost: 12.45s
Train Epoch: 1451 [81920/90000 (91%)]	Loss: -7.7488	Cost: 12.23s
Train Epoch: 1451 	Average Loss: -7.3867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8499

Learning rate: 9.489446602402978e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1452 [0/90000 (0%)]	Loss: -3.6350	Cost: 51.51s
Train Epoch: 1452 [20480/90000 (23%)]	Loss: -7.5819	Cost: 7.87s
Train Epoch: 1452 [40960/90000 (45%)]	Loss: -7.3547	Cost: 12.70s
Train Epoch: 1452 [61440/90000 (68%)]	Loss: -7.7509	Cost: 8.54s
Train Epoch: 1452 [81920/90000 (91%)]	Loss: -7.4556	Cost: 8.82s
Train Epoch: 1452 	Average Loss: -7.2955
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6852

Learning rate: 9.488754882912286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1453 [0/90000 (0%)]	Loss: -3.3656	Cost: 34.14s
Train Epoch: 1453 [20480/90000 (23%)]	Loss: -7.5165	Cost: 6.75s
Train Epoch: 1453 [40960/90000 (45%)]	Loss: -7.5976	Cost: 18.52s
Train Epoch: 1453 [61440/90000 (68%)]	Loss: -7.8053	Cost: 12.26s
Train Epoch: 1453 [81920/90000 (91%)]	Loss: -7.8607	Cost: 12.00s
Train Epoch: 1453 	Average Loss: -7.3494
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0078

Learning rate: 9.488062720399246e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1454 [0/90000 (0%)]	Loss: -3.7593	Cost: 33.20s
Train Epoch: 1454 [20480/90000 (23%)]	Loss: -7.4425	Cost: 11.96s
Train Epoch: 1454 [40960/90000 (45%)]	Loss: -7.4388	Cost: 8.02s
Train Epoch: 1454 [61440/90000 (68%)]	Loss: -7.3569	Cost: 6.38s
Train Epoch: 1454 [81920/90000 (91%)]	Loss: -7.2498	Cost: 14.93s
Train Epoch: 1454 	Average Loss: -7.0656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.6211

Learning rate: 9.487370114932177e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1455 [0/90000 (0%)]	Loss: -3.4479	Cost: 36.87s
Train Epoch: 1455 [20480/90000 (23%)]	Loss: -7.5211	Cost: 9.35s
Train Epoch: 1455 [40960/90000 (45%)]	Loss: -7.6648	Cost: 16.97s
Train Epoch: 1455 [61440/90000 (68%)]	Loss: -7.8454	Cost: 12.28s
Train Epoch: 1455 [81920/90000 (91%)]	Loss: -7.8916	Cost: 11.91s
Train Epoch: 1455 	Average Loss: -7.3473
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0263

Learning rate: 9.486677066579433e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1456 [0/90000 (0%)]	Loss: -3.8608	Cost: 36.55s
Train Epoch: 1456 [20480/90000 (23%)]	Loss: -7.6706	Cost: 8.73s
Train Epoch: 1456 [40960/90000 (45%)]	Loss: -7.7307	Cost: 10.95s
Train Epoch: 1456 [61440/90000 (68%)]	Loss: -8.1952	Cost: 6.23s
Train Epoch: 1456 [81920/90000 (91%)]	Loss: -8.0401	Cost: 13.47s
Train Epoch: 1456 	Average Loss: -7.5602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1408

Saving model as e1456_model.pt & e1456_waveforms_supplementary.hdf5
Learning rate: 9.485983575409414e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1457 [0/90000 (0%)]	Loss: -3.8769	Cost: 29.01s
Train Epoch: 1457 [20480/90000 (23%)]	Loss: -7.9539	Cost: 8.24s
Train Epoch: 1457 [40960/90000 (45%)]	Loss: -7.6401	Cost: 18.85s
Train Epoch: 1457 [61440/90000 (68%)]	Loss: -7.5992	Cost: 12.80s
Train Epoch: 1457 [81920/90000 (91%)]	Loss: -7.5013	Cost: 12.01s
Train Epoch: 1457 	Average Loss: -7.3829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8237

Learning rate: 9.485289641490566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1458 [0/90000 (0%)]	Loss: -3.8438	Cost: 50.97s
Train Epoch: 1458 [20480/90000 (23%)]	Loss: -7.5738	Cost: 6.18s
Train Epoch: 1458 [40960/90000 (45%)]	Loss: -7.5781	Cost: 14.00s
Train Epoch: 1458 [61440/90000 (68%)]	Loss: -8.1298	Cost: 8.94s
Train Epoch: 1458 [81920/90000 (91%)]	Loss: -7.9756	Cost: 10.97s
Train Epoch: 1458 	Average Loss: -7.4915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1734

Saving model as e1458_model.pt & e1458_waveforms_supplementary.hdf5
Learning rate: 9.484595264891378e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1459 [0/90000 (0%)]	Loss: -4.0450	Cost: 27.67s
Train Epoch: 1459 [20480/90000 (23%)]	Loss: -7.8122	Cost: 14.63s
Train Epoch: 1459 [40960/90000 (45%)]	Loss: -7.7554	Cost: 17.13s
Train Epoch: 1459 [61440/90000 (68%)]	Loss: -8.0172	Cost: 13.02s
Train Epoch: 1459 [81920/90000 (91%)]	Loss: -7.8967	Cost: 12.20s
Train Epoch: 1459 	Average Loss: -7.5782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1522

Learning rate: 9.483900445680383e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1460 [0/90000 (0%)]	Loss: -4.2947	Cost: 32.72s
Train Epoch: 1460 [20480/90000 (23%)]	Loss: -7.6882	Cost: 11.53s
Train Epoch: 1460 [40960/90000 (45%)]	Loss: -7.7879	Cost: 13.89s
Train Epoch: 1460 [61440/90000 (68%)]	Loss: -8.1218	Cost: 7.90s
Train Epoch: 1460 [81920/90000 (91%)]	Loss: -7.8545	Cost: 12.93s
Train Epoch: 1460 	Average Loss: -7.5553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1268

Learning rate: 9.483205183926155e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1461 [0/90000 (0%)]	Loss: -4.1085	Cost: 39.32s
Train Epoch: 1461 [20480/90000 (23%)]	Loss: -7.4617	Cost: 10.04s
Train Epoch: 1461 [40960/90000 (45%)]	Loss: -7.5017	Cost: 15.40s
Train Epoch: 1461 [61440/90000 (68%)]	Loss: -7.7624	Cost: 12.10s
Train Epoch: 1461 [81920/90000 (91%)]	Loss: -7.8608	Cost: 12.23s
Train Epoch: 1461 	Average Loss: -7.4088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1030

Learning rate: 9.482509479697314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1462 [0/90000 (0%)]	Loss: -3.6318	Cost: 38.99s
Train Epoch: 1462 [20480/90000 (23%)]	Loss: -7.7351	Cost: 12.15s
Train Epoch: 1462 [40960/90000 (45%)]	Loss: -7.7034	Cost: 7.02s
Train Epoch: 1462 [61440/90000 (68%)]	Loss: -8.2155	Cost: 6.29s
Train Epoch: 1462 [81920/90000 (91%)]	Loss: -8.1632	Cost: 15.47s
Train Epoch: 1462 	Average Loss: -7.6324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1981

Saving model as e1462_model.pt & e1462_waveforms_supplementary.hdf5
Learning rate: 9.481813333062525e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1463 [0/90000 (0%)]	Loss: -4.0455	Cost: 29.81s
Train Epoch: 1463 [20480/90000 (23%)]	Loss: -7.8266	Cost: 8.39s
Train Epoch: 1463 [40960/90000 (45%)]	Loss: -7.8920	Cost: 16.67s
Train Epoch: 1463 [61440/90000 (68%)]	Loss: -8.2580	Cost: 12.08s
Train Epoch: 1463 [81920/90000 (91%)]	Loss: -8.0907	Cost: 12.20s
Train Epoch: 1463 	Average Loss: -7.7232
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2702

Saving model as e1463_model.pt & e1463_waveforms_supplementary.hdf5
Learning rate: 9.481116744090494e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1464 [0/90000 (0%)]	Loss: -4.3495	Cost: 30.89s
Train Epoch: 1464 [20480/90000 (23%)]	Loss: -7.7704	Cost: 10.77s
Train Epoch: 1464 [40960/90000 (45%)]	Loss: -6.3121	Cost: 7.27s
Train Epoch: 1464 [61440/90000 (68%)]	Loss: -6.1413	Cost: 6.96s
Train Epoch: 1464 [81920/90000 (91%)]	Loss: -6.6235	Cost: 15.55s
Train Epoch: 1464 	Average Loss: -6.6512
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.1115

Learning rate: 9.48041971284997e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1465 [0/90000 (0%)]	Loss: -3.0897	Cost: 31.64s
Train Epoch: 1465 [20480/90000 (23%)]	Loss: -6.5965	Cost: 10.88s
Train Epoch: 1465 [40960/90000 (45%)]	Loss: -6.9033	Cost: 21.75s
Train Epoch: 1465 [61440/90000 (68%)]	Loss: -7.4168	Cost: 12.13s
Train Epoch: 1465 [81920/90000 (91%)]	Loss: -7.2897	Cost: 11.84s
Train Epoch: 1465 	Average Loss: -6.6725
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7150

Learning rate: 9.479722239409749e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1466 [0/90000 (0%)]	Loss: -3.2783	Cost: 40.61s
Train Epoch: 1466 [20480/90000 (23%)]	Loss: -7.2595	Cost: 11.03s
Train Epoch: 1466 [40960/90000 (45%)]	Loss: -7.1875	Cost: 7.15s
Train Epoch: 1466 [61440/90000 (68%)]	Loss: -7.6567	Cost: 6.39s
Train Epoch: 1466 [81920/90000 (91%)]	Loss: -7.6264	Cost: 14.78s
Train Epoch: 1466 	Average Loss: -7.1068
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9731

Learning rate: 9.479024323838667e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1467 [0/90000 (0%)]	Loss: -3.8693	Cost: 39.78s
Train Epoch: 1467 [20480/90000 (23%)]	Loss: -7.6727	Cost: 6.75s
Train Epoch: 1467 [40960/90000 (45%)]	Loss: -7.9738	Cost: 18.07s
Train Epoch: 1467 [61440/90000 (68%)]	Loss: -8.1030	Cost: 12.10s
Train Epoch: 1467 [81920/90000 (91%)]	Loss: -7.7812	Cost: 11.87s
Train Epoch: 1467 	Average Loss: -7.5441
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0136

Learning rate: 9.478325966205609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1468 [0/90000 (0%)]	Loss: -3.8761	Cost: 31.95s
Train Epoch: 1468 [20480/90000 (23%)]	Loss: -7.6791	Cost: 9.41s
Train Epoch: 1468 [40960/90000 (45%)]	Loss: -7.8587	Cost: 10.20s
Train Epoch: 1468 [61440/90000 (68%)]	Loss: -8.0814	Cost: 6.22s
Train Epoch: 1468 [81920/90000 (91%)]	Loss: -7.9235	Cost: 10.58s
Train Epoch: 1468 	Average Loss: -7.5211
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1450

Learning rate: 9.477627166579498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1469 [0/90000 (0%)]	Loss: -4.4897	Cost: 26.80s
Train Epoch: 1469 [20480/90000 (23%)]	Loss: -7.7299	Cost: 11.00s
Train Epoch: 1469 [40960/90000 (45%)]	Loss: -7.5282	Cost: 23.85s
Train Epoch: 1469 [61440/90000 (68%)]	Loss: -7.9019	Cost: 12.54s
Train Epoch: 1469 [81920/90000 (91%)]	Loss: -7.9314	Cost: 12.03s
Train Epoch: 1469 	Average Loss: -7.5302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1238

Learning rate: 9.4769279250293e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1470 [0/90000 (0%)]	Loss: -3.7543	Cost: 43.99s
Train Epoch: 1470 [20480/90000 (23%)]	Loss: -7.6243	Cost: 12.27s
Train Epoch: 1470 [40960/90000 (45%)]	Loss: -7.8041	Cost: 10.76s
Train Epoch: 1470 [61440/90000 (68%)]	Loss: -8.0273	Cost: 6.07s
Train Epoch: 1470 [81920/90000 (91%)]	Loss: -7.9819	Cost: 8.01s
Train Epoch: 1470 	Average Loss: -7.5300
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1021

Learning rate: 9.476228241624034e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1471 [0/90000 (0%)]	Loss: -4.0065	Cost: 26.99s
Train Epoch: 1471 [20480/90000 (23%)]	Loss: -7.5804	Cost: 9.12s
Train Epoch: 1471 [40960/90000 (45%)]	Loss: -7.7283	Cost: 17.65s
Train Epoch: 1471 [61440/90000 (68%)]	Loss: -8.0764	Cost: 12.68s
Train Epoch: 1471 [81920/90000 (91%)]	Loss: -7.9242	Cost: 12.60s
Train Epoch: 1471 	Average Loss: -7.5146
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0390

Learning rate: 9.47552811643275e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1472 [0/90000 (0%)]	Loss: -4.4506	Cost: 41.63s
Train Epoch: 1472 [20480/90000 (23%)]	Loss: -7.6683	Cost: 12.07s
Train Epoch: 1472 [40960/90000 (45%)]	Loss: -7.9095	Cost: 8.97s
Train Epoch: 1472 [61440/90000 (68%)]	Loss: -8.4349	Cost: 6.77s
Train Epoch: 1472 [81920/90000 (91%)]	Loss: -8.1077	Cost: 10.52s
Train Epoch: 1472 	Average Loss: -7.6676
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1843

Learning rate: 9.47482754952455e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1473 [0/90000 (0%)]	Loss: -3.8371	Cost: 27.58s
Train Epoch: 1473 [20480/90000 (23%)]	Loss: -7.8558	Cost: 6.69s
Train Epoch: 1473 [40960/90000 (45%)]	Loss: -7.7721	Cost: 21.68s
Train Epoch: 1473 [61440/90000 (68%)]	Loss: -7.9940	Cost: 14.59s
Train Epoch: 1473 [81920/90000 (91%)]	Loss: -8.2327	Cost: 15.04s
Train Epoch: 1473 	Average Loss: -7.6084
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2358

Learning rate: 9.474126540968577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1474 [0/90000 (0%)]	Loss: -3.6763	Cost: 55.71s
Train Epoch: 1474 [20480/90000 (23%)]	Loss: -7.5688	Cost: 12.11s
Train Epoch: 1474 [40960/90000 (45%)]	Loss: -7.5361	Cost: 8.94s
Train Epoch: 1474 [61440/90000 (68%)]	Loss: -7.9460	Cost: 6.29s
Train Epoch: 1474 [81920/90000 (91%)]	Loss: -7.9593	Cost: 9.03s
Train Epoch: 1474 	Average Loss: -7.3918
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0421

Learning rate: 9.473425090834017e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1475 [0/90000 (0%)]	Loss: -4.0715	Cost: 32.56s
Train Epoch: 1475 [20480/90000 (23%)]	Loss: -7.6200	Cost: 8.78s
Train Epoch: 1475 [40960/90000 (45%)]	Loss: -7.8624	Cost: 8.38s
Train Epoch: 1475 [61440/90000 (68%)]	Loss: -8.0769	Cost: 7.27s
Train Epoch: 1475 [81920/90000 (91%)]	Loss: -8.1150	Cost: 17.42s
Train Epoch: 1475 	Average Loss: -7.5576
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1673

Learning rate: 9.472723199190101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1476 [0/90000 (0%)]	Loss: -4.1525	Cost: 33.61s
Train Epoch: 1476 [20480/90000 (23%)]	Loss: -7.6745	Cost: 13.76s
Train Epoch: 1476 [40960/90000 (45%)]	Loss: -7.7888	Cost: 11.97s
Train Epoch: 1476 [61440/90000 (68%)]	Loss: -8.3260	Cost: 12.00s
Train Epoch: 1476 [81920/90000 (91%)]	Loss: -8.0011	Cost: 7.58s
Train Epoch: 1476 	Average Loss: -7.6378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2670

Learning rate: 9.472020866106103e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1477 [0/90000 (0%)]	Loss: -3.8794	Cost: 32.14s
Train Epoch: 1477 [20480/90000 (23%)]	Loss: -7.7444	Cost: 8.16s
Train Epoch: 1477 [40960/90000 (45%)]	Loss: -7.6439	Cost: 11.97s
Train Epoch: 1477 [61440/90000 (68%)]	Loss: -8.0326	Cost: 8.64s
Train Epoch: 1477 [81920/90000 (91%)]	Loss: -7.6434	Cost: 7.02s
Train Epoch: 1477 	Average Loss: -7.5544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9228

Learning rate: 9.471318091651342e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1478 [0/90000 (0%)]	Loss: -3.6283	Cost: 29.19s
Train Epoch: 1478 [20480/90000 (23%)]	Loss: -7.6954	Cost: 7.83s
Train Epoch: 1478 [40960/90000 (45%)]	Loss: -7.5079	Cost: 17.84s
Train Epoch: 1478 [61440/90000 (68%)]	Loss: -7.7823	Cost: 13.21s
Train Epoch: 1478 [81920/90000 (91%)]	Loss: -7.9116	Cost: 12.33s
Train Epoch: 1478 	Average Loss: -7.4056
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9962

Learning rate: 9.470614875895176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1479 [0/90000 (0%)]	Loss: -3.7732	Cost: 33.67s
Train Epoch: 1479 [20480/90000 (23%)]	Loss: -7.8827	Cost: 9.78s
Train Epoch: 1479 [40960/90000 (45%)]	Loss: -7.9856	Cost: 12.88s
Train Epoch: 1479 [61440/90000 (68%)]	Loss: -8.2990	Cost: 8.36s
Train Epoch: 1479 [81920/90000 (91%)]	Loss: -8.1701	Cost: 13.56s
Train Epoch: 1479 	Average Loss: -7.7185
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3053

Saving model as e1479_model.pt & e1479_waveforms_supplementary.hdf5
Learning rate: 9.46991121890701e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1480 [0/90000 (0%)]	Loss: -3.9219	Cost: 40.96s
Train Epoch: 1480 [20480/90000 (23%)]	Loss: -7.9054	Cost: 11.28s
Train Epoch: 1480 [40960/90000 (45%)]	Loss: -7.8874	Cost: 13.56s
Train Epoch: 1480 [61440/90000 (68%)]	Loss: -8.3679	Cost: 12.14s
Train Epoch: 1480 [81920/90000 (91%)]	Loss: -8.2668	Cost: 12.05s
Train Epoch: 1480 	Average Loss: -7.7655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3286

Saving model as e1480_model.pt & e1480_waveforms_supplementary.hdf5
Learning rate: 9.469207120756294e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1481 [0/90000 (0%)]	Loss: -4.0646	Cost: 41.68s
Train Epoch: 1481 [20480/90000 (23%)]	Loss: -8.0536	Cost: 9.38s
Train Epoch: 1481 [40960/90000 (45%)]	Loss: -8.0693	Cost: 7.98s
Train Epoch: 1481 [61440/90000 (68%)]	Loss: -8.3540	Cost: 6.91s
Train Epoch: 1481 [81920/90000 (91%)]	Loss: -8.2411	Cost: 13.31s
Train Epoch: 1481 	Average Loss: -7.8491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2649

Learning rate: 9.468502581512518e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1482 [0/90000 (0%)]	Loss: -3.9009	Cost: 34.98s
Train Epoch: 1482 [20480/90000 (23%)]	Loss: -8.0523	Cost: 10.26s
Train Epoch: 1482 [40960/90000 (45%)]	Loss: -7.5465	Cost: 20.09s
Train Epoch: 1482 [61440/90000 (68%)]	Loss: -8.0245	Cost: 12.44s
Train Epoch: 1482 [81920/90000 (91%)]	Loss: -7.9638	Cost: 11.90s
Train Epoch: 1482 	Average Loss: -7.5660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7728

Learning rate: 9.46779760124522e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1483 [0/90000 (0%)]	Loss: -3.4240	Cost: 37.84s
Train Epoch: 1483 [20480/90000 (23%)]	Loss: -7.2580	Cost: 11.99s
Train Epoch: 1483 [40960/90000 (45%)]	Loss: -7.4643	Cost: 8.01s
Train Epoch: 1483 [61440/90000 (68%)]	Loss: -7.9197	Cost: 6.39s
Train Epoch: 1483 [81920/90000 (91%)]	Loss: -7.9087	Cost: 14.54s
Train Epoch: 1483 	Average Loss: -7.2903
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9944

Learning rate: 9.467092180023976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1484 [0/90000 (0%)]	Loss: -3.8656	Cost: 31.63s
Train Epoch: 1484 [20480/90000 (23%)]	Loss: -7.8218	Cost: 9.00s
Train Epoch: 1484 [40960/90000 (45%)]	Loss: -7.8092	Cost: 20.84s
Train Epoch: 1484 [61440/90000 (68%)]	Loss: -8.4541	Cost: 12.47s
Train Epoch: 1484 [81920/90000 (91%)]	Loss: -8.3121	Cost: 12.11s
Train Epoch: 1484 	Average Loss: -7.7177
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2756

Learning rate: 9.46638631791841e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1485 [0/90000 (0%)]	Loss: -4.0585	Cost: 40.17s
Train Epoch: 1485 [20480/90000 (23%)]	Loss: -8.0974	Cost: 7.31s
Train Epoch: 1485 [40960/90000 (45%)]	Loss: -8.0082	Cost: 11.55s
Train Epoch: 1485 [61440/90000 (68%)]	Loss: -8.4292	Cost: 8.51s
Train Epoch: 1485 [81920/90000 (91%)]	Loss: -8.1558	Cost: 9.56s
Train Epoch: 1485 	Average Loss: -7.8720
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1413

Learning rate: 9.465680014998187e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1486 [0/90000 (0%)]	Loss: -3.8744	Cost: 27.68s
Train Epoch: 1486 [20480/90000 (23%)]	Loss: -7.9131	Cost: 6.81s
Train Epoch: 1486 [40960/90000 (45%)]	Loss: -8.1030	Cost: 19.03s
Train Epoch: 1486 [61440/90000 (68%)]	Loss: -8.0771	Cost: 14.74s
Train Epoch: 1486 [81920/90000 (91%)]	Loss: -7.5716	Cost: 12.30s
Train Epoch: 1486 	Average Loss: -7.5695
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7840

Learning rate: 9.464973271333016e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1487 [0/90000 (0%)]	Loss: -3.3543	Cost: 33.20s
Train Epoch: 1487 [20480/90000 (23%)]	Loss: -7.3513	Cost: 13.26s
Train Epoch: 1487 [40960/90000 (45%)]	Loss: -7.6416	Cost: 13.43s
Train Epoch: 1487 [61440/90000 (68%)]	Loss: -8.0321	Cost: 6.76s
Train Epoch: 1487 [81920/90000 (91%)]	Loss: -8.0870	Cost: 6.67s
Train Epoch: 1487 	Average Loss: -7.3917
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0939

Learning rate: 9.464266086992651e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1488 [0/90000 (0%)]	Loss: -3.9223	Cost: 31.94s
Train Epoch: 1488 [20480/90000 (23%)]	Loss: -7.4849	Cost: 8.11s
Train Epoch: 1488 [40960/90000 (45%)]	Loss: -7.3206	Cost: 13.52s
Train Epoch: 1488 [61440/90000 (68%)]	Loss: -7.9139	Cost: 10.32s
Train Epoch: 1488 [81920/90000 (91%)]	Loss: -8.0192	Cost: 15.52s
Train Epoch: 1488 	Average Loss: -7.3655
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0544

Learning rate: 9.463558462046886e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1489 [0/90000 (0%)]	Loss: -3.3297	Cost: 43.76s
Train Epoch: 1489 [20480/90000 (23%)]	Loss: -7.7767	Cost: 12.27s
Train Epoch: 1489 [40960/90000 (45%)]	Loss: -7.7644	Cost: 13.03s
Train Epoch: 1489 [61440/90000 (68%)]	Loss: -8.1549	Cost: 7.82s
Train Epoch: 1489 [81920/90000 (91%)]	Loss: -8.0998	Cost: 6.49s
Train Epoch: 1489 	Average Loss: -7.5630
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1808

Learning rate: 9.462850396565563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1490 [0/90000 (0%)]	Loss: -4.3662	Cost: 31.68s
Train Epoch: 1490 [20480/90000 (23%)]	Loss: -7.9434	Cost: 9.09s
Train Epoch: 1490 [40960/90000 (45%)]	Loss: -8.0520	Cost: 11.03s
Train Epoch: 1490 [61440/90000 (68%)]	Loss: -8.3534	Cost: 8.64s
Train Epoch: 1490 [81920/90000 (91%)]	Loss: -8.1644	Cost: 7.31s
Train Epoch: 1490 	Average Loss: -7.7950
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2143

Learning rate: 9.462141890618565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1491 [0/90000 (0%)]	Loss: -4.0830	Cost: 29.78s
Train Epoch: 1491 [20480/90000 (23%)]	Loss: -7.8031	Cost: 8.62s
Train Epoch: 1491 [40960/90000 (45%)]	Loss: -7.7841	Cost: 16.08s
Train Epoch: 1491 [61440/90000 (68%)]	Loss: -8.0872	Cost: 11.92s
Train Epoch: 1491 [81920/90000 (91%)]	Loss: -7.6871	Cost: 12.16s
Train Epoch: 1491 	Average Loss: -7.5364
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9388

Learning rate: 9.461432944275817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1492 [0/90000 (0%)]	Loss: -3.9758	Cost: 33.04s
Train Epoch: 1492 [20480/90000 (23%)]	Loss: -7.6262	Cost: 11.79s
Train Epoch: 1492 [40960/90000 (45%)]	Loss: -7.7425	Cost: 6.89s
Train Epoch: 1492 [61440/90000 (68%)]	Loss: -8.3073	Cost: 7.04s
Train Epoch: 1492 [81920/90000 (91%)]	Loss: -8.0528	Cost: 15.30s
Train Epoch: 1492 	Average Loss: -7.6531
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1730

Learning rate: 9.46072355760729e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1493 [0/90000 (0%)]	Loss: -3.7921	Cost: 34.39s
Train Epoch: 1493 [20480/90000 (23%)]	Loss: -7.9141	Cost: 10.23s
Train Epoch: 1493 [40960/90000 (45%)]	Loss: -7.9571	Cost: 21.47s
Train Epoch: 1493 [61440/90000 (68%)]	Loss: -8.4372	Cost: 12.15s
Train Epoch: 1493 [81920/90000 (91%)]	Loss: -8.1671	Cost: 12.16s
Train Epoch: 1493 	Average Loss: -7.7525
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.5234

Learning rate: 9.460013730682999e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1494 [0/90000 (0%)]	Loss: -3.5349	Cost: 34.30s
Train Epoch: 1494 [20480/90000 (23%)]	Loss: -5.8598	Cost: 8.52s
Train Epoch: 1494 [40960/90000 (45%)]	Loss: -6.4988	Cost: 11.28s
Train Epoch: 1494 [61440/90000 (68%)]	Loss: -7.0301	Cost: 8.79s
Train Epoch: 1494 [81920/90000 (91%)]	Loss: -7.4184	Cost: 13.24s
Train Epoch: 1494 	Average Loss: -6.3426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7943

Learning rate: 9.459303463572999e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1495 [0/90000 (0%)]	Loss: -3.1287	Cost: 30.15s
Train Epoch: 1495 [20480/90000 (23%)]	Loss: -7.4399	Cost: 8.03s
Train Epoch: 1495 [40960/90000 (45%)]	Loss: -7.4732	Cost: 19.38s
Train Epoch: 1495 [61440/90000 (68%)]	Loss: -7.8186	Cost: 12.89s
Train Epoch: 1495 [81920/90000 (91%)]	Loss: -7.0836	Cost: 11.97s
Train Epoch: 1495 	Average Loss: -7.1091
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4132

Learning rate: 9.458592756347392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1496 [0/90000 (0%)]	Loss: -3.5256	Cost: 32.97s
Train Epoch: 1496 [20480/90000 (23%)]	Loss: -7.4148	Cost: 11.09s
Train Epoch: 1496 [40960/90000 (45%)]	Loss: -7.4427	Cost: 9.33s
Train Epoch: 1496 [61440/90000 (68%)]	Loss: -8.1163	Cost: 6.53s
Train Epoch: 1496 [81920/90000 (91%)]	Loss: -7.9097	Cost: 16.88s
Train Epoch: 1496 	Average Loss: -7.2829
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0227

Learning rate: 9.457881609076323e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1497 [0/90000 (0%)]	Loss: -3.3860	Cost: 36.69s
Train Epoch: 1497 [20480/90000 (23%)]	Loss: -7.4571	Cost: 8.43s
Train Epoch: 1497 [40960/90000 (45%)]	Loss: -7.6396	Cost: 19.68s
Train Epoch: 1497 [61440/90000 (68%)]	Loss: -7.3943	Cost: 11.98s
Train Epoch: 1497 [81920/90000 (91%)]	Loss: -7.1369	Cost: 12.14s
Train Epoch: 1497 	Average Loss: -7.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.4815

Learning rate: 9.457170021829978e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1498 [0/90000 (0%)]	Loss: -3.3156	Cost: 48.34s
Train Epoch: 1498 [20480/90000 (23%)]	Loss: -7.0769	Cost: 11.08s
Train Epoch: 1498 [40960/90000 (45%)]	Loss: -7.4720	Cost: 8.63s
Train Epoch: 1498 [61440/90000 (68%)]	Loss: -7.9147	Cost: 6.19s
Train Epoch: 1498 [81920/90000 (91%)]	Loss: -7.9726	Cost: 13.99s
Train Epoch: 1498 	Average Loss: -7.1976
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0515

Learning rate: 9.456457994678588e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1499 [0/90000 (0%)]	Loss: -3.5305	Cost: 34.88s
Train Epoch: 1499 [20480/90000 (23%)]	Loss: -7.9640	Cost: 11.18s
Train Epoch: 1499 [40960/90000 (45%)]	Loss: -8.1397	Cost: 21.04s
Train Epoch: 1499 [61440/90000 (68%)]	Loss: -8.3446	Cost: 12.20s
Train Epoch: 1499 [81920/90000 (91%)]	Loss: -8.2514	Cost: 11.82s
Train Epoch: 1499 	Average Loss: -7.8159
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2192

Learning rate: 9.455745527692427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1500 [0/90000 (0%)]	Loss: -4.2671	Cost: 32.91s
Train Epoch: 1500 [20480/90000 (23%)]	Loss: -7.8636	Cost: 11.66s
Train Epoch: 1500 [40960/90000 (45%)]	Loss: -7.6782	Cost: 7.68s
Train Epoch: 1500 [61440/90000 (68%)]	Loss: -8.0670	Cost: 6.33s
Train Epoch: 1500 [81920/90000 (91%)]	Loss: -8.1365	Cost: 14.01s
Train Epoch: 1500 	Average Loss: -7.6640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1933

Learning rate: 9.455032620941813e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1501 [0/90000 (0%)]	Loss: -3.8148	Cost: 31.99s
Train Epoch: 1501 [20480/90000 (23%)]	Loss: -7.4447	Cost: 10.69s
Train Epoch: 1501 [40960/90000 (45%)]	Loss: -7.4945	Cost: 14.47s
Train Epoch: 1501 [61440/90000 (68%)]	Loss: -7.7425	Cost: 12.51s
Train Epoch: 1501 [81920/90000 (91%)]	Loss: -7.6016	Cost: 12.19s
Train Epoch: 1501 	Average Loss: -7.2910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8055

Learning rate: 9.454319274497107e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1502 [0/90000 (0%)]	Loss: -3.6324	Cost: 39.50s
Train Epoch: 1502 [20480/90000 (23%)]	Loss: -7.4508	Cost: 9.98s
Train Epoch: 1502 [40960/90000 (45%)]	Loss: -7.7681	Cost: 9.95s
Train Epoch: 1502 [61440/90000 (68%)]	Loss: -8.0992	Cost: 6.16s
Train Epoch: 1502 [81920/90000 (91%)]	Loss: -8.2025	Cost: 10.99s
Train Epoch: 1502 	Average Loss: -7.5007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3379

Saving model as e1502_model.pt & e1502_waveforms_supplementary.hdf5
Learning rate: 9.453605488428713e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1503 [0/90000 (0%)]	Loss: -4.2326	Cost: 28.70s
Train Epoch: 1503 [20480/90000 (23%)]	Loss: -8.1591	Cost: 6.88s
Train Epoch: 1503 [40960/90000 (45%)]	Loss: -8.0067	Cost: 23.38s
Train Epoch: 1503 [61440/90000 (68%)]	Loss: -8.3808	Cost: 13.64s
Train Epoch: 1503 [81920/90000 (91%)]	Loss: -8.0726	Cost: 17.39s
Train Epoch: 1503 	Average Loss: -7.8237
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8710

Learning rate: 9.452891262807079e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1504 [0/90000 (0%)]	Loss: -4.1359	Cost: 35.88s
Train Epoch: 1504 [20480/90000 (23%)]	Loss: -7.8670	Cost: 13.99s
Train Epoch: 1504 [40960/90000 (45%)]	Loss: -7.8479	Cost: 10.54s
Train Epoch: 1504 [61440/90000 (68%)]	Loss: -8.0205	Cost: 6.64s
Train Epoch: 1504 [81920/90000 (91%)]	Loss: -8.0653	Cost: 11.99s
Train Epoch: 1504 	Average Loss: -7.6145
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0805

Learning rate: 9.452176597702696e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1505 [0/90000 (0%)]	Loss: -4.0395	Cost: 33.70s
Train Epoch: 1505 [20480/90000 (23%)]	Loss: -7.9121	Cost: 8.06s
Train Epoch: 1505 [40960/90000 (45%)]	Loss: -7.9365	Cost: 16.62s
Train Epoch: 1505 [61440/90000 (68%)]	Loss: -8.3029	Cost: 12.75s
Train Epoch: 1505 [81920/90000 (91%)]	Loss: -8.3054	Cost: 12.07s
Train Epoch: 1505 	Average Loss: -7.8028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2947

Learning rate: 9.4514614931861e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1506 [0/90000 (0%)]	Loss: -4.1968	Cost: 41.38s
Train Epoch: 1506 [20480/90000 (23%)]	Loss: -7.9478	Cost: 10.79s
Train Epoch: 1506 [40960/90000 (45%)]	Loss: -8.0759	Cost: 9.64s
Train Epoch: 1506 [61440/90000 (68%)]	Loss: -8.0607	Cost: 6.71s
Train Epoch: 1506 [81920/90000 (91%)]	Loss: -7.6342	Cost: 12.73s
Train Epoch: 1506 	Average Loss: -7.6169
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9817

Learning rate: 9.450745949327868e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1507 [0/90000 (0%)]	Loss: -3.6118	Cost: 32.03s
Train Epoch: 1507 [20480/90000 (23%)]	Loss: -7.6141	Cost: 6.26s
Train Epoch: 1507 [40960/90000 (45%)]	Loss: -8.0507	Cost: 15.38s
Train Epoch: 1507 [61440/90000 (68%)]	Loss: -8.2812	Cost: 12.42s
Train Epoch: 1507 [81920/90000 (91%)]	Loss: -8.1259	Cost: 12.54s
Train Epoch: 1507 	Average Loss: -7.6124
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3498

Saving model as e1507_model.pt & e1507_waveforms_supplementary.hdf5
Learning rate: 9.450029966198623e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1508 [0/90000 (0%)]	Loss: -4.0601	Cost: 32.66s
Train Epoch: 1508 [20480/90000 (23%)]	Loss: -8.1633	Cost: 10.66s
Train Epoch: 1508 [40960/90000 (45%)]	Loss: -8.2364	Cost: 11.37s
Train Epoch: 1508 [61440/90000 (68%)]	Loss: -8.5276	Cost: 9.58s
Train Epoch: 1508 [81920/90000 (91%)]	Loss: -8.3832	Cost: 15.84s
Train Epoch: 1508 	Average Loss: -7.9077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3975

Saving model as e1508_model.pt & e1508_waveforms_supplementary.hdf5
Learning rate: 9.449313543869027e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1509 [0/90000 (0%)]	Loss: -4.4116	Cost: 33.98s
Train Epoch: 1509 [20480/90000 (23%)]	Loss: -8.1546	Cost: 9.22s
Train Epoch: 1509 [40960/90000 (45%)]	Loss: -7.8997	Cost: 14.46s
Train Epoch: 1509 [61440/90000 (68%)]	Loss: -8.3829	Cost: 12.31s
Train Epoch: 1509 [81920/90000 (91%)]	Loss: -8.1858	Cost: 12.21s
Train Epoch: 1509 	Average Loss: -7.8478
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2630

Learning rate: 9.448596682409789e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1510 [0/90000 (0%)]	Loss: -4.1060	Cost: 34.49s
Train Epoch: 1510 [20480/90000 (23%)]	Loss: -8.0779	Cost: 12.08s
Train Epoch: 1510 [40960/90000 (45%)]	Loss: -7.6882	Cost: 9.24s
Train Epoch: 1510 [61440/90000 (68%)]	Loss: -7.9271	Cost: 6.32s
Train Epoch: 1510 [81920/90000 (91%)]	Loss: -8.2471	Cost: 12.33s
Train Epoch: 1510 	Average Loss: -7.6194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1968

Learning rate: 9.447879381891662e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1511 [0/90000 (0%)]	Loss: -4.1226	Cost: 36.36s
Train Epoch: 1511 [20480/90000 (23%)]	Loss: -8.0214	Cost: 8.04s
Train Epoch: 1511 [40960/90000 (45%)]	Loss: -8.2994	Cost: 20.93s
Train Epoch: 1511 [61440/90000 (68%)]	Loss: -8.6312	Cost: 12.28s
Train Epoch: 1511 [81920/90000 (91%)]	Loss: -8.5434	Cost: 12.11s
Train Epoch: 1511 	Average Loss: -7.9980
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5584

Saving model as e1511_model.pt & e1511_waveforms_supplementary.hdf5
Learning rate: 9.447161642385438e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1512 [0/90000 (0%)]	Loss: -4.1435	Cost: 32.91s
Train Epoch: 1512 [20480/90000 (23%)]	Loss: -8.2764	Cost: 9.00s
Train Epoch: 1512 [40960/90000 (45%)]	Loss: -8.4509	Cost: 19.95s
Train Epoch: 1512 [61440/90000 (68%)]	Loss: -8.6755	Cost: 8.67s
Train Epoch: 1512 [81920/90000 (91%)]	Loss: -8.4691	Cost: 9.49s
Train Epoch: 1512 	Average Loss: -8.0799
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4146

Learning rate: 9.446443463961957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1513 [0/90000 (0%)]	Loss: -4.2496	Cost: 35.51s
Train Epoch: 1513 [20480/90000 (23%)]	Loss: -8.3781	Cost: 10.23s
Train Epoch: 1513 [40960/90000 (45%)]	Loss: -8.1773	Cost: 19.70s
Train Epoch: 1513 [61440/90000 (68%)]	Loss: -8.5228	Cost: 11.87s
Train Epoch: 1513 [81920/90000 (91%)]	Loss: -8.4232	Cost: 12.09s
Train Epoch: 1513 	Average Loss: -8.0758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3726

Learning rate: 9.4457248466921e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1514 [0/90000 (0%)]	Loss: -3.9895	Cost: 48.99s
Train Epoch: 1514 [20480/90000 (23%)]	Loss: -7.9349	Cost: 6.41s
Train Epoch: 1514 [40960/90000 (45%)]	Loss: -7.9772	Cost: 13.79s
Train Epoch: 1514 [61440/90000 (68%)]	Loss: -8.3781	Cost: 8.73s
Train Epoch: 1514 [81920/90000 (91%)]	Loss: -8.1217	Cost: 8.75s
Train Epoch: 1514 	Average Loss: -7.8176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2223

Learning rate: 9.44500579064679e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1515 [0/90000 (0%)]	Loss: -4.3020	Cost: 32.39s
Train Epoch: 1515 [20480/90000 (23%)]	Loss: -7.8954	Cost: 12.28s
Train Epoch: 1515 [40960/90000 (45%)]	Loss: -7.9965	Cost: 20.86s
Train Epoch: 1515 [61440/90000 (68%)]	Loss: -8.1932	Cost: 12.47s
Train Epoch: 1515 [81920/90000 (91%)]	Loss: -8.1337	Cost: 11.92s
Train Epoch: 1515 	Average Loss: -7.7544
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1440

Learning rate: 9.444286295896998e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1516 [0/90000 (0%)]	Loss: -4.3030	Cost: 49.31s
Train Epoch: 1516 [20480/90000 (23%)]	Loss: -8.0282	Cost: 6.69s
Train Epoch: 1516 [40960/90000 (45%)]	Loss: -8.0774	Cost: 14.09s
Train Epoch: 1516 [61440/90000 (68%)]	Loss: -8.5143	Cost: 8.51s
Train Epoch: 1516 [81920/90000 (91%)]	Loss: -8.4311	Cost: 6.41s
Train Epoch: 1516 	Average Loss: -7.9491
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3196

Learning rate: 9.443566362513733e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1517 [0/90000 (0%)]	Loss: -4.4403	Cost: 29.10s
Train Epoch: 1517 [20480/90000 (23%)]	Loss: -7.9248	Cost: 9.98s
Train Epoch: 1517 [40960/90000 (45%)]	Loss: -8.0021	Cost: 17.69s
Train Epoch: 1517 [61440/90000 (68%)]	Loss: -8.3985	Cost: 13.03s
Train Epoch: 1517 [81920/90000 (91%)]	Loss: -8.5110	Cost: 11.90s
Train Epoch: 1517 	Average Loss: -7.8716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4622

Learning rate: 9.442845990568051e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1518 [0/90000 (0%)]	Loss: -4.3520	Cost: 33.29s
Train Epoch: 1518 [20480/90000 (23%)]	Loss: -8.3142	Cost: 6.85s
Train Epoch: 1518 [40960/90000 (45%)]	Loss: -8.3609	Cost: 15.83s
Train Epoch: 1518 [61440/90000 (68%)]	Loss: -8.5653	Cost: 8.59s
Train Epoch: 1518 [81920/90000 (91%)]	Loss: -8.5395	Cost: 8.77s
Train Epoch: 1518 	Average Loss: -8.1363
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6063

Saving model as e1518_model.pt & e1518_waveforms_supplementary.hdf5
Learning rate: 9.442125180131048e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1519 [0/90000 (0%)]	Loss: -4.5725	Cost: 29.57s
Train Epoch: 1519 [20480/90000 (23%)]	Loss: -8.0175	Cost: 7.08s
Train Epoch: 1519 [40960/90000 (45%)]	Loss: -8.1403	Cost: 18.29s
Train Epoch: 1519 [61440/90000 (68%)]	Loss: -8.4200	Cost: 14.19s
Train Epoch: 1519 [81920/90000 (91%)]	Loss: -8.2860	Cost: 12.33s
Train Epoch: 1519 	Average Loss: -7.9172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1397

Learning rate: 9.441403931273867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1520 [0/90000 (0%)]	Loss: -4.2020	Cost: 36.30s
Train Epoch: 1520 [20480/90000 (23%)]	Loss: -8.1595	Cost: 11.40s
Train Epoch: 1520 [40960/90000 (45%)]	Loss: -8.3999	Cost: 9.30s
Train Epoch: 1520 [61440/90000 (68%)]	Loss: -8.3161	Cost: 8.94s
Train Epoch: 1520 [81920/90000 (91%)]	Loss: -8.2789	Cost: 12.21s
Train Epoch: 1520 	Average Loss: -7.9689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4607

Learning rate: 9.440682244067694e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1521 [0/90000 (0%)]	Loss: -3.8392	Cost: 33.06s
Train Epoch: 1521 [20480/90000 (23%)]	Loss: -8.2600	Cost: 9.86s
Train Epoch: 1521 [40960/90000 (45%)]	Loss: -8.3004	Cost: 10.44s
Train Epoch: 1521 [61440/90000 (68%)]	Loss: -8.6239	Cost: 7.07s
Train Epoch: 1521 [81920/90000 (91%)]	Loss: -8.2796	Cost: 19.46s
Train Epoch: 1521 	Average Loss: -8.0094
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3720

Learning rate: 9.439960118583752e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1522 [0/90000 (0%)]	Loss: -4.4092	Cost: 39.58s
Train Epoch: 1522 [20480/90000 (23%)]	Loss: -8.2708	Cost: 10.43s
Train Epoch: 1522 [40960/90000 (45%)]	Loss: -8.4087	Cost: 12.22s
Train Epoch: 1522 [61440/90000 (68%)]	Loss: -8.6877	Cost: 11.94s
Train Epoch: 1522 [81920/90000 (91%)]	Loss: -8.3786	Cost: 7.29s
Train Epoch: 1522 	Average Loss: -8.0583
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2529

Learning rate: 9.439237554893315e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1523 [0/90000 (0%)]	Loss: -3.5753	Cost: 30.09s
Train Epoch: 1523 [20480/90000 (23%)]	Loss: -8.1499	Cost: 9.06s
Train Epoch: 1523 [40960/90000 (45%)]	Loss: -8.4132	Cost: 11.17s
Train Epoch: 1523 [61440/90000 (68%)]	Loss: -8.8389	Cost: 7.89s
Train Epoch: 1523 [81920/90000 (91%)]	Loss: -8.6846	Cost: 8.50s
Train Epoch: 1523 	Average Loss: -8.1257
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5113

Learning rate: 9.438514553067697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1524 [0/90000 (0%)]	Loss: -4.0347	Cost: 38.24s
Train Epoch: 1524 [20480/90000 (23%)]	Loss: -8.1876	Cost: 12.96s
Train Epoch: 1524 [40960/90000 (45%)]	Loss: -8.0234	Cost: 12.32s
Train Epoch: 1524 [61440/90000 (68%)]	Loss: -8.3484	Cost: 12.29s
Train Epoch: 1524 [81920/90000 (91%)]	Loss: -8.3420	Cost: 11.90s
Train Epoch: 1524 	Average Loss: -7.9573
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3656

Learning rate: 9.437791113178254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1525 [0/90000 (0%)]	Loss: -4.4064	Cost: 30.79s
Train Epoch: 1525 [20480/90000 (23%)]	Loss: -8.2340	Cost: 7.64s
Train Epoch: 1525 [40960/90000 (45%)]	Loss: -7.9089	Cost: 14.11s
Train Epoch: 1525 [61440/90000 (68%)]	Loss: -8.5484	Cost: 9.80s
Train Epoch: 1525 [81920/90000 (91%)]	Loss: -8.1909	Cost: 9.92s
Train Epoch: 1525 	Average Loss: -7.9180
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9781

Learning rate: 9.437067235296389e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1526 [0/90000 (0%)]	Loss: -3.9990	Cost: 33.39s
Train Epoch: 1526 [20480/90000 (23%)]	Loss: -8.0032	Cost: 13.88s
Train Epoch: 1526 [40960/90000 (45%)]	Loss: -8.2005	Cost: 17.16s
Train Epoch: 1526 [61440/90000 (68%)]	Loss: -8.5439	Cost: 12.31s
Train Epoch: 1526 [81920/90000 (91%)]	Loss: -8.5508	Cost: 11.78s
Train Epoch: 1526 	Average Loss: -7.9756
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4812

Learning rate: 9.436342919493543e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1527 [0/90000 (0%)]	Loss: -4.0610	Cost: 36.44s
Train Epoch: 1527 [20480/90000 (23%)]	Loss: -8.3768	Cost: 11.10s
Train Epoch: 1527 [40960/90000 (45%)]	Loss: -8.4221	Cost: 10.28s
Train Epoch: 1527 [61440/90000 (68%)]	Loss: -8.4696	Cost: 8.39s
Train Epoch: 1527 [81920/90000 (91%)]	Loss: -8.2372	Cost: 11.77s
Train Epoch: 1527 	Average Loss: -8.0354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.8104

Learning rate: 9.435618165841206e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1528 [0/90000 (0%)]	Loss: -3.7503	Cost: 36.52s
Train Epoch: 1528 [20480/90000 (23%)]	Loss: -7.7562	Cost: 6.98s
Train Epoch: 1528 [40960/90000 (45%)]	Loss: -7.3191	Cost: 17.75s
Train Epoch: 1528 [61440/90000 (68%)]	Loss: -7.1116	Cost: 12.20s
Train Epoch: 1528 [81920/90000 (91%)]	Loss: -6.9585	Cost: 12.08s
Train Epoch: 1528 	Average Loss: -7.0619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.3269

Learning rate: 9.434892974410905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1529 [0/90000 (0%)]	Loss: -3.5876	Cost: 31.37s
Train Epoch: 1529 [20480/90000 (23%)]	Loss: -6.2925	Cost: 11.81s
Train Epoch: 1529 [40960/90000 (45%)]	Loss: -5.9861	Cost: 7.60s
Train Epoch: 1529 [61440/90000 (68%)]	Loss: -6.9225	Cost: 6.47s
Train Epoch: 1529 [81920/90000 (91%)]	Loss: -7.2671	Cost: 14.87s
Train Epoch: 1529 	Average Loss: -6.4090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7925

Learning rate: 9.434167345274215e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1530 [0/90000 (0%)]	Loss: -3.4195	Cost: 30.02s
Train Epoch: 1530 [20480/90000 (23%)]	Loss: -7.5374	Cost: 6.78s
Train Epoch: 1530 [40960/90000 (45%)]	Loss: -7.6959	Cost: 22.92s
Train Epoch: 1530 [61440/90000 (68%)]	Loss: -7.8387	Cost: 12.33s
Train Epoch: 1530 [81920/90000 (91%)]	Loss: -7.8956	Cost: 12.06s
Train Epoch: 1530 	Average Loss: -7.4075
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0417

Learning rate: 9.433441278502756e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1531 [0/90000 (0%)]	Loss: -3.7337	Cost: 33.53s
Train Epoch: 1531 [20480/90000 (23%)]	Loss: -7.3772	Cost: 8.04s
Train Epoch: 1531 [40960/90000 (45%)]	Loss: -7.5800	Cost: 13.62s
Train Epoch: 1531 [61440/90000 (68%)]	Loss: -7.9983	Cost: 8.97s
Train Epoch: 1531 [81920/90000 (91%)]	Loss: -8.0103	Cost: 11.94s
Train Epoch: 1531 	Average Loss: -7.3700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0870

Learning rate: 9.432714774168182e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1532 [0/90000 (0%)]	Loss: -3.9621	Cost: 35.23s
Train Epoch: 1532 [20480/90000 (23%)]	Loss: -7.9955	Cost: 10.66s
Train Epoch: 1532 [40960/90000 (45%)]	Loss: -7.9182	Cost: 20.39s
Train Epoch: 1532 [61440/90000 (68%)]	Loss: -8.4160	Cost: 12.09s
Train Epoch: 1532 [81920/90000 (91%)]	Loss: -8.2500	Cost: 12.04s
Train Epoch: 1532 	Average Loss: -7.7662
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3851

Learning rate: 9.431987832342201e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1533 [0/90000 (0%)]	Loss: -3.9115	Cost: 48.35s
Train Epoch: 1533 [20480/90000 (23%)]	Loss: -8.1130	Cost: 9.89s
Train Epoch: 1533 [40960/90000 (45%)]	Loss: -8.1365	Cost: 6.30s
Train Epoch: 1533 [61440/90000 (68%)]	Loss: -8.5935	Cost: 6.68s
Train Epoch: 1533 [81920/90000 (91%)]	Loss: -8.5242	Cost: 12.40s
Train Epoch: 1533 	Average Loss: -8.0004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5501

Learning rate: 9.431260453096557e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1534 [0/90000 (0%)]	Loss: -4.2757	Cost: 29.11s
Train Epoch: 1534 [20480/90000 (23%)]	Loss: -8.2577	Cost: 10.71s
Train Epoch: 1534 [40960/90000 (45%)]	Loss: -8.1749	Cost: 23.12s
Train Epoch: 1534 [61440/90000 (68%)]	Loss: -8.5209	Cost: 12.39s
Train Epoch: 1534 [81920/90000 (91%)]	Loss: -8.6892	Cost: 12.21s
Train Epoch: 1534 	Average Loss: -8.1403
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6747

Saving model as e1534_model.pt & e1534_waveforms_supplementary.hdf5
Learning rate: 9.43053263650304e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1535 [0/90000 (0%)]	Loss: -4.9385	Cost: 38.98s
Train Epoch: 1535 [20480/90000 (23%)]	Loss: -8.6349	Cost: 11.96s
Train Epoch: 1535 [40960/90000 (45%)]	Loss: -8.6819	Cost: 8.32s
Train Epoch: 1535 [61440/90000 (68%)]	Loss: -8.7734	Cost: 6.03s
Train Epoch: 1535 [81920/90000 (91%)]	Loss: -8.8912	Cost: 15.12s
Train Epoch: 1535 	Average Loss: -8.4241
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6113

Learning rate: 9.429804382633482e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1536 [0/90000 (0%)]	Loss: -4.0922	Cost: 31.45s
Train Epoch: 1536 [20480/90000 (23%)]	Loss: -8.6171	Cost: 9.42s
Train Epoch: 1536 [40960/90000 (45%)]	Loss: -8.0489	Cost: 21.97s
Train Epoch: 1536 [61440/90000 (68%)]	Loss: -8.2240	Cost: 12.43s
Train Epoch: 1536 [81920/90000 (91%)]	Loss: -8.1822	Cost: 12.13s
Train Epoch: 1536 	Average Loss: -7.8860
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3655

Learning rate: 9.429075691559762e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1537 [0/90000 (0%)]	Loss: -4.2702	Cost: 49.26s
Train Epoch: 1537 [20480/90000 (23%)]	Loss: -8.2020	Cost: 6.07s
Train Epoch: 1537 [40960/90000 (45%)]	Loss: -8.4739	Cost: 14.06s
Train Epoch: 1537 [61440/90000 (68%)]	Loss: -8.7704	Cost: 8.48s
Train Epoch: 1537 [81920/90000 (91%)]	Loss: -8.1420	Cost: 8.30s
Train Epoch: 1537 	Average Loss: -8.0267
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2534

Learning rate: 9.428346563353793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1538 [0/90000 (0%)]	Loss: -4.0186	Cost: 29.36s
Train Epoch: 1538 [20480/90000 (23%)]	Loss: -8.2339	Cost: 8.02s
Train Epoch: 1538 [40960/90000 (45%)]	Loss: -8.2399	Cost: 18.89s
Train Epoch: 1538 [61440/90000 (68%)]	Loss: -8.5821	Cost: 11.72s
Train Epoch: 1538 [81920/90000 (91%)]	Loss: -8.2308	Cost: 12.91s
Train Epoch: 1538 	Average Loss: -7.9797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2858

Learning rate: 9.427616998087541e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1539 [0/90000 (0%)]	Loss: -3.8040	Cost: 36.32s
Train Epoch: 1539 [20480/90000 (23%)]	Loss: -8.1949	Cost: 7.95s
Train Epoch: 1539 [40960/90000 (45%)]	Loss: -8.2825	Cost: 15.96s
Train Epoch: 1539 [61440/90000 (68%)]	Loss: -8.5494	Cost: 8.85s
Train Epoch: 1539 [81920/90000 (91%)]	Loss: -8.3744	Cost: 12.30s
Train Epoch: 1539 	Average Loss: -7.9167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4022

Learning rate: 9.426886995833012e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1540 [0/90000 (0%)]	Loss: -3.8709	Cost: 30.14s
Train Epoch: 1540 [20480/90000 (23%)]	Loss: -8.4703	Cost: 11.04s
Train Epoch: 1540 [40960/90000 (45%)]	Loss: -7.9974	Cost: 16.46s
Train Epoch: 1540 [61440/90000 (68%)]	Loss: -8.2424	Cost: 12.18s
Train Epoch: 1540 [81920/90000 (91%)]	Loss: -8.3156	Cost: 12.12s
Train Epoch: 1540 	Average Loss: -7.9404
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5438

Learning rate: 9.426156556662252e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1541 [0/90000 (0%)]	Loss: -4.2044	Cost: 38.62s
Train Epoch: 1541 [20480/90000 (23%)]	Loss: -8.2603	Cost: 11.96s
Train Epoch: 1541 [40960/90000 (45%)]	Loss: -8.2723	Cost: 9.32s
Train Epoch: 1541 [61440/90000 (68%)]	Loss: -8.6012	Cost: 7.25s
Train Epoch: 1541 [81920/90000 (91%)]	Loss: -8.5138	Cost: 12.78s
Train Epoch: 1541 	Average Loss: -8.1255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7043

Saving model as e1541_model.pt & e1541_waveforms_supplementary.hdf5
Learning rate: 9.425425680647353e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1542 [0/90000 (0%)]	Loss: -3.9076	Cost: 31.75s
Train Epoch: 1542 [20480/90000 (23%)]	Loss: -8.5426	Cost: 7.58s
Train Epoch: 1542 [40960/90000 (45%)]	Loss: -8.3139	Cost: 17.83s
Train Epoch: 1542 [61440/90000 (68%)]	Loss: -8.6335	Cost: 11.99s
Train Epoch: 1542 [81920/90000 (91%)]	Loss: -8.5204	Cost: 11.89s
Train Epoch: 1542 	Average Loss: -8.1834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8014

Saving model as e1542_model.pt & e1542_waveforms_supplementary.hdf5
Learning rate: 9.42469436786045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1543 [0/90000 (0%)]	Loss: -4.5656	Cost: 31.07s
Train Epoch: 1543 [20480/90000 (23%)]	Loss: -8.4746	Cost: 11.75s
Train Epoch: 1543 [40960/90000 (45%)]	Loss: -8.6756	Cost: 6.34s
Train Epoch: 1543 [61440/90000 (68%)]	Loss: -8.6173	Cost: 6.99s
Train Epoch: 1543 [81920/90000 (91%)]	Loss: -8.6563	Cost: 14.34s
Train Epoch: 1543 	Average Loss: -8.2972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6841

Learning rate: 9.42396261837372e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1544 [0/90000 (0%)]	Loss: -4.3796	Cost: 36.44s
Train Epoch: 1544 [20480/90000 (23%)]	Loss: -8.2803	Cost: 14.05s
Train Epoch: 1544 [40960/90000 (45%)]	Loss: -8.3788	Cost: 14.60s
Train Epoch: 1544 [61440/90000 (68%)]	Loss: -8.7220	Cost: 12.46s
Train Epoch: 1544 [81920/90000 (91%)]	Loss: -8.7425	Cost: 11.87s
Train Epoch: 1544 	Average Loss: -8.1564
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6731

Learning rate: 9.423230432259386e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1545 [0/90000 (0%)]	Loss: -4.5976	Cost: 36.24s
Train Epoch: 1545 [20480/90000 (23%)]	Loss: -8.6167	Cost: 7.42s
Train Epoch: 1545 [40960/90000 (45%)]	Loss: -8.8113	Cost: 13.10s
Train Epoch: 1545 [61440/90000 (68%)]	Loss: -8.8171	Cost: 8.49s
Train Epoch: 1545 [81920/90000 (91%)]	Loss: -8.7214	Cost: 8.59s
Train Epoch: 1545 	Average Loss: -8.3606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6463

Learning rate: 9.422497809589708e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1546 [0/90000 (0%)]	Loss: -4.0261	Cost: 31.99s
Train Epoch: 1546 [20480/90000 (23%)]	Loss: -8.5027	Cost: 7.08s
Train Epoch: 1546 [40960/90000 (45%)]	Loss: -8.5212	Cost: 23.61s
Train Epoch: 1546 [61440/90000 (68%)]	Loss: -8.7992	Cost: 12.03s
Train Epoch: 1546 [81920/90000 (91%)]	Loss: -8.7100	Cost: 11.86s
Train Epoch: 1546 	Average Loss: -8.2634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5748

Learning rate: 9.421764750436996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1547 [0/90000 (0%)]	Loss: -4.5544	Cost: 43.07s
Train Epoch: 1547 [20480/90000 (23%)]	Loss: -7.7452	Cost: 11.95s
Train Epoch: 1547 [40960/90000 (45%)]	Loss: -7.8490	Cost: 6.87s
Train Epoch: 1547 [61440/90000 (68%)]	Loss: -8.3152	Cost: 6.24s
Train Epoch: 1547 [81920/90000 (91%)]	Loss: -7.4702	Cost: 12.78s
Train Epoch: 1547 	Average Loss: -7.6863
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.7730

Learning rate: 9.421031254873599e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1548 [0/90000 (0%)]	Loss: -3.8996	Cost: 25.97s
Train Epoch: 1548 [20480/90000 (23%)]	Loss: -7.4693	Cost: 6.99s
Train Epoch: 1548 [40960/90000 (45%)]	Loss: -7.6631	Cost: 24.11s
Train Epoch: 1548 [61440/90000 (68%)]	Loss: -7.8350	Cost: 14.90s
Train Epoch: 1548 [81920/90000 (91%)]	Loss: -7.9829	Cost: 12.13s
Train Epoch: 1548 	Average Loss: -7.4015
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.0754

Learning rate: 9.42029732297191e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1549 [0/90000 (0%)]	Loss: -3.7563	Cost: 34.78s
Train Epoch: 1549 [20480/90000 (23%)]	Loss: -8.0065	Cost: 13.78s
Train Epoch: 1549 [40960/90000 (45%)]	Loss: -8.2391	Cost: 10.10s
Train Epoch: 1549 [61440/90000 (68%)]	Loss: -8.7001	Cost: 6.25s
Train Epoch: 1549 [81920/90000 (91%)]	Loss: -8.3581	Cost: 15.23s
Train Epoch: 1549 	Average Loss: -7.9471
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4842

Learning rate: 9.419562954804365e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1550 [0/90000 (0%)]	Loss: -4.3221	Cost: 31.14s
Train Epoch: 1550 [20480/90000 (23%)]	Loss: -8.1541	Cost: 7.99s
Train Epoch: 1550 [40960/90000 (45%)]	Loss: -8.3855	Cost: 15.69s
Train Epoch: 1550 [61440/90000 (68%)]	Loss: -8.8521	Cost: 12.48s
Train Epoch: 1550 [81920/90000 (91%)]	Loss: -8.4022	Cost: 12.24s
Train Epoch: 1550 	Average Loss: -8.0465
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6013

Learning rate: 9.418828150443444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1551 [0/90000 (0%)]	Loss: -4.3208	Cost: 45.86s
Train Epoch: 1551 [20480/90000 (23%)]	Loss: -8.3884	Cost: 10.36s
Train Epoch: 1551 [40960/90000 (45%)]	Loss: -8.3540	Cost: 9.66s
Train Epoch: 1551 [61440/90000 (68%)]	Loss: -8.6101	Cost: 6.20s
Train Epoch: 1551 [81920/90000 (91%)]	Loss: -8.5300	Cost: 13.48s
Train Epoch: 1551 	Average Loss: -8.1545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6250

Learning rate: 9.41809290996167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1552 [0/90000 (0%)]	Loss: -4.1939	Cost: 28.86s
Train Epoch: 1552 [20480/90000 (23%)]	Loss: -8.6378	Cost: 6.66s
Train Epoch: 1552 [40960/90000 (45%)]	Loss: -8.5030	Cost: 18.41s
Train Epoch: 1552 [61440/90000 (68%)]	Loss: -8.8051	Cost: 12.25s
Train Epoch: 1552 [81920/90000 (91%)]	Loss: -8.5824	Cost: 11.92s
Train Epoch: 1552 	Average Loss: -8.2938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6903

Learning rate: 9.417357233431606e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1553 [0/90000 (0%)]	Loss: -4.3849	Cost: 37.75s
Train Epoch: 1553 [20480/90000 (23%)]	Loss: -8.5977	Cost: 11.97s
Train Epoch: 1553 [40960/90000 (45%)]	Loss: -8.7471	Cost: 10.80s
Train Epoch: 1553 [61440/90000 (68%)]	Loss: -8.8704	Cost: 9.29s
Train Epoch: 1553 [81920/90000 (91%)]	Loss: -8.3897	Cost: 8.58s
Train Epoch: 1553 	Average Loss: -8.2783
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4153

Learning rate: 9.416621120925861e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1554 [0/90000 (0%)]	Loss: -4.4404	Cost: 33.31s
Train Epoch: 1554 [20480/90000 (23%)]	Loss: -8.2377	Cost: 9.23s
Train Epoch: 1554 [40960/90000 (45%)]	Loss: -8.1563	Cost: 18.88s
Train Epoch: 1554 [61440/90000 (68%)]	Loss: -8.6654	Cost: 12.44s
Train Epoch: 1554 [81920/90000 (91%)]	Loss: -8.6078	Cost: 12.02s
Train Epoch: 1554 	Average Loss: -8.0877
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6895

Learning rate: 9.415884572517089e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1555 [0/90000 (0%)]	Loss: -4.7105	Cost: 39.90s
Train Epoch: 1555 [20480/90000 (23%)]	Loss: -8.7436	Cost: 9.98s
Train Epoch: 1555 [40960/90000 (45%)]	Loss: -8.5423	Cost: 7.72s
Train Epoch: 1555 [61440/90000 (68%)]	Loss: -8.8177	Cost: 6.99s
Train Epoch: 1555 [81920/90000 (91%)]	Loss: -8.8259	Cost: 14.22s
Train Epoch: 1555 	Average Loss: -8.3905
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6022

Learning rate: 9.415147588277982e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1556 [0/90000 (0%)]	Loss: -4.4604	Cost: 31.19s
Train Epoch: 1556 [20480/90000 (23%)]	Loss: -8.5072	Cost: 8.43s
Train Epoch: 1556 [40960/90000 (45%)]	Loss: -8.7460	Cost: 16.56s
Train Epoch: 1556 [61440/90000 (68%)]	Loss: -9.0706	Cost: 13.00s
Train Epoch: 1556 [81920/90000 (91%)]	Loss: -8.8504	Cost: 12.04s
Train Epoch: 1556 	Average Loss: -8.4221
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8371

Saving model as e1556_model.pt & e1556_waveforms_supplementary.hdf5
Learning rate: 9.414410168281278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1557 [0/90000 (0%)]	Loss: -4.3678	Cost: 36.54s
Train Epoch: 1557 [20480/90000 (23%)]	Loss: -8.7281	Cost: 11.97s
Train Epoch: 1557 [40960/90000 (45%)]	Loss: -8.7494	Cost: 8.27s
Train Epoch: 1557 [61440/90000 (68%)]	Loss: -8.8449	Cost: 6.32s
Train Epoch: 1557 [81920/90000 (91%)]	Loss: -8.6469	Cost: 14.90s
Train Epoch: 1557 	Average Loss: -8.4954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8400

Saving model as e1557_model.pt & e1557_waveforms_supplementary.hdf5
Learning rate: 9.413672312599757e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1558 [0/90000 (0%)]	Loss: -4.0292	Cost: 38.05s
Train Epoch: 1558 [20480/90000 (23%)]	Loss: -8.5665	Cost: 8.99s
Train Epoch: 1558 [40960/90000 (45%)]	Loss: -8.6040	Cost: 19.89s
Train Epoch: 1558 [61440/90000 (68%)]	Loss: -8.9247	Cost: 12.19s
Train Epoch: 1558 [81920/90000 (91%)]	Loss: -8.6662	Cost: 12.03s
Train Epoch: 1558 	Average Loss: -8.3176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7293

Learning rate: 9.412934021306243e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1559 [0/90000 (0%)]	Loss: -3.8291	Cost: 43.93s
Train Epoch: 1559 [20480/90000 (23%)]	Loss: -8.3188	Cost: 9.77s
Train Epoch: 1559 [40960/90000 (45%)]	Loss: -8.3713	Cost: 7.84s
Train Epoch: 1559 [61440/90000 (68%)]	Loss: -8.5770	Cost: 6.84s
Train Epoch: 1559 [81920/90000 (91%)]	Loss: -7.9998	Cost: 12.47s
Train Epoch: 1559 	Average Loss: -8.0451
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1014

Learning rate: 9.412195294473602e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1560 [0/90000 (0%)]	Loss: -4.0192	Cost: 27.94s
Train Epoch: 1560 [20480/90000 (23%)]	Loss: -7.9306	Cost: 10.47s
Train Epoch: 1560 [40960/90000 (45%)]	Loss: -8.0934	Cost: 23.94s
Train Epoch: 1560 [61440/90000 (68%)]	Loss: -8.4428	Cost: 13.28s
Train Epoch: 1560 [81920/90000 (91%)]	Loss: -8.5927	Cost: 12.15s
Train Epoch: 1560 	Average Loss: -7.9028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6608

Learning rate: 9.411456132174745e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1561 [0/90000 (0%)]	Loss: -4.7193	Cost: 44.02s
Train Epoch: 1561 [20480/90000 (23%)]	Loss: -8.6082	Cost: 10.86s
Train Epoch: 1561 [40960/90000 (45%)]	Loss: -8.5432	Cost: 8.97s
Train Epoch: 1561 [61440/90000 (68%)]	Loss: -8.2478	Cost: 6.36s
Train Epoch: 1561 [81920/90000 (91%)]	Loss: -7.6984	Cost: 13.53s
Train Epoch: 1561 	Average Loss: -8.0179
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1507

Learning rate: 9.410716534482622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1562 [0/90000 (0%)]	Loss: -4.1877	Cost: 29.65s
Train Epoch: 1562 [20480/90000 (23%)]	Loss: -7.6191	Cost: 6.99s
Train Epoch: 1562 [40960/90000 (45%)]	Loss: -7.7888	Cost: 15.98s
Train Epoch: 1562 [61440/90000 (68%)]	Loss: -8.2413	Cost: 13.37s
Train Epoch: 1562 [81920/90000 (91%)]	Loss: -8.4022	Cost: 14.04s
Train Epoch: 1562 	Average Loss: -7.7049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5832

Learning rate: 9.409976501470228e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1563 [0/90000 (0%)]	Loss: -4.4267	Cost: 48.94s
Train Epoch: 1563 [20480/90000 (23%)]	Loss: -8.3540	Cost: 12.32s
Train Epoch: 1563 [40960/90000 (45%)]	Loss: -8.4453	Cost: 11.92s
Train Epoch: 1563 [61440/90000 (68%)]	Loss: -8.7906	Cost: 6.32s
Train Epoch: 1563 [81920/90000 (91%)]	Loss: -8.4310	Cost: 6.56s
Train Epoch: 1563 	Average Loss: -8.1493
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5110

Learning rate: 9.409236033210605e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1564 [0/90000 (0%)]	Loss: -5.0649	Cost: 28.46s
Train Epoch: 1564 [20480/90000 (23%)]	Loss: -8.1735	Cost: 8.67s
Train Epoch: 1564 [40960/90000 (45%)]	Loss: -8.4742	Cost: 9.94s
Train Epoch: 1564 [61440/90000 (68%)]	Loss: -8.7327	Cost: 7.02s
Train Epoch: 1564 [81920/90000 (91%)]	Loss: -8.5860	Cost: 19.56s
Train Epoch: 1564 	Average Loss: -8.1700
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6531

Learning rate: 9.40849512977683e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1565 [0/90000 (0%)]	Loss: -4.1212	Cost: 38.50s
Train Epoch: 1565 [20480/90000 (23%)]	Loss: -7.8179	Cost: 12.31s
Train Epoch: 1565 [40960/90000 (45%)]	Loss: -7.7264	Cost: 12.79s
Train Epoch: 1565 [61440/90000 (68%)]	Loss: -8.4928	Cost: 9.09s
Train Epoch: 1565 [81920/90000 (91%)]	Loss: -8.2130	Cost: 6.67s
Train Epoch: 1565 	Average Loss: -7.7979
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4660

Learning rate: 9.40775379124203e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1566 [0/90000 (0%)]	Loss: -4.0685	Cost: 29.44s
Train Epoch: 1566 [20480/90000 (23%)]	Loss: -8.1452	Cost: 9.08s
Train Epoch: 1566 [40960/90000 (45%)]	Loss: -8.2831	Cost: 11.40s
Train Epoch: 1566 [61440/90000 (68%)]	Loss: -8.5943	Cost: 8.84s
Train Epoch: 1566 [81920/90000 (91%)]	Loss: -7.9600	Cost: 9.39s
Train Epoch: 1566 	Average Loss: -7.9753
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3167

Learning rate: 9.407012017679371e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1567 [0/90000 (0%)]	Loss: -4.0318	Cost: 31.50s
Train Epoch: 1567 [20480/90000 (23%)]	Loss: -7.8138	Cost: 13.80s
Train Epoch: 1567 [40960/90000 (45%)]	Loss: -8.1159	Cost: 16.95s
Train Epoch: 1567 [61440/90000 (68%)]	Loss: -7.9920	Cost: 12.73s
Train Epoch: 1567 [81920/90000 (91%)]	Loss: -8.2090	Cost: 12.15s
Train Epoch: 1567 	Average Loss: -7.7321
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2332

Learning rate: 9.406269809162065e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1568 [0/90000 (0%)]	Loss: -4.0301	Cost: 47.81s
Train Epoch: 1568 [20480/90000 (23%)]	Loss: -8.1034	Cost: 6.41s
Train Epoch: 1568 [40960/90000 (45%)]	Loss: -8.3529	Cost: 13.52s
Train Epoch: 1568 [61440/90000 (68%)]	Loss: -8.5991	Cost: 8.78s
Train Epoch: 1568 [81920/90000 (91%)]	Loss: -8.0308	Cost: 8.48s
Train Epoch: 1568 	Average Loss: -7.9585
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2186

Learning rate: 9.405527165763362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1569 [0/90000 (0%)]	Loss: -3.9991	Cost: 35.38s
Train Epoch: 1569 [20480/90000 (23%)]	Loss: -7.3173	Cost: 8.18s
Train Epoch: 1569 [40960/90000 (45%)]	Loss: -7.3411	Cost: 17.66s
Train Epoch: 1569 [61440/90000 (68%)]	Loss: -7.8202	Cost: 12.24s
Train Epoch: 1569 [81920/90000 (91%)]	Loss: -7.9588	Cost: 12.37s
Train Epoch: 1569 	Average Loss: -7.3712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3520

Learning rate: 9.40478408755656e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1570 [0/90000 (0%)]	Loss: -4.1020	Cost: 32.83s
Train Epoch: 1570 [20480/90000 (23%)]	Loss: -7.7915	Cost: 9.87s
Train Epoch: 1570 [40960/90000 (45%)]	Loss: -8.1082	Cost: 10.40s
Train Epoch: 1570 [61440/90000 (68%)]	Loss: -8.4404	Cost: 9.14s
Train Epoch: 1570 [81920/90000 (91%)]	Loss: -7.9479	Cost: 13.79s
Train Epoch: 1570 	Average Loss: -7.7189
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2299

Learning rate: 9.404040574614996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1571 [0/90000 (0%)]	Loss: -4.1443	Cost: 32.70s
Train Epoch: 1571 [20480/90000 (23%)]	Loss: -7.9457	Cost: 9.89s
Train Epoch: 1571 [40960/90000 (45%)]	Loss: -8.3265	Cost: 19.97s
Train Epoch: 1571 [61440/90000 (68%)]	Loss: -8.6786	Cost: 12.05s
Train Epoch: 1571 [81920/90000 (91%)]	Loss: -8.5034	Cost: 11.88s
Train Epoch: 1571 	Average Loss: -8.0239
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4951

Learning rate: 9.403296627012055e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1572 [0/90000 (0%)]	Loss: -4.4525	Cost: 34.60s
Train Epoch: 1572 [20480/90000 (23%)]	Loss: -8.0974	Cost: 12.64s
Train Epoch: 1572 [40960/90000 (45%)]	Loss: -8.2034	Cost: 7.24s
Train Epoch: 1572 [61440/90000 (68%)]	Loss: -8.6857	Cost: 6.41s
Train Epoch: 1572 [81920/90000 (91%)]	Loss: -8.5139	Cost: 16.34s
Train Epoch: 1572 	Average Loss: -8.0352
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5011

Learning rate: 9.402552244821159e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1573 [0/90000 (0%)]	Loss: -4.4615	Cost: 42.61s
Train Epoch: 1573 [20480/90000 (23%)]	Loss: -8.0404	Cost: 8.26s
Train Epoch: 1573 [40960/90000 (45%)]	Loss: -8.3639	Cost: 17.57s
Train Epoch: 1573 [61440/90000 (68%)]	Loss: -8.7558	Cost: 11.94s
Train Epoch: 1573 [81920/90000 (91%)]	Loss: -8.4734	Cost: 12.14s
Train Epoch: 1573 	Average Loss: -8.1578
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5654

Learning rate: 9.401807428115777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1574 [0/90000 (0%)]	Loss: -4.0931	Cost: 29.69s
Train Epoch: 1574 [20480/90000 (23%)]	Loss: -8.4549	Cost: 7.84s
Train Epoch: 1574 [40960/90000 (45%)]	Loss: -7.3259	Cost: 11.96s
Train Epoch: 1574 [61440/90000 (68%)]	Loss: -7.8725	Cost: 9.74s
Train Epoch: 1574 [81920/90000 (91%)]	Loss: -8.0195	Cost: 10.41s
Train Epoch: 1574 	Average Loss: -7.7577
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3600

Learning rate: 9.40106217696942e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1575 [0/90000 (0%)]	Loss: -4.0047	Cost: 34.95s
Train Epoch: 1575 [20480/90000 (23%)]	Loss: -8.0805	Cost: 14.71s
Train Epoch: 1575 [40960/90000 (45%)]	Loss: -8.5074	Cost: 14.60s
Train Epoch: 1575 [61440/90000 (68%)]	Loss: -8.5553	Cost: 12.13s
Train Epoch: 1575 [81920/90000 (91%)]	Loss: -8.2665	Cost: 12.08s
Train Epoch: 1575 	Average Loss: -8.0572
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2480

Learning rate: 9.40031649145564e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1576 [0/90000 (0%)]	Loss: -3.9187	Cost: 45.59s
Train Epoch: 1576 [20480/90000 (23%)]	Loss: -8.3103	Cost: 6.21s
Train Epoch: 1576 [40960/90000 (45%)]	Loss: -8.3904	Cost: 14.52s
Train Epoch: 1576 [61440/90000 (68%)]	Loss: -8.7227	Cost: 8.55s
Train Epoch: 1576 [81920/90000 (91%)]	Loss: -8.7336	Cost: 7.84s
Train Epoch: 1576 	Average Loss: -8.1034
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5634

Learning rate: 9.399570371648032e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1577 [0/90000 (0%)]	Loss: -4.4017	Cost: 30.25s
Train Epoch: 1577 [20480/90000 (23%)]	Loss: -8.3568	Cost: 10.45s
Train Epoch: 1577 [40960/90000 (45%)]	Loss: -8.4812	Cost: 14.75s
Train Epoch: 1577 [61440/90000 (68%)]	Loss: -9.0182	Cost: 13.30s
Train Epoch: 1577 [81920/90000 (91%)]	Loss: -8.9528	Cost: 12.21s
Train Epoch: 1577 	Average Loss: -8.3212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7433

Learning rate: 9.398823817620238e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1578 [0/90000 (0%)]	Loss: -4.8114	Cost: 46.73s
Train Epoch: 1578 [20480/90000 (23%)]	Loss: -8.5831	Cost: 11.74s
Train Epoch: 1578 [40960/90000 (45%)]	Loss: -8.8493	Cost: 6.94s
Train Epoch: 1578 [61440/90000 (68%)]	Loss: -8.9062	Cost: 6.22s
Train Epoch: 1578 [81920/90000 (91%)]	Loss: -8.2392	Cost: 11.42s
Train Epoch: 1578 	Average Loss: -8.3501
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3418

Learning rate: 9.398076829445937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1579 [0/90000 (0%)]	Loss: -4.6135	Cost: 27.37s
Train Epoch: 1579 [20480/90000 (23%)]	Loss: -8.4090	Cost: 6.84s
Train Epoch: 1579 [40960/90000 (45%)]	Loss: -8.5509	Cost: 23.12s
Train Epoch: 1579 [61440/90000 (68%)]	Loss: -9.0271	Cost: 13.67s
Train Epoch: 1579 [81920/90000 (91%)]	Loss: -8.8027	Cost: 12.94s
Train Epoch: 1579 	Average Loss: -8.2895
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7114

Learning rate: 9.397329407198858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1580 [0/90000 (0%)]	Loss: -4.7533	Cost: 33.46s
Train Epoch: 1580 [20480/90000 (23%)]	Loss: -8.7116	Cost: 14.37s
Train Epoch: 1580 [40960/90000 (45%)]	Loss: -8.9651	Cost: 14.57s
Train Epoch: 1580 [61440/90000 (68%)]	Loss: -9.1801	Cost: 6.41s
Train Epoch: 1580 [81920/90000 (91%)]	Loss: -8.9191	Cost: 14.02s
Train Epoch: 1580 	Average Loss: -8.6138
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9318

Saving model as e1580_model.pt & e1580_waveforms_supplementary.hdf5
Learning rate: 9.396581550952764e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1581 [0/90000 (0%)]	Loss: -4.9640	Cost: 38.42s
Train Epoch: 1581 [20480/90000 (23%)]	Loss: -8.7514	Cost: 7.39s
Train Epoch: 1581 [40960/90000 (45%)]	Loss: -8.1733	Cost: 16.53s
Train Epoch: 1581 [61440/90000 (68%)]	Loss: -8.7774	Cost: 12.07s
Train Epoch: 1581 [81920/90000 (91%)]	Loss: -8.5343	Cost: 12.18s
Train Epoch: 1581 	Average Loss: -8.2601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4738

Learning rate: 9.395833260781467e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1582 [0/90000 (0%)]	Loss: -4.1698	Cost: 40.17s
Train Epoch: 1582 [20480/90000 (23%)]	Loss: -8.2767	Cost: 12.13s
Train Epoch: 1582 [40960/90000 (45%)]	Loss: -8.6620	Cost: 7.34s
Train Epoch: 1582 [61440/90000 (68%)]	Loss: -8.9799	Cost: 6.61s
Train Epoch: 1582 [81920/90000 (91%)]	Loss: -9.1156	Cost: 14.65s
Train Epoch: 1582 	Average Loss: -8.3528
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9547

Saving model as e1582_model.pt & e1582_waveforms_supplementary.hdf5
Learning rate: 9.395084536758821e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1583 [0/90000 (0%)]	Loss: -4.0612	Cost: 29.00s
Train Epoch: 1583 [20480/90000 (23%)]	Loss: -8.8840	Cost: 7.48s
Train Epoch: 1583 [40960/90000 (45%)]	Loss: -8.7534	Cost: 17.54s
Train Epoch: 1583 [61440/90000 (68%)]	Loss: -9.2410	Cost: 12.10s
Train Epoch: 1583 [81920/90000 (91%)]	Loss: -9.0094	Cost: 12.34s
Train Epoch: 1583 	Average Loss: -8.5910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9622

Saving model as e1583_model.pt & e1583_waveforms_supplementary.hdf5
Learning rate: 9.39433537895872e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1584 [0/90000 (0%)]	Loss: -5.2634	Cost: 32.24s
Train Epoch: 1584 [20480/90000 (23%)]	Loss: -8.0961	Cost: 8.30s
Train Epoch: 1584 [40960/90000 (45%)]	Loss: -8.1439	Cost: 9.86s
Train Epoch: 1584 [61440/90000 (68%)]	Loss: -8.4776	Cost: 8.88s
Train Epoch: 1584 [81920/90000 (91%)]	Loss: -8.3121	Cost: 13.17s
Train Epoch: 1584 	Average Loss: -8.0245
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3287

Learning rate: 9.393585787455106e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1585 [0/90000 (0%)]	Loss: -4.1268	Cost: 40.41s
Train Epoch: 1585 [20480/90000 (23%)]	Loss: -7.9024	Cost: 10.67s
Train Epoch: 1585 [40960/90000 (45%)]	Loss: -8.2674	Cost: 15.46s
Train Epoch: 1585 [61440/90000 (68%)]	Loss: -8.6621	Cost: 12.07s
Train Epoch: 1585 [81920/90000 (91%)]	Loss: -8.7140	Cost: 11.88s
Train Epoch: 1585 	Average Loss: -8.0867
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7100

Learning rate: 9.39283576232196e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1586 [0/90000 (0%)]	Loss: -4.6018	Cost: 43.18s
Train Epoch: 1586 [20480/90000 (23%)]	Loss: -8.6768	Cost: 6.13s
Train Epoch: 1586 [40960/90000 (45%)]	Loss: -8.6908	Cost: 13.92s
Train Epoch: 1586 [61440/90000 (68%)]	Loss: -9.0590	Cost: 9.02s
Train Epoch: 1586 [81920/90000 (91%)]	Loss: -8.8533	Cost: 11.07s
Train Epoch: 1586 	Average Loss: -8.4744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7957

Learning rate: 9.392085303633305e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1587 [0/90000 (0%)]	Loss: -4.8381	Cost: 27.79s
Train Epoch: 1587 [20480/90000 (23%)]	Loss: -8.6695	Cost: 10.11s
Train Epoch: 1587 [40960/90000 (45%)]	Loss: -8.7906	Cost: 20.86s
Train Epoch: 1587 [61440/90000 (68%)]	Loss: -9.2023	Cost: 12.10s
Train Epoch: 1587 [81920/90000 (91%)]	Loss: -8.9024	Cost: 11.99s
Train Epoch: 1587 	Average Loss: -8.5874
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9521

Learning rate: 9.39133441146321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1588 [0/90000 (0%)]	Loss: -4.3454	Cost: 44.84s
Train Epoch: 1588 [20480/90000 (23%)]	Loss: -8.7617	Cost: 8.28s
Train Epoch: 1588 [40960/90000 (45%)]	Loss: -8.8183	Cost: 9.72s
Train Epoch: 1588 [61440/90000 (68%)]	Loss: -9.0628	Cost: 8.23s
Train Epoch: 1588 [81920/90000 (91%)]	Loss: -9.1443	Cost: 14.01s
Train Epoch: 1588 	Average Loss: -8.5459
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9741

Saving model as e1588_model.pt & e1588_waveforms_supplementary.hdf5
Learning rate: 9.390583085885783e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1589 [0/90000 (0%)]	Loss: -4.6238	Cost: 31.60s
Train Epoch: 1589 [20480/90000 (23%)]	Loss: -8.9216	Cost: 10.53s
Train Epoch: 1589 [40960/90000 (45%)]	Loss: -8.9552	Cost: 22.33s
Train Epoch: 1589 [61440/90000 (68%)]	Loss: -9.2207	Cost: 12.63s
Train Epoch: 1589 [81920/90000 (91%)]	Loss: -8.7346	Cost: 11.84s
Train Epoch: 1589 	Average Loss: -8.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6338

Learning rate: 9.389831326975179e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1590 [0/90000 (0%)]	Loss: -4.6502	Cost: 57.39s
Train Epoch: 1590 [20480/90000 (23%)]	Loss: -8.5745	Cost: 7.05s
Train Epoch: 1590 [40960/90000 (45%)]	Loss: -8.8906	Cost: 12.75s
Train Epoch: 1590 [61440/90000 (68%)]	Loss: -9.1657	Cost: 8.70s
Train Epoch: 1590 [81920/90000 (91%)]	Loss: -8.9025	Cost: 7.90s
Train Epoch: 1590 	Average Loss: -8.5615
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9364

Learning rate: 9.389079134805592e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1591 [0/90000 (0%)]	Loss: -4.9193	Cost: 28.45s
Train Epoch: 1591 [20480/90000 (23%)]	Loss: -8.6373	Cost: 10.05s
Train Epoch: 1591 [40960/90000 (45%)]	Loss: -8.7368	Cost: 17.31s
Train Epoch: 1591 [61440/90000 (68%)]	Loss: -9.1772	Cost: 12.74s
Train Epoch: 1591 [81920/90000 (91%)]	Loss: -9.1139	Cost: 12.28s
Train Epoch: 1591 	Average Loss: -8.6440
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1520

Saving model as e1591_model.pt & e1591_waveforms_supplementary.hdf5
Learning rate: 9.388326509451261e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1592 [0/90000 (0%)]	Loss: -4.2175	Cost: 31.34s
Train Epoch: 1592 [20480/90000 (23%)]	Loss: -8.9740	Cost: 9.53s
Train Epoch: 1592 [40960/90000 (45%)]	Loss: -8.9411	Cost: 10.40s
Train Epoch: 1592 [61440/90000 (68%)]	Loss: -9.3734	Cost: 8.65s
Train Epoch: 1592 [81920/90000 (91%)]	Loss: -9.0685	Cost: 10.25s
Train Epoch: 1592 	Average Loss: -8.7175
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0025

Learning rate: 9.387573450986467e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1593 [0/90000 (0%)]	Loss: -4.7787	Cost: 28.41s
Train Epoch: 1593 [20480/90000 (23%)]	Loss: -8.6008	Cost: 8.10s
Train Epoch: 1593 [40960/90000 (45%)]	Loss: -8.8554	Cost: 16.54s
Train Epoch: 1593 [61440/90000 (68%)]	Loss: -9.0457	Cost: 13.34s
Train Epoch: 1593 [81920/90000 (91%)]	Loss: -9.1126	Cost: 12.44s
Train Epoch: 1593 	Average Loss: -8.6217
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0143

Learning rate: 9.386819959485536e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1594 [0/90000 (0%)]	Loss: -4.8891	Cost: 34.97s
Train Epoch: 1594 [20480/90000 (23%)]	Loss: -8.8034	Cost: 10.94s
Train Epoch: 1594 [40960/90000 (45%)]	Loss: -8.9453	Cost: 7.06s
Train Epoch: 1594 [61440/90000 (68%)]	Loss: -9.0799	Cost: 8.65s
Train Epoch: 1594 [81920/90000 (91%)]	Loss: -8.7829	Cost: 15.32s
Train Epoch: 1594 	Average Loss: -8.6601
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8163

Learning rate: 9.386066035022831e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1595 [0/90000 (0%)]	Loss: -3.9209	Cost: 48.12s
Train Epoch: 1595 [20480/90000 (23%)]	Loss: -8.6190	Cost: 7.22s
Train Epoch: 1595 [40960/90000 (45%)]	Loss: -8.8788	Cost: 17.90s
Train Epoch: 1595 [61440/90000 (68%)]	Loss: -9.2427	Cost: 12.28s
Train Epoch: 1595 [81920/90000 (91%)]	Loss: -9.0426	Cost: 11.91s
Train Epoch: 1595 	Average Loss: -8.5565
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8598

Learning rate: 9.385311677672765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1596 [0/90000 (0%)]	Loss: -4.7912	Cost: 36.08s
Train Epoch: 1596 [20480/90000 (23%)]	Loss: -8.6750	Cost: 11.93s
Train Epoch: 1596 [40960/90000 (45%)]	Loss: -8.6343	Cost: 7.07s
Train Epoch: 1596 [61440/90000 (68%)]	Loss: -8.9092	Cost: 6.61s
Train Epoch: 1596 [81920/90000 (91%)]	Loss: -8.6101	Cost: 15.50s
Train Epoch: 1596 	Average Loss: -8.4385
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8242

Learning rate: 9.384556887509786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1597 [0/90000 (0%)]	Loss: -4.2616	Cost: 30.24s
Train Epoch: 1597 [20480/90000 (23%)]	Loss: -8.7593	Cost: 9.07s
Train Epoch: 1597 [40960/90000 (45%)]	Loss: -8.5874	Cost: 17.34s
Train Epoch: 1597 [61440/90000 (68%)]	Loss: -9.0160	Cost: 12.40s
Train Epoch: 1597 [81920/90000 (91%)]	Loss: -8.8894	Cost: 12.04s
Train Epoch: 1597 	Average Loss: -8.4823
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5095

Learning rate: 9.383801664608392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1598 [0/90000 (0%)]	Loss: -4.2732	Cost: 37.96s
Train Epoch: 1598 [20480/90000 (23%)]	Loss: -8.1028	Cost: 9.13s
Train Epoch: 1598 [40960/90000 (45%)]	Loss: -8.4285	Cost: 11.72s
Train Epoch: 1598 [61440/90000 (68%)]	Loss: -8.9093	Cost: 6.29s
Train Epoch: 1598 [81920/90000 (91%)]	Loss: -8.7718	Cost: 14.78s
Train Epoch: 1598 	Average Loss: -8.2511
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8103

Learning rate: 9.38304600904312e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1599 [0/90000 (0%)]	Loss: -4.9064	Cost: 48.25s
Train Epoch: 1599 [20480/90000 (23%)]	Loss: -8.6719	Cost: 8.51s
Train Epoch: 1599 [40960/90000 (45%)]	Loss: -8.5174	Cost: 15.37s
Train Epoch: 1599 [61440/90000 (68%)]	Loss: -8.9538	Cost: 11.98s
Train Epoch: 1599 [81920/90000 (91%)]	Loss: -8.9527	Cost: 11.82s
Train Epoch: 1599 	Average Loss: -8.4872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9530

Learning rate: 9.382289920888548e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1600 [0/90000 (0%)]	Loss: -4.8926	Cost: 33.76s
Train Epoch: 1600 [20480/90000 (23%)]	Loss: -8.5669	Cost: 11.85s
Train Epoch: 1600 [40960/90000 (45%)]	Loss: -8.7432	Cost: 7.05s
Train Epoch: 1600 [61440/90000 (68%)]	Loss: -9.1789	Cost: 6.32s
Train Epoch: 1600 [81920/90000 (91%)]	Loss: -8.9960	Cost: 12.92s
Train Epoch: 1600 	Average Loss: -8.5399
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9416

Learning rate: 9.3815334002193e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1601 [0/90000 (0%)]	Loss: -4.8593	Cost: 30.27s
Train Epoch: 1601 [20480/90000 (23%)]	Loss: -8.7297	Cost: 10.26s
Train Epoch: 1601 [40960/90000 (45%)]	Loss: -8.7563	Cost: 20.26s
Train Epoch: 1601 [61440/90000 (68%)]	Loss: -9.2168	Cost: 12.61s
Train Epoch: 1601 [81920/90000 (91%)]	Loss: -8.9810	Cost: 12.15s
Train Epoch: 1601 	Average Loss: -8.6868
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9924

Learning rate: 9.380776447110046e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1602 [0/90000 (0%)]	Loss: -4.4245	Cost: 40.75s
Train Epoch: 1602 [20480/90000 (23%)]	Loss: -8.6576	Cost: 10.61s
Train Epoch: 1602 [40960/90000 (45%)]	Loss: -8.8259	Cost: 9.25s
Train Epoch: 1602 [61440/90000 (68%)]	Loss: -9.1904	Cost: 6.24s
Train Epoch: 1602 [81920/90000 (91%)]	Loss: -8.7587	Cost: 15.86s
Train Epoch: 1602 	Average Loss: -8.5156
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7757

Learning rate: 9.380019061635488e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1603 [0/90000 (0%)]	Loss: -4.6497	Cost: 35.70s
Train Epoch: 1603 [20480/90000 (23%)]	Loss: -8.7870	Cost: 10.01s
Train Epoch: 1603 [40960/90000 (45%)]	Loss: -8.8926	Cost: 22.16s
Train Epoch: 1603 [61440/90000 (68%)]	Loss: -9.2293	Cost: 11.88s
Train Epoch: 1603 [81920/90000 (91%)]	Loss: -9.2468	Cost: 11.76s
Train Epoch: 1603 	Average Loss: -8.6712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0516

Learning rate: 9.37926124387038e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1604 [0/90000 (0%)]	Loss: -4.8199	Cost: 36.91s
Train Epoch: 1604 [20480/90000 (23%)]	Loss: -8.9265	Cost: 6.47s
Train Epoch: 1604 [40960/90000 (45%)]	Loss: -8.9623	Cost: 14.55s
Train Epoch: 1604 [61440/90000 (68%)]	Loss: -9.5020	Cost: 8.44s
Train Epoch: 1604 [81920/90000 (91%)]	Loss: -9.1628	Cost: 7.62s
Train Epoch: 1604 	Average Loss: -8.8251
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1474

Learning rate: 9.378502993889515e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1605 [0/90000 (0%)]	Loss: -4.9088	Cost: 27.45s
Train Epoch: 1605 [20480/90000 (23%)]	Loss: -9.0574	Cost: 8.39s
Train Epoch: 1605 [40960/90000 (45%)]	Loss: -9.1627	Cost: 16.09s
Train Epoch: 1605 [61440/90000 (68%)]	Loss: -9.5449	Cost: 13.08s
Train Epoch: 1605 [81920/90000 (91%)]	Loss: -9.1875	Cost: 12.37s
Train Epoch: 1605 	Average Loss: -8.8941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9386

Learning rate: 9.377744311767728e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1606 [0/90000 (0%)]	Loss: -4.8285	Cost: 36.77s
Train Epoch: 1606 [20480/90000 (23%)]	Loss: -8.3691	Cost: 9.12s
Train Epoch: 1606 [40960/90000 (45%)]	Loss: -8.1824	Cost: 10.51s
Train Epoch: 1606 [61440/90000 (68%)]	Loss: -9.0141	Cost: 8.91s
Train Epoch: 1606 [81920/90000 (91%)]	Loss: -8.8996	Cost: 12.21s
Train Epoch: 1606 	Average Loss: -8.3417
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0049

Learning rate: 9.376985197579901e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1607 [0/90000 (0%)]	Loss: -4.6473	Cost: 28.54s
Train Epoch: 1607 [20480/90000 (23%)]	Loss: -8.8657	Cost: 7.96s
Train Epoch: 1607 [40960/90000 (45%)]	Loss: -7.5419	Cost: 17.65s
Train Epoch: 1607 [61440/90000 (68%)]	Loss: -8.3887	Cost: 12.71s
Train Epoch: 1607 [81920/90000 (91%)]	Loss: -8.0923	Cost: 12.13s
Train Epoch: 1607 	Average Loss: -7.9285
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2826

Learning rate: 9.376225651400952e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1608 [0/90000 (0%)]	Loss: -3.6590	Cost: 32.78s
Train Epoch: 1608 [20480/90000 (23%)]	Loss: -7.9305	Cost: 12.28s
Train Epoch: 1608 [40960/90000 (45%)]	Loss: -8.0869	Cost: 12.59s
Train Epoch: 1608 [61440/90000 (68%)]	Loss: -8.6766	Cost: 7.53s
Train Epoch: 1608 [81920/90000 (91%)]	Loss: -8.7860	Cost: 7.46s
Train Epoch: 1608 	Average Loss: -7.9797
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8556

Learning rate: 9.375465673305849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1609 [0/90000 (0%)]	Loss: -3.9897	Cost: 42.23s
Train Epoch: 1609 [20480/90000 (23%)]	Loss: -8.6697	Cost: 6.55s
Train Epoch: 1609 [40960/90000 (45%)]	Loss: -8.6723	Cost: 16.37s
Train Epoch: 1609 [61440/90000 (68%)]	Loss: -8.9079	Cost: 12.33s
Train Epoch: 1609 [81920/90000 (91%)]	Loss: -8.4827	Cost: 11.91s
Train Epoch: 1609 	Average Loss: -8.3632
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4922

Learning rate: 9.374705263369597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1610 [0/90000 (0%)]	Loss: -4.0326	Cost: 35.12s
Train Epoch: 1610 [20480/90000 (23%)]	Loss: -8.1322	Cost: 12.94s
Train Epoch: 1610 [40960/90000 (45%)]	Loss: -8.2285	Cost: 10.81s
Train Epoch: 1610 [61440/90000 (68%)]	Loss: -9.0037	Cost: 6.49s
Train Epoch: 1610 [81920/90000 (91%)]	Loss: -8.9140	Cost: 7.06s
Train Epoch: 1610 	Average Loss: -8.2006
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8620

Learning rate: 9.373944421667244e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1611 [0/90000 (0%)]	Loss: -4.3001	Cost: 28.04s
Train Epoch: 1611 [20480/90000 (23%)]	Loss: -8.7293	Cost: 8.77s
Train Epoch: 1611 [40960/90000 (45%)]	Loss: -8.8404	Cost: 22.61s
Train Epoch: 1611 [61440/90000 (68%)]	Loss: -9.3843	Cost: 12.68s
Train Epoch: 1611 [81920/90000 (91%)]	Loss: -9.2219	Cost: 12.89s
Train Epoch: 1611 	Average Loss: -8.6475
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2524

Saving model as e1611_model.pt & e1611_waveforms_supplementary.hdf5
Learning rate: 9.373183148273885e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1612 [0/90000 (0%)]	Loss: -4.5845	Cost: 53.77s
Train Epoch: 1612 [20480/90000 (23%)]	Loss: -9.1521	Cost: 6.33s
Train Epoch: 1612 [40960/90000 (45%)]	Loss: -9.2434	Cost: 13.79s
Train Epoch: 1612 [61440/90000 (68%)]	Loss: -9.5746	Cost: 8.72s
Train Epoch: 1612 [81920/90000 (91%)]	Loss: -9.5381	Cost: 10.05s
Train Epoch: 1612 	Average Loss: -8.9683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3237

Saving model as e1612_model.pt & e1612_waveforms_supplementary.hdf5
Learning rate: 9.372421443264651e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1613 [0/90000 (0%)]	Loss: -5.4770	Cost: 28.83s
Train Epoch: 1613 [20480/90000 (23%)]	Loss: -9.4262	Cost: 12.87s
Train Epoch: 1613 [40960/90000 (45%)]	Loss: -9.2336	Cost: 17.70s
Train Epoch: 1613 [61440/90000 (68%)]	Loss: -9.5341	Cost: 12.49s
Train Epoch: 1613 [81920/90000 (91%)]	Loss: -9.3702	Cost: 11.98s
Train Epoch: 1613 	Average Loss: -9.0834
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2374

Learning rate: 9.371659306714724e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1614 [0/90000 (0%)]	Loss: -5.3704	Cost: 44.32s
Train Epoch: 1614 [20480/90000 (23%)]	Loss: -9.2875	Cost: 8.61s
Train Epoch: 1614 [40960/90000 (45%)]	Loss: -9.3119	Cost: 10.12s
Train Epoch: 1614 [61440/90000 (68%)]	Loss: -9.5579	Cost: 8.94s
Train Epoch: 1614 [81920/90000 (91%)]	Loss: -9.1567	Cost: 9.17s
Train Epoch: 1614 	Average Loss: -8.9600
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2001

Learning rate: 9.37089673869932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1615 [0/90000 (0%)]	Loss: -4.8983	Cost: 31.91s
Train Epoch: 1615 [20480/90000 (23%)]	Loss: -9.1221	Cost: 13.48s
Train Epoch: 1615 [40960/90000 (45%)]	Loss: -8.8972	Cost: 14.98s
Train Epoch: 1615 [61440/90000 (68%)]	Loss: -9.0269	Cost: 12.53s
Train Epoch: 1615 [81920/90000 (91%)]	Loss: -8.9802	Cost: 11.45s
Train Epoch: 1615 	Average Loss: -8.7104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8696

Learning rate: 9.370133739293702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1616 [0/90000 (0%)]	Loss: -4.4025	Cost: 30.26s
Train Epoch: 1616 [20480/90000 (23%)]	Loss: -8.7705	Cost: 10.71s
Train Epoch: 1616 [40960/90000 (45%)]	Loss: -8.8401	Cost: 11.35s
Train Epoch: 1616 [61440/90000 (68%)]	Loss: -9.1131	Cost: 8.68s
Train Epoch: 1616 [81920/90000 (91%)]	Loss: -9.0624	Cost: 15.47s
Train Epoch: 1616 	Average Loss: -8.6158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9719

Learning rate: 9.369370308573176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1617 [0/90000 (0%)]	Loss: -5.0315	Cost: 36.21s
Train Epoch: 1617 [20480/90000 (23%)]	Loss: -8.7874	Cost: 9.38s
Train Epoch: 1617 [40960/90000 (45%)]	Loss: -8.8742	Cost: 19.75s
Train Epoch: 1617 [61440/90000 (68%)]	Loss: -9.5660	Cost: 11.76s
Train Epoch: 1617 [81920/90000 (91%)]	Loss: -9.3257	Cost: 11.93s
Train Epoch: 1617 	Average Loss: -8.8287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1018

Learning rate: 9.36860644661309e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1618 [0/90000 (0%)]	Loss: -4.9364	Cost: 41.36s
Train Epoch: 1618 [20480/90000 (23%)]	Loss: -8.9072	Cost: 6.26s
Train Epoch: 1618 [40960/90000 (45%)]	Loss: -9.1236	Cost: 13.72s
Train Epoch: 1618 [61440/90000 (68%)]	Loss: -9.6676	Cost: 8.80s
Train Epoch: 1618 [81920/90000 (91%)]	Loss: -9.2397	Cost: 8.24s
Train Epoch: 1618 	Average Loss: -8.8499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0034

Learning rate: 9.367842153488833e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1619 [0/90000 (0%)]	Loss: -4.9108	Cost: 36.07s
Train Epoch: 1619 [20480/90000 (23%)]	Loss: -8.8564	Cost: 14.01s
Train Epoch: 1619 [40960/90000 (45%)]	Loss: -9.0476	Cost: 13.65s
Train Epoch: 1619 [61440/90000 (68%)]	Loss: -9.3256	Cost: 12.14s
Train Epoch: 1619 [81920/90000 (91%)]	Loss: -7.9648	Cost: 12.15s
Train Epoch: 1619 	Average Loss: -8.5035
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.1236

Learning rate: 9.367077429275838e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1620 [0/90000 (0%)]	Loss: -3.6126	Cost: 40.04s
Train Epoch: 1620 [20480/90000 (23%)]	Loss: -8.1328	Cost: 7.46s
Train Epoch: 1620 [40960/90000 (45%)]	Loss: -8.2756	Cost: 10.94s
Train Epoch: 1620 [61440/90000 (68%)]	Loss: -8.6154	Cost: 8.92s
Train Epoch: 1620 [81920/90000 (91%)]	Loss: -8.7022	Cost: 11.14s
Train Epoch: 1620 	Average Loss: -8.0059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7023

Learning rate: 9.366312274049581e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1621 [0/90000 (0%)]	Loss: -4.4868	Cost: 30.58s
Train Epoch: 1621 [20480/90000 (23%)]	Loss: -8.1134	Cost: 9.86s
Train Epoch: 1621 [40960/90000 (45%)]	Loss: -8.3744	Cost: 25.67s
Train Epoch: 1621 [61440/90000 (68%)]	Loss: -8.9158	Cost: 12.07s
Train Epoch: 1621 [81920/90000 (91%)]	Loss: -8.8261	Cost: 12.84s
Train Epoch: 1621 	Average Loss: -8.2575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8263

Learning rate: 9.365546687885579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1622 [0/90000 (0%)]	Loss: -4.7320	Cost: 41.45s
Train Epoch: 1622 [20480/90000 (23%)]	Loss: -8.8792	Cost: 8.41s
Train Epoch: 1622 [40960/90000 (45%)]	Loss: -8.8799	Cost: 14.88s
Train Epoch: 1622 [61440/90000 (68%)]	Loss: -9.4037	Cost: 8.67s
Train Epoch: 1622 [81920/90000 (91%)]	Loss: -9.1609	Cost: 9.54s
Train Epoch: 1622 	Average Loss: -8.7184
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0190

Learning rate: 9.364780670859392e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1623 [0/90000 (0%)]	Loss: -5.0264	Cost: 33.85s
Train Epoch: 1623 [20480/90000 (23%)]	Loss: -8.8768	Cost: 7.15s
Train Epoch: 1623 [40960/90000 (45%)]	Loss: -8.8538	Cost: 17.39s
Train Epoch: 1623 [61440/90000 (68%)]	Loss: -9.3883	Cost: 12.63s
Train Epoch: 1623 [81920/90000 (91%)]	Loss: -9.0731	Cost: 12.15s
Train Epoch: 1623 	Average Loss: -8.8167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.0468

Learning rate: 9.364014223046625e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1624 [0/90000 (0%)]	Loss: -4.5658	Cost: 31.11s
Train Epoch: 1624 [20480/90000 (23%)]	Loss: -9.1977	Cost: 8.70s
Train Epoch: 1624 [40960/90000 (45%)]	Loss: -8.9157	Cost: 11.00s
Train Epoch: 1624 [61440/90000 (68%)]	Loss: -9.2625	Cost: 8.55s
Train Epoch: 1624 [81920/90000 (91%)]	Loss: -9.3026	Cost: 12.46s
Train Epoch: 1624 	Average Loss: -8.8087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1548

Learning rate: 9.363247344522919e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1625 [0/90000 (0%)]	Loss: -5.1891	Cost: 30.74s
Train Epoch: 1625 [20480/90000 (23%)]	Loss: -8.8692	Cost: 6.83s
Train Epoch: 1625 [40960/90000 (45%)]	Loss: -8.8741	Cost: 18.37s
Train Epoch: 1625 [61440/90000 (68%)]	Loss: -9.3775	Cost: 12.38s
Train Epoch: 1625 [81920/90000 (91%)]	Loss: -9.3831	Cost: 12.26s
Train Epoch: 1625 	Average Loss: -8.8393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2685

Learning rate: 9.362480035363967e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1626 [0/90000 (0%)]	Loss: -4.6344	Cost: 35.71s
Train Epoch: 1626 [20480/90000 (23%)]	Loss: -8.3760	Cost: 13.17s
Train Epoch: 1626 [40960/90000 (45%)]	Loss: -8.2545	Cost: 10.39s
Train Epoch: 1626 [61440/90000 (68%)]	Loss: -8.9336	Cost: 8.51s
Train Epoch: 1626 [81920/90000 (91%)]	Loss: -8.9221	Cost: 15.86s
Train Epoch: 1626 	Average Loss: -8.4054
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7915

Learning rate: 9.361712295645495e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1627 [0/90000 (0%)]	Loss: -4.7506	Cost: 46.76s
Train Epoch: 1627 [20480/90000 (23%)]	Loss: -8.8098	Cost: 13.18s
Train Epoch: 1627 [40960/90000 (45%)]	Loss: -8.8106	Cost: 12.30s
Train Epoch: 1627 [61440/90000 (68%)]	Loss: -9.4387	Cost: 11.94s
Train Epoch: 1627 [81920/90000 (91%)]	Loss: -9.3401	Cost: 12.07s
Train Epoch: 1627 	Average Loss: -8.7416
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2602

Learning rate: 9.360944125443278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1628 [0/90000 (0%)]	Loss: -4.9067	Cost: 51.03s
Train Epoch: 1628 [20480/90000 (23%)]	Loss: -9.1184	Cost: 6.33s
Train Epoch: 1628 [40960/90000 (45%)]	Loss: -9.1480	Cost: 14.94s
Train Epoch: 1628 [61440/90000 (68%)]	Loss: -9.4860	Cost: 8.49s
Train Epoch: 1628 [81920/90000 (91%)]	Loss: -9.4765	Cost: 8.45s
Train Epoch: 1628 	Average Loss: -8.9687
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1602

Learning rate: 9.360175524833132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1629 [0/90000 (0%)]	Loss: -4.9755	Cost: 29.08s
Train Epoch: 1629 [20480/90000 (23%)]	Loss: -9.1882	Cost: 8.27s
Train Epoch: 1629 [40960/90000 (45%)]	Loss: -9.2499	Cost: 22.37s
Train Epoch: 1629 [61440/90000 (68%)]	Loss: -9.4575	Cost: 14.81s
Train Epoch: 1629 [81920/90000 (91%)]	Loss: -9.2898	Cost: 13.11s
Train Epoch: 1629 	Average Loss: -8.9448
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3478

Saving model as e1629_model.pt & e1629_waveforms_supplementary.hdf5
Learning rate: 9.359406493890915e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1630 [0/90000 (0%)]	Loss: -5.0420	Cost: 39.39s
Train Epoch: 1630 [20480/90000 (23%)]	Loss: -9.1421	Cost: 11.66s
Train Epoch: 1630 [40960/90000 (45%)]	Loss: -9.2879	Cost: 7.44s
Train Epoch: 1630 [61440/90000 (68%)]	Loss: -9.6397	Cost: 6.10s
Train Epoch: 1630 [81920/90000 (91%)]	Loss: -9.3460	Cost: 14.93s
Train Epoch: 1630 	Average Loss: -9.0605
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2498

Learning rate: 9.358637032692525e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1631 [0/90000 (0%)]	Loss: -4.9785	Cost: 32.02s
Train Epoch: 1631 [20480/90000 (23%)]	Loss: -9.0554	Cost: 9.44s
Train Epoch: 1631 [40960/90000 (45%)]	Loss: -9.0788	Cost: 15.68s
Train Epoch: 1631 [61440/90000 (68%)]	Loss: -9.5639	Cost: 12.73s
Train Epoch: 1631 [81920/90000 (91%)]	Loss: -9.4232	Cost: 12.27s
Train Epoch: 1631 	Average Loss: -8.9105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2403

Learning rate: 9.357867141313905e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1632 [0/90000 (0%)]	Loss: -5.1512	Cost: 58.62s
Train Epoch: 1632 [20480/90000 (23%)]	Loss: -9.2138	Cost: 6.31s
Train Epoch: 1632 [40960/90000 (45%)]	Loss: -9.1489	Cost: 14.55s
Train Epoch: 1632 [61440/90000 (68%)]	Loss: -9.6949	Cost: 8.69s
Train Epoch: 1632 [81920/90000 (91%)]	Loss: -9.5173	Cost: 8.24s
Train Epoch: 1632 	Average Loss: -9.0906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2982

Learning rate: 9.357096819831042e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1633 [0/90000 (0%)]	Loss: -5.0055	Cost: 28.40s
Train Epoch: 1633 [20480/90000 (23%)]	Loss: -8.2227	Cost: 7.37s
Train Epoch: 1633 [40960/90000 (45%)]	Loss: -8.3077	Cost: 17.21s
Train Epoch: 1633 [61440/90000 (68%)]	Loss: -8.8622	Cost: 12.30s
Train Epoch: 1633 [81920/90000 (91%)]	Loss: -9.1726	Cost: 12.40s
Train Epoch: 1633 	Average Loss: -8.4891
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9825

Learning rate: 9.356326068319965e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1634 [0/90000 (0%)]	Loss: -4.7063	Cost: 33.57s
Train Epoch: 1634 [20480/90000 (23%)]	Loss: -9.0481	Cost: 7.66s
Train Epoch: 1634 [40960/90000 (45%)]	Loss: -8.8489	Cost: 13.14s
Train Epoch: 1634 [61440/90000 (68%)]	Loss: -9.1917	Cost: 8.77s
Train Epoch: 1634 [81920/90000 (91%)]	Loss: -9.4880	Cost: 12.53s
Train Epoch: 1634 	Average Loss: -8.7782
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4227

Saving model as e1634_model.pt & e1634_waveforms_supplementary.hdf5
Learning rate: 9.355554886856741e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1635 [0/90000 (0%)]	Loss: -4.7489	Cost: 33.96s
Train Epoch: 1635 [20480/90000 (23%)]	Loss: -9.1666	Cost: 8.10s
Train Epoch: 1635 [40960/90000 (45%)]	Loss: -8.9725	Cost: 19.00s
Train Epoch: 1635 [61440/90000 (68%)]	Loss: -9.2418	Cost: 12.08s
Train Epoch: 1635 [81920/90000 (91%)]	Loss: -9.4215	Cost: 12.18s
Train Epoch: 1635 	Average Loss: -8.8376
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1843

Learning rate: 9.354783275517484e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1636 [0/90000 (0%)]	Loss: -5.0096	Cost: 40.11s
Train Epoch: 1636 [20480/90000 (23%)]	Loss: -9.1697	Cost: 7.60s
Train Epoch: 1636 [40960/90000 (45%)]	Loss: -8.9809	Cost: 12.41s
Train Epoch: 1636 [61440/90000 (68%)]	Loss: -9.4303	Cost: 8.97s
Train Epoch: 1636 [81920/90000 (91%)]	Loss: -9.4977	Cost: 12.26s
Train Epoch: 1636 	Average Loss: -8.9517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3840

Learning rate: 9.354011234378349e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1637 [0/90000 (0%)]	Loss: -5.0366	Cost: 31.61s
Train Epoch: 1637 [20480/90000 (23%)]	Loss: -9.5331	Cost: 7.55s
Train Epoch: 1637 [40960/90000 (45%)]	Loss: -9.4221	Cost: 16.81s
Train Epoch: 1637 [61440/90000 (68%)]	Loss: -9.5079	Cost: 12.08s
Train Epoch: 1637 [81920/90000 (91%)]	Loss: -9.4553	Cost: 11.94s
Train Epoch: 1637 	Average Loss: -9.0781
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1752

Learning rate: 9.353238763515532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1638 [0/90000 (0%)]	Loss: -5.1040	Cost: 32.03s
Train Epoch: 1638 [20480/90000 (23%)]	Loss: -9.2277	Cost: 11.85s
Train Epoch: 1638 [40960/90000 (45%)]	Loss: -9.1097	Cost: 6.54s
Train Epoch: 1638 [61440/90000 (68%)]	Loss: -9.6208	Cost: 6.14s
Train Epoch: 1638 [81920/90000 (91%)]	Loss: -9.3071	Cost: 12.75s
Train Epoch: 1638 	Average Loss: -8.9815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2788

Learning rate: 9.352465863005275e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1639 [0/90000 (0%)]	Loss: -4.9549	Cost: 27.12s
Train Epoch: 1639 [20480/90000 (23%)]	Loss: -8.9687	Cost: 9.35s
Train Epoch: 1639 [40960/90000 (45%)]	Loss: -8.7627	Cost: 25.32s
Train Epoch: 1639 [61440/90000 (68%)]	Loss: -8.9599	Cost: 13.26s
Train Epoch: 1639 [81920/90000 (91%)]	Loss: -9.0791	Cost: 12.00s
Train Epoch: 1639 	Average Loss: -8.6741
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1250

Learning rate: 9.35169253292386e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1640 [0/90000 (0%)]	Loss: -5.1019	Cost: 53.04s
Train Epoch: 1640 [20480/90000 (23%)]	Loss: -9.1749	Cost: 6.48s
Train Epoch: 1640 [40960/90000 (45%)]	Loss: -9.2511	Cost: 14.00s
Train Epoch: 1640 [61440/90000 (68%)]	Loss: -9.7253	Cost: 8.49s
Train Epoch: 1640 [81920/90000 (91%)]	Loss: -9.4749	Cost: 8.44s
Train Epoch: 1640 	Average Loss: -9.0277
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1326

Learning rate: 9.350918773347609e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1641 [0/90000 (0%)]	Loss: -4.2487	Cost: 27.02s
Train Epoch: 1641 [20480/90000 (23%)]	Loss: -9.2083	Cost: 9.39s
Train Epoch: 1641 [40960/90000 (45%)]	Loss: -9.3628	Cost: 22.11s
Train Epoch: 1641 [61440/90000 (68%)]	Loss: -9.5589	Cost: 12.39s
Train Epoch: 1641 [81920/90000 (91%)]	Loss: -9.3088	Cost: 11.97s
Train Epoch: 1641 	Average Loss: -9.0155
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2368

Learning rate: 9.350144584352891e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1642 [0/90000 (0%)]	Loss: -5.1005	Cost: 46.37s
Train Epoch: 1642 [20480/90000 (23%)]	Loss: -9.3392	Cost: 6.95s
Train Epoch: 1642 [40960/90000 (45%)]	Loss: -9.4506	Cost: 12.69s
Train Epoch: 1642 [61440/90000 (68%)]	Loss: -9.8119	Cost: 8.61s
Train Epoch: 1642 [81920/90000 (91%)]	Loss: -9.4256	Cost: 9.13s
Train Epoch: 1642 	Average Loss: -9.1833
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4052

Learning rate: 9.349369966016114e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1643 [0/90000 (0%)]	Loss: -5.1838	Cost: 27.74s
Train Epoch: 1643 [20480/90000 (23%)]	Loss: -9.1689	Cost: 8.22s
Train Epoch: 1643 [40960/90000 (45%)]	Loss: -8.8979	Cost: 25.28s
Train Epoch: 1643 [61440/90000 (68%)]	Loss: -8.9504	Cost: 13.18s
Train Epoch: 1643 [81920/90000 (91%)]	Loss: -8.9990	Cost: 12.34s
Train Epoch: 1643 	Average Loss: -8.7115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8824

Learning rate: 9.348594918413733e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1644 [0/90000 (0%)]	Loss: -4.8117	Cost: 32.40s
Train Epoch: 1644 [20480/90000 (23%)]	Loss: -8.8896	Cost: 14.10s
Train Epoch: 1644 [40960/90000 (45%)]	Loss: -9.0591	Cost: 12.70s
Train Epoch: 1644 [61440/90000 (68%)]	Loss: -9.6146	Cost: 8.50s
Train Epoch: 1644 [81920/90000 (91%)]	Loss: -9.5083	Cost: 13.88s
Train Epoch: 1644 	Average Loss: -8.9708
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4201

Learning rate: 9.34781944162224e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1645 [0/90000 (0%)]	Loss: -5.3533	Cost: 39.54s
Train Epoch: 1645 [20480/90000 (23%)]	Loss: -9.0047	Cost: 7.10s
Train Epoch: 1645 [40960/90000 (45%)]	Loss: -9.1042	Cost: 17.11s
Train Epoch: 1645 [61440/90000 (68%)]	Loss: -9.2085	Cost: 12.28s
Train Epoch: 1645 [81920/90000 (91%)]	Loss: -9.2245	Cost: 11.86s
Train Epoch: 1645 	Average Loss: -8.8678
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1482

Learning rate: 9.34704353571817e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1646 [0/90000 (0%)]	Loss: -4.7345	Cost: 34.74s
Train Epoch: 1646 [20480/90000 (23%)]	Loss: -9.1465	Cost: 12.10s
Train Epoch: 1646 [40960/90000 (45%)]	Loss: -9.3837	Cost: 9.53s
Train Epoch: 1646 [61440/90000 (68%)]	Loss: -9.7692	Cost: 6.30s
Train Epoch: 1646 [81920/90000 (91%)]	Loss: -9.6635	Cost: 12.49s
Train Epoch: 1646 	Average Loss: -9.0849
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2549

Learning rate: 9.346267200778104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1647 [0/90000 (0%)]	Loss: -5.3748	Cost: 31.72s
Train Epoch: 1647 [20480/90000 (23%)]	Loss: -9.4438	Cost: 9.77s
Train Epoch: 1647 [40960/90000 (45%)]	Loss: -9.1784	Cost: 22.47s
Train Epoch: 1647 [61440/90000 (68%)]	Loss: -9.5859	Cost: 12.12s
Train Epoch: 1647 [81920/90000 (91%)]	Loss: -9.3482	Cost: 11.81s
Train Epoch: 1647 	Average Loss: -9.1077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1993

Learning rate: 9.345490436878664e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1648 [0/90000 (0%)]	Loss: -4.4070	Cost: 48.05s
Train Epoch: 1648 [20480/90000 (23%)]	Loss: -8.6219	Cost: 6.25s
Train Epoch: 1648 [40960/90000 (45%)]	Loss: -8.5819	Cost: 12.80s
Train Epoch: 1648 [61440/90000 (68%)]	Loss: -8.5617	Cost: 9.57s
Train Epoch: 1648 [81920/90000 (91%)]	Loss: -8.6657	Cost: 9.96s
Train Epoch: 1648 	Average Loss: -8.3546
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.5654

Learning rate: 9.344713244096511e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1649 [0/90000 (0%)]	Loss: -4.4145	Cost: 33.24s
Train Epoch: 1649 [20480/90000 (23%)]	Loss: -8.7228	Cost: 7.66s
Train Epoch: 1649 [40960/90000 (45%)]	Loss: -8.8355	Cost: 16.83s
Train Epoch: 1649 [61440/90000 (68%)]	Loss: -9.1530	Cost: 12.20s
Train Epoch: 1649 [81920/90000 (91%)]	Loss: -8.8646	Cost: 11.73s
Train Epoch: 1649 	Average Loss: -8.4166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6762

Learning rate: 9.343935622508351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1650 [0/90000 (0%)]	Loss: -4.1266	Cost: 31.03s
Train Epoch: 1650 [20480/90000 (23%)]	Loss: -8.3092	Cost: 6.52s
Train Epoch: 1650 [40960/90000 (45%)]	Loss: -8.5262	Cost: 13.12s
Train Epoch: 1650 [61440/90000 (68%)]	Loss: -8.9292	Cost: 8.58s
Train Epoch: 1650 [81920/90000 (91%)]	Loss: -7.9103	Cost: 9.12s
Train Epoch: 1650 	Average Loss: -8.1838
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.2612

Learning rate: 9.343157572190936e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1651 [0/90000 (0%)]	Loss: -4.1581	Cost: 27.26s
Train Epoch: 1651 [20480/90000 (23%)]	Loss: -7.9300	Cost: 9.93s
Train Epoch: 1651 [40960/90000 (45%)]	Loss: -8.5342	Cost: 21.21s
Train Epoch: 1651 [61440/90000 (68%)]	Loss: -8.7693	Cost: 13.69s
Train Epoch: 1651 [81920/90000 (91%)]	Loss: -7.3420	Cost: 12.00s
Train Epoch: 1651 	Average Loss: -7.8077
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -3.9566

Learning rate: 9.34237909322105e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1652 [0/90000 (0%)]	Loss: -3.5821	Cost: 57.96s
Train Epoch: 1652 [20480/90000 (23%)]	Loss: -7.4907	Cost: 10.40s
Train Epoch: 1652 [40960/90000 (45%)]	Loss: -8.2597	Cost: 7.37s
Train Epoch: 1652 [61440/90000 (68%)]	Loss: -8.5907	Cost: 6.71s
Train Epoch: 1652 [81920/90000 (91%)]	Loss: -8.6212	Cost: 13.17s
Train Epoch: 1652 	Average Loss: -7.7707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.8122

Learning rate: 9.341600185675532e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1653 [0/90000 (0%)]	Loss: -4.4591	Cost: 28.09s
Train Epoch: 1653 [20480/90000 (23%)]	Loss: -8.8308	Cost: 9.58s
Train Epoch: 1653 [40960/90000 (45%)]	Loss: -9.1705	Cost: 24.18s
Train Epoch: 1653 [61440/90000 (68%)]	Loss: -9.4618	Cost: 12.17s
Train Epoch: 1653 [81920/90000 (91%)]	Loss: -9.2591	Cost: 12.01s
Train Epoch: 1653 	Average Loss: -8.7930
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2970

Learning rate: 9.340820849631254e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1654 [0/90000 (0%)]	Loss: -4.8220	Cost: 43.46s
Train Epoch: 1654 [20480/90000 (23%)]	Loss: -9.3296	Cost: 6.22s
Train Epoch: 1654 [40960/90000 (45%)]	Loss: -9.5123	Cost: 13.03s
Train Epoch: 1654 [61440/90000 (68%)]	Loss: -9.6736	Cost: 8.78s
Train Epoch: 1654 [81920/90000 (91%)]	Loss: -9.7093	Cost: 9.20s
Train Epoch: 1654 	Average Loss: -9.2233
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5784

Saving model as e1654_model.pt & e1654_waveforms_supplementary.hdf5
Learning rate: 9.340041085165135e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1655 [0/90000 (0%)]	Loss: -5.2293	Cost: 31.02s
Train Epoch: 1655 [20480/90000 (23%)]	Loss: -9.5202	Cost: 14.59s
Train Epoch: 1655 [40960/90000 (45%)]	Loss: -9.4430	Cost: 14.50s
Train Epoch: 1655 [61440/90000 (68%)]	Loss: -9.6125	Cost: 12.48s
Train Epoch: 1655 [81920/90000 (91%)]	Loss: -9.5558	Cost: 12.11s
Train Epoch: 1655 	Average Loss: -9.2163
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4087

Learning rate: 9.339260892354131e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1656 [0/90000 (0%)]	Loss: -4.6375	Cost: 31.09s
Train Epoch: 1656 [20480/90000 (23%)]	Loss: -9.0833	Cost: 9.61s
Train Epoch: 1656 [40960/90000 (45%)]	Loss: -9.0426	Cost: 17.81s
Train Epoch: 1656 [61440/90000 (68%)]	Loss: -9.6344	Cost: 8.87s
Train Epoch: 1656 [81920/90000 (91%)]	Loss: -8.5004	Cost: 13.49s
Train Epoch: 1656 	Average Loss: -8.8344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6370

Learning rate: 9.338480271275247e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1657 [0/90000 (0%)]	Loss: -4.4953	Cost: 43.34s
Train Epoch: 1657 [20480/90000 (23%)]	Loss: -8.7393	Cost: 12.62s
Train Epoch: 1657 [40960/90000 (45%)]	Loss: -9.0201	Cost: 12.85s
Train Epoch: 1657 [61440/90000 (68%)]	Loss: -9.2781	Cost: 11.99s
Train Epoch: 1657 [81920/90000 (91%)]	Loss: -9.5354	Cost: 12.01s
Train Epoch: 1657 	Average Loss: -8.7260
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2780

Learning rate: 9.337699222005527e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1658 [0/90000 (0%)]	Loss: -4.8192	Cost: 36.82s
Train Epoch: 1658 [20480/90000 (23%)]	Loss: -9.0200	Cost: 6.65s
Train Epoch: 1658 [40960/90000 (45%)]	Loss: -9.0763	Cost: 13.12s
Train Epoch: 1658 [61440/90000 (68%)]	Loss: -9.7538	Cost: 8.96s
Train Epoch: 1658 [81920/90000 (91%)]	Loss: -9.3363	Cost: 10.99s
Train Epoch: 1658 	Average Loss: -8.9188
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4133

Learning rate: 9.336917744622058e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1659 [0/90000 (0%)]	Loss: -4.2335	Cost: 30.12s
Train Epoch: 1659 [20480/90000 (23%)]	Loss: -8.2539	Cost: 10.06s
Train Epoch: 1659 [40960/90000 (45%)]	Loss: -8.6716	Cost: 15.53s
Train Epoch: 1659 [61440/90000 (68%)]	Loss: -9.2850	Cost: 12.32s
Train Epoch: 1659 [81920/90000 (91%)]	Loss: -9.1980	Cost: 12.24s
Train Epoch: 1659 	Average Loss: -8.4796
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3495

Learning rate: 9.336135839201968e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1660 [0/90000 (0%)]	Loss: -4.8057	Cost: 46.31s
Train Epoch: 1660 [20480/90000 (23%)]	Loss: -9.4602	Cost: 9.94s
Train Epoch: 1660 [40960/90000 (45%)]	Loss: -9.3603	Cost: 9.99s
Train Epoch: 1660 [61440/90000 (68%)]	Loss: -9.7282	Cost: 6.51s
Train Epoch: 1660 [81920/90000 (91%)]	Loss: -9.6087	Cost: 12.59s
Train Epoch: 1660 	Average Loss: -9.1606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4073

Learning rate: 9.335353505822426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1661 [0/90000 (0%)]	Loss: -5.0556	Cost: 45.58s
Train Epoch: 1661 [20480/90000 (23%)]	Loss: -9.5429	Cost: 12.46s
Train Epoch: 1661 [40960/90000 (45%)]	Loss: -9.5280	Cost: 12.37s
Train Epoch: 1661 [61440/90000 (68%)]	Loss: -9.8783	Cost: 11.97s
Train Epoch: 1661 [81920/90000 (91%)]	Loss: -9.7500	Cost: 12.02s
Train Epoch: 1661 	Average Loss: -9.2988
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6457

Saving model as e1661_model.pt & e1661_waveforms_supplementary.hdf5
Learning rate: 9.334570744560649e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1662 [0/90000 (0%)]	Loss: -5.6088	Cost: 41.12s
Train Epoch: 1662 [20480/90000 (23%)]	Loss: -9.6537	Cost: 11.31s
Train Epoch: 1662 [40960/90000 (45%)]	Loss: -9.5148	Cost: 6.32s
Train Epoch: 1662 [61440/90000 (68%)]	Loss: -10.0450	Cost: 6.41s
Train Epoch: 1662 [81920/90000 (91%)]	Loss: -10.0871	Cost: 12.37s
Train Epoch: 1662 	Average Loss: -9.4141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6350

Learning rate: 9.33378755549389e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1663 [0/90000 (0%)]	Loss: -5.5753	Cost: 30.05s
Train Epoch: 1663 [20480/90000 (23%)]	Loss: -9.5309	Cost: 6.78s
Train Epoch: 1663 [40960/90000 (45%)]	Loss: -9.6079	Cost: 18.68s
Train Epoch: 1663 [61440/90000 (68%)]	Loss: -10.0598	Cost: 12.62s
Train Epoch: 1663 [81920/90000 (91%)]	Loss: -9.8376	Cost: 12.45s
Train Epoch: 1663 	Average Loss: -9.4534
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7515

Saving model as e1663_model.pt & e1663_waveforms_supplementary.hdf5
Learning rate: 9.333003938699447e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1664 [0/90000 (0%)]	Loss: -5.6482	Cost: 37.51s
Train Epoch: 1664 [20480/90000 (23%)]	Loss: -9.4434	Cost: 12.30s
Train Epoch: 1664 [40960/90000 (45%)]	Loss: -9.7861	Cost: 9.21s
Train Epoch: 1664 [61440/90000 (68%)]	Loss: -10.0552	Cost: 6.69s
Train Epoch: 1664 [81920/90000 (91%)]	Loss: -9.6706	Cost: 11.56s
Train Epoch: 1664 	Average Loss: -9.3944
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4781

Learning rate: 9.332219894254661e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1665 [0/90000 (0%)]	Loss: -5.2781	Cost: 26.83s
Train Epoch: 1665 [20480/90000 (23%)]	Loss: -9.4513	Cost: 9.47s
Train Epoch: 1665 [40960/90000 (45%)]	Loss: -9.6843	Cost: 17.57s
Train Epoch: 1665 [61440/90000 (68%)]	Loss: -9.8808	Cost: 14.11s
Train Epoch: 1665 [81920/90000 (91%)]	Loss: -9.6326	Cost: 12.82s
Train Epoch: 1665 	Average Loss: -9.3373
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3686

Learning rate: 9.331435422236914e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1666 [0/90000 (0%)]	Loss: -4.4844	Cost: 40.92s
Train Epoch: 1666 [20480/90000 (23%)]	Loss: -9.5081	Cost: 13.89s
Train Epoch: 1666 [40960/90000 (45%)]	Loss: -9.6819	Cost: 12.62s
Train Epoch: 1666 [61440/90000 (68%)]	Loss: -9.7932	Cost: 8.55s
Train Epoch: 1666 [81920/90000 (91%)]	Loss: -8.9915	Cost: 5.97s
Train Epoch: 1666 	Average Loss: -9.1608
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9046

Learning rate: 9.330650522723627e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1667 [0/90000 (0%)]	Loss: -4.3791	Cost: 44.31s
Train Epoch: 1667 [20480/90000 (23%)]	Loss: -8.8548	Cost: 6.53s
Train Epoch: 1667 [40960/90000 (45%)]	Loss: -9.0101	Cost: 12.45s
Train Epoch: 1667 [61440/90000 (68%)]	Loss: -9.4139	Cost: 11.95s
Train Epoch: 1667 [81920/90000 (91%)]	Loss: -9.5529	Cost: 13.44s
Train Epoch: 1667 	Average Loss: -8.8397
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2217

Learning rate: 9.329865195792271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1668 [0/90000 (0%)]	Loss: -4.9459	Cost: 39.66s
Train Epoch: 1668 [20480/90000 (23%)]	Loss: -9.1036	Cost: 12.65s
Train Epoch: 1668 [40960/90000 (45%)]	Loss: -9.4557	Cost: 12.16s
Train Epoch: 1668 [61440/90000 (68%)]	Loss: -9.6561	Cost: 6.53s
Train Epoch: 1668 [81920/90000 (91%)]	Loss: -9.4954	Cost: 6.18s
Train Epoch: 1668 	Average Loss: -9.0353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2998

Learning rate: 9.329079441520351e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1669 [0/90000 (0%)]	Loss: -4.3790	Cost: 33.85s
Train Epoch: 1669 [20480/90000 (23%)]	Loss: -9.4224	Cost: 6.86s
Train Epoch: 1669 [40960/90000 (45%)]	Loss: -8.8461	Cost: 10.92s
Train Epoch: 1669 [61440/90000 (68%)]	Loss: -9.4772	Cost: 8.48s
Train Epoch: 1669 [81920/90000 (91%)]	Loss: -9.3422	Cost: 17.03s
Train Epoch: 1669 	Average Loss: -8.8987
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1701

Learning rate: 9.328293259985419e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1670 [0/90000 (0%)]	Loss: -4.6815	Cost: 38.79s
Train Epoch: 1670 [20480/90000 (23%)]	Loss: -8.8830	Cost: 12.80s
Train Epoch: 1670 [40960/90000 (45%)]	Loss: -9.3083	Cost: 13.52s
Train Epoch: 1670 [61440/90000 (68%)]	Loss: -9.5178	Cost: 9.45s
Train Epoch: 1670 [81920/90000 (91%)]	Loss: -9.5183	Cost: 7.38s
Train Epoch: 1670 	Average Loss: -8.9406
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5044

Learning rate: 9.32750665126507e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1671 [0/90000 (0%)]	Loss: -5.2522	Cost: 41.59s
Train Epoch: 1671 [20480/90000 (23%)]	Loss: -9.5176	Cost: 8.97s
Train Epoch: 1671 [40960/90000 (45%)]	Loss: -9.3619	Cost: 11.08s
Train Epoch: 1671 [61440/90000 (68%)]	Loss: -9.6818	Cost: 8.77s
Train Epoch: 1671 [81920/90000 (91%)]	Loss: -9.0913	Cost: 5.57s
Train Epoch: 1671 	Average Loss: -9.1731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1382

Learning rate: 9.326719615436937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1672 [0/90000 (0%)]	Loss: -4.8157	Cost: 43.60s
Train Epoch: 1672 [20480/90000 (23%)]	Loss: -8.9022	Cost: 6.69s
Train Epoch: 1672 [40960/90000 (45%)]	Loss: -8.7364	Cost: 17.18s
Train Epoch: 1672 [61440/90000 (68%)]	Loss: -9.4359	Cost: 12.01s
Train Epoch: 1672 [81920/90000 (91%)]	Loss: -9.5453	Cost: 12.72s
Train Epoch: 1672 	Average Loss: -8.8656
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5160

Learning rate: 9.325932152578697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1673 [0/90000 (0%)]	Loss: -5.1275	Cost: 31.28s
Train Epoch: 1673 [20480/90000 (23%)]	Loss: -9.4712	Cost: 8.05s
Train Epoch: 1673 [40960/90000 (45%)]	Loss: -9.4132	Cost: 11.87s
Train Epoch: 1673 [61440/90000 (68%)]	Loss: -9.9144	Cost: 8.96s
Train Epoch: 1673 [81920/90000 (91%)]	Loss: -9.7221	Cost: 10.46s
Train Epoch: 1673 	Average Loss: -9.2887
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7895

Saving model as e1673_model.pt & e1673_waveforms_supplementary.hdf5
Learning rate: 9.325144262768072e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1674 [0/90000 (0%)]	Loss: -5.5221	Cost: 42.94s
Train Epoch: 1674 [20480/90000 (23%)]	Loss: -9.6740	Cost: 14.17s
Train Epoch: 1674 [40960/90000 (45%)]	Loss: -9.9366	Cost: 12.63s
Train Epoch: 1674 [61440/90000 (68%)]	Loss: -10.1038	Cost: 12.09s
Train Epoch: 1674 [81920/90000 (91%)]	Loss: -9.8908	Cost: 10.31s
Train Epoch: 1674 	Average Loss: -9.5353
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6578

Learning rate: 9.324355946082821e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1675 [0/90000 (0%)]	Loss: -5.1651	Cost: 35.04s
Train Epoch: 1675 [20480/90000 (23%)]	Loss: -9.8307	Cost: 8.79s
Train Epoch: 1675 [40960/90000 (45%)]	Loss: -9.9463	Cost: 10.24s
Train Epoch: 1675 [61440/90000 (68%)]	Loss: -10.1932	Cost: 8.57s
Train Epoch: 1675 [81920/90000 (91%)]	Loss: -10.0194	Cost: 8.41s
Train Epoch: 1675 	Average Loss: -9.5865
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7180

Learning rate: 9.32356720260075e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1676 [0/90000 (0%)]	Loss: -5.6266	Cost: 31.39s
Train Epoch: 1676 [20480/90000 (23%)]	Loss: -9.7686	Cost: 12.52s
Train Epoch: 1676 [40960/90000 (45%)]	Loss: -9.8874	Cost: 16.72s
Train Epoch: 1676 [61440/90000 (68%)]	Loss: -9.9581	Cost: 12.29s
Train Epoch: 1676 [81920/90000 (91%)]	Loss: -9.5869	Cost: 12.21s
Train Epoch: 1676 	Average Loss: -9.4995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5279

Learning rate: 9.322778032399702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1677 [0/90000 (0%)]	Loss: -5.0718	Cost: 38.67s
Train Epoch: 1677 [20480/90000 (23%)]	Loss: -9.4452	Cost: 10.26s
Train Epoch: 1677 [40960/90000 (45%)]	Loss: -9.7895	Cost: 8.54s
Train Epoch: 1677 [61440/90000 (68%)]	Loss: -9.9779	Cost: 6.07s
Train Epoch: 1677 [81920/90000 (91%)]	Loss: -10.0404	Cost: 12.50s
Train Epoch: 1677 	Average Loss: -9.4271
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6335

Learning rate: 9.321988435557567e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1678 [0/90000 (0%)]	Loss: -5.3581	Cost: 28.98s
Train Epoch: 1678 [20480/90000 (23%)]	Loss: -9.6613	Cost: 8.91s
Train Epoch: 1678 [40960/90000 (45%)]	Loss: -9.6056	Cost: 26.00s
Train Epoch: 1678 [61440/90000 (68%)]	Loss: -10.1764	Cost: 12.80s
Train Epoch: 1678 [81920/90000 (91%)]	Loss: -9.9585	Cost: 14.94s
Train Epoch: 1678 	Average Loss: -9.4604
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7526

Learning rate: 9.321198412152276e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1679 [0/90000 (0%)]	Loss: -5.6382	Cost: 42.03s
Train Epoch: 1679 [20480/90000 (23%)]	Loss: -9.6077	Cost: 7.29s
Train Epoch: 1679 [40960/90000 (45%)]	Loss: -9.5423	Cost: 14.49s
Train Epoch: 1679 [61440/90000 (68%)]	Loss: -9.9262	Cost: 9.02s
Train Epoch: 1679 [81920/90000 (91%)]	Loss: -9.9772	Cost: 10.48s
Train Epoch: 1679 	Average Loss: -9.4777
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7797

Learning rate: 9.3204079622618e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1680 [0/90000 (0%)]	Loss: -5.2778	Cost: 32.10s
Train Epoch: 1680 [20480/90000 (23%)]	Loss: -9.7521	Cost: 8.46s
Train Epoch: 1680 [40960/90000 (45%)]	Loss: -9.8253	Cost: 14.95s
Train Epoch: 1680 [61440/90000 (68%)]	Loss: -10.2038	Cost: 12.30s
Train Epoch: 1680 [81920/90000 (91%)]	Loss: -10.1267	Cost: 12.34s
Train Epoch: 1680 	Average Loss: -9.5410
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8270

Saving model as e1680_model.pt & e1680_waveforms_supplementary.hdf5
Learning rate: 9.31961708596415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1681 [0/90000 (0%)]	Loss: -5.5300	Cost: 48.27s
Train Epoch: 1681 [20480/90000 (23%)]	Loss: -9.6777	Cost: 6.38s
Train Epoch: 1681 [40960/90000 (45%)]	Loss: -9.7586	Cost: 14.83s
Train Epoch: 1681 [61440/90000 (68%)]	Loss: -10.0408	Cost: 8.45s
Train Epoch: 1681 [81920/90000 (91%)]	Loss: -9.9964	Cost: 8.41s
Train Epoch: 1681 	Average Loss: -9.4713
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5977

Learning rate: 9.318825783337389e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1682 [0/90000 (0%)]	Loss: -5.7461	Cost: 27.96s
Train Epoch: 1682 [20480/90000 (23%)]	Loss: -9.6139	Cost: 7.51s
Train Epoch: 1682 [40960/90000 (45%)]	Loss: -9.7305	Cost: 17.30s
Train Epoch: 1682 [61440/90000 (68%)]	Loss: -10.2041	Cost: 12.09s
Train Epoch: 1682 [81920/90000 (91%)]	Loss: -10.1508	Cost: 12.51s
Train Epoch: 1682 	Average Loss: -9.5864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7419

Learning rate: 9.318034054459612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1683 [0/90000 (0%)]	Loss: -5.3761	Cost: 34.94s
Train Epoch: 1683 [20480/90000 (23%)]	Loss: -9.9188	Cost: 11.64s
Train Epoch: 1683 [40960/90000 (45%)]	Loss: -9.9295	Cost: 6.91s
Train Epoch: 1683 [61440/90000 (68%)]	Loss: -10.2489	Cost: 10.32s
Train Epoch: 1683 [81920/90000 (91%)]	Loss: -10.0601	Cost: 15.54s
Train Epoch: 1683 	Average Loss: -9.7187
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8239

Learning rate: 9.317241899408957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1684 [0/90000 (0%)]	Loss: -5.5812	Cost: 37.98s
Train Epoch: 1684 [20480/90000 (23%)]	Loss: -9.7364	Cost: 9.07s
Train Epoch: 1684 [40960/90000 (45%)]	Loss: -9.4333	Cost: 16.11s
Train Epoch: 1684 [61440/90000 (68%)]	Loss: -9.7691	Cost: 12.12s
Train Epoch: 1684 [81920/90000 (91%)]	Loss: -9.8839	Cost: 11.93s
Train Epoch: 1684 	Average Loss: -9.4040
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8485

Saving model as e1684_model.pt & e1684_waveforms_supplementary.hdf5
Learning rate: 9.31644931826361e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1685 [0/90000 (0%)]	Loss: -5.1900	Cost: 34.26s
Train Epoch: 1685 [20480/90000 (23%)]	Loss: -9.8151	Cost: 8.72s
Train Epoch: 1685 [40960/90000 (45%)]	Loss: -9.8199	Cost: 11.38s
Train Epoch: 1685 [61440/90000 (68%)]	Loss: -10.0802	Cost: 8.99s
Train Epoch: 1685 [81920/90000 (91%)]	Loss: -9.9873	Cost: 12.59s
Train Epoch: 1685 	Average Loss: -9.5513
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7234

Learning rate: 9.315656311101795e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1686 [0/90000 (0%)]	Loss: -5.3145	Cost: 38.13s
Train Epoch: 1686 [20480/90000 (23%)]	Loss: -9.8056	Cost: 11.16s
Train Epoch: 1686 [40960/90000 (45%)]	Loss: -10.0813	Cost: 13.72s
Train Epoch: 1686 [61440/90000 (68%)]	Loss: -10.3289	Cost: 12.60s
Train Epoch: 1686 [81920/90000 (91%)]	Loss: -10.2612	Cost: 12.08s
Train Epoch: 1686 	Average Loss: -9.7007
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8154

Learning rate: 9.314862878001778e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1687 [0/90000 (0%)]	Loss: -5.3410	Cost: 35.89s
Train Epoch: 1687 [20480/90000 (23%)]	Loss: -9.8168	Cost: 8.75s
Train Epoch: 1687 [40960/90000 (45%)]	Loss: -10.0568	Cost: 10.73s
Train Epoch: 1687 [61440/90000 (68%)]	Loss: -10.2828	Cost: 8.24s
Train Epoch: 1687 [81920/90000 (91%)]	Loss: -10.1574	Cost: 14.72s
Train Epoch: 1687 	Average Loss: -9.6734
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7635

Learning rate: 9.314069019041867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1688 [0/90000 (0%)]	Loss: -5.5207	Cost: 31.54s
Train Epoch: 1688 [20480/90000 (23%)]	Loss: -9.9682	Cost: 8.96s
Train Epoch: 1688 [40960/90000 (45%)]	Loss: -9.8221	Cost: 19.49s
Train Epoch: 1688 [61440/90000 (68%)]	Loss: -10.0733	Cost: 12.36s
Train Epoch: 1688 [81920/90000 (91%)]	Loss: -9.0797	Cost: 12.33s
Train Epoch: 1688 	Average Loss: -9.5129
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.7415

Learning rate: 9.313274734300415e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1689 [0/90000 (0%)]	Loss: -4.5082	Cost: 56.41s
Train Epoch: 1689 [20480/90000 (23%)]	Loss: -8.7520	Cost: 10.23s
Train Epoch: 1689 [40960/90000 (45%)]	Loss: -9.0611	Cost: 6.35s
Train Epoch: 1689 [61440/90000 (68%)]	Loss: -9.4876	Cost: 6.61s
Train Epoch: 1689 [81920/90000 (91%)]	Loss: -9.2828	Cost: 12.30s
Train Epoch: 1689 	Average Loss: -8.7878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4449

Learning rate: 9.312480023855812e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1690 [0/90000 (0%)]	Loss: -4.8762	Cost: 28.01s
Train Epoch: 1690 [20480/90000 (23%)]	Loss: -9.3194	Cost: 7.16s
Train Epoch: 1690 [40960/90000 (45%)]	Loss: -9.6398	Cost: 24.42s
Train Epoch: 1690 [61440/90000 (68%)]	Loss: -9.8928	Cost: 14.21s
Train Epoch: 1690 [81920/90000 (91%)]	Loss: -9.8611	Cost: 12.36s
Train Epoch: 1690 	Average Loss: -9.3325
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6781

Learning rate: 9.311684887786495e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1691 [0/90000 (0%)]	Loss: -5.1109	Cost: 53.79s
Train Epoch: 1691 [20480/90000 (23%)]	Loss: -9.2070	Cost: 9.81s
Train Epoch: 1691 [40960/90000 (45%)]	Loss: -8.9268	Cost: 8.72s
Train Epoch: 1691 [61440/90000 (68%)]	Loss: -9.0811	Cost: 7.68s
Train Epoch: 1691 [81920/90000 (91%)]	Loss: -8.8555	Cost: 10.44s
Train Epoch: 1691 	Average Loss: -8.7517
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.1734

Learning rate: 9.310889326170941e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1692 [0/90000 (0%)]	Loss: -4.8759	Cost: 25.80s
Train Epoch: 1692 [20480/90000 (23%)]	Loss: -9.1017	Cost: 9.36s
Train Epoch: 1692 [40960/90000 (45%)]	Loss: -9.0151	Cost: 17.35s
Train Epoch: 1692 [61440/90000 (68%)]	Loss: -9.0047	Cost: 13.06s
Train Epoch: 1692 [81920/90000 (91%)]	Loss: -8.6892	Cost: 12.06s
Train Epoch: 1692 	Average Loss: -8.7064
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.9760

Learning rate: 9.310093339087666e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1693 [0/90000 (0%)]	Loss: -4.7967	Cost: 31.41s
Train Epoch: 1693 [20480/90000 (23%)]	Loss: -8.8848	Cost: 12.95s
Train Epoch: 1693 [40960/90000 (45%)]	Loss: -8.5166	Cost: 10.58s
Train Epoch: 1693 [61440/90000 (68%)]	Loss: -8.9828	Cost: 6.52s
Train Epoch: 1693 [81920/90000 (91%)]	Loss: -9.0254	Cost: 11.37s
Train Epoch: 1693 	Average Loss: -8.5383
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.2542

Learning rate: 9.309296926615233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1694 [0/90000 (0%)]	Loss: -5.2049	Cost: 28.61s
Train Epoch: 1694 [20480/90000 (23%)]	Loss: -9.1598	Cost: 8.48s
Train Epoch: 1694 [40960/90000 (45%)]	Loss: -9.4307	Cost: 18.51s
Train Epoch: 1694 [61440/90000 (68%)]	Loss: -9.7039	Cost: 13.08s
Train Epoch: 1694 [81920/90000 (91%)]	Loss: -9.5567	Cost: 12.46s
Train Epoch: 1694 	Average Loss: -9.1344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4819

Learning rate: 9.308500088832246e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1695 [0/90000 (0%)]	Loss: -4.8114	Cost: 34.40s
Train Epoch: 1695 [20480/90000 (23%)]	Loss: -9.4850	Cost: 12.96s
Train Epoch: 1695 [40960/90000 (45%)]	Loss: -9.7141	Cost: 12.35s
Train Epoch: 1695 [61440/90000 (68%)]	Loss: -10.0679	Cost: 6.72s
Train Epoch: 1695 [81920/90000 (91%)]	Loss: -9.8216	Cost: 10.96s
Train Epoch: 1695 	Average Loss: -9.3509
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.4365

Learning rate: 9.307702825817347e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1696 [0/90000 (0%)]	Loss: -4.3818	Cost: 32.30s
Train Epoch: 1696 [20480/90000 (23%)]	Loss: -8.3842	Cost: 11.28s
Train Epoch: 1696 [40960/90000 (45%)]	Loss: -8.7756	Cost: 13.37s
Train Epoch: 1696 [61440/90000 (68%)]	Loss: -9.5309	Cost: 7.32s
Train Epoch: 1696 [81920/90000 (91%)]	Loss: -9.5172	Cost: 19.77s
Train Epoch: 1696 	Average Loss: -8.6254
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6072

Learning rate: 9.306905137649225e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1697 [0/90000 (0%)]	Loss: -5.2528	Cost: 49.23s
Train Epoch: 1697 [20480/90000 (23%)]	Loss: -9.5094	Cost: 12.26s
Train Epoch: 1697 [40960/90000 (45%)]	Loss: -9.7300	Cost: 12.14s
Train Epoch: 1697 [61440/90000 (68%)]	Loss: -9.9873	Cost: 9.61s
Train Epoch: 1697 [81920/90000 (91%)]	Loss: -9.9263	Cost: 6.48s
Train Epoch: 1697 	Average Loss: -9.4329
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8338

Learning rate: 9.306107024406607e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1698 [0/90000 (0%)]	Loss: -5.0651	Cost: 30.41s
Train Epoch: 1698 [20480/90000 (23%)]	Loss: -9.6877	Cost: 7.94s
Train Epoch: 1698 [40960/90000 (45%)]	Loss: -9.6608	Cost: 17.85s
Train Epoch: 1698 [61440/90000 (68%)]	Loss: -9.9144	Cost: 13.54s
Train Epoch: 1698 [81920/90000 (91%)]	Loss: -9.9074	Cost: 12.97s
Train Epoch: 1698 	Average Loss: -9.4113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6521

Learning rate: 9.305308486168263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1699 [0/90000 (0%)]	Loss: -4.9298	Cost: 44.08s
Train Epoch: 1699 [20480/90000 (23%)]	Loss: -9.3881	Cost: 12.83s
Train Epoch: 1699 [40960/90000 (45%)]	Loss: -9.8382	Cost: 12.20s
Train Epoch: 1699 [61440/90000 (68%)]	Loss: -10.0075	Cost: 8.15s
Train Epoch: 1699 [81920/90000 (91%)]	Loss: -9.8353	Cost: 6.00s
Train Epoch: 1699 	Average Loss: -9.4543
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8155

Learning rate: 9.304509523013007e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1700 [0/90000 (0%)]	Loss: -5.2721	Cost: 35.99s
Train Epoch: 1700 [20480/90000 (23%)]	Loss: -9.7307	Cost: 8.50s
Train Epoch: 1700 [40960/90000 (45%)]	Loss: -9.4930	Cost: 19.50s
Train Epoch: 1700 [61440/90000 (68%)]	Loss: -9.9144	Cost: 12.70s
Train Epoch: 1700 [81920/90000 (91%)]	Loss: -9.5598	Cost: 12.05s
Train Epoch: 1700 	Average Loss: -9.3894
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5796

Learning rate: 9.303710135019694e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1701 [0/90000 (0%)]	Loss: -4.8789	Cost: 42.41s
Train Epoch: 1701 [20480/90000 (23%)]	Loss: -9.3583	Cost: 11.91s
Train Epoch: 1701 [40960/90000 (45%)]	Loss: -9.8514	Cost: 10.08s
Train Epoch: 1701 [61440/90000 (68%)]	Loss: -9.4903	Cost: 6.17s
Train Epoch: 1701 [81920/90000 (91%)]	Loss: -9.4171	Cost: 7.32s
Train Epoch: 1701 	Average Loss: -9.2504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5878

Learning rate: 9.30291032226722e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1702 [0/90000 (0%)]	Loss: -5.1822	Cost: 27.87s
Train Epoch: 1702 [20480/90000 (23%)]	Loss: -9.5197	Cost: 7.22s
Train Epoch: 1702 [40960/90000 (45%)]	Loss: -9.4191	Cost: 24.91s
Train Epoch: 1702 [61440/90000 (68%)]	Loss: -9.5954	Cost: 14.86s
Train Epoch: 1702 [81920/90000 (91%)]	Loss: -9.1217	Cost: 12.06s
Train Epoch: 1702 	Average Loss: -9.1893
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3887

Learning rate: 9.302110084834521e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1703 [0/90000 (0%)]	Loss: -4.9557	Cost: 55.85s
Train Epoch: 1703 [20480/90000 (23%)]	Loss: -9.4290	Cost: 10.62s
Train Epoch: 1703 [40960/90000 (45%)]	Loss: -9.1188	Cost: 8.21s
Train Epoch: 1703 [61440/90000 (68%)]	Loss: -9.4886	Cost: 6.87s
Train Epoch: 1703 [81920/90000 (91%)]	Loss: -9.4206	Cost: 12.04s
Train Epoch: 1703 	Average Loss: -9.0283
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.3665

Learning rate: 9.30130942280058e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1704 [0/90000 (0%)]	Loss: -4.6287	Cost: 25.83s
Train Epoch: 1704 [20480/90000 (23%)]	Loss: -9.5162	Cost: 7.93s
Train Epoch: 1704 [40960/90000 (45%)]	Loss: -9.9292	Cost: 19.72s
Train Epoch: 1704 [61440/90000 (68%)]	Loss: -10.0665	Cost: 12.57s
Train Epoch: 1704 [81920/90000 (91%)]	Loss: -10.2505	Cost: 11.98s
Train Epoch: 1704 	Average Loss: -9.5136
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9531

Saving model as e1704_model.pt & e1704_waveforms_supplementary.hdf5
Learning rate: 9.300508336244418e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1705 [0/90000 (0%)]	Loss: -5.4235	Cost: 48.69s
Train Epoch: 1705 [20480/90000 (23%)]	Loss: -9.9911	Cost: 10.99s
Train Epoch: 1705 [40960/90000 (45%)]	Loss: -9.7900	Cost: 6.55s
Train Epoch: 1705 [61440/90000 (68%)]	Loss: -10.1057	Cost: 6.79s
Train Epoch: 1705 [81920/90000 (91%)]	Loss: -9.8824	Cost: 14.15s
Train Epoch: 1705 	Average Loss: -9.6262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7499

Learning rate: 9.2997068252451e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1706 [0/90000 (0%)]	Loss: -5.6160	Cost: 34.24s
Train Epoch: 1706 [20480/90000 (23%)]	Loss: -9.4765	Cost: 11.47s
Train Epoch: 1706 [40960/90000 (45%)]	Loss: -9.7635	Cost: 22.61s
Train Epoch: 1706 [61440/90000 (68%)]	Loss: -10.0582	Cost: 11.99s
Train Epoch: 1706 [81920/90000 (91%)]	Loss: -10.0603	Cost: 11.89s
Train Epoch: 1706 	Average Loss: -9.5724
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9105

Learning rate: 9.298904889881731e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1707 [0/90000 (0%)]	Loss: -5.9007	Cost: 56.74s
Train Epoch: 1707 [20480/90000 (23%)]	Loss: -9.7474	Cost: 6.31s
Train Epoch: 1707 [40960/90000 (45%)]	Loss: -9.8567	Cost: 12.36s
Train Epoch: 1707 [61440/90000 (68%)]	Loss: -10.3384	Cost: 8.71s
Train Epoch: 1707 [81920/90000 (91%)]	Loss: -10.2985	Cost: 8.59s
Train Epoch: 1707 	Average Loss: -9.7299
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0233

Saving model as e1707_model.pt & e1707_waveforms_supplementary.hdf5
Learning rate: 9.29810253023346e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1708 [0/90000 (0%)]	Loss: -6.0071	Cost: 28.53s
Train Epoch: 1708 [20480/90000 (23%)]	Loss: -10.0445	Cost: 8.43s
Train Epoch: 1708 [40960/90000 (45%)]	Loss: -9.9628	Cost: 16.72s
Train Epoch: 1708 [61440/90000 (68%)]	Loss: -9.8214	Cost: 12.67s
Train Epoch: 1708 [81920/90000 (91%)]	Loss: -9.6186	Cost: 12.03s
Train Epoch: 1708 	Average Loss: -9.5602
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5993

Learning rate: 9.297299746379476e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1709 [0/90000 (0%)]	Loss: -5.2420	Cost: 33.16s
Train Epoch: 1709 [20480/90000 (23%)]	Loss: -9.7025	Cost: 12.33s
Train Epoch: 1709 [40960/90000 (45%)]	Loss: -9.8975	Cost: 12.19s
Train Epoch: 1709 [61440/90000 (68%)]	Loss: -10.2930	Cost: 6.06s
Train Epoch: 1709 [81920/90000 (91%)]	Loss: -10.1588	Cost: 6.27s
Train Epoch: 1709 	Average Loss: -9.6467
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9204

Learning rate: 9.29649653839901e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1710 [0/90000 (0%)]	Loss: -5.3492	Cost: 32.44s
Train Epoch: 1710 [20480/90000 (23%)]	Loss: -9.9266	Cost: 8.70s
Train Epoch: 1710 [40960/90000 (45%)]	Loss: -10.1968	Cost: 8.78s
Train Epoch: 1710 [61440/90000 (68%)]	Loss: -10.4606	Cost: 7.02s
Train Epoch: 1710 [81920/90000 (91%)]	Loss: -10.2861	Cost: 20.53s
Train Epoch: 1710 	Average Loss: -9.8309
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0911

Saving model as e1710_model.pt & e1710_waveforms_supplementary.hdf5
Learning rate: 9.295692906371338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1711 [0/90000 (0%)]	Loss: -6.1495	Cost: 31.21s
Train Epoch: 1711 [20480/90000 (23%)]	Loss: -9.8493	Cost: 14.08s
Train Epoch: 1711 [40960/90000 (45%)]	Loss: -9.3931	Cost: 14.28s
Train Epoch: 1711 [61440/90000 (68%)]	Loss: -9.7799	Cost: 8.27s
Train Epoch: 1711 [81920/90000 (91%)]	Loss: -9.7275	Cost: 6.33s
Train Epoch: 1711 	Average Loss: -9.4890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7302

Learning rate: 9.294888850375771e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1712 [0/90000 (0%)]	Loss: -5.1751	Cost: 31.23s
Train Epoch: 1712 [20480/90000 (23%)]	Loss: -9.9044	Cost: 11.35s
Train Epoch: 1712 [40960/90000 (45%)]	Loss: -9.9214	Cost: 11.18s
Train Epoch: 1712 [61440/90000 (68%)]	Loss: -10.3364	Cost: 8.19s
Train Epoch: 1712 [81920/90000 (91%)]	Loss: -10.1366	Cost: 7.27s
Train Epoch: 1712 	Average Loss: -9.6954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9621

Learning rate: 9.29408437049167e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1713 [0/90000 (0%)]	Loss: -5.4570	Cost: 42.32s
Train Epoch: 1713 [20480/90000 (23%)]	Loss: -9.9401	Cost: 10.05s
Train Epoch: 1713 [40960/90000 (45%)]	Loss: -9.9476	Cost: 15.46s
Train Epoch: 1713 [61440/90000 (68%)]	Loss: -10.2286	Cost: 12.24s
Train Epoch: 1713 [81920/90000 (91%)]	Loss: -9.4763	Cost: 11.97s
Train Epoch: 1713 	Average Loss: -9.6004
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.4752

Learning rate: 9.293279466798431e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1714 [0/90000 (0%)]	Loss: -5.3680	Cost: 35.31s
Train Epoch: 1714 [20480/90000 (23%)]	Loss: -9.5398	Cost: 6.49s
Train Epoch: 1714 [40960/90000 (45%)]	Loss: -9.7193	Cost: 15.00s
Train Epoch: 1714 [61440/90000 (68%)]	Loss: -10.0769	Cost: 8.72s
Train Epoch: 1714 [81920/90000 (91%)]	Loss: -10.0994	Cost: 11.21s
Train Epoch: 1714 	Average Loss: -9.5158
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7474

Learning rate: 9.292474139375496e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1715 [0/90000 (0%)]	Loss: -5.2719	Cost: 30.05s
Train Epoch: 1715 [20480/90000 (23%)]	Loss: -9.7000	Cost: 8.95s
Train Epoch: 1715 [40960/90000 (45%)]	Loss: -10.0974	Cost: 17.14s
Train Epoch: 1715 [61440/90000 (68%)]	Loss: -10.3779	Cost: 13.48s
Train Epoch: 1715 [81920/90000 (91%)]	Loss: -10.0868	Cost: 12.06s
Train Epoch: 1715 	Average Loss: -9.7104
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9571

Learning rate: 9.291668388302348e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1716 [0/90000 (0%)]	Loss: -4.9597	Cost: 38.10s
Train Epoch: 1716 [20480/90000 (23%)]	Loss: -9.8352	Cost: 11.87s
Train Epoch: 1716 [40960/90000 (45%)]	Loss: -10.1021	Cost: 8.17s
Train Epoch: 1716 [61440/90000 (68%)]	Loss: -10.0766	Cost: 6.15s
Train Epoch: 1716 [81920/90000 (91%)]	Loss: -9.4705	Cost: 15.48s
Train Epoch: 1716 	Average Loss: -9.5858
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5476

Learning rate: 9.290862213658514e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1717 [0/90000 (0%)]	Loss: -4.9193	Cost: 35.81s
Train Epoch: 1717 [20480/90000 (23%)]	Loss: -9.3495	Cost: 11.05s
Train Epoch: 1717 [40960/90000 (45%)]	Loss: -9.7902	Cost: 19.53s
Train Epoch: 1717 [61440/90000 (68%)]	Loss: -10.0598	Cost: 12.25s
Train Epoch: 1717 [81920/90000 (91%)]	Loss: -9.9649	Cost: 12.39s
Train Epoch: 1717 	Average Loss: -9.4455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9275

Learning rate: 9.290055615523555e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1718 [0/90000 (0%)]	Loss: -5.5481	Cost: 51.09s
Train Epoch: 1718 [20480/90000 (23%)]	Loss: -9.7794	Cost: 9.08s
Train Epoch: 1718 [40960/90000 (45%)]	Loss: -9.7688	Cost: 6.78s
Train Epoch: 1718 [61440/90000 (68%)]	Loss: -10.2923	Cost: 7.27s
Train Epoch: 1718 [81920/90000 (91%)]	Loss: -10.2859	Cost: 12.26s
Train Epoch: 1718 	Average Loss: -9.7115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9419

Learning rate: 9.289248593977082e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1719 [0/90000 (0%)]	Loss: -5.7973	Cost: 26.84s
Train Epoch: 1719 [20480/90000 (23%)]	Loss: -9.7537	Cost: 8.22s
Train Epoch: 1719 [40960/90000 (45%)]	Loss: -9.9557	Cost: 17.98s
Train Epoch: 1719 [61440/90000 (68%)]	Loss: -10.2906	Cost: 12.47s
Train Epoch: 1719 [81920/90000 (91%)]	Loss: -10.2741	Cost: 12.13s
Train Epoch: 1719 	Average Loss: -9.7186
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8837

Learning rate: 9.288441149098744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1720 [0/90000 (0%)]	Loss: -6.0037	Cost: 37.05s
Train Epoch: 1720 [20480/90000 (23%)]	Loss: -10.0111	Cost: 11.97s
Train Epoch: 1720 [40960/90000 (45%)]	Loss: -10.2534	Cost: 6.76s
Train Epoch: 1720 [61440/90000 (68%)]	Loss: -10.4452	Cost: 6.35s
Train Epoch: 1720 [81920/90000 (91%)]	Loss: -10.2359	Cost: 15.96s
Train Epoch: 1720 	Average Loss: -9.8716
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9493

Learning rate: 9.287633280968234e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1721 [0/90000 (0%)]	Loss: -5.9394	Cost: 29.37s
Train Epoch: 1721 [20480/90000 (23%)]	Loss: -10.0715	Cost: 9.56s
Train Epoch: 1721 [40960/90000 (45%)]	Loss: -10.0861	Cost: 23.24s
Train Epoch: 1721 [61440/90000 (68%)]	Loss: -10.4094	Cost: 12.12s
Train Epoch: 1721 [81920/90000 (91%)]	Loss: -10.1648	Cost: 12.04s
Train Epoch: 1721 	Average Loss: -9.8087
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9770

Learning rate: 9.286824989665286e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1722 [0/90000 (0%)]	Loss: -4.9818	Cost: 36.42s
Train Epoch: 1722 [20480/90000 (23%)]	Loss: -10.0964	Cost: 8.93s
Train Epoch: 1722 [40960/90000 (45%)]	Loss: -10.2987	Cost: 12.46s
Train Epoch: 1722 [61440/90000 (68%)]	Loss: -10.5909	Cost: 8.83s
Train Epoch: 1722 [81920/90000 (91%)]	Loss: -10.4037	Cost: 11.56s
Train Epoch: 1722 	Average Loss: -9.9176
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0842

Learning rate: 9.286016275269671e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1723 [0/90000 (0%)]	Loss: -5.7698	Cost: 33.23s
Train Epoch: 1723 [20480/90000 (23%)]	Loss: -9.9398	Cost: 7.08s
Train Epoch: 1723 [40960/90000 (45%)]	Loss: -10.0402	Cost: 17.90s
Train Epoch: 1723 [61440/90000 (68%)]	Loss: -10.3762	Cost: 12.37s
Train Epoch: 1723 [81920/90000 (91%)]	Loss: -10.3041	Cost: 11.62s
Train Epoch: 1723 	Average Loss: -9.8599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0825

Learning rate: 9.28520713786121e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1724 [0/90000 (0%)]	Loss: -5.6779	Cost: 35.01s
Train Epoch: 1724 [20480/90000 (23%)]	Loss: -9.9357	Cost: 7.50s
Train Epoch: 1724 [40960/90000 (45%)]	Loss: -9.9297	Cost: 12.16s
Train Epoch: 1724 [61440/90000 (68%)]	Loss: -10.3829	Cost: 6.06s
Train Epoch: 1724 [81920/90000 (91%)]	Loss: -10.0532	Cost: 12.68s
Train Epoch: 1724 	Average Loss: -9.7415
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9289

Learning rate: 9.28439757751976e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1725 [0/90000 (0%)]	Loss: -5.7903	Cost: 36.70s
Train Epoch: 1725 [20480/90000 (23%)]	Loss: -9.5738	Cost: 7.44s
Train Epoch: 1725 [40960/90000 (45%)]	Loss: -9.9116	Cost: 20.69s
Train Epoch: 1725 [61440/90000 (68%)]	Loss: -10.3371	Cost: 12.47s
Train Epoch: 1725 [81920/90000 (91%)]	Loss: -10.2498	Cost: 12.33s
Train Epoch: 1725 	Average Loss: -9.6171
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0477

Learning rate: 9.283587594325222e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1726 [0/90000 (0%)]	Loss: -5.1426	Cost: 33.61s
Train Epoch: 1726 [20480/90000 (23%)]	Loss: -10.0330	Cost: 12.25s
Train Epoch: 1726 [40960/90000 (45%)]	Loss: -10.2737	Cost: 12.21s
Train Epoch: 1726 [61440/90000 (68%)]	Loss: -10.7302	Cost: 6.98s
Train Epoch: 1726 [81920/90000 (91%)]	Loss: -10.1907	Cost: 5.90s
Train Epoch: 1726 	Average Loss: -9.9044
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8061

Learning rate: 9.282777188357535e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1727 [0/90000 (0%)]	Loss: -5.4965	Cost: 32.30s
Train Epoch: 1727 [20480/90000 (23%)]	Loss: -10.0082	Cost: 8.95s
Train Epoch: 1727 [40960/90000 (45%)]	Loss: -9.9766	Cost: 15.40s
Train Epoch: 1727 [61440/90000 (68%)]	Loss: -10.5160	Cost: 12.06s
Train Epoch: 1727 [81920/90000 (91%)]	Loss: -10.4616	Cost: 13.19s
Train Epoch: 1727 	Average Loss: -9.8320
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1602

Saving model as e1727_model.pt & e1727_waveforms_supplementary.hdf5
Learning rate: 9.281966359696688e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1728 [0/90000 (0%)]	Loss: -5.6489	Cost: 45.45s
Train Epoch: 1728 [20480/90000 (23%)]	Loss: -10.1224	Cost: 9.83s
Train Epoch: 1728 [40960/90000 (45%)]	Loss: -10.0990	Cost: 9.54s
Train Epoch: 1728 [61440/90000 (68%)]	Loss: -10.5668	Cost: 6.13s
Train Epoch: 1728 [81920/90000 (91%)]	Loss: -10.4172	Cost: 11.78s
Train Epoch: 1728 	Average Loss: -9.9793
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1609

Saving model as e1728_model.pt & e1728_waveforms_supplementary.hdf5
Learning rate: 9.281155108422703e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1729 [0/90000 (0%)]	Loss: -5.6029	Cost: 28.06s
Train Epoch: 1729 [20480/90000 (23%)]	Loss: -10.2520	Cost: 10.48s
Train Epoch: 1729 [40960/90000 (45%)]	Loss: -9.6920	Cost: 22.35s
Train Epoch: 1729 [61440/90000 (68%)]	Loss: -10.0951	Cost: 12.46s
Train Epoch: 1729 [81920/90000 (91%)]	Loss: -9.8239	Cost: 12.46s
Train Epoch: 1729 	Average Loss: -9.6571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7123

Learning rate: 9.28034343461565e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1730 [0/90000 (0%)]	Loss: -5.4004	Cost: 54.63s
Train Epoch: 1730 [20480/90000 (23%)]	Loss: -9.8607	Cost: 6.34s
Train Epoch: 1730 [40960/90000 (45%)]	Loss: -9.9901	Cost: 14.00s
Train Epoch: 1730 [61440/90000 (68%)]	Loss: -10.3945	Cost: 8.56s
Train Epoch: 1730 [81920/90000 (91%)]	Loss: -10.1978	Cost: 8.42s
Train Epoch: 1730 	Average Loss: -9.7811
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0518

Learning rate: 9.279531338355635e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1731 [0/90000 (0%)]	Loss: -5.9721	Cost: 29.06s
Train Epoch: 1731 [20480/90000 (23%)]	Loss: -10.2177	Cost: 9.97s
Train Epoch: 1731 [40960/90000 (45%)]	Loss: -10.0504	Cost: 17.45s
Train Epoch: 1731 [61440/90000 (68%)]	Loss: -10.7801	Cost: 12.51s
Train Epoch: 1731 [81920/90000 (91%)]	Loss: -10.3543	Cost: 11.93s
Train Epoch: 1731 	Average Loss: -9.9575
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0395

Learning rate: 9.278718819722811e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1732 [0/90000 (0%)]	Loss: -4.9916	Cost: 37.17s
Train Epoch: 1732 [20480/90000 (23%)]	Loss: -10.2038	Cost: 12.69s
Train Epoch: 1732 [40960/90000 (45%)]	Loss: -10.1415	Cost: 10.19s
Train Epoch: 1732 [61440/90000 (68%)]	Loss: -10.1483	Cost: 6.21s
Train Epoch: 1732 [81920/90000 (91%)]	Loss: -9.9292	Cost: 12.62s
Train Epoch: 1732 	Average Loss: -9.8005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7762

Learning rate: 9.27790587879737e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1733 [0/90000 (0%)]	Loss: -5.0394	Cost: 28.07s
Train Epoch: 1733 [20480/90000 (23%)]	Loss: -9.8837	Cost: 6.52s
Train Epoch: 1733 [40960/90000 (45%)]	Loss: -10.0845	Cost: 22.00s
Train Epoch: 1733 [61440/90000 (68%)]	Loss: -10.5636	Cost: 14.74s
Train Epoch: 1733 [81920/90000 (91%)]	Loss: -10.4439	Cost: 13.72s
Train Epoch: 1733 	Average Loss: -9.8744
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2412

Saving model as e1733_model.pt & e1733_waveforms_supplementary.hdf5
Learning rate: 9.277092515659545e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1734 [0/90000 (0%)]	Loss: -5.8436	Cost: 36.31s
Train Epoch: 1734 [20480/90000 (23%)]	Loss: -10.3975	Cost: 12.89s
Train Epoch: 1734 [40960/90000 (45%)]	Loss: -10.1690	Cost: 11.97s
Train Epoch: 1734 [61440/90000 (68%)]	Loss: -10.3639	Cost: 6.61s
Train Epoch: 1734 [81920/90000 (91%)]	Loss: -10.2575	Cost: 11.38s
Train Epoch: 1734 	Average Loss: -9.9326
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0430

Learning rate: 9.276278730389611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1735 [0/90000 (0%)]	Loss: -4.9873	Cost: 38.25s
Train Epoch: 1735 [20480/90000 (23%)]	Loss: -10.2915	Cost: 7.13s
Train Epoch: 1735 [40960/90000 (45%)]	Loss: -10.3737	Cost: 15.72s
Train Epoch: 1735 [61440/90000 (68%)]	Loss: -10.8170	Cost: 12.46s
Train Epoch: 1735 [81920/90000 (91%)]	Loss: -10.6381	Cost: 12.26s
Train Epoch: 1735 	Average Loss: -10.0640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3263

Saving model as e1735_model.pt & e1735_waveforms_supplementary.hdf5
Learning rate: 9.275464523067889e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1736 [0/90000 (0%)]	Loss: -6.3088	Cost: 33.22s
Train Epoch: 1736 [20480/90000 (23%)]	Loss: -10.3547	Cost: 12.28s
Train Epoch: 1736 [40960/90000 (45%)]	Loss: -10.5993	Cost: 6.70s
Train Epoch: 1736 [61440/90000 (68%)]	Loss: -10.9607	Cost: 6.16s
Train Epoch: 1736 [81920/90000 (91%)]	Loss: -10.6036	Cost: 15.47s
Train Epoch: 1736 	Average Loss: -10.2264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2805

Learning rate: 9.274649893774736e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1737 [0/90000 (0%)]	Loss: -5.8386	Cost: 30.24s
Train Epoch: 1737 [20480/90000 (23%)]	Loss: -10.0813	Cost: 7.14s
Train Epoch: 1737 [40960/90000 (45%)]	Loss: -9.9439	Cost: 23.69s
Train Epoch: 1737 [61440/90000 (68%)]	Loss: -10.4284	Cost: 12.20s
Train Epoch: 1737 [81920/90000 (91%)]	Loss: -10.0716	Cost: 12.07s
Train Epoch: 1737 	Average Loss: -9.7964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8537

Learning rate: 9.27383484259055e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1738 [0/90000 (0%)]	Loss: -5.3430	Cost: 33.09s
Train Epoch: 1738 [20480/90000 (23%)]	Loss: -10.0202	Cost: 11.80s
Train Epoch: 1738 [40960/90000 (45%)]	Loss: -10.1723	Cost: 8.58s
Train Epoch: 1738 [61440/90000 (68%)]	Loss: -10.5510	Cost: 6.42s
Train Epoch: 1738 [81920/90000 (91%)]	Loss: -10.5411	Cost: 16.51s
Train Epoch: 1738 	Average Loss: -9.9005
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1454

Learning rate: 9.273019369595777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1739 [0/90000 (0%)]	Loss: -5.6966	Cost: 55.24s
Train Epoch: 1739 [20480/90000 (23%)]	Loss: -10.4776	Cost: 12.06s
Train Epoch: 1739 [40960/90000 (45%)]	Loss: -10.3113	Cost: 12.22s
Train Epoch: 1739 [61440/90000 (68%)]	Loss: -10.8799	Cost: 12.27s
Train Epoch: 1739 [81920/90000 (91%)]	Loss: -10.6422	Cost: 11.69s
Train Epoch: 1739 	Average Loss: -10.1619
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3349

Saving model as e1739_model.pt & e1739_waveforms_supplementary.hdf5
Learning rate: 9.2722034748709e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1740 [0/90000 (0%)]	Loss: -5.9808	Cost: 31.87s
Train Epoch: 1740 [20480/90000 (23%)]	Loss: -10.2835	Cost: 6.33s
Train Epoch: 1740 [40960/90000 (45%)]	Loss: -10.4449	Cost: 14.15s
Train Epoch: 1740 [61440/90000 (68%)]	Loss: -10.8143	Cost: 8.58s
Train Epoch: 1740 [81920/90000 (91%)]	Loss: -10.3124	Cost: 7.43s
Train Epoch: 1740 	Average Loss: -10.0977
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0995

Learning rate: 9.271387158496444e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1741 [0/90000 (0%)]	Loss: -5.4999	Cost: 32.69s
Train Epoch: 1741 [20480/90000 (23%)]	Loss: -10.2365	Cost: 14.60s
Train Epoch: 1741 [40960/90000 (45%)]	Loss: -10.4863	Cost: 14.86s
Train Epoch: 1741 [61440/90000 (68%)]	Loss: -10.7680	Cost: 12.74s
Train Epoch: 1741 [81920/90000 (91%)]	Loss: -10.3099	Cost: 12.13s
Train Epoch: 1741 	Average Loss: -10.0536
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0034

Learning rate: 9.270570420552977e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1742 [0/90000 (0%)]	Loss: -5.7830	Cost: 48.27s
Train Epoch: 1742 [20480/90000 (23%)]	Loss: -10.1827	Cost: 6.89s
Train Epoch: 1742 [40960/90000 (45%)]	Loss: -10.2185	Cost: 14.19s
Train Epoch: 1742 [61440/90000 (68%)]	Loss: -10.7759	Cost: 8.55s
Train Epoch: 1742 [81920/90000 (91%)]	Loss: -10.4337	Cost: 9.76s
Train Epoch: 1742 	Average Loss: -9.9973
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0251

Learning rate: 9.269753261121107e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1743 [0/90000 (0%)]	Loss: -6.0320	Cost: 33.01s
Train Epoch: 1743 [20480/90000 (23%)]	Loss: -9.9858	Cost: 8.42s
Train Epoch: 1743 [40960/90000 (45%)]	Loss: -9.9826	Cost: 20.84s
Train Epoch: 1743 [61440/90000 (68%)]	Loss: -10.3676	Cost: 12.47s
Train Epoch: 1743 [81920/90000 (91%)]	Loss: -10.4166	Cost: 12.15s
Train Epoch: 1743 	Average Loss: -9.9172
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1823

Learning rate: 9.268935680281485e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1744 [0/90000 (0%)]	Loss: -5.3307	Cost: 52.28s
Train Epoch: 1744 [20480/90000 (23%)]	Loss: -10.0471	Cost: 6.32s
Train Epoch: 1744 [40960/90000 (45%)]	Loss: -10.1667	Cost: 14.46s
Train Epoch: 1744 [61440/90000 (68%)]	Loss: -10.6751	Cost: 8.67s
Train Epoch: 1744 [81920/90000 (91%)]	Loss: -10.3211	Cost: 8.62s
Train Epoch: 1744 	Average Loss: -10.0735
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1263

Learning rate: 9.268117678114803e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1745 [0/90000 (0%)]	Loss: -5.7472	Cost: 27.25s
Train Epoch: 1745 [20480/90000 (23%)]	Loss: -10.1909	Cost: 6.98s
Train Epoch: 1745 [40960/90000 (45%)]	Loss: -9.9737	Cost: 17.64s
Train Epoch: 1745 [61440/90000 (68%)]	Loss: -10.0698	Cost: 13.11s
Train Epoch: 1745 [81920/90000 (91%)]	Loss: -10.0337	Cost: 12.54s
Train Epoch: 1745 	Average Loss: -9.8268
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8982

Learning rate: 9.267299254701793e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1746 [0/90000 (0%)]	Loss: -5.5520	Cost: 34.19s
Train Epoch: 1746 [20480/90000 (23%)]	Loss: -10.2889	Cost: 11.34s
Train Epoch: 1746 [40960/90000 (45%)]	Loss: -9.9713	Cost: 9.51s
Train Epoch: 1746 [61440/90000 (68%)]	Loss: -10.5885	Cost: 9.80s
Train Epoch: 1746 [81920/90000 (91%)]	Loss: -10.6190	Cost: 12.06s
Train Epoch: 1746 	Average Loss: -10.0119
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1934

Learning rate: 9.266480410123233e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1747 [0/90000 (0%)]	Loss: -5.6740	Cost: 37.13s
Train Epoch: 1747 [20480/90000 (23%)]	Loss: -10.2792	Cost: 7.62s
Train Epoch: 1747 [40960/90000 (45%)]	Loss: -10.3680	Cost: 18.86s
Train Epoch: 1747 [61440/90000 (68%)]	Loss: -10.8464	Cost: 12.31s
Train Epoch: 1747 [81920/90000 (91%)]	Loss: -10.7368	Cost: 11.81s
Train Epoch: 1747 	Average Loss: -10.1378
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3232

Learning rate: 9.265661144459937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1748 [0/90000 (0%)]	Loss: -5.5385	Cost: 36.94s
Train Epoch: 1748 [20480/90000 (23%)]	Loss: -10.5241	Cost: 11.10s
Train Epoch: 1748 [40960/90000 (45%)]	Loss: -10.3578	Cost: 7.93s
Train Epoch: 1748 [61440/90000 (68%)]	Loss: -10.7701	Cost: 6.35s
Train Epoch: 1748 [81920/90000 (91%)]	Loss: -10.6320	Cost: 13.78s
Train Epoch: 1748 	Average Loss: -10.1801
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3938

Saving model as e1748_model.pt & e1748_waveforms_supplementary.hdf5
Learning rate: 9.264841457792765e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1749 [0/90000 (0%)]	Loss: -5.8014	Cost: 31.09s
Train Epoch: 1749 [20480/90000 (23%)]	Loss: -10.6056	Cost: 8.96s
Train Epoch: 1749 [40960/90000 (45%)]	Loss: -10.2302	Cost: 18.10s
Train Epoch: 1749 [61440/90000 (68%)]	Loss: -10.6957	Cost: 11.93s
Train Epoch: 1749 [81920/90000 (91%)]	Loss: -10.5748	Cost: 12.17s
Train Epoch: 1749 	Average Loss: -10.1324
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1396

Learning rate: 9.264021350202617e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1750 [0/90000 (0%)]	Loss: -5.6817	Cost: 32.63s
Train Epoch: 1750 [20480/90000 (23%)]	Loss: -10.6432	Cost: 10.60s
Train Epoch: 1750 [40960/90000 (45%)]	Loss: -10.6423	Cost: 6.20s
Train Epoch: 1750 [61440/90000 (68%)]	Loss: -10.6360	Cost: 6.15s
Train Epoch: 1750 [81920/90000 (91%)]	Loss: -10.5981	Cost: 15.33s
Train Epoch: 1750 	Average Loss: -10.1870
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2185

Learning rate: 9.263200821770431e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1751 [0/90000 (0%)]	Loss: -5.6176	Cost: 29.60s
Train Epoch: 1751 [20480/90000 (23%)]	Loss: -10.3333	Cost: 10.35s
Train Epoch: 1751 [40960/90000 (45%)]	Loss: -10.1317	Cost: 22.94s
Train Epoch: 1751 [61440/90000 (68%)]	Loss: -8.6077	Cost: 12.33s
Train Epoch: 1751 [81920/90000 (91%)]	Loss: -8.4074	Cost: 11.92s
Train Epoch: 1751 	Average Loss: -9.0582
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.6681

Learning rate: 9.262379872577195e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1752 [0/90000 (0%)]	Loss: -3.7193	Cost: 46.79s
Train Epoch: 1752 [20480/90000 (23%)]	Loss: -9.1229	Cost: 6.31s
Train Epoch: 1752 [40960/90000 (45%)]	Loss: -9.4671	Cost: 14.56s
Train Epoch: 1752 [61440/90000 (68%)]	Loss: -9.8762	Cost: 8.54s
Train Epoch: 1752 [81920/90000 (91%)]	Loss: -10.0604	Cost: 8.41s
Train Epoch: 1752 	Average Loss: -9.1059
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8589

Learning rate: 9.26155850270393e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1753 [0/90000 (0%)]	Loss: -5.2342	Cost: 26.08s
Train Epoch: 1753 [20480/90000 (23%)]	Loss: -9.9283	Cost: 7.76s
Train Epoch: 1753 [40960/90000 (45%)]	Loss: -10.4044	Cost: 24.72s
Train Epoch: 1753 [61440/90000 (68%)]	Loss: -10.6247	Cost: 12.72s
Train Epoch: 1753 [81920/90000 (91%)]	Loss: -10.4806	Cost: 11.92s
Train Epoch: 1753 	Average Loss: -9.9558
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2298

Learning rate: 9.260736712231702e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1754 [0/90000 (0%)]	Loss: -6.1227	Cost: 35.57s
Train Epoch: 1754 [20480/90000 (23%)]	Loss: -10.4836	Cost: 12.15s
Train Epoch: 1754 [40960/90000 (45%)]	Loss: -10.6355	Cost: 9.04s
Train Epoch: 1754 [61440/90000 (68%)]	Loss: -10.2591	Cost: 6.23s
Train Epoch: 1754 [81920/90000 (91%)]	Loss: -10.1971	Cost: 12.26s
Train Epoch: 1754 	Average Loss: -10.0265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0026

Learning rate: 9.25991450124162e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1755 [0/90000 (0%)]	Loss: -5.4051	Cost: 28.45s
Train Epoch: 1755 [20480/90000 (23%)]	Loss: -10.2308	Cost: 6.76s
Train Epoch: 1755 [40960/90000 (45%)]	Loss: -10.4443	Cost: 22.43s
Train Epoch: 1755 [61440/90000 (68%)]	Loss: -10.7753	Cost: 15.48s
Train Epoch: 1755 [81920/90000 (91%)]	Loss: -10.6865	Cost: 12.45s
Train Epoch: 1755 	Average Loss: -10.1341
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2278

Learning rate: 9.259091869814832e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1756 [0/90000 (0%)]	Loss: -5.5328	Cost: 34.07s
Train Epoch: 1756 [20480/90000 (23%)]	Loss: -10.2471	Cost: 11.83s
Train Epoch: 1756 [40960/90000 (45%)]	Loss: -10.4082	Cost: 10.72s
Train Epoch: 1756 [61440/90000 (68%)]	Loss: -10.7738	Cost: 10.54s
Train Epoch: 1756 [81920/90000 (91%)]	Loss: -10.5814	Cost: 12.52s
Train Epoch: 1756 	Average Loss: -10.1691
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3669

Learning rate: 9.25826881803253e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1757 [0/90000 (0%)]	Loss: -5.5236	Cost: 38.16s
Train Epoch: 1757 [20480/90000 (23%)]	Loss: -10.5066	Cost: 7.01s
Train Epoch: 1757 [40960/90000 (45%)]	Loss: -10.2918	Cost: 15.93s
Train Epoch: 1757 [61440/90000 (68%)]	Loss: -10.2584	Cost: 12.37s
Train Epoch: 1757 [81920/90000 (91%)]	Loss: -10.0512	Cost: 12.27s
Train Epoch: 1757 	Average Loss: -9.9999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8757

Learning rate: 9.257445345975943e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1758 [0/90000 (0%)]	Loss: -5.6139	Cost: 37.74s
Train Epoch: 1758 [20480/90000 (23%)]	Loss: -10.1768	Cost: 11.94s
Train Epoch: 1758 [40960/90000 (45%)]	Loss: -10.3005	Cost: 9.93s
Train Epoch: 1758 [61440/90000 (68%)]	Loss: -10.7159	Cost: 6.48s
Train Epoch: 1758 [81920/90000 (91%)]	Loss: -10.3880	Cost: 11.09s
Train Epoch: 1758 	Average Loss: -10.0209
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1801

Learning rate: 9.256621453726348e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1759 [0/90000 (0%)]	Loss: -5.5536	Cost: 35.91s
Train Epoch: 1759 [20480/90000 (23%)]	Loss: -10.4064	Cost: 9.11s
Train Epoch: 1759 [40960/90000 (45%)]	Loss: -10.5920	Cost: 18.47s
Train Epoch: 1759 [61440/90000 (68%)]	Loss: -10.5589	Cost: 12.18s
Train Epoch: 1759 [81920/90000 (91%)]	Loss: -10.3985	Cost: 12.01s
Train Epoch: 1759 	Average Loss: -10.0660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2322

Learning rate: 9.255797141365057e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1760 [0/90000 (0%)]	Loss: -5.4928	Cost: 43.96s
Train Epoch: 1760 [20480/90000 (23%)]	Loss: -10.2324	Cost: 7.23s
Train Epoch: 1760 [40960/90000 (45%)]	Loss: -10.3670	Cost: 12.14s
Train Epoch: 1760 [61440/90000 (68%)]	Loss: -10.7559	Cost: 8.65s
Train Epoch: 1760 [81920/90000 (91%)]	Loss: -10.7464	Cost: 11.62s
Train Epoch: 1760 	Average Loss: -10.1085
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2466

Learning rate: 9.254972408973427e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1761 [0/90000 (0%)]	Loss: -5.9139	Cost: 32.30s
Train Epoch: 1761 [20480/90000 (23%)]	Loss: -10.2058	Cost: 10.61s
Train Epoch: 1761 [40960/90000 (45%)]	Loss: -10.4522	Cost: 14.81s
Train Epoch: 1761 [61440/90000 (68%)]	Loss: -10.6861	Cost: 12.59s
Train Epoch: 1761 [81920/90000 (91%)]	Loss: -10.6191	Cost: 12.27s
Train Epoch: 1761 	Average Loss: -10.1262
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3153

Learning rate: 9.254147256632858e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1762 [0/90000 (0%)]	Loss: -5.7980	Cost: 34.76s
Train Epoch: 1762 [20480/90000 (23%)]	Loss: -10.3013	Cost: 10.53s
Train Epoch: 1762 [40960/90000 (45%)]	Loss: -10.5125	Cost: 9.29s
Train Epoch: 1762 [61440/90000 (68%)]	Loss: -10.7856	Cost: 8.08s
Train Epoch: 1762 [81920/90000 (91%)]	Loss: -10.6480	Cost: 14.81s
Train Epoch: 1762 	Average Loss: -10.1599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2452

Learning rate: 9.253321684424786e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1763 [0/90000 (0%)]	Loss: -5.5443	Cost: 44.14s
Train Epoch: 1763 [20480/90000 (23%)]	Loss: -10.2864	Cost: 13.91s
Train Epoch: 1763 [40960/90000 (45%)]	Loss: -10.1553	Cost: 16.59s
Train Epoch: 1763 [61440/90000 (68%)]	Loss: -10.4679	Cost: 11.87s
Train Epoch: 1763 [81920/90000 (91%)]	Loss: -10.3210	Cost: 12.24s
Train Epoch: 1763 	Average Loss: -10.0162
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2404

Learning rate: 9.252495692430695e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1764 [0/90000 (0%)]	Loss: -5.5514	Cost: 51.32s
Train Epoch: 1764 [20480/90000 (23%)]	Loss: -10.4251	Cost: 6.20s
Train Epoch: 1764 [40960/90000 (45%)]	Loss: -10.7306	Cost: 13.66s
Train Epoch: 1764 [61440/90000 (68%)]	Loss: -11.0764	Cost: 8.69s
Train Epoch: 1764 [81920/90000 (91%)]	Loss: -10.7789	Cost: 7.78s
Train Epoch: 1764 	Average Loss: -10.3166
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4696

Saving model as e1764_model.pt & e1764_waveforms_supplementary.hdf5
Learning rate: 9.251669280732104e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1765 [0/90000 (0%)]	Loss: -5.7570	Cost: 30.21s
Train Epoch: 1765 [20480/90000 (23%)]	Loss: -9.9644	Cost: 14.83s
Train Epoch: 1765 [40960/90000 (45%)]	Loss: -9.9413	Cost: 14.41s
Train Epoch: 1765 [61440/90000 (68%)]	Loss: -10.3025	Cost: 12.05s
Train Epoch: 1765 [81920/90000 (91%)]	Loss: -10.1979	Cost: 12.19s
Train Epoch: 1765 	Average Loss: -9.7859
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0545

Learning rate: 9.250842449410579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1766 [0/90000 (0%)]	Loss: -5.6646	Cost: 42.72s
Train Epoch: 1766 [20480/90000 (23%)]	Loss: -10.2086	Cost: 10.55s
Train Epoch: 1766 [40960/90000 (45%)]	Loss: -10.2290	Cost: 9.17s
Train Epoch: 1766 [61440/90000 (68%)]	Loss: -10.3502	Cost: 6.23s
Train Epoch: 1766 [81920/90000 (91%)]	Loss: -10.1123	Cost: 13.85s
Train Epoch: 1766 	Average Loss: -9.8775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8678

Learning rate: 9.250015198547725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1767 [0/90000 (0%)]	Loss: -5.8319	Cost: 27.25s
Train Epoch: 1767 [20480/90000 (23%)]	Loss: -10.1154	Cost: 7.14s
Train Epoch: 1767 [40960/90000 (45%)]	Loss: -10.3534	Cost: 15.43s
Train Epoch: 1767 [61440/90000 (68%)]	Loss: -10.5247	Cost: 9.04s
Train Epoch: 1767 [81920/90000 (91%)]	Loss: -10.4024	Cost: 15.82s
Train Epoch: 1767 	Average Loss: -9.9909
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1380

Learning rate: 9.249187528225185e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1768 [0/90000 (0%)]	Loss: -5.5709	Cost: 57.97s
Train Epoch: 1768 [20480/90000 (23%)]	Loss: -10.4691	Cost: 11.81s
Train Epoch: 1768 [40960/90000 (45%)]	Loss: -10.4654	Cost: 7.76s
Train Epoch: 1768 [61440/90000 (68%)]	Loss: -10.6388	Cost: 6.35s
Train Epoch: 1768 [81920/90000 (91%)]	Loss: -10.3534	Cost: 11.52s
Train Epoch: 1768 	Average Loss: -10.1020
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1389

Learning rate: 9.248359438524651e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1769 [0/90000 (0%)]	Loss: -5.8533	Cost: 32.58s
Train Epoch: 1769 [20480/90000 (23%)]	Loss: -9.9653	Cost: 6.76s
Train Epoch: 1769 [40960/90000 (45%)]	Loss: -10.2225	Cost: 16.84s
Train Epoch: 1769 [61440/90000 (68%)]	Loss: -10.5798	Cost: 12.18s
Train Epoch: 1769 [81920/90000 (91%)]	Loss: -10.5392	Cost: 12.21s
Train Epoch: 1769 	Average Loss: -9.9937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1099

Learning rate: 9.247530929527849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1770 [0/90000 (0%)]	Loss: -6.1025	Cost: 34.77s
Train Epoch: 1770 [20480/90000 (23%)]	Loss: -10.4916	Cost: 12.53s
Train Epoch: 1770 [40960/90000 (45%)]	Loss: -10.5728	Cost: 9.44s
Train Epoch: 1770 [61440/90000 (68%)]	Loss: -10.7780	Cost: 6.99s
Train Epoch: 1770 [81920/90000 (91%)]	Loss: -10.6972	Cost: 12.36s
Train Epoch: 1770 	Average Loss: -10.3437
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2789

Learning rate: 9.24670200131655e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1771 [0/90000 (0%)]	Loss: -5.9101	Cost: 28.30s
Train Epoch: 1771 [20480/90000 (23%)]	Loss: -10.4598	Cost: 8.96s
Train Epoch: 1771 [40960/90000 (45%)]	Loss: -10.5106	Cost: 23.17s
Train Epoch: 1771 [61440/90000 (68%)]	Loss: -10.7620	Cost: 12.26s
Train Epoch: 1771 [81920/90000 (91%)]	Loss: -10.3312	Cost: 11.92s
Train Epoch: 1771 	Average Loss: -10.1553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2021

Learning rate: 9.24587265397257e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1772 [0/90000 (0%)]	Loss: -5.8726	Cost: 33.98s
Train Epoch: 1772 [20480/90000 (23%)]	Loss: -10.2782	Cost: 12.73s
Train Epoch: 1772 [40960/90000 (45%)]	Loss: -10.2523	Cost: 11.77s
Train Epoch: 1772 [61440/90000 (68%)]	Loss: -10.5282	Cost: 7.29s
Train Epoch: 1772 [81920/90000 (91%)]	Loss: -10.0090	Cost: 9.18s
Train Epoch: 1772 	Average Loss: -9.9571
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8405

Learning rate: 9.245042887577755e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1773 [0/90000 (0%)]	Loss: -5.6675	Cost: 47.84s
Train Epoch: 1773 [20480/90000 (23%)]	Loss: -9.7175	Cost: 6.77s
Train Epoch: 1773 [40960/90000 (45%)]	Loss: -9.8000	Cost: 17.29s
Train Epoch: 1773 [61440/90000 (68%)]	Loss: -10.4283	Cost: 12.34s
Train Epoch: 1773 [81920/90000 (91%)]	Loss: -10.1149	Cost: 11.84s
Train Epoch: 1773 	Average Loss: -9.6964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9946

Learning rate: 9.244212702214006e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1774 [0/90000 (0%)]	Loss: -5.8028	Cost: 40.16s
Train Epoch: 1774 [20480/90000 (23%)]	Loss: -10.2148	Cost: 11.18s
Train Epoch: 1774 [40960/90000 (45%)]	Loss: -10.4175	Cost: 6.38s
Train Epoch: 1774 [61440/90000 (68%)]	Loss: -10.7782	Cost: 6.66s
Train Epoch: 1774 [81920/90000 (91%)]	Loss: -10.7346	Cost: 13.40s
Train Epoch: 1774 	Average Loss: -10.0634
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3133

Learning rate: 9.243382097963258e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1775 [0/90000 (0%)]	Loss: -5.5087	Cost: 33.80s
Train Epoch: 1775 [20480/90000 (23%)]	Loss: -10.5260	Cost: 10.58s
Train Epoch: 1775 [40960/90000 (45%)]	Loss: -10.7964	Cost: 23.06s
Train Epoch: 1775 [61440/90000 (68%)]	Loss: -10.9637	Cost: 12.23s
Train Epoch: 1775 [81920/90000 (91%)]	Loss: -10.8445	Cost: 11.85s
Train Epoch: 1775 	Average Loss: -10.4029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4808

Saving model as e1775_model.pt & e1775_waveforms_supplementary.hdf5
Learning rate: 9.242551074907487e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1776 [0/90000 (0%)]	Loss: -6.3430	Cost: 39.62s
Train Epoch: 1776 [20480/90000 (23%)]	Loss: -10.7379	Cost: 8.58s
Train Epoch: 1776 [40960/90000 (45%)]	Loss: -10.6433	Cost: 9.04s
Train Epoch: 1776 [61440/90000 (68%)]	Loss: -10.8711	Cost: 8.13s
Train Epoch: 1776 [81920/90000 (91%)]	Loss: -10.5767	Cost: 11.23s
Train Epoch: 1776 	Average Loss: -10.3167
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1619

Learning rate: 9.241719633128709e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1777 [0/90000 (0%)]	Loss: -5.2075	Cost: 28.80s
Train Epoch: 1777 [20480/90000 (23%)]	Loss: -10.4507	Cost: 9.57s
Train Epoch: 1777 [40960/90000 (45%)]	Loss: -10.4808	Cost: 24.01s
Train Epoch: 1777 [61440/90000 (68%)]	Loss: -10.7910	Cost: 12.10s
Train Epoch: 1777 [81920/90000 (91%)]	Loss: -10.7346	Cost: 11.84s
Train Epoch: 1777 	Average Loss: -10.2449
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3109

Learning rate: 9.240887772708989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1778 [0/90000 (0%)]	Loss: -6.2603	Cost: 46.64s
Train Epoch: 1778 [20480/90000 (23%)]	Loss: -10.6783	Cost: 7.32s
Train Epoch: 1778 [40960/90000 (45%)]	Loss: -10.7630	Cost: 10.19s
Train Epoch: 1778 [61440/90000 (68%)]	Loss: -10.6563	Cost: 8.82s
Train Epoch: 1778 [81920/90000 (91%)]	Loss: -10.7580	Cost: 12.87s
Train Epoch: 1778 	Average Loss: -10.3450
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2301

Learning rate: 9.240055493730426e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1779 [0/90000 (0%)]	Loss: -4.9089	Cost: 27.39s
Train Epoch: 1779 [20480/90000 (23%)]	Loss: -10.2288	Cost: 9.78s
Train Epoch: 1779 [40960/90000 (45%)]	Loss: -10.0762	Cost: 16.26s
Train Epoch: 1779 [61440/90000 (68%)]	Loss: -10.5908	Cost: 14.31s
Train Epoch: 1779 [81920/90000 (91%)]	Loss: -10.6413	Cost: 12.63s
Train Epoch: 1779 	Average Loss: -10.0140
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3973

Learning rate: 9.239222796275163e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1780 [0/90000 (0%)]	Loss: -6.0750	Cost: 42.75s
Train Epoch: 1780 [20480/90000 (23%)]	Loss: -10.5866	Cost: 13.26s
Train Epoch: 1780 [40960/90000 (45%)]	Loss: -10.4266	Cost: 11.84s
Train Epoch: 1780 [61440/90000 (68%)]	Loss: -10.6583	Cost: 6.13s
Train Epoch: 1780 [81920/90000 (91%)]	Loss: -10.5135	Cost: 9.27s
Train Epoch: 1780 	Average Loss: -10.1910
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4158

Learning rate: 9.238389680425384e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1781 [0/90000 (0%)]	Loss: -5.9573	Cost: 34.52s
Train Epoch: 1781 [20480/90000 (23%)]	Loss: -10.5594	Cost: 6.97s
Train Epoch: 1781 [40960/90000 (45%)]	Loss: -10.7676	Cost: 18.01s
Train Epoch: 1781 [61440/90000 (68%)]	Loss: -11.1177	Cost: 12.60s
Train Epoch: 1781 [81920/90000 (91%)]	Loss: -10.8798	Cost: 12.03s
Train Epoch: 1781 	Average Loss: -10.3992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5500

Saving model as e1781_model.pt & e1781_waveforms_supplementary.hdf5
Learning rate: 9.237556146263314e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1782 [0/90000 (0%)]	Loss: -6.1208	Cost: 34.24s
Train Epoch: 1782 [20480/90000 (23%)]	Loss: -10.4287	Cost: 11.80s
Train Epoch: 1782 [40960/90000 (45%)]	Loss: -10.6538	Cost: 7.97s
Train Epoch: 1782 [61440/90000 (68%)]	Loss: -10.8990	Cost: 6.37s
Train Epoch: 1782 [81920/90000 (91%)]	Loss: -10.9540	Cost: 16.58s
Train Epoch: 1782 	Average Loss: -10.3952
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5656

Saving model as e1782_model.pt & e1782_waveforms_supplementary.hdf5
Learning rate: 9.236722193871219e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1783 [0/90000 (0%)]	Loss: -6.5188	Cost: 28.77s
Train Epoch: 1783 [20480/90000 (23%)]	Loss: -10.2804	Cost: 11.05s
Train Epoch: 1783 [40960/90000 (45%)]	Loss: -10.1335	Cost: 21.61s
Train Epoch: 1783 [61440/90000 (68%)]	Loss: -10.6649	Cost: 12.20s
Train Epoch: 1783 [81920/90000 (91%)]	Loss: -10.4343	Cost: 11.95s
Train Epoch: 1783 	Average Loss: -10.1022
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2780

Learning rate: 9.235887823331407e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1784 [0/90000 (0%)]	Loss: -6.1161	Cost: 37.83s
Train Epoch: 1784 [20480/90000 (23%)]	Loss: -10.3125	Cost: 8.98s
Train Epoch: 1784 [40960/90000 (45%)]	Loss: -10.3995	Cost: 11.97s
Train Epoch: 1784 [61440/90000 (68%)]	Loss: -11.0356	Cost: 6.37s
Train Epoch: 1784 [81920/90000 (91%)]	Loss: -10.7742	Cost: 14.43s
Train Epoch: 1784 	Average Loss: -10.2660
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4075

Learning rate: 9.235053034726228e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1785 [0/90000 (0%)]	Loss: -5.4745	Cost: 33.91s
Train Epoch: 1785 [20480/90000 (23%)]	Loss: -10.4886	Cost: 8.28s
Train Epoch: 1785 [40960/90000 (45%)]	Loss: -10.3491	Cost: 11.26s
Train Epoch: 1785 [61440/90000 (68%)]	Loss: -10.9078	Cost: 6.40s
Train Epoch: 1785 [81920/90000 (91%)]	Loss: -10.7617	Cost: 20.55s
Train Epoch: 1785 	Average Loss: -10.2259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5645

Learning rate: 9.234217828138071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1786 [0/90000 (0%)]	Loss: -6.0104	Cost: 31.93s
Train Epoch: 1786 [20480/90000 (23%)]	Loss: -10.5396	Cost: 12.48s
Train Epoch: 1786 [40960/90000 (45%)]	Loss: -10.6919	Cost: 12.20s
Train Epoch: 1786 [61440/90000 (68%)]	Loss: -11.0109	Cost: 6.89s
Train Epoch: 1786 [81920/90000 (91%)]	Loss: -10.7586	Cost: 7.73s
Train Epoch: 1786 	Average Loss: -10.3360
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4826

Learning rate: 9.23338220364937e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1787 [0/90000 (0%)]	Loss: -6.1034	Cost: 28.36s
Train Epoch: 1787 [20480/90000 (23%)]	Loss: -10.7123	Cost: 9.75s
Train Epoch: 1787 [40960/90000 (45%)]	Loss: -10.7216	Cost: 17.23s
Train Epoch: 1787 [61440/90000 (68%)]	Loss: -10.9449	Cost: 11.37s
Train Epoch: 1787 [81920/90000 (91%)]	Loss: -11.0066	Cost: 17.55s
Train Epoch: 1787 	Average Loss: -10.4668
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5905

Saving model as e1787_model.pt & e1787_waveforms_supplementary.hdf5
Learning rate: 9.232546161342596e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1788 [0/90000 (0%)]	Loss: -6.4125	Cost: 45.73s
Train Epoch: 1788 [20480/90000 (23%)]	Loss: -10.7686	Cost: 12.24s
Train Epoch: 1788 [40960/90000 (45%)]	Loss: -10.8275	Cost: 12.16s
Train Epoch: 1788 [61440/90000 (68%)]	Loss: -11.1797	Cost: 6.54s
Train Epoch: 1788 [81920/90000 (91%)]	Loss: -11.0815	Cost: 6.39s
Train Epoch: 1788 	Average Loss: -10.6198
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5566

Learning rate: 9.231709701300262e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1789 [0/90000 (0%)]	Loss: -6.4990	Cost: 27.65s
Train Epoch: 1789 [20480/90000 (23%)]	Loss: -10.8995	Cost: 8.84s
Train Epoch: 1789 [40960/90000 (45%)]	Loss: -10.8982	Cost: 9.68s
Train Epoch: 1789 [61440/90000 (68%)]	Loss: -11.1793	Cost: 8.45s
Train Epoch: 1789 [81920/90000 (91%)]	Loss: -10.9373	Cost: 18.75s
Train Epoch: 1789 	Average Loss: -10.5876
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6333

Saving model as e1789_model.pt & e1789_waveforms_supplementary.hdf5
Learning rate: 9.230872823604925e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1790 [0/90000 (0%)]	Loss: -5.5536	Cost: 50.78s
Train Epoch: 1790 [20480/90000 (23%)]	Loss: -10.6982	Cost: 12.04s
Train Epoch: 1790 [40960/90000 (45%)]	Loss: -10.8177	Cost: 11.90s
Train Epoch: 1790 [61440/90000 (68%)]	Loss: -11.0097	Cost: 8.35s
Train Epoch: 1790 [81920/90000 (91%)]	Loss: -10.7555	Cost: 8.82s
Train Epoch: 1790 	Average Loss: -10.4864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1018

Learning rate: 9.23003552833918e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1791 [0/90000 (0%)]	Loss: -5.2012	Cost: 26.39s
Train Epoch: 1791 [20480/90000 (23%)]	Loss: -10.3089	Cost: 10.73s
Train Epoch: 1791 [40960/90000 (45%)]	Loss: -10.1537	Cost: 13.67s
Train Epoch: 1791 [61440/90000 (68%)]	Loss: -10.5738	Cost: 9.86s
Train Epoch: 1791 [81920/90000 (91%)]	Loss: -10.6194	Cost: 24.13s
Train Epoch: 1791 	Average Loss: -10.0995
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4131

Learning rate: 9.229197815585665e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1792 [0/90000 (0%)]	Loss: -6.3472	Cost: 41.90s
Train Epoch: 1792 [20480/90000 (23%)]	Loss: -10.7632	Cost: 13.78s
Train Epoch: 1792 [40960/90000 (45%)]	Loss: -11.0935	Cost: 12.05s
Train Epoch: 1792 [61440/90000 (68%)]	Loss: -11.1708	Cost: 9.96s
Train Epoch: 1792 [81920/90000 (91%)]	Loss: -10.5870	Cost: 6.10s
Train Epoch: 1792 	Average Loss: -10.5122
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1984

Learning rate: 9.228359685427062e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1793 [0/90000 (0%)]	Loss: -5.6677	Cost: 33.80s
Train Epoch: 1793 [20480/90000 (23%)]	Loss: -10.2759	Cost: 6.85s
Train Epoch: 1793 [40960/90000 (45%)]	Loss: -10.1594	Cost: 12.65s
Train Epoch: 1793 [61440/90000 (68%)]	Loss: -10.6334	Cost: 10.75s
Train Epoch: 1793 [81920/90000 (91%)]	Loss: -10.6512	Cost: 15.17s
Train Epoch: 1793 	Average Loss: -10.0202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4834

Learning rate: 9.227521137946087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1794 [0/90000 (0%)]	Loss: -6.1076	Cost: 39.22s
Train Epoch: 1794 [20480/90000 (23%)]	Loss: -10.7531	Cost: 11.80s
Train Epoch: 1794 [40960/90000 (45%)]	Loss: -10.9787	Cost: 11.83s
Train Epoch: 1794 [61440/90000 (68%)]	Loss: -11.2898	Cost: 7.70s
Train Epoch: 1794 [81920/90000 (91%)]	Loss: -11.0750	Cost: 7.08s
Train Epoch: 1794 	Average Loss: -10.5954
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5921

Learning rate: 9.226682173225505e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1795 [0/90000 (0%)]	Loss: -5.7105	Cost: 33.72s
Train Epoch: 1795 [20480/90000 (23%)]	Loss: -11.0319	Cost: 8.50s
Train Epoch: 1795 [40960/90000 (45%)]	Loss: -10.9047	Cost: 12.19s
Train Epoch: 1795 [61440/90000 (68%)]	Loss: -10.2681	Cost: 6.56s
Train Epoch: 1795 [81920/90000 (91%)]	Loss: -10.0095	Cost: 21.37s
Train Epoch: 1795 	Average Loss: -10.2606
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9684

Learning rate: 9.225842791348115e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1796 [0/90000 (0%)]	Loss: -5.3756	Cost: 33.85s
Train Epoch: 1796 [20480/90000 (23%)]	Loss: -10.1403	Cost: 11.90s
Train Epoch: 1796 [40960/90000 (45%)]	Loss: -10.4179	Cost: 11.59s
Train Epoch: 1796 [61440/90000 (68%)]	Loss: -10.9124	Cost: 8.42s
Train Epoch: 1796 [81920/90000 (91%)]	Loss: -10.8112	Cost: 7.57s
Train Epoch: 1796 	Average Loss: -10.1707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4464

Learning rate: 9.225002992396763e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1797 [0/90000 (0%)]	Loss: -5.9800	Cost: 28.47s
Train Epoch: 1797 [20480/90000 (23%)]	Loss: -10.5498	Cost: 9.53s
Train Epoch: 1797 [40960/90000 (45%)]	Loss: -10.9029	Cost: 24.80s
Train Epoch: 1797 [61440/90000 (68%)]	Loss: -11.0966	Cost: 12.90s
Train Epoch: 1797 [81920/90000 (91%)]	Loss: -10.7347	Cost: 11.94s
Train Epoch: 1797 	Average Loss: -10.4740
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2603

Learning rate: 9.224162776454334e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1798 [0/90000 (0%)]	Loss: -5.7322	Cost: 53.52s
Train Epoch: 1798 [20480/90000 (23%)]	Loss: -10.7286	Cost: 9.64s
Train Epoch: 1798 [40960/90000 (45%)]	Loss: -10.8815	Cost: 6.75s
Train Epoch: 1798 [61440/90000 (68%)]	Loss: -11.0396	Cost: 7.05s
Train Epoch: 1798 [81920/90000 (91%)]	Loss: -10.5812	Cost: 13.31s
Train Epoch: 1798 	Average Loss: -10.4658
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2126

Learning rate: 9.223322143603753e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1799 [0/90000 (0%)]	Loss: -5.7481	Cost: 27.97s
Train Epoch: 1799 [20480/90000 (23%)]	Loss: -10.2740	Cost: 10.01s
Train Epoch: 1799 [40960/90000 (45%)]	Loss: -10.3700	Cost: 16.13s
Train Epoch: 1799 [61440/90000 (68%)]	Loss: -11.0105	Cost: 12.53s
Train Epoch: 1799 [81920/90000 (91%)]	Loss: -10.7675	Cost: 12.80s
Train Epoch: 1799 	Average Loss: -10.2545
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3506

Learning rate: 9.222481093927987e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1800 [0/90000 (0%)]	Loss: -5.7520	Cost: 45.73s
Train Epoch: 1800 [20480/90000 (23%)]	Loss: -10.3865	Cost: 10.68s
Train Epoch: 1800 [40960/90000 (45%)]	Loss: -10.8038	Cost: 9.15s
Train Epoch: 1800 [61440/90000 (68%)]	Loss: -10.6076	Cost: 6.36s
Train Epoch: 1800 [81920/90000 (91%)]	Loss: -10.6920	Cost: 13.52s
Train Epoch: 1800 	Average Loss: -10.2596
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3170

Learning rate: 9.221639627510043e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1801 [0/90000 (0%)]	Loss: -6.1481	Cost: 35.65s
Train Epoch: 1801 [20480/90000 (23%)]	Loss: -10.4144	Cost: 9.66s
Train Epoch: 1801 [40960/90000 (45%)]	Loss: -10.3785	Cost: 16.97s
Train Epoch: 1801 [61440/90000 (68%)]	Loss: -10.6863	Cost: 12.36s
Train Epoch: 1801 [81920/90000 (91%)]	Loss: -10.5922	Cost: 11.89s
Train Epoch: 1801 	Average Loss: -10.1902
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3767

Learning rate: 9.220797744432973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1802 [0/90000 (0%)]	Loss: -5.5491	Cost: 57.80s
Train Epoch: 1802 [20480/90000 (23%)]	Loss: -10.3881	Cost: 8.41s
Train Epoch: 1802 [40960/90000 (45%)]	Loss: -10.6794	Cost: 7.58s
Train Epoch: 1802 [61440/90000 (68%)]	Loss: -10.8370	Cost: 8.10s
Train Epoch: 1802 [81920/90000 (91%)]	Loss: -10.6966	Cost: 12.15s
Train Epoch: 1802 	Average Loss: -10.3003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4342

Learning rate: 9.219955444779867e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1803 [0/90000 (0%)]	Loss: -5.8651	Cost: 28.41s
Train Epoch: 1803 [20480/90000 (23%)]	Loss: -10.4344	Cost: 6.97s
Train Epoch: 1803 [40960/90000 (45%)]	Loss: -10.7335	Cost: 17.65s
Train Epoch: 1803 [61440/90000 (68%)]	Loss: -11.2548	Cost: 13.29s
Train Epoch: 1803 [81920/90000 (91%)]	Loss: -11.0443	Cost: 13.18s
Train Epoch: 1803 	Average Loss: -10.5710
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5414

Learning rate: 9.219112728633856e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1804 [0/90000 (0%)]	Loss: -6.3154	Cost: 39.62s
Train Epoch: 1804 [20480/90000 (23%)]	Loss: -9.2302	Cost: 12.01s
Train Epoch: 1804 [40960/90000 (45%)]	Loss: -9.1576	Cost: 11.84s
Train Epoch: 1804 [61440/90000 (68%)]	Loss: -9.5232	Cost: 6.69s
Train Epoch: 1804 [81920/90000 (91%)]	Loss: -9.6404	Cost: 8.58s
Train Epoch: 1804 	Average Loss: -9.3686
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.6242

Learning rate: 9.218269596078113e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1805 [0/90000 (0%)]	Loss: -5.3555	Cost: 29.93s
Train Epoch: 1805 [20480/90000 (23%)]	Loss: -9.9725	Cost: 8.97s
Train Epoch: 1805 [40960/90000 (45%)]	Loss: -10.3553	Cost: 12.13s
Train Epoch: 1805 [61440/90000 (68%)]	Loss: -10.9180	Cost: 7.82s
Train Epoch: 1805 [81920/90000 (91%)]	Loss: -10.6527	Cost: 16.45s
Train Epoch: 1805 	Average Loss: -10.0210
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4196

Learning rate: 9.217426047195853e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1806 [0/90000 (0%)]	Loss: -4.7930	Cost: 36.08s
Train Epoch: 1806 [20480/90000 (23%)]	Loss: -10.3966	Cost: 13.57s
Train Epoch: 1806 [40960/90000 (45%)]	Loss: -10.5977	Cost: 12.67s
Train Epoch: 1806 [61440/90000 (68%)]	Loss: -10.9865	Cost: 11.31s
Train Epoch: 1806 [81920/90000 (91%)]	Loss: -10.8633	Cost: 6.47s
Train Epoch: 1806 	Average Loss: -10.2728
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5147

Learning rate: 9.216582082070327e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1807 [0/90000 (0%)]	Loss: -5.8203	Cost: 39.70s
Train Epoch: 1807 [20480/90000 (23%)]	Loss: -10.8567	Cost: 8.63s
Train Epoch: 1807 [40960/90000 (45%)]	Loss: -10.8066	Cost: 10.44s
Train Epoch: 1807 [61440/90000 (68%)]	Loss: -11.1170	Cost: 8.63s
Train Epoch: 1807 [81920/90000 (91%)]	Loss: -10.1780	Cost: 7.02s
Train Epoch: 1807 	Average Loss: -10.3223
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1523

Learning rate: 9.215737700784834e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1808 [0/90000 (0%)]	Loss: -6.0544	Cost: 28.44s
Train Epoch: 1808 [20480/90000 (23%)]	Loss: -10.3428	Cost: 8.28s
Train Epoch: 1808 [40960/90000 (45%)]	Loss: -10.6763	Cost: 17.56s
Train Epoch: 1808 [61440/90000 (68%)]	Loss: -11.0052	Cost: 12.10s
Train Epoch: 1808 [81920/90000 (91%)]	Loss: -10.8534	Cost: 12.15s
Train Epoch: 1808 	Average Loss: -10.3255
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5244

Learning rate: 9.214892903422712e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1809 [0/90000 (0%)]	Loss: -6.0401	Cost: 31.19s
Train Epoch: 1809 [20480/90000 (23%)]	Loss: -10.8669	Cost: 8.57s
Train Epoch: 1809 [40960/90000 (45%)]	Loss: -10.9426	Cost: 9.47s
Train Epoch: 1809 [61440/90000 (68%)]	Loss: -11.3249	Cost: 8.64s
Train Epoch: 1809 [81920/90000 (91%)]	Loss: -11.1679	Cost: 13.26s
Train Epoch: 1809 	Average Loss: -10.7105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6331

Learning rate: 9.214047690067338e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1810 [0/90000 (0%)]	Loss: -6.4454	Cost: 34.73s
Train Epoch: 1810 [20480/90000 (23%)]	Loss: -10.8497	Cost: 10.31s
Train Epoch: 1810 [40960/90000 (45%)]	Loss: -10.8695	Cost: 18.22s
Train Epoch: 1810 [61440/90000 (68%)]	Loss: -10.9774	Cost: 12.52s
Train Epoch: 1810 [81920/90000 (91%)]	Loss: -11.0064	Cost: 11.80s
Train Epoch: 1810 	Average Loss: -10.6029
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6504

Saving model as e1810_model.pt & e1810_waveforms_supplementary.hdf5
Learning rate: 9.213202060802132e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1811 [0/90000 (0%)]	Loss: -6.6819	Cost: 44.15s
Train Epoch: 1811 [20480/90000 (23%)]	Loss: -11.0061	Cost: 5.99s
Train Epoch: 1811 [40960/90000 (45%)]	Loss: -10.8436	Cost: 12.98s
Train Epoch: 1811 [61440/90000 (68%)]	Loss: -11.2164	Cost: 8.77s
Train Epoch: 1811 [81920/90000 (91%)]	Loss: -10.9112	Cost: 10.66s
Train Epoch: 1811 	Average Loss: -10.6194
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5460

Learning rate: 9.212356015710551e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1812 [0/90000 (0%)]	Loss: -5.7490	Cost: 28.65s
Train Epoch: 1812 [20480/90000 (23%)]	Loss: -10.9509	Cost: 10.00s
Train Epoch: 1812 [40960/90000 (45%)]	Loss: -11.0207	Cost: 13.37s
Train Epoch: 1812 [61440/90000 (68%)]	Loss: -11.3284	Cost: 12.87s
Train Epoch: 1812 [81920/90000 (91%)]	Loss: -11.1062	Cost: 12.05s
Train Epoch: 1812 	Average Loss: -10.7182
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5555

Learning rate: 9.2115095548761e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1813 [0/90000 (0%)]	Loss: -5.3732	Cost: 37.27s
Train Epoch: 1813 [20480/90000 (23%)]	Loss: -10.9957	Cost: 12.67s
Train Epoch: 1813 [40960/90000 (45%)]	Loss: -10.9665	Cost: 12.09s
Train Epoch: 1813 [61440/90000 (68%)]	Loss: -11.5569	Cost: 9.73s
Train Epoch: 1813 [81920/90000 (91%)]	Loss: -11.1292	Cost: 7.36s
Train Epoch: 1813 	Average Loss: -10.7553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5412

Learning rate: 9.210662678382321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1814 [0/90000 (0%)]	Loss: -6.3211	Cost: 28.58s
Train Epoch: 1814 [20480/90000 (23%)]	Loss: -10.8577	Cost: 9.65s
Train Epoch: 1814 [40960/90000 (45%)]	Loss: -10.7954	Cost: 16.68s
Train Epoch: 1814 [61440/90000 (68%)]	Loss: -10.9719	Cost: 12.00s
Train Epoch: 1814 [81920/90000 (91%)]	Loss: -10.8889	Cost: 18.29s
Train Epoch: 1814 	Average Loss: -10.5835
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6259

Learning rate: 9.209815386312794e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1815 [0/90000 (0%)]	Loss: -5.9283	Cost: 55.86s
Train Epoch: 1815 [20480/90000 (23%)]	Loss: -10.9309	Cost: 11.09s
Train Epoch: 1815 [40960/90000 (45%)]	Loss: -10.9598	Cost: 7.85s
Train Epoch: 1815 [61440/90000 (68%)]	Loss: -11.3982	Cost: 6.44s
Train Epoch: 1815 [81920/90000 (91%)]	Loss: -11.3876	Cost: 12.53s
Train Epoch: 1815 	Average Loss: -10.7344
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6802

Saving model as e1815_model.pt & e1815_waveforms_supplementary.hdf5
Learning rate: 9.208967678751147e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1816 [0/90000 (0%)]	Loss: -6.0674	Cost: 29.22s
Train Epoch: 1816 [20480/90000 (23%)]	Loss: -10.7832	Cost: 10.90s
Train Epoch: 1816 [40960/90000 (45%)]	Loss: -10.8032	Cost: 22.15s
Train Epoch: 1816 [61440/90000 (68%)]	Loss: -11.1634	Cost: 12.41s
Train Epoch: 1816 [81920/90000 (91%)]	Loss: -10.8747	Cost: 12.15s
Train Epoch: 1816 	Average Loss: -10.6499
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2826

Learning rate: 9.208119555781044e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1817 [0/90000 (0%)]	Loss: -5.8903	Cost: 41.08s
Train Epoch: 1817 [20480/90000 (23%)]	Loss: -10.7289	Cost: 7.53s
Train Epoch: 1817 [40960/90000 (45%)]	Loss: -10.9464	Cost: 11.41s
Train Epoch: 1817 [61440/90000 (68%)]	Loss: -11.2857	Cost: 9.09s
Train Epoch: 1817 [81920/90000 (91%)]	Loss: -10.0412	Cost: 11.99s
Train Epoch: 1817 	Average Loss: -10.4088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9985

Learning rate: 9.20727101748619e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1818 [0/90000 (0%)]	Loss: -5.2773	Cost: 27.02s
Train Epoch: 1818 [20480/90000 (23%)]	Loss: -9.7822	Cost: 9.37s
Train Epoch: 1818 [40960/90000 (45%)]	Loss: -10.0833	Cost: 23.13s
Train Epoch: 1818 [61440/90000 (68%)]	Loss: -10.1941	Cost: 12.32s
Train Epoch: 1818 [81920/90000 (91%)]	Loss: -10.3424	Cost: 12.12s
Train Epoch: 1818 	Average Loss: -9.8115
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1295

Learning rate: 9.206422063950336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1819 [0/90000 (0%)]	Loss: -5.3924	Cost: 43.24s
Train Epoch: 1819 [20480/90000 (23%)]	Loss: -10.5232	Cost: 12.26s
Train Epoch: 1819 [40960/90000 (45%)]	Loss: -10.7275	Cost: 10.16s
Train Epoch: 1819 [61440/90000 (68%)]	Loss: -11.0790	Cost: 6.31s
Train Epoch: 1819 [81920/90000 (91%)]	Loss: -11.0308	Cost: 12.75s
Train Epoch: 1819 	Average Loss: -10.5302
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8026

Saving model as e1819_model.pt & e1819_waveforms_supplementary.hdf5
Learning rate: 9.205572695257268e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1820 [0/90000 (0%)]	Loss: -5.8551	Cost: 28.43s
Train Epoch: 1820 [20480/90000 (23%)]	Loss: -11.0041	Cost: 8.57s
Train Epoch: 1820 [40960/90000 (45%)]	Loss: -10.9923	Cost: 15.71s
Train Epoch: 1820 [61440/90000 (68%)]	Loss: -11.3667	Cost: 12.14s
Train Epoch: 1820 [81920/90000 (91%)]	Loss: -11.2796	Cost: 12.03s
Train Epoch: 1820 	Average Loss: -10.7949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7901

Learning rate: 9.204722911490815e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1821 [0/90000 (0%)]	Loss: -6.3164	Cost: 37.36s
Train Epoch: 1821 [20480/90000 (23%)]	Loss: -10.9217	Cost: 12.08s
Train Epoch: 1821 [40960/90000 (45%)]	Loss: -11.0502	Cost: 7.08s
Train Epoch: 1821 [61440/90000 (68%)]	Loss: -11.3399	Cost: 8.22s
Train Epoch: 1821 [81920/90000 (91%)]	Loss: -11.0113	Cost: 14.93s
Train Epoch: 1821 	Average Loss: -10.7757
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5123

Learning rate: 9.203872712734849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1822 [0/90000 (0%)]	Loss: -6.5296	Cost: 39.01s
Train Epoch: 1822 [20480/90000 (23%)]	Loss: -10.8831	Cost: 8.81s
Train Epoch: 1822 [40960/90000 (45%)]	Loss: -10.9172	Cost: 17.06s
Train Epoch: 1822 [61440/90000 (68%)]	Loss: -11.2845	Cost: 12.02s
Train Epoch: 1822 [81920/90000 (91%)]	Loss: -11.2604	Cost: 12.09s
Train Epoch: 1822 	Average Loss: -10.7532
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6601

Learning rate: 9.203022099073279e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1823 [0/90000 (0%)]	Loss: -6.1678	Cost: 48.58s
Train Epoch: 1823 [20480/90000 (23%)]	Loss: -11.0830	Cost: 6.31s
Train Epoch: 1823 [40960/90000 (45%)]	Loss: -11.2690	Cost: 12.85s
Train Epoch: 1823 [61440/90000 (68%)]	Loss: -11.3940	Cost: 8.79s
Train Epoch: 1823 [81920/90000 (91%)]	Loss: -11.0101	Cost: 11.58s
Train Epoch: 1823 	Average Loss: -10.7563
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6108

Learning rate: 9.202171070590059e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1824 [0/90000 (0%)]	Loss: -6.4122	Cost: 30.82s
Train Epoch: 1824 [20480/90000 (23%)]	Loss: -10.9952	Cost: 7.76s
Train Epoch: 1824 [40960/90000 (45%)]	Loss: -11.0193	Cost: 16.95s
Train Epoch: 1824 [61440/90000 (68%)]	Loss: -11.3540	Cost: 12.23s
Train Epoch: 1824 [81920/90000 (91%)]	Loss: -11.1806	Cost: 11.90s
Train Epoch: 1824 	Average Loss: -10.7334
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7674

Learning rate: 9.201319627369181e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1825 [0/90000 (0%)]	Loss: -6.5768	Cost: 32.45s
Train Epoch: 1825 [20480/90000 (23%)]	Loss: -10.7779	Cost: 12.39s
Train Epoch: 1825 [40960/90000 (45%)]	Loss: -10.8776	Cost: 11.05s
Train Epoch: 1825 [61440/90000 (68%)]	Loss: -11.0787	Cost: 5.98s
Train Epoch: 1825 [81920/90000 (91%)]	Loss: -10.9510	Cost: 7.27s
Train Epoch: 1825 	Average Loss: -10.5804
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4986

Learning rate: 9.20046776949468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1826 [0/90000 (0%)]	Loss: -5.8765	Cost: 27.47s
Train Epoch: 1826 [20480/90000 (23%)]	Loss: -10.8135	Cost: 8.03s
Train Epoch: 1826 [40960/90000 (45%)]	Loss: -10.8811	Cost: 22.93s
Train Epoch: 1826 [61440/90000 (68%)]	Loss: -11.2007	Cost: 13.44s
Train Epoch: 1826 [81920/90000 (91%)]	Loss: -10.7870	Cost: 11.92s
Train Epoch: 1826 	Average Loss: -10.5105
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4275

Learning rate: 9.199615497050631e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1827 [0/90000 (0%)]	Loss: -5.7419	Cost: 49.04s
Train Epoch: 1827 [20480/90000 (23%)]	Loss: -10.8207	Cost: 12.11s
Train Epoch: 1827 [40960/90000 (45%)]	Loss: -10.6711	Cost: 10.14s
Train Epoch: 1827 [61440/90000 (68%)]	Loss: -11.2436	Cost: 6.23s
Train Epoch: 1827 [81920/90000 (91%)]	Loss: -11.0069	Cost: 7.84s
Train Epoch: 1827 	Average Loss: -10.5775
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6067

Learning rate: 9.198762810121149e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1828 [0/90000 (0%)]	Loss: -6.3413	Cost: 28.12s
Train Epoch: 1828 [20480/90000 (23%)]	Loss: -10.7900	Cost: 7.37s
Train Epoch: 1828 [40960/90000 (45%)]	Loss: -10.7952	Cost: 17.58s
Train Epoch: 1828 [61440/90000 (68%)]	Loss: -11.2913	Cost: 13.09s
Train Epoch: 1828 [81920/90000 (91%)]	Loss: -11.0095	Cost: 12.78s
Train Epoch: 1828 	Average Loss: -10.6078
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0482

Learning rate: 9.19790970879039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1829 [0/90000 (0%)]	Loss: -6.0602	Cost: 41.12s
Train Epoch: 1829 [20480/90000 (23%)]	Loss: -10.0758	Cost: 12.12s
Train Epoch: 1829 [40960/90000 (45%)]	Loss: -10.1687	Cost: 12.24s
Train Epoch: 1829 [61440/90000 (68%)]	Loss: -10.9050	Cost: 9.83s
Train Epoch: 1829 [81920/90000 (91%)]	Loss: -10.8427	Cost: 6.26s
Train Epoch: 1829 	Average Loss: -10.1824
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5495

Learning rate: 9.197056193142553e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1830 [0/90000 (0%)]	Loss: -6.1237	Cost: 28.69s
Train Epoch: 1830 [20480/90000 (23%)]	Loss: -10.5310	Cost: 8.69s
Train Epoch: 1830 [40960/90000 (45%)]	Loss: -10.9380	Cost: 10.20s
Train Epoch: 1830 [61440/90000 (68%)]	Loss: -11.2130	Cost: 8.49s
Train Epoch: 1830 [81920/90000 (91%)]	Loss: -10.7973	Cost: 13.41s
Train Epoch: 1830 	Average Loss: -10.5702
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4567

Learning rate: 9.196202263261877e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1831 [0/90000 (0%)]	Loss: -5.4969	Cost: 29.63s
Train Epoch: 1831 [20480/90000 (23%)]	Loss: -10.5652	Cost: 11.06s
Train Epoch: 1831 [40960/90000 (45%)]	Loss: -10.5852	Cost: 20.59s
Train Epoch: 1831 [61440/90000 (68%)]	Loss: -10.8424	Cost: 12.60s
Train Epoch: 1831 [81920/90000 (91%)]	Loss: -10.9512	Cost: 11.94s
Train Epoch: 1831 	Average Loss: -10.4183
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5738

Learning rate: 9.195347919232642e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1832 [0/90000 (0%)]	Loss: -6.2896	Cost: 50.00s
Train Epoch: 1832 [20480/90000 (23%)]	Loss: -10.5895	Cost: 6.34s
Train Epoch: 1832 [40960/90000 (45%)]	Loss: -10.7431	Cost: 13.91s
Train Epoch: 1832 [61440/90000 (68%)]	Loss: -11.1959	Cost: 8.60s
Train Epoch: 1832 [81920/90000 (91%)]	Loss: -10.9051	Cost: 7.37s
Train Epoch: 1832 	Average Loss: -10.4964
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4926

Learning rate: 9.19449316113917e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1833 [0/90000 (0%)]	Loss: -6.6747	Cost: 32.49s
Train Epoch: 1833 [20480/90000 (23%)]	Loss: -10.8462	Cost: 8.14s
Train Epoch: 1833 [40960/90000 (45%)]	Loss: -10.8164	Cost: 16.19s
Train Epoch: 1833 [61440/90000 (68%)]	Loss: -11.1730	Cost: 12.75s
Train Epoch: 1833 [81920/90000 (91%)]	Loss: -10.1806	Cost: 12.08s
Train Epoch: 1833 	Average Loss: -10.4154
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.9977

Learning rate: 9.193637989065816e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1834 [0/90000 (0%)]	Loss: -5.6755	Cost: 45.12s
Train Epoch: 1834 [20480/90000 (23%)]	Loss: -9.6485	Cost: 6.53s
Train Epoch: 1834 [40960/90000 (45%)]	Loss: -10.0625	Cost: 14.47s
Train Epoch: 1834 [61440/90000 (68%)]	Loss: -10.4820	Cost: 8.47s
Train Epoch: 1834 [81920/90000 (91%)]	Loss: -10.1451	Cost: 8.43s
Train Epoch: 1834 	Average Loss: -9.6821
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.8286

Learning rate: 9.192782403096989e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1835 [0/90000 (0%)]	Loss: -5.9128	Cost: 28.99s
Train Epoch: 1835 [20480/90000 (23%)]	Loss: -10.4073	Cost: 7.54s
Train Epoch: 1835 [40960/90000 (45%)]	Loss: -10.7820	Cost: 16.41s
Train Epoch: 1835 [61440/90000 (68%)]	Loss: -11.3035	Cost: 12.32s
Train Epoch: 1835 [81920/90000 (91%)]	Loss: -10.8829	Cost: 12.46s
Train Epoch: 1835 	Average Loss: -10.4212
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2084

Learning rate: 9.191926403317126e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1836 [0/90000 (0%)]	Loss: -6.1175	Cost: 33.99s
Train Epoch: 1836 [20480/90000 (23%)]	Loss: -10.7325	Cost: 9.31s
Train Epoch: 1836 [40960/90000 (45%)]	Loss: -11.1421	Cost: 8.17s
Train Epoch: 1836 [61440/90000 (68%)]	Loss: -11.4254	Cost: 9.27s
Train Epoch: 1836 [81920/90000 (91%)]	Loss: -10.9793	Cost: 13.86s
Train Epoch: 1836 	Average Loss: -10.6484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3878

Learning rate: 9.191069989810715e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1837 [0/90000 (0%)]	Loss: -5.8601	Cost: 37.94s
Train Epoch: 1837 [20480/90000 (23%)]	Loss: -10.7384	Cost: 9.50s
Train Epoch: 1837 [40960/90000 (45%)]	Loss: -10.8489	Cost: 15.97s
Train Epoch: 1837 [61440/90000 (68%)]	Loss: -11.3001	Cost: 11.82s
Train Epoch: 1837 [81920/90000 (91%)]	Loss: -11.1770	Cost: 11.90s
Train Epoch: 1837 	Average Loss: -10.6038
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4602

Learning rate: 9.190213162662278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1838 [0/90000 (0%)]	Loss: -6.0808	Cost: 47.58s
Train Epoch: 1838 [20480/90000 (23%)]	Loss: -10.7809	Cost: 9.06s
Train Epoch: 1838 [40960/90000 (45%)]	Loss: -10.9999	Cost: 8.42s
Train Epoch: 1838 [61440/90000 (68%)]	Loss: -11.4723	Cost: 8.11s
Train Epoch: 1838 [81920/90000 (91%)]	Loss: -11.0739	Cost: 12.00s
Train Epoch: 1838 	Average Loss: -10.6743
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5352

Learning rate: 9.189355921956384e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1839 [0/90000 (0%)]	Loss: -6.5033	Cost: 34.94s
Train Epoch: 1839 [20480/90000 (23%)]	Loss: -11.0619	Cost: 11.53s
Train Epoch: 1839 [40960/90000 (45%)]	Loss: -11.1400	Cost: 13.19s
Train Epoch: 1839 [61440/90000 (68%)]	Loss: -11.6881	Cost: 12.19s
Train Epoch: 1839 [81920/90000 (91%)]	Loss: -11.2465	Cost: 12.06s
Train Epoch: 1839 	Average Loss: -10.8311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3314

Learning rate: 9.188498267777634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1840 [0/90000 (0%)]	Loss: -5.8827	Cost: 31.89s
Train Epoch: 1840 [20480/90000 (23%)]	Loss: -10.7280	Cost: 12.19s
Train Epoch: 1840 [40960/90000 (45%)]	Loss: -10.7726	Cost: 10.88s
Train Epoch: 1840 [61440/90000 (68%)]	Loss: -11.3738	Cost: 6.36s
Train Epoch: 1840 [81920/90000 (91%)]	Loss: -10.7128	Cost: 6.88s
Train Epoch: 1840 	Average Loss: -10.5390
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1836

Learning rate: 9.187640200210681e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1841 [0/90000 (0%)]	Loss: -5.9942	Cost: 27.72s
Train Epoch: 1841 [20480/90000 (23%)]	Loss: -11.0421	Cost: 9.25s
Train Epoch: 1841 [40960/90000 (45%)]	Loss: -10.9194	Cost: 20.19s
Train Epoch: 1841 [61440/90000 (68%)]	Loss: -11.1208	Cost: 13.26s
Train Epoch: 1841 [81920/90000 (91%)]	Loss: -10.9225	Cost: 13.36s
Train Epoch: 1841 	Average Loss: -10.5726
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3594

Learning rate: 9.186781719340208e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1842 [0/90000 (0%)]	Loss: -5.7058	Cost: 57.29s
Train Epoch: 1842 [20480/90000 (23%)]	Loss: -10.7760	Cost: 11.24s
Train Epoch: 1842 [40960/90000 (45%)]	Loss: -10.9777	Cost: 6.29s
Train Epoch: 1842 [61440/90000 (68%)]	Loss: -11.4081	Cost: 6.38s
Train Epoch: 1842 [81920/90000 (91%)]	Loss: -10.8579	Cost: 13.26s
Train Epoch: 1842 	Average Loss: -10.6023
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1608

Learning rate: 9.185922825250947e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1843 [0/90000 (0%)]	Loss: -5.6216	Cost: 27.30s
Train Epoch: 1843 [20480/90000 (23%)]	Loss: -10.8020	Cost: 10.15s
Train Epoch: 1843 [40960/90000 (45%)]	Loss: -10.9770	Cost: 19.70s
Train Epoch: 1843 [61440/90000 (68%)]	Loss: -11.5014	Cost: 12.16s
Train Epoch: 1843 [81920/90000 (91%)]	Loss: -11.4132	Cost: 11.87s
Train Epoch: 1843 	Average Loss: -10.7311
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4632

Learning rate: 9.185063518027664e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1844 [0/90000 (0%)]	Loss: -6.0790	Cost: 49.06s
Train Epoch: 1844 [20480/90000 (23%)]	Loss: -10.7120	Cost: 6.19s
Train Epoch: 1844 [40960/90000 (45%)]	Loss: -10.9074	Cost: 13.56s
Train Epoch: 1844 [61440/90000 (68%)]	Loss: -11.3003	Cost: 9.03s
Train Epoch: 1844 [81920/90000 (91%)]	Loss: -11.3053	Cost: 11.17s
Train Epoch: 1844 	Average Loss: -10.6620
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6187

Learning rate: 9.184203797755172e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1845 [0/90000 (0%)]	Loss: -6.2864	Cost: 35.68s
Train Epoch: 1845 [20480/90000 (23%)]	Loss: -10.6967	Cost: 12.93s
Train Epoch: 1845 [40960/90000 (45%)]	Loss: -11.1860	Cost: 19.05s
Train Epoch: 1845 [61440/90000 (68%)]	Loss: -11.5544	Cost: 12.16s
Train Epoch: 1845 [81920/90000 (91%)]	Loss: -10.3116	Cost: 11.87s
Train Epoch: 1845 	Average Loss: -10.7247
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7459

Learning rate: 9.183343664518321e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1846 [0/90000 (0%)]	Loss: -5.0887	Cost: 46.45s
Train Epoch: 1846 [20480/90000 (23%)]	Loss: -10.1963	Cost: 11.43s
Train Epoch: 1846 [40960/90000 (45%)]	Loss: -10.1632	Cost: 6.51s
Train Epoch: 1846 [61440/90000 (68%)]	Loss: -10.6802	Cost: 6.79s
Train Epoch: 1846 [81920/90000 (91%)]	Loss: -10.8013	Cost: 12.84s
Train Epoch: 1846 	Average Loss: -10.1030
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3981

Learning rate: 9.182483118402004e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1847 [0/90000 (0%)]	Loss: -5.8332	Cost: 29.33s
Train Epoch: 1847 [20480/90000 (23%)]	Loss: -10.7185	Cost: 7.07s
Train Epoch: 1847 [40960/90000 (45%)]	Loss: -10.8960	Cost: 18.26s
Train Epoch: 1847 [61440/90000 (68%)]	Loss: -11.1500	Cost: 12.61s
Train Epoch: 1847 [81920/90000 (91%)]	Loss: -11.0150	Cost: 12.05s
Train Epoch: 1847 	Average Loss: -10.6026
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3740

Learning rate: 9.181622159491152e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1848 [0/90000 (0%)]	Loss: -6.3368	Cost: 36.78s
Train Epoch: 1848 [20480/90000 (23%)]	Loss: -10.9193	Cost: 12.77s
Train Epoch: 1848 [40960/90000 (45%)]	Loss: -10.8026	Cost: 12.15s
Train Epoch: 1848 [61440/90000 (68%)]	Loss: -11.2286	Cost: 6.39s
Train Epoch: 1848 [81920/90000 (91%)]	Loss: -11.0301	Cost: 6.83s
Train Epoch: 1848 	Average Loss: -10.6393
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3950

Learning rate: 9.180760787870738e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1849 [0/90000 (0%)]	Loss: -4.9908	Cost: 28.65s
Train Epoch: 1849 [20480/90000 (23%)]	Loss: -10.7179	Cost: 6.22s
Train Epoch: 1849 [40960/90000 (45%)]	Loss: -10.0375	Cost: 15.19s
Train Epoch: 1849 [61440/90000 (68%)]	Loss: -10.3407	Cost: 13.71s
Train Epoch: 1849 [81920/90000 (91%)]	Loss: -10.5427	Cost: 13.47s
Train Epoch: 1849 	Average Loss: -10.1287
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1011

Learning rate: 9.179899003625777e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1850 [0/90000 (0%)]	Loss: -6.3480	Cost: 34.66s
Train Epoch: 1850 [20480/90000 (23%)]	Loss: -10.5722	Cost: 14.32s
Train Epoch: 1850 [40960/90000 (45%)]	Loss: -10.7728	Cost: 13.31s
Train Epoch: 1850 [61440/90000 (68%)]	Loss: -11.3278	Cost: 7.17s
Train Epoch: 1850 [81920/90000 (91%)]	Loss: -10.9314	Cost: 9.69s
Train Epoch: 1850 	Average Loss: -10.5266
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4017

Learning rate: 9.179036806841325e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1851 [0/90000 (0%)]	Loss: -5.9702	Cost: 32.71s
Train Epoch: 1851 [20480/90000 (23%)]	Loss: -10.7373	Cost: 8.84s
Train Epoch: 1851 [40960/90000 (45%)]	Loss: -11.0847	Cost: 16.48s
Train Epoch: 1851 [61440/90000 (68%)]	Loss: -11.3370	Cost: 12.66s
Train Epoch: 1851 [81920/90000 (91%)]	Loss: -11.1778	Cost: 12.26s
Train Epoch: 1851 	Average Loss: -10.7024
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5575

Learning rate: 9.178174197602472e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1852 [0/90000 (0%)]	Loss: -5.9418	Cost: 45.96s
Train Epoch: 1852 [20480/90000 (23%)]	Loss: -11.0230	Cost: 12.25s
Train Epoch: 1852 [40960/90000 (45%)]	Loss: -11.3417	Cost: 12.01s
Train Epoch: 1852 [61440/90000 (68%)]	Loss: -11.4984	Cost: 6.25s
Train Epoch: 1852 [81920/90000 (91%)]	Loss: -11.3478	Cost: 6.35s
Train Epoch: 1852 	Average Loss: -10.9280
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5694

Learning rate: 9.177311175994362e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1853 [0/90000 (0%)]	Loss: -6.7330	Cost: 28.02s
Train Epoch: 1853 [20480/90000 (23%)]	Loss: -10.8190	Cost: 8.09s
Train Epoch: 1853 [40960/90000 (45%)]	Loss: -10.9457	Cost: 15.38s
Train Epoch: 1853 [61440/90000 (68%)]	Loss: -11.4625	Cost: 11.77s
Train Epoch: 1853 [81920/90000 (91%)]	Loss: -11.1961	Cost: 13.32s
Train Epoch: 1853 	Average Loss: -10.7274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6029

Learning rate: 9.176447742102165e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1854 [0/90000 (0%)]	Loss: -6.3920	Cost: 35.78s
Train Epoch: 1854 [20480/90000 (23%)]	Loss: -11.0491	Cost: 12.28s
Train Epoch: 1854 [40960/90000 (45%)]	Loss: -11.2676	Cost: 12.28s
Train Epoch: 1854 [61440/90000 (68%)]	Loss: -11.7301	Cost: 9.48s
Train Epoch: 1854 [81920/90000 (91%)]	Loss: -11.5536	Cost: 8.50s
Train Epoch: 1854 	Average Loss: -11.0599
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6751

Learning rate: 9.175583896011101e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1855 [0/90000 (0%)]	Loss: -6.9787	Cost: 26.69s
Train Epoch: 1855 [20480/90000 (23%)]	Loss: -11.3051	Cost: 9.68s
Train Epoch: 1855 [40960/90000 (45%)]	Loss: -11.3879	Cost: 14.27s
Train Epoch: 1855 [61440/90000 (68%)]	Loss: -11.6385	Cost: 10.52s
Train Epoch: 1855 [81920/90000 (91%)]	Loss: -11.4183	Cost: 20.00s
Train Epoch: 1855 	Average Loss: -11.1100
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8452

Saving model as e1855_model.pt & e1855_waveforms_supplementary.hdf5
Learning rate: 9.17471963780643e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1856 [0/90000 (0%)]	Loss: -6.4986	Cost: 43.84s
Train Epoch: 1856 [20480/90000 (23%)]	Loss: -11.3712	Cost: 12.83s
Train Epoch: 1856 [40960/90000 (45%)]	Loss: -11.4079	Cost: 12.13s
Train Epoch: 1856 [61440/90000 (68%)]	Loss: -11.5004	Cost: 7.61s
Train Epoch: 1856 [81920/90000 (91%)]	Loss: -11.1041	Cost: 6.26s
Train Epoch: 1856 	Average Loss: -11.0550
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5693

Learning rate: 9.173854967573448e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1857 [0/90000 (0%)]	Loss: -6.1967	Cost: 33.92s
Train Epoch: 1857 [20480/90000 (23%)]	Loss: -10.1196	Cost: 8.81s
Train Epoch: 1857 [40960/90000 (45%)]	Loss: -10.2590	Cost: 8.47s
Train Epoch: 1857 [61440/90000 (68%)]	Loss: -10.7412	Cost: 6.50s
Train Epoch: 1857 [81920/90000 (91%)]	Loss: -10.6009	Cost: 16.28s
Train Epoch: 1857 	Average Loss: -10.0906
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2019

Learning rate: 9.172989885397498e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1858 [0/90000 (0%)]	Loss: -5.3798	Cost: 44.02s
Train Epoch: 1858 [20480/90000 (23%)]	Loss: -10.8698	Cost: 11.75s
Train Epoch: 1858 [40960/90000 (45%)]	Loss: -10.8912	Cost: 12.21s
Train Epoch: 1858 [61440/90000 (68%)]	Loss: -11.1394	Cost: 9.42s
Train Epoch: 1858 [81920/90000 (91%)]	Loss: -10.9574	Cost: 5.98s
Train Epoch: 1858 	Average Loss: -10.5670
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3672

Learning rate: 9.172124391363957e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1859 [0/90000 (0%)]	Loss: -5.7093	Cost: 29.16s
Train Epoch: 1859 [20480/90000 (23%)]	Loss: -10.8159	Cost: 8.71s
Train Epoch: 1859 [40960/90000 (45%)]	Loss: -11.1760	Cost: 11.92s
Train Epoch: 1859 [61440/90000 (68%)]	Loss: -11.1878	Cost: 5.98s
Train Epoch: 1859 [81920/90000 (91%)]	Loss: -10.9684	Cost: 12.83s
Train Epoch: 1859 	Average Loss: -10.6073
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4808

Learning rate: 9.171258485558245e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1860 [0/90000 (0%)]	Loss: -5.9698	Cost: 32.52s
Train Epoch: 1860 [20480/90000 (23%)]	Loss: -11.1093	Cost: 13.09s
Train Epoch: 1860 [40960/90000 (45%)]	Loss: -11.2451	Cost: 12.08s
Train Epoch: 1860 [61440/90000 (68%)]	Loss: -11.6289	Cost: 12.08s
Train Epoch: 1860 [81920/90000 (91%)]	Loss: -11.5012	Cost: 9.47s
Train Epoch: 1860 	Average Loss: -10.8961
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4790

Learning rate: 9.170392168065828e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1861 [0/90000 (0%)]	Loss: -6.5395	Cost: 29.93s
Train Epoch: 1861 [20480/90000 (23%)]	Loss: -10.7247	Cost: 9.43s
Train Epoch: 1861 [40960/90000 (45%)]	Loss: -11.1031	Cost: 13.39s
Train Epoch: 1861 [61440/90000 (68%)]	Loss: -11.4006	Cost: 9.60s
Train Epoch: 1861 [81920/90000 (91%)]	Loss: -8.3311	Cost: 8.38s
Train Epoch: 1861 	Average Loss: -10.0762
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -4.3297

Learning rate: 9.169525438972204e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1862 [0/90000 (0%)]	Loss: -4.1194	Cost: 34.28s
Train Epoch: 1862 [20480/90000 (23%)]	Loss: -8.7666	Cost: 11.40s
Train Epoch: 1862 [40960/90000 (45%)]	Loss: -9.7232	Cost: 16.59s
Train Epoch: 1862 [61440/90000 (68%)]	Loss: -10.4114	Cost: 12.20s
Train Epoch: 1862 [81920/90000 (91%)]	Loss: -10.2167	Cost: 11.81s
Train Epoch: 1862 	Average Loss: -9.2480
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1557

Learning rate: 9.168658298362917e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1863 [0/90000 (0%)]	Loss: -6.0082	Cost: 38.64s
Train Epoch: 1863 [20480/90000 (23%)]	Loss: -10.4190	Cost: 6.42s
Train Epoch: 1863 [40960/90000 (45%)]	Loss: -10.6204	Cost: 14.52s
Train Epoch: 1863 [61440/90000 (68%)]	Loss: -11.2762	Cost: 8.81s
Train Epoch: 1863 [81920/90000 (91%)]	Loss: -10.8849	Cost: 11.57s
Train Epoch: 1863 	Average Loss: -10.3915
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3353

Learning rate: 9.16779074632355e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1864 [0/90000 (0%)]	Loss: -5.3561	Cost: 31.70s
Train Epoch: 1864 [20480/90000 (23%)]	Loss: -10.5880	Cost: 10.03s
Train Epoch: 1864 [40960/90000 (45%)]	Loss: -10.9315	Cost: 16.17s
Train Epoch: 1864 [61440/90000 (68%)]	Loss: -11.5716	Cost: 12.46s
Train Epoch: 1864 [81920/90000 (91%)]	Loss: -11.2542	Cost: 12.14s
Train Epoch: 1864 	Average Loss: -10.6712
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7579

Learning rate: 9.166922782939728e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1865 [0/90000 (0%)]	Loss: -6.7399	Cost: 37.41s
Train Epoch: 1865 [20480/90000 (23%)]	Loss: -11.1243	Cost: 11.79s
Train Epoch: 1865 [40960/90000 (45%)]	Loss: -11.0621	Cost: 6.90s
Train Epoch: 1865 [61440/90000 (68%)]	Loss: -11.5310	Cost: 6.22s
Train Epoch: 1865 [81920/90000 (91%)]	Loss: -11.4535	Cost: 15.29s
Train Epoch: 1865 	Average Loss: -10.9264
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6884

Learning rate: 9.166054408297117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1866 [0/90000 (0%)]	Loss: -6.2900	Cost: 42.60s
Train Epoch: 1866 [20480/90000 (23%)]	Loss: -11.2974	Cost: 13.13s
Train Epoch: 1866 [40960/90000 (45%)]	Loss: -11.2258	Cost: 15.48s
Train Epoch: 1866 [61440/90000 (68%)]	Loss: -11.5463	Cost: 11.93s
Train Epoch: 1866 [81920/90000 (91%)]	Loss: -11.5883	Cost: 12.02s
Train Epoch: 1866 	Average Loss: -11.0047
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7878

Learning rate: 9.165185622481417e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1867 [0/90000 (0%)]	Loss: -6.5218	Cost: 54.97s
Train Epoch: 1867 [20480/90000 (23%)]	Loss: -11.3753	Cost: 6.27s
Train Epoch: 1867 [40960/90000 (45%)]	Loss: -11.4266	Cost: 13.43s
Train Epoch: 1867 [61440/90000 (68%)]	Loss: -11.6293	Cost: 8.69s
Train Epoch: 1867 [81920/90000 (91%)]	Loss: -11.0664	Cost: 9.64s
Train Epoch: 1867 	Average Loss: -11.0238
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4963

Learning rate: 9.16431642557838e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1868 [0/90000 (0%)]	Loss: -6.3285	Cost: 28.72s
Train Epoch: 1868 [20480/90000 (23%)]	Loss: -10.8634	Cost: 7.58s
Train Epoch: 1868 [40960/90000 (45%)]	Loss: -11.1761	Cost: 20.41s
Train Epoch: 1868 [61440/90000 (68%)]	Loss: -11.5533	Cost: 13.16s
Train Epoch: 1868 [81920/90000 (91%)]	Loss: -11.3141	Cost: 12.23s
Train Epoch: 1868 	Average Loss: -10.8649
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6419

Learning rate: 9.163446817673787e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1869 [0/90000 (0%)]	Loss: -6.1396	Cost: 32.78s
Train Epoch: 1869 [20480/90000 (23%)]	Loss: -10.7175	Cost: 10.37s
Train Epoch: 1869 [40960/90000 (45%)]	Loss: -10.8319	Cost: 9.76s
Train Epoch: 1869 [61440/90000 (68%)]	Loss: -10.7785	Cost: 7.13s
Train Epoch: 1869 [81920/90000 (91%)]	Loss: -9.9960	Cost: 15.14s
Train Epoch: 1869 	Average Loss: -10.2931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.7392

Learning rate: 9.162576798853468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1870 [0/90000 (0%)]	Loss: -5.5566	Cost: 28.30s
Train Epoch: 1870 [20480/90000 (23%)]	Loss: -10.1722	Cost: 10.28s
Train Epoch: 1870 [40960/90000 (45%)]	Loss: -10.5027	Cost: 22.18s
Train Epoch: 1870 [61440/90000 (68%)]	Loss: -11.1213	Cost: 12.21s
Train Epoch: 1870 [81920/90000 (91%)]	Loss: -10.9026	Cost: 11.87s
Train Epoch: 1870 	Average Loss: -10.2913
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5410

Learning rate: 9.161706369203289e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1871 [0/90000 (0%)]	Loss: -6.0616	Cost: 36.80s
Train Epoch: 1871 [20480/90000 (23%)]	Loss: -10.9506	Cost: 11.41s
Train Epoch: 1871 [40960/90000 (45%)]	Loss: -11.1671	Cost: 10.42s
Train Epoch: 1871 [61440/90000 (68%)]	Loss: -11.6664	Cost: 7.61s
Train Epoch: 1871 [81920/90000 (91%)]	Loss: -11.3049	Cost: 13.86s
Train Epoch: 1871 	Average Loss: -10.8934
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5286

Learning rate: 9.160835528809158e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1872 [0/90000 (0%)]	Loss: -6.1063	Cost: 33.28s
Train Epoch: 1872 [20480/90000 (23%)]	Loss: -11.1856	Cost: 7.05s
Train Epoch: 1872 [40960/90000 (45%)]	Loss: -11.2479	Cost: 18.48s
Train Epoch: 1872 [61440/90000 (68%)]	Loss: -11.6997	Cost: 12.18s
Train Epoch: 1872 [81920/90000 (91%)]	Loss: -11.4629	Cost: 11.95s
Train Epoch: 1872 	Average Loss: -11.0638
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8997

Saving model as e1872_model.pt & e1872_waveforms_supplementary.hdf5
Learning rate: 9.159964277757025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1873 [0/90000 (0%)]	Loss: -6.2699	Cost: 30.72s
Train Epoch: 1873 [20480/90000 (23%)]	Loss: -11.1786	Cost: 8.47s
Train Epoch: 1873 [40960/90000 (45%)]	Loss: -11.6382	Cost: 11.85s
Train Epoch: 1873 [61440/90000 (68%)]	Loss: -11.5820	Cost: 6.48s
Train Epoch: 1873 [81920/90000 (91%)]	Loss: -11.4543	Cost: 13.65s
Train Epoch: 1873 	Average Loss: -11.0888
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8261

Learning rate: 9.159092616132876e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1874 [0/90000 (0%)]	Loss: -6.2488	Cost: 37.00s
Train Epoch: 1874 [20480/90000 (23%)]	Loss: -11.2776	Cost: 10.60s
Train Epoch: 1874 [40960/90000 (45%)]	Loss: -11.1030	Cost: 19.23s
Train Epoch: 1874 [61440/90000 (68%)]	Loss: -11.7975	Cost: 12.44s
Train Epoch: 1874 [81920/90000 (91%)]	Loss: -11.5829	Cost: 11.82s
Train Epoch: 1874 	Average Loss: -11.0648
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8766

Learning rate: 9.158220544022744e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1875 [0/90000 (0%)]	Loss: -5.5314	Cost: 45.39s
Train Epoch: 1875 [20480/90000 (23%)]	Loss: -11.1688	Cost: 6.24s
Train Epoch: 1875 [40960/90000 (45%)]	Loss: -11.3255	Cost: 13.22s
Train Epoch: 1875 [61440/90000 (68%)]	Loss: -11.7540	Cost: 8.76s
Train Epoch: 1875 [81920/90000 (91%)]	Loss: -11.5082	Cost: 9.02s
Train Epoch: 1875 	Average Loss: -11.1050
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9220

Saving model as e1875_model.pt & e1875_waveforms_supplementary.hdf5
Learning rate: 9.157348061512699e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1876 [0/90000 (0%)]	Loss: -6.2693	Cost: 29.95s
Train Epoch: 1876 [20480/90000 (23%)]	Loss: -11.4286	Cost: 10.54s
Train Epoch: 1876 [40960/90000 (45%)]	Loss: -11.5880	Cost: 17.24s
Train Epoch: 1876 [61440/90000 (68%)]	Loss: -11.9215	Cost: 12.44s
Train Epoch: 1876 [81920/90000 (91%)]	Loss: -11.5017	Cost: 11.86s
Train Epoch: 1876 	Average Loss: -11.2012
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8011

Learning rate: 9.156475168688847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1877 [0/90000 (0%)]	Loss: -5.8842	Cost: 43.76s
Train Epoch: 1877 [20480/90000 (23%)]	Loss: -11.5810	Cost: 6.34s
Train Epoch: 1877 [40960/90000 (45%)]	Loss: -11.6715	Cost: 13.73s
Train Epoch: 1877 [61440/90000 (68%)]	Loss: -12.0412	Cost: 9.02s
Train Epoch: 1877 [81920/90000 (91%)]	Loss: -11.7432	Cost: 10.68s
Train Epoch: 1877 	Average Loss: -11.3278
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0225

Saving model as e1877_model.pt & e1877_waveforms_supplementary.hdf5
Learning rate: 9.155601865637345e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1878 [0/90000 (0%)]	Loss: -6.6083	Cost: 26.37s
Train Epoch: 1878 [20480/90000 (23%)]	Loss: -11.5426	Cost: 9.35s
Train Epoch: 1878 [40960/90000 (45%)]	Loss: -11.2893	Cost: 23.93s
Train Epoch: 1878 [61440/90000 (68%)]	Loss: -11.8066	Cost: 13.48s
Train Epoch: 1878 [81920/90000 (91%)]	Loss: -11.6057	Cost: 12.11s
Train Epoch: 1878 	Average Loss: -11.1689
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7738

Learning rate: 9.154728152444381e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1879 [0/90000 (0%)]	Loss: -6.7498	Cost: 44.90s
Train Epoch: 1879 [20480/90000 (23%)]	Loss: -11.1250	Cost: 9.72s
Train Epoch: 1879 [40960/90000 (45%)]	Loss: -11.3928	Cost: 11.99s
Train Epoch: 1879 [61440/90000 (68%)]	Loss: -11.6758	Cost: 8.66s
Train Epoch: 1879 [81920/90000 (91%)]	Loss: -11.3018	Cost: 9.92s
Train Epoch: 1879 	Average Loss: -11.0190
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7771

Learning rate: 9.153854029196186e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1880 [0/90000 (0%)]	Loss: -5.4047	Cost: 35.08s
Train Epoch: 1880 [20480/90000 (23%)]	Loss: -11.0478	Cost: 7.56s
Train Epoch: 1880 [40960/90000 (45%)]	Loss: -11.3974	Cost: 18.17s
Train Epoch: 1880 [61440/90000 (68%)]	Loss: -11.6606	Cost: 11.88s
Train Epoch: 1880 [81920/90000 (91%)]	Loss: -11.5396	Cost: 12.07s
Train Epoch: 1880 	Average Loss: -11.0332
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7892

Learning rate: 9.152979495979036e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1881 [0/90000 (0%)]	Loss: -6.2377	Cost: 49.79s
Train Epoch: 1881 [20480/90000 (23%)]	Loss: -11.2557	Cost: 6.16s
Train Epoch: 1881 [40960/90000 (45%)]	Loss: -11.3220	Cost: 15.06s
Train Epoch: 1881 [61440/90000 (68%)]	Loss: -11.6888	Cost: 8.91s
Train Epoch: 1881 [81920/90000 (91%)]	Loss: -11.6796	Cost: 8.77s
Train Epoch: 1881 	Average Loss: -11.1519
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8628

Learning rate: 9.152104552879241e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1882 [0/90000 (0%)]	Loss: -6.6541	Cost: 31.52s
Train Epoch: 1882 [20480/90000 (23%)]	Loss: -11.0736	Cost: 7.82s
Train Epoch: 1882 [40960/90000 (45%)]	Loss: -11.2675	Cost: 16.20s
Train Epoch: 1882 [61440/90000 (68%)]	Loss: -11.7799	Cost: 12.11s
Train Epoch: 1882 [81920/90000 (91%)]	Loss: -11.4348	Cost: 12.07s
Train Epoch: 1882 	Average Loss: -10.9972
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7575

Learning rate: 9.151229199983157e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1883 [0/90000 (0%)]	Loss: -6.5612	Cost: 32.87s
Train Epoch: 1883 [20480/90000 (23%)]	Loss: -11.3300	Cost: 11.77s
Train Epoch: 1883 [40960/90000 (45%)]	Loss: -11.0149	Cost: 7.12s
Train Epoch: 1883 [61440/90000 (68%)]	Loss: -11.3788	Cost: 6.28s
Train Epoch: 1883 [81920/90000 (91%)]	Loss: -11.2687	Cost: 12.65s
Train Epoch: 1883 	Average Loss: -10.9108
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8779

Learning rate: 9.150353437377176e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1884 [0/90000 (0%)]	Loss: -6.4767	Cost: 28.35s
Train Epoch: 1884 [20480/90000 (23%)]	Loss: -11.3533	Cost: 9.26s
Train Epoch: 1884 [40960/90000 (45%)]	Loss: -11.5889	Cost: 23.58s
Train Epoch: 1884 [61440/90000 (68%)]	Loss: -11.8580	Cost: 12.44s
Train Epoch: 1884 [81920/90000 (91%)]	Loss: -11.5230	Cost: 12.52s
Train Epoch: 1884 	Average Loss: -11.1401
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9137

Learning rate: 9.149477265147733e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1885 [0/90000 (0%)]	Loss: -6.4788	Cost: 52.73s
Train Epoch: 1885 [20480/90000 (23%)]	Loss: -11.3439	Cost: 12.18s
Train Epoch: 1885 [40960/90000 (45%)]	Loss: -10.0634	Cost: 6.64s
Train Epoch: 1885 [61440/90000 (68%)]	Loss: -10.4069	Cost: 6.51s
Train Epoch: 1885 [81920/90000 (91%)]	Loss: -10.3204	Cost: 11.96s
Train Epoch: 1885 	Average Loss: -10.2112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.1403

Learning rate: 9.148600683381301e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1886 [0/90000 (0%)]	Loss: -5.8509	Cost: 25.91s
Train Epoch: 1886 [20480/90000 (23%)]	Loss: -10.6011	Cost: 7.48s
Train Epoch: 1886 [40960/90000 (45%)]	Loss: -11.1866	Cost: 20.00s
Train Epoch: 1886 [61440/90000 (68%)]	Loss: -11.6219	Cost: 12.98s
Train Epoch: 1886 [81920/90000 (91%)]	Loss: -11.2254	Cost: 12.03s
Train Epoch: 1886 	Average Loss: -10.6817
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6481

Learning rate: 9.147723692164398e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1887 [0/90000 (0%)]	Loss: -6.4559	Cost: 50.49s
Train Epoch: 1887 [20480/90000 (23%)]	Loss: -11.1879	Cost: 11.92s
Train Epoch: 1887 [40960/90000 (45%)]	Loss: -11.5466	Cost: 7.18s
Train Epoch: 1887 [61440/90000 (68%)]	Loss: -11.7717	Cost: 6.31s
Train Epoch: 1887 [81920/90000 (91%)]	Loss: -11.7262	Cost: 14.67s
Train Epoch: 1887 	Average Loss: -11.1640
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3186

Learning rate: 9.146846291583579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1888 [0/90000 (0%)]	Loss: -5.8547	Cost: 25.71s
Train Epoch: 1888 [20480/90000 (23%)]	Loss: -10.5570	Cost: 7.87s
Train Epoch: 1888 [40960/90000 (45%)]	Loss: -10.8818	Cost: 24.46s
Train Epoch: 1888 [61440/90000 (68%)]	Loss: -11.3768	Cost: 13.73s
Train Epoch: 1888 [81920/90000 (91%)]	Loss: -11.4036	Cost: 12.77s
Train Epoch: 1888 	Average Loss: -10.6533
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8365

Learning rate: 9.145968481725437e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1889 [0/90000 (0%)]	Loss: -6.5865	Cost: 43.60s
Train Epoch: 1889 [20480/90000 (23%)]	Loss: -11.0435	Cost: 10.02s
Train Epoch: 1889 [40960/90000 (45%)]	Loss: -11.1853	Cost: 9.75s
Train Epoch: 1889 [61440/90000 (68%)]	Loss: -11.6361	Cost: 7.91s
Train Epoch: 1889 [81920/90000 (91%)]	Loss: -11.4983	Cost: 13.94s
Train Epoch: 1889 	Average Loss: -11.0259
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1221

Saving model as e1889_model.pt & e1889_waveforms_supplementary.hdf5
Learning rate: 9.145090262676614e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1890 [0/90000 (0%)]	Loss: -6.5233	Cost: 31.23s
Train Epoch: 1890 [20480/90000 (23%)]	Loss: -11.3552	Cost: 10.08s
Train Epoch: 1890 [40960/90000 (45%)]	Loss: -11.6378	Cost: 13.85s
Train Epoch: 1890 [61440/90000 (68%)]	Loss: -11.8681	Cost: 12.52s
Train Epoch: 1890 [81920/90000 (91%)]	Loss: -11.6930	Cost: 12.20s
Train Epoch: 1890 	Average Loss: -11.3090
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0835

Learning rate: 9.144211634523782e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1891 [0/90000 (0%)]	Loss: -6.1104	Cost: 43.42s
Train Epoch: 1891 [20480/90000 (23%)]	Loss: -11.6773	Cost: 6.24s
Train Epoch: 1891 [40960/90000 (45%)]	Loss: -11.7202	Cost: 15.26s
Train Epoch: 1891 [61440/90000 (68%)]	Loss: -12.0816	Cost: 8.77s
Train Epoch: 1891 [81920/90000 (91%)]	Loss: -11.9169	Cost: 11.13s
Train Epoch: 1891 	Average Loss: -11.3455
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1395

Saving model as e1891_model.pt & e1891_waveforms_supplementary.hdf5
Learning rate: 9.143332597353658e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1892 [0/90000 (0%)]	Loss: -6.8367	Cost: 28.81s
Train Epoch: 1892 [20480/90000 (23%)]	Loss: -11.2929	Cost: 10.03s
Train Epoch: 1892 [40960/90000 (45%)]	Loss: -11.4142	Cost: 14.89s
Train Epoch: 1892 [61440/90000 (68%)]	Loss: -11.6000	Cost: 12.32s
Train Epoch: 1892 [81920/90000 (91%)]	Loss: -11.5233	Cost: 12.46s
Train Epoch: 1892 	Average Loss: -11.1490
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7994

Learning rate: 9.142453151253003e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1893 [0/90000 (0%)]	Loss: -6.3999	Cost: 33.46s
Train Epoch: 1893 [20480/90000 (23%)]	Loss: -11.1878	Cost: 8.70s
Train Epoch: 1893 [40960/90000 (45%)]	Loss: -11.0536	Cost: 8.63s
Train Epoch: 1893 [61440/90000 (68%)]	Loss: -11.4803	Cost: 8.05s
Train Epoch: 1893 [81920/90000 (91%)]	Loss: -11.2897	Cost: 15.34s
Train Epoch: 1893 	Average Loss: -10.9763
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5443

Learning rate: 9.141573296308612e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1894 [0/90000 (0%)]	Loss: -6.3533	Cost: 31.00s
Train Epoch: 1894 [20480/90000 (23%)]	Loss: -10.9525	Cost: 10.39s
Train Epoch: 1894 [40960/90000 (45%)]	Loss: -11.3212	Cost: 22.24s
Train Epoch: 1894 [61440/90000 (68%)]	Loss: -11.8636	Cost: 12.21s
Train Epoch: 1894 [81920/90000 (91%)]	Loss: -11.7853	Cost: 11.86s
Train Epoch: 1894 	Average Loss: -11.1021
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0838

Learning rate: 9.140693032607324e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1895 [0/90000 (0%)]	Loss: -5.8940	Cost: 43.51s
Train Epoch: 1895 [20480/90000 (23%)]	Loss: -10.9176	Cost: 6.26s
Train Epoch: 1895 [40960/90000 (45%)]	Loss: -11.2943	Cost: 12.71s
Train Epoch: 1895 [61440/90000 (68%)]	Loss: -11.6632	Cost: 8.77s
Train Epoch: 1895 [81920/90000 (91%)]	Loss: -11.6629	Cost: 9.98s
Train Epoch: 1895 	Average Loss: -10.9412
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9773

Learning rate: 9.139812360236018e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1896 [0/90000 (0%)]	Loss: -6.7342	Cost: 27.42s
Train Epoch: 1896 [20480/90000 (23%)]	Loss: -11.4005	Cost: 10.04s
Train Epoch: 1896 [40960/90000 (45%)]	Loss: -11.5705	Cost: 18.20s
Train Epoch: 1896 [61440/90000 (68%)]	Loss: -12.0060	Cost: 12.18s
Train Epoch: 1896 [81920/90000 (91%)]	Loss: -11.8728	Cost: 11.81s
Train Epoch: 1896 	Average Loss: -11.2878
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0250

Learning rate: 9.13893127928161e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1897 [0/90000 (0%)]	Loss: -6.6925	Cost: 37.53s
Train Epoch: 1897 [20480/90000 (23%)]	Loss: -11.3121	Cost: 11.76s
Train Epoch: 1897 [40960/90000 (45%)]	Loss: -11.6099	Cost: 7.44s
Train Epoch: 1897 [61440/90000 (68%)]	Loss: -11.8367	Cost: 6.52s
Train Epoch: 1897 [81920/90000 (91%)]	Loss: -11.7846	Cost: 13.66s
Train Epoch: 1897 	Average Loss: -11.3504
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1440

Saving model as e1897_model.pt & e1897_waveforms_supplementary.hdf5
Learning rate: 9.138049789831064e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1898 [0/90000 (0%)]	Loss: -6.0602	Cost: 33.36s
Train Epoch: 1898 [20480/90000 (23%)]	Loss: -11.5554	Cost: 9.54s
Train Epoch: 1898 [40960/90000 (45%)]	Loss: -11.7613	Cost: 22.88s
Train Epoch: 1898 [61440/90000 (68%)]	Loss: -11.8840	Cost: 11.75s
Train Epoch: 1898 [81920/90000 (91%)]	Loss: -11.9239	Cost: 11.81s
Train Epoch: 1898 	Average Loss: -11.3644
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0260

Learning rate: 9.137167891971379e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1899 [0/90000 (0%)]	Loss: -6.9170	Cost: 54.65s
Train Epoch: 1899 [20480/90000 (23%)]	Loss: -11.5051	Cost: 6.06s
Train Epoch: 1899 [40960/90000 (45%)]	Loss: -11.5497	Cost: 12.96s
Train Epoch: 1899 [61440/90000 (68%)]	Loss: -11.0077	Cost: 8.80s
Train Epoch: 1899 [81920/90000 (91%)]	Loss: -10.9185	Cost: 9.34s
Train Epoch: 1899 	Average Loss: -10.9055
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3425

Learning rate: 9.13628558578959e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1900 [0/90000 (0%)]	Loss: -5.8551	Cost: 26.37s
Train Epoch: 1900 [20480/90000 (23%)]	Loss: -11.0993	Cost: 8.22s
Train Epoch: 1900 [40960/90000 (45%)]	Loss: -11.1083	Cost: 16.48s
Train Epoch: 1900 [61440/90000 (68%)]	Loss: -11.5570	Cost: 12.17s
Train Epoch: 1900 [81920/90000 (91%)]	Loss: -11.5591	Cost: 12.22s
Train Epoch: 1900 	Average Loss: -10.9048
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8081

Learning rate: 9.13540287137278e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1901 [0/90000 (0%)]	Loss: -5.3799	Cost: 38.85s
Train Epoch: 1901 [20480/90000 (23%)]	Loss: -11.2287	Cost: 10.46s
Train Epoch: 1901 [40960/90000 (45%)]	Loss: -11.3860	Cost: 8.02s
Train Epoch: 1901 [61440/90000 (68%)]	Loss: -11.7705	Cost: 7.10s
Train Epoch: 1901 [81920/90000 (91%)]	Loss: -11.6777	Cost: 15.09s
Train Epoch: 1901 	Average Loss: -11.1028
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0324

Learning rate: 9.134519748808071e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1902 [0/90000 (0%)]	Loss: -6.6100	Cost: 29.95s
Train Epoch: 1902 [20480/90000 (23%)]	Loss: -11.6396	Cost: 9.74s
Train Epoch: 1902 [40960/90000 (45%)]	Loss: -11.6450	Cost: 22.25s
Train Epoch: 1902 [61440/90000 (68%)]	Loss: -12.0926	Cost: 12.18s
Train Epoch: 1902 [81920/90000 (91%)]	Loss: -11.6842	Cost: 11.73s
Train Epoch: 1902 	Average Loss: -11.4095
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9151

Learning rate: 9.133636218182622e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1903 [0/90000 (0%)]	Loss: -6.1257	Cost: 38.22s
Train Epoch: 1903 [20480/90000 (23%)]	Loss: -11.3775	Cost: 12.12s
Train Epoch: 1903 [40960/90000 (45%)]	Loss: -11.7421	Cost: 7.26s
Train Epoch: 1903 [61440/90000 (68%)]	Loss: -11.8766	Cost: 6.35s
Train Epoch: 1903 [81920/90000 (91%)]	Loss: -11.6459	Cost: 14.45s
Train Epoch: 1903 	Average Loss: -11.2842
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8438

Learning rate: 9.132752279583634e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1904 [0/90000 (0%)]	Loss: -6.4415	Cost: 33.10s
Train Epoch: 1904 [20480/90000 (23%)]	Loss: -11.0301	Cost: 6.78s
Train Epoch: 1904 [40960/90000 (45%)]	Loss: -11.3699	Cost: 17.22s
Train Epoch: 1904 [61440/90000 (68%)]	Loss: -11.9106	Cost: 12.67s
Train Epoch: 1904 [81920/90000 (91%)]	Loss: -11.7260	Cost: 11.68s
Train Epoch: 1904 	Average Loss: -11.2197
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9746

Learning rate: 9.13186793309835e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1905 [0/90000 (0%)]	Loss: -6.8155	Cost: 33.51s
Train Epoch: 1905 [20480/90000 (23%)]	Loss: -11.5716	Cost: 12.84s
Train Epoch: 1905 [40960/90000 (45%)]	Loss: -11.0378	Cost: 12.22s
Train Epoch: 1905 [61440/90000 (68%)]	Loss: -11.4663	Cost: 8.44s
Train Epoch: 1905 [81920/90000 (91%)]	Loss: -11.3174	Cost: 6.45s
Train Epoch: 1905 	Average Loss: -11.0045
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6219

Learning rate: 9.130983178814048e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1906 [0/90000 (0%)]	Loss: -6.3411	Cost: 30.73s
Train Epoch: 1906 [20480/90000 (23%)]	Loss: -11.1452	Cost: 6.64s
Train Epoch: 1906 [40960/90000 (45%)]	Loss: -11.4622	Cost: 14.87s
Train Epoch: 1906 [61440/90000 (68%)]	Loss: -11.9175	Cost: 13.34s
Train Epoch: 1906 [81920/90000 (91%)]	Loss: -11.3363	Cost: 12.59s
Train Epoch: 1906 	Average Loss: -11.0872
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7917

Learning rate: 9.130098016818053e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1907 [0/90000 (0%)]	Loss: -6.6382	Cost: 41.78s
Train Epoch: 1907 [20480/90000 (23%)]	Loss: -11.3627	Cost: 12.95s
Train Epoch: 1907 [40960/90000 (45%)]	Loss: -11.6292	Cost: 12.14s
Train Epoch: 1907 [61440/90000 (68%)]	Loss: -11.9670	Cost: 11.08s
Train Epoch: 1907 [81920/90000 (91%)]	Loss: -11.5555	Cost: 6.11s
Train Epoch: 1907 	Average Loss: -11.2400
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8232

Learning rate: 9.129212447197726e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1908 [0/90000 (0%)]	Loss: -5.9886	Cost: 31.68s
Train Epoch: 1908 [20480/90000 (23%)]	Loss: -11.2258	Cost: 8.84s
Train Epoch: 1908 [40960/90000 (45%)]	Loss: -11.4891	Cost: 9.70s
Train Epoch: 1908 [61440/90000 (68%)]	Loss: -11.9168	Cost: 7.83s
Train Epoch: 1908 [81920/90000 (91%)]	Loss: -11.7246	Cost: 17.62s
Train Epoch: 1908 	Average Loss: -11.1113
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0033

Learning rate: 9.128326470040468e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1909 [0/90000 (0%)]	Loss: -6.5435	Cost: 45.85s
Train Epoch: 1909 [20480/90000 (23%)]	Loss: -11.4245	Cost: 12.45s
Train Epoch: 1909 [40960/90000 (45%)]	Loss: -11.7544	Cost: 12.32s
Train Epoch: 1909 [61440/90000 (68%)]	Loss: -11.7084	Cost: 11.87s
Train Epoch: 1909 [81920/90000 (91%)]	Loss: -11.4142	Cost: 9.16s
Train Epoch: 1909 	Average Loss: -11.2557
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8618

Learning rate: 9.127440085433723e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1910 [0/90000 (0%)]	Loss: -6.0605	Cost: 28.24s
Train Epoch: 1910 [20480/90000 (23%)]	Loss: -11.4284	Cost: 7.77s
Train Epoch: 1910 [40960/90000 (45%)]	Loss: -11.3883	Cost: 11.02s
Train Epoch: 1910 [61440/90000 (68%)]	Loss: -11.1117	Cost: 8.83s
Train Epoch: 1910 [81920/90000 (91%)]	Loss: -10.9027	Cost: 8.74s
Train Epoch: 1910 	Average Loss: -10.9049
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.3928

Learning rate: 9.126553293464973e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1911 [0/90000 (0%)]	Loss: -6.2338	Cost: 30.88s
Train Epoch: 1911 [20480/90000 (23%)]	Loss: -10.9384	Cost: 11.83s
Train Epoch: 1911 [40960/90000 (45%)]	Loss: -10.9817	Cost: 22.55s
Train Epoch: 1911 [61440/90000 (68%)]	Loss: -11.6790	Cost: 12.09s
Train Epoch: 1911 [81920/90000 (91%)]	Loss: -11.3527	Cost: 11.93s
Train Epoch: 1911 	Average Loss: -10.8274
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.4495

Learning rate: 9.125666094221739e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1912 [0/90000 (0%)]	Loss: -6.3088	Cost: 38.84s
Train Epoch: 1912 [20480/90000 (23%)]	Loss: -10.7120	Cost: 10.89s
Train Epoch: 1912 [40960/90000 (45%)]	Loss: -11.1090	Cost: 8.19s
Train Epoch: 1912 [61440/90000 (68%)]	Loss: -11.5264	Cost: 6.96s
Train Epoch: 1912 [81920/90000 (91%)]	Loss: -11.4670	Cost: 12.80s
Train Epoch: 1912 	Average Loss: -10.7999
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7708

Learning rate: 9.124778487791588e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1913 [0/90000 (0%)]	Loss: -6.3330	Cost: 35.99s
Train Epoch: 1913 [20480/90000 (23%)]	Loss: -11.3466	Cost: 8.21s
Train Epoch: 1913 [40960/90000 (45%)]	Loss: -11.6443	Cost: 18.42s
Train Epoch: 1913 [61440/90000 (68%)]	Loss: -12.0205	Cost: 13.25s
Train Epoch: 1913 [81920/90000 (91%)]	Loss: -11.8765	Cost: 12.31s
Train Epoch: 1913 	Average Loss: -11.3127
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9981

Learning rate: 9.12389047426212e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1914 [0/90000 (0%)]	Loss: -5.9691	Cost: 48.97s
Train Epoch: 1914 [20480/90000 (23%)]	Loss: -11.5471	Cost: 7.45s
Train Epoch: 1914 [40960/90000 (45%)]	Loss: -11.5538	Cost: 10.66s
Train Epoch: 1914 [61440/90000 (68%)]	Loss: -12.0319	Cost: 8.69s
Train Epoch: 1914 [81920/90000 (91%)]	Loss: -11.7967	Cost: 9.41s
Train Epoch: 1914 	Average Loss: -11.3151
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9338

Learning rate: 9.12300205372098e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1915 [0/90000 (0%)]	Loss: -6.9204	Cost: 28.15s
Train Epoch: 1915 [20480/90000 (23%)]	Loss: -11.3762	Cost: 6.53s
Train Epoch: 1915 [40960/90000 (45%)]	Loss: -11.3998	Cost: 17.59s
Train Epoch: 1915 [61440/90000 (68%)]	Loss: -11.8541	Cost: 13.69s
Train Epoch: 1915 [81920/90000 (91%)]	Loss: -11.7087	Cost: 12.46s
Train Epoch: 1915 	Average Loss: -11.2642
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9332

Learning rate: 9.12211322625585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1916 [0/90000 (0%)]	Loss: -6.4701	Cost: 34.32s
Train Epoch: 1916 [20480/90000 (23%)]	Loss: -11.5537	Cost: 10.71s
Train Epoch: 1916 [40960/90000 (45%)]	Loss: -11.7988	Cost: 11.18s
Train Epoch: 1916 [61440/90000 (68%)]	Loss: -12.1039	Cost: 8.61s
Train Epoch: 1916 [81920/90000 (91%)]	Loss: -11.6149	Cost: 13.79s
Train Epoch: 1916 	Average Loss: -11.4265
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8605

Learning rate: 9.121223991954458e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1917 [0/90000 (0%)]	Loss: -6.0734	Cost: 38.94s
Train Epoch: 1917 [20480/90000 (23%)]	Loss: -11.5711	Cost: 8.59s
Train Epoch: 1917 [40960/90000 (45%)]	Loss: -11.0439	Cost: 16.33s
Train Epoch: 1917 [61440/90000 (68%)]	Loss: -11.0993	Cost: 12.01s
Train Epoch: 1917 [81920/90000 (91%)]	Loss: -11.2185	Cost: 12.04s
Train Epoch: 1917 	Average Loss: -10.9890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7345

Learning rate: 9.120334350904563e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1918 [0/90000 (0%)]	Loss: -6.5433	Cost: 52.07s
Train Epoch: 1918 [20480/90000 (23%)]	Loss: -11.3780	Cost: 6.47s
Train Epoch: 1918 [40960/90000 (45%)]	Loss: -11.4723	Cost: 13.46s
Train Epoch: 1918 [61440/90000 (68%)]	Loss: -11.9526	Cost: 8.68s
Train Epoch: 1918 [81920/90000 (91%)]	Loss: -11.6000	Cost: 11.13s
Train Epoch: 1918 	Average Loss: -11.3003
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1100

Learning rate: 9.11944430319397e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1919 [0/90000 (0%)]	Loss: -6.5668	Cost: 30.70s
Train Epoch: 1919 [20480/90000 (23%)]	Loss: -11.5830	Cost: 7.99s
Train Epoch: 1919 [40960/90000 (45%)]	Loss: -11.5219	Cost: 16.93s
Train Epoch: 1919 [61440/90000 (68%)]	Loss: -11.9606	Cost: 12.07s
Train Epoch: 1919 [81920/90000 (91%)]	Loss: -11.2957	Cost: 12.45s
Train Epoch: 1919 	Average Loss: -11.2507
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2446

Learning rate: 9.118553848910525e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1920 [0/90000 (0%)]	Loss: -5.3690	Cost: 36.00s
Train Epoch: 1920 [20480/90000 (23%)]	Loss: -10.9696	Cost: 9.24s
Train Epoch: 1920 [40960/90000 (45%)]	Loss: -11.2083	Cost: 8.00s
Train Epoch: 1920 [61440/90000 (68%)]	Loss: -11.6805	Cost: 9.54s
Train Epoch: 1920 [81920/90000 (91%)]	Loss: -10.7125	Cost: 13.63s
Train Epoch: 1920 	Average Loss: -10.7192
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0627

Learning rate: 9.11766298814211e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1921 [0/90000 (0%)]	Loss: -5.3922	Cost: 31.65s
Train Epoch: 1921 [20480/90000 (23%)]	Loss: -10.8080	Cost: 10.26s
Train Epoch: 1921 [40960/90000 (45%)]	Loss: -11.2233	Cost: 22.97s
Train Epoch: 1921 [61440/90000 (68%)]	Loss: -11.6706	Cost: 12.08s
Train Epoch: 1921 [81920/90000 (91%)]	Loss: -11.6136	Cost: 12.08s
Train Epoch: 1921 	Average Loss: -10.9033
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6819

Learning rate: 9.116771720976654e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1922 [0/90000 (0%)]	Loss: -6.2381	Cost: 51.15s
Train Epoch: 1922 [20480/90000 (23%)]	Loss: -11.3351	Cost: 6.74s
Train Epoch: 1922 [40960/90000 (45%)]	Loss: -11.6942	Cost: 11.32s
Train Epoch: 1922 [61440/90000 (68%)]	Loss: -12.0297	Cost: 8.87s
Train Epoch: 1922 [81920/90000 (91%)]	Loss: -11.7723	Cost: 11.59s
Train Epoch: 1922 	Average Loss: -11.3723
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.5693

Learning rate: 9.115880047502117e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1923 [0/90000 (0%)]	Loss: -6.6738	Cost: 28.16s
Train Epoch: 1923 [20480/90000 (23%)]	Loss: -10.4973	Cost: 9.74s
Train Epoch: 1923 [40960/90000 (45%)]	Loss: -10.8128	Cost: 22.08s
Train Epoch: 1923 [61440/90000 (68%)]	Loss: -11.3280	Cost: 12.30s
Train Epoch: 1923 [81920/90000 (91%)]	Loss: -11.2016	Cost: 12.25s
Train Epoch: 1923 	Average Loss: -10.6553
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8457

Learning rate: 9.114987967806504e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1924 [0/90000 (0%)]	Loss: -6.7461	Cost: 35.27s
Train Epoch: 1924 [20480/90000 (23%)]	Loss: -11.2475	Cost: 6.66s
Train Epoch: 1924 [40960/90000 (45%)]	Loss: -11.5966	Cost: 13.63s
Train Epoch: 1924 [61440/90000 (68%)]	Loss: -12.0549	Cost: 8.93s
Train Epoch: 1924 [81920/90000 (91%)]	Loss: -11.6571	Cost: 10.85s
Train Epoch: 1924 	Average Loss: -11.2645
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0070

Learning rate: 9.114095481977862e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1925 [0/90000 (0%)]	Loss: -6.9727	Cost: 26.09s
Train Epoch: 1925 [20480/90000 (23%)]	Loss: -11.7113	Cost: 7.07s
Train Epoch: 1925 [40960/90000 (45%)]	Loss: -11.9543	Cost: 22.81s
Train Epoch: 1925 [61440/90000 (68%)]	Loss: -12.1629	Cost: 14.09s
Train Epoch: 1925 [81920/90000 (91%)]	Loss: -11.9925	Cost: 13.22s
Train Epoch: 1925 	Average Loss: -11.5088
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2061

Saving model as e1925_model.pt & e1925_waveforms_supplementary.hdf5
Learning rate: 9.113202590104274e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1926 [0/90000 (0%)]	Loss: -7.1590	Cost: 51.16s
Train Epoch: 1926 [20480/90000 (23%)]	Loss: -11.7461	Cost: 6.45s
Train Epoch: 1926 [40960/90000 (45%)]	Loss: -11.8293	Cost: 14.42s
Train Epoch: 1926 [61440/90000 (68%)]	Loss: -12.1212	Cost: 8.61s
Train Epoch: 1926 [81920/90000 (91%)]	Loss: -12.1324	Cost: 9.43s
Train Epoch: 1926 	Average Loss: -11.5920
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0898

Learning rate: 9.112309292273865e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1927 [0/90000 (0%)]	Loss: -6.4196	Cost: 31.21s
Train Epoch: 1927 [20480/90000 (23%)]	Loss: -11.7984	Cost: 6.75s
Train Epoch: 1927 [40960/90000 (45%)]	Loss: -12.0156	Cost: 18.60s
Train Epoch: 1927 [61440/90000 (68%)]	Loss: -12.4632	Cost: 12.00s
Train Epoch: 1927 [81920/90000 (91%)]	Loss: -12.1490	Cost: 11.84s
Train Epoch: 1927 	Average Loss: -11.6911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3521

Saving model as e1927_model.pt & e1927_waveforms_supplementary.hdf5
Learning rate: 9.111415588574802e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1928 [0/90000 (0%)]	Loss: -6.7391	Cost: 38.39s
Train Epoch: 1928 [20480/90000 (23%)]	Loss: -11.8997	Cost: 12.15s
Train Epoch: 1928 [40960/90000 (45%)]	Loss: -11.2779	Cost: 7.40s
Train Epoch: 1928 [61440/90000 (68%)]	Loss: -11.6304	Cost: 6.32s
Train Epoch: 1928 [81920/90000 (91%)]	Loss: -11.5341	Cost: 13.38s
Train Epoch: 1928 	Average Loss: -11.2928
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8776

Learning rate: 9.110521479095288e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1929 [0/90000 (0%)]	Loss: -6.5147	Cost: 27.49s
Train Epoch: 1929 [20480/90000 (23%)]	Loss: -11.5298	Cost: 6.26s
Train Epoch: 1929 [40960/90000 (45%)]	Loss: -11.8289	Cost: 13.10s
Train Epoch: 1929 [61440/90000 (68%)]	Loss: -12.3086	Cost: 11.52s
Train Epoch: 1929 [81920/90000 (91%)]	Loss: -11.9124	Cost: 17.34s
Train Epoch: 1929 	Average Loss: -11.4924
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0888

Learning rate: 9.109626963923566e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1930 [0/90000 (0%)]	Loss: -6.8941	Cost: 38.84s
Train Epoch: 1930 [20480/90000 (23%)]	Loss: -11.6978	Cost: 10.60s
Train Epoch: 1930 [40960/90000 (45%)]	Loss: -11.8820	Cost: 10.42s
Train Epoch: 1930 [61440/90000 (68%)]	Loss: -12.0524	Cost: 8.78s
Train Epoch: 1930 [81920/90000 (91%)]	Loss: -11.7114	Cost: 12.53s
Train Epoch: 1930 	Average Loss: -11.4456
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9761

Learning rate: 9.108732043147926e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1931 [0/90000 (0%)]	Loss: -7.0240	Cost: 38.77s
Train Epoch: 1931 [20480/90000 (23%)]	Loss: -11.4780	Cost: 8.55s
Train Epoch: 1931 [40960/90000 (45%)]	Loss: -12.1344	Cost: 16.47s
Train Epoch: 1931 [61440/90000 (68%)]	Loss: -12.0621	Cost: 12.17s
Train Epoch: 1931 [81920/90000 (91%)]	Loss: -12.0526	Cost: 12.11s
Train Epoch: 1931 	Average Loss: -11.4846
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0086

Learning rate: 9.10783671685669e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1932 [0/90000 (0%)]	Loss: -7.1028	Cost: 35.76s
Train Epoch: 1932 [20480/90000 (23%)]	Loss: -11.7524	Cost: 12.44s
Train Epoch: 1932 [40960/90000 (45%)]	Loss: -11.6316	Cost: 12.05s
Train Epoch: 1932 [61440/90000 (68%)]	Loss: -12.0461	Cost: 6.54s
Train Epoch: 1932 [81920/90000 (91%)]	Loss: -11.8057	Cost: 7.15s
Train Epoch: 1932 	Average Loss: -11.4938
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8384

Learning rate: 9.106940985138223e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1933 [0/90000 (0%)]	Loss: -6.5615	Cost: 33.49s
Train Epoch: 1933 [20480/90000 (23%)]	Loss: -11.5892	Cost: 6.36s
Train Epoch: 1933 [40960/90000 (45%)]	Loss: -11.1729	Cost: 16.35s
Train Epoch: 1933 [61440/90000 (68%)]	Loss: -11.7132	Cost: 13.27s
Train Epoch: 1933 [81920/90000 (91%)]	Loss: -10.4828	Cost: 12.76s
Train Epoch: 1933 	Average Loss: -10.9683
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0772

Learning rate: 9.106044848080932e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1934 [0/90000 (0%)]	Loss: -5.1632	Cost: 45.31s
Train Epoch: 1934 [20480/90000 (23%)]	Loss: -10.3022	Cost: 10.57s
Train Epoch: 1934 [40960/90000 (45%)]	Loss: -10.8070	Cost: 9.19s
Train Epoch: 1934 [61440/90000 (68%)]	Loss: -11.1826	Cost: 8.41s
Train Epoch: 1934 [81920/90000 (91%)]	Loss: -11.2076	Cost: 12.58s
Train Epoch: 1934 	Average Loss: -10.4684
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7114

Learning rate: 9.105148305773263e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1935 [0/90000 (0%)]	Loss: -6.3205	Cost: 35.34s
Train Epoch: 1935 [20480/90000 (23%)]	Loss: -11.3207	Cost: 8.87s
Train Epoch: 1935 [40960/90000 (45%)]	Loss: -11.6403	Cost: 10.30s
Train Epoch: 1935 [61440/90000 (68%)]	Loss: -11.9072	Cost: 6.48s
Train Epoch: 1935 [81920/90000 (91%)]	Loss: -11.6663	Cost: 19.95s
Train Epoch: 1935 	Average Loss: -11.1588
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8650

Learning rate: 9.104251358303697e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1936 [0/90000 (0%)]	Loss: -6.8731	Cost: 52.91s
Train Epoch: 1936 [20480/90000 (23%)]	Loss: -11.4642	Cost: 12.10s
Train Epoch: 1936 [40960/90000 (45%)]	Loss: -11.6183	Cost: 6.39s
Train Epoch: 1936 [61440/90000 (68%)]	Loss: -12.1838	Cost: 6.28s
Train Epoch: 1936 [81920/90000 (91%)]	Loss: -11.6197	Cost: 12.52s
Train Epoch: 1936 	Average Loss: -11.2936
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0579

Learning rate: 9.103354005760764e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1937 [0/90000 (0%)]	Loss: -6.3200	Cost: 29.43s
Train Epoch: 1937 [20480/90000 (23%)]	Loss: -11.4055	Cost: 10.63s
Train Epoch: 1937 [40960/90000 (45%)]	Loss: -11.6286	Cost: 14.76s
Train Epoch: 1937 [61440/90000 (68%)]	Loss: -12.0084	Cost: 12.86s
Train Epoch: 1937 [81920/90000 (91%)]	Loss: -11.7152	Cost: 13.99s
Train Epoch: 1937 	Average Loss: -11.3174
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9830

Learning rate: 9.102456248233025e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1938 [0/90000 (0%)]	Loss: -6.2448	Cost: 51.52s
Train Epoch: 1938 [20480/90000 (23%)]	Loss: -11.6167	Cost: 7.74s
Train Epoch: 1938 [40960/90000 (45%)]	Loss: -12.0109	Cost: 12.11s
Train Epoch: 1938 [61440/90000 (68%)]	Loss: -12.2032	Cost: 8.60s
Train Epoch: 1938 [81920/90000 (91%)]	Loss: -11.9062	Cost: 9.40s
Train Epoch: 1938 	Average Loss: -11.5371
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0293

Learning rate: 9.101558085809087e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1939 [0/90000 (0%)]	Loss: -6.2407	Cost: 30.82s
Train Epoch: 1939 [20480/90000 (23%)]	Loss: -11.8062	Cost: 7.23s
Train Epoch: 1939 [40960/90000 (45%)]	Loss: -11.7801	Cost: 18.60s
Train Epoch: 1939 [61440/90000 (68%)]	Loss: -12.1334	Cost: 13.26s
Train Epoch: 1939 [81920/90000 (91%)]	Loss: -11.8377	Cost: 12.10s
Train Epoch: 1939 	Average Loss: -11.4141
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -5.5251

Learning rate: 9.100659518577597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1940 [0/90000 (0%)]	Loss: -5.4997	Cost: 50.16s
Train Epoch: 1940 [20480/90000 (23%)]	Loss: -9.4718	Cost: 11.60s
Train Epoch: 1940 [40960/90000 (45%)]	Loss: -10.1046	Cost: 7.76s
Train Epoch: 1940 [61440/90000 (68%)]	Loss: -10.3577	Cost: 6.40s
Train Epoch: 1940 [81920/90000 (91%)]	Loss: -10.5354	Cost: 11.84s
Train Epoch: 1940 	Average Loss: -9.7569
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.2309

Learning rate: 9.099760546627236e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1941 [0/90000 (0%)]	Loss: -6.3090	Cost: 27.99s
Train Epoch: 1941 [20480/90000 (23%)]	Loss: -10.8200	Cost: 6.75s
Train Epoch: 1941 [40960/90000 (45%)]	Loss: -11.0771	Cost: 20.95s
Train Epoch: 1941 [61440/90000 (68%)]	Loss: -11.5462	Cost: 12.07s
Train Epoch: 1941 [81920/90000 (91%)]	Loss: -11.4729	Cost: 12.80s
Train Epoch: 1941 	Average Loss: -10.8690
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9261

Learning rate: 9.09886117004673e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1942 [0/90000 (0%)]	Loss: -6.5517	Cost: 35.73s
Train Epoch: 1942 [20480/90000 (23%)]	Loss: -11.3853	Cost: 13.20s
Train Epoch: 1942 [40960/90000 (45%)]	Loss: -11.8362	Cost: 10.23s
Train Epoch: 1942 [61440/90000 (68%)]	Loss: -11.8098	Cost: 7.27s
Train Epoch: 1942 [81920/90000 (91%)]	Loss: -11.6798	Cost: 12.63s
Train Epoch: 1942 	Average Loss: -11.2758
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0737

Learning rate: 9.097961388924847e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1943 [0/90000 (0%)]	Loss: -6.9587	Cost: 36.74s
Train Epoch: 1943 [20480/90000 (23%)]	Loss: -11.6244	Cost: 9.01s
Train Epoch: 1943 [40960/90000 (45%)]	Loss: -11.9069	Cost: 15.41s
Train Epoch: 1943 [61440/90000 (68%)]	Loss: -12.0289	Cost: 12.16s
Train Epoch: 1943 [81920/90000 (91%)]	Loss: -11.8959	Cost: 12.30s
Train Epoch: 1943 	Average Loss: -11.5135
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7551

Learning rate: 9.09706120335039e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1944 [0/90000 (0%)]	Loss: -6.9454	Cost: 46.76s
Train Epoch: 1944 [20480/90000 (23%)]	Loss: -10.9241	Cost: 11.90s
Train Epoch: 1944 [40960/90000 (45%)]	Loss: -11.0858	Cost: 7.76s
Train Epoch: 1944 [61440/90000 (68%)]	Loss: -11.6030	Cost: 6.66s
Train Epoch: 1944 [81920/90000 (91%)]	Loss: -11.3827	Cost: 13.46s
Train Epoch: 1944 	Average Loss: -10.9770
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8005

Learning rate: 9.096160613412202e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1945 [0/90000 (0%)]	Loss: -6.4583	Cost: 31.30s
Train Epoch: 1945 [20480/90000 (23%)]	Loss: -11.1216	Cost: 7.25s
Train Epoch: 1945 [40960/90000 (45%)]	Loss: -11.2639	Cost: 18.05s
Train Epoch: 1945 [61440/90000 (68%)]	Loss: -11.7588	Cost: 12.49s
Train Epoch: 1945 [81920/90000 (91%)]	Loss: -11.7636	Cost: 12.23s
Train Epoch: 1945 	Average Loss: -11.1014
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.7557

Learning rate: 9.095259619199171e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1946 [0/90000 (0%)]	Loss: -6.4621	Cost: 33.17s
Train Epoch: 1946 [20480/90000 (23%)]	Loss: -11.6158	Cost: 11.58s
Train Epoch: 1946 [40960/90000 (45%)]	Loss: -11.7310	Cost: 6.16s
Train Epoch: 1946 [61440/90000 (68%)]	Loss: -12.2850	Cost: 7.32s
Train Epoch: 1946 [81920/90000 (91%)]	Loss: -11.8536	Cost: 15.97s
Train Epoch: 1946 	Average Loss: -11.4515
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9562

Learning rate: 9.094358220800217e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1947 [0/90000 (0%)]	Loss: -6.6733	Cost: 38.84s
Train Epoch: 1947 [20480/90000 (23%)]	Loss: -11.2987	Cost: 11.62s
Train Epoch: 1947 [40960/90000 (45%)]	Loss: -11.5751	Cost: 18.82s
Train Epoch: 1947 [61440/90000 (68%)]	Loss: -12.0733	Cost: 12.24s
Train Epoch: 1947 [81920/90000 (91%)]	Loss: -11.9541	Cost: 12.06s
Train Epoch: 1947 	Average Loss: -11.4631
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2618

Learning rate: 9.09345641830431e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1948 [0/90000 (0%)]	Loss: -7.1039	Cost: 38.84s
Train Epoch: 1948 [20480/90000 (23%)]	Loss: -11.9784	Cost: 6.19s
Train Epoch: 1948 [40960/90000 (45%)]	Loss: -11.9933	Cost: 13.78s
Train Epoch: 1948 [61440/90000 (68%)]	Loss: -12.2349	Cost: 9.01s
Train Epoch: 1948 [81920/90000 (91%)]	Loss: -12.2252	Cost: 10.53s
Train Epoch: 1948 	Average Loss: -11.7291
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2996

Learning rate: 9.09255421180045e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1949 [0/90000 (0%)]	Loss: -7.0564	Cost: 27.70s
Train Epoch: 1949 [20480/90000 (23%)]	Loss: -11.9241	Cost: 9.66s
Train Epoch: 1949 [40960/90000 (45%)]	Loss: -11.8969	Cost: 16.00s
Train Epoch: 1949 [61440/90000 (68%)]	Loss: -12.0597	Cost: 12.75s
Train Epoch: 1949 [81920/90000 (91%)]	Loss: -11.8932	Cost: 12.07s
Train Epoch: 1949 	Average Loss: -11.6559
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0918

Learning rate: 9.091651601377684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1950 [0/90000 (0%)]	Loss: -6.8658	Cost: 48.76s
Train Epoch: 1950 [20480/90000 (23%)]	Loss: -11.6159	Cost: 6.81s
Train Epoch: 1950 [40960/90000 (45%)]	Loss: -11.9192	Cost: 11.78s
Train Epoch: 1950 [61440/90000 (68%)]	Loss: -12.2055	Cost: 8.82s
Train Epoch: 1950 [81920/90000 (91%)]	Loss: -11.9133	Cost: 11.09s
Train Epoch: 1950 	Average Loss: -11.4890
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0985

Learning rate: 9.090748587125094e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1951 [0/90000 (0%)]	Loss: -6.5764	Cost: 33.31s
Train Epoch: 1951 [20480/90000 (23%)]	Loss: -11.7465	Cost: 9.29s
Train Epoch: 1951 [40960/90000 (45%)]	Loss: -11.9075	Cost: 22.24s
Train Epoch: 1951 [61440/90000 (68%)]	Loss: -12.0818	Cost: 12.18s
Train Epoch: 1951 [81920/90000 (91%)]	Loss: -12.0278	Cost: 11.83s
Train Epoch: 1951 	Average Loss: -11.5774
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1176

Learning rate: 9.089845169131804e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1952 [0/90000 (0%)]	Loss: -6.8136	Cost: 43.17s
Train Epoch: 1952 [20480/90000 (23%)]	Loss: -11.8418	Cost: 7.34s
Train Epoch: 1952 [40960/90000 (45%)]	Loss: -11.9904	Cost: 10.60s
Train Epoch: 1952 [61440/90000 (68%)]	Loss: -12.2950	Cost: 8.11s
Train Epoch: 1952 [81920/90000 (91%)]	Loss: -12.0146	Cost: 9.65s
Train Epoch: 1952 	Average Loss: -11.6529
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.9835

Learning rate: 9.08894134748698e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1953 [0/90000 (0%)]	Loss: -6.4776	Cost: 28.40s
Train Epoch: 1953 [20480/90000 (23%)]	Loss: -10.7750	Cost: 6.80s
Train Epoch: 1953 [40960/90000 (45%)]	Loss: -10.7971	Cost: 17.91s
Train Epoch: 1953 [61440/90000 (68%)]	Loss: -11.2179	Cost: 13.39s
Train Epoch: 1953 [81920/90000 (91%)]	Loss: -11.0037	Cost: 12.48s
Train Epoch: 1953 	Average Loss: -10.6424
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.0721

Learning rate: 9.088037122279823e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1954 [0/90000 (0%)]	Loss: -6.0655	Cost: 35.12s
Train Epoch: 1954 [20480/90000 (23%)]	Loss: -10.5970	Cost: 11.83s
Train Epoch: 1954 [40960/90000 (45%)]	Loss: -10.6492	Cost: 10.41s
Train Epoch: 1954 [61440/90000 (68%)]	Loss: -11.1558	Cost: 6.43s
Train Epoch: 1954 [81920/90000 (91%)]	Loss: -11.4109	Cost: 10.88s
Train Epoch: 1954 	Average Loss: -10.5290
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6335

Learning rate: 9.087132493599577e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1955 [0/90000 (0%)]	Loss: -6.7941	Cost: 29.12s
Train Epoch: 1955 [20480/90000 (23%)]	Loss: -11.2323	Cost: 9.28s
Train Epoch: 1955 [40960/90000 (45%)]	Loss: -11.3980	Cost: 15.95s
Train Epoch: 1955 [61440/90000 (68%)]	Loss: -11.8563	Cost: 12.69s
Train Epoch: 1955 [81920/90000 (91%)]	Loss: -11.6458	Cost: 12.13s
Train Epoch: 1955 	Average Loss: -11.1780
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8213

Learning rate: 9.086227461535529e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1956 [0/90000 (0%)]	Loss: -6.5098	Cost: 33.99s
Train Epoch: 1956 [20480/90000 (23%)]	Loss: -11.5889	Cost: 13.06s
Train Epoch: 1956 [40960/90000 (45%)]	Loss: -11.5066	Cost: 12.39s
Train Epoch: 1956 [61440/90000 (68%)]	Loss: -11.6587	Cost: 12.48s
Train Epoch: 1956 [81920/90000 (91%)]	Loss: -11.6292	Cost: 6.61s
Train Epoch: 1956 	Average Loss: -11.1848
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.8164

Learning rate: 9.085322026176996e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1957 [0/90000 (0%)]	Loss: -6.5069	Cost: 42.81s
Train Epoch: 1957 [20480/90000 (23%)]	Loss: -11.3261	Cost: 6.72s
Train Epoch: 1957 [40960/90000 (45%)]	Loss: -11.5187	Cost: 13.27s
Train Epoch: 1957 [61440/90000 (68%)]	Loss: -11.6863	Cost: 8.47s
Train Epoch: 1957 [81920/90000 (91%)]	Loss: -11.6063	Cost: 8.02s
Train Epoch: 1957 	Average Loss: -11.1043
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.0588

Learning rate: 9.084416187613343e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1958 [0/90000 (0%)]	Loss: -7.2028	Cost: 29.42s
Train Epoch: 1958 [20480/90000 (23%)]	Loss: -11.6695	Cost: 8.31s
Train Epoch: 1958 [40960/90000 (45%)]	Loss: -11.8325	Cost: 16.42s
Train Epoch: 1958 [61440/90000 (68%)]	Loss: -11.8308	Cost: 12.11s
Train Epoch: 1958 [81920/90000 (91%)]	Loss: -11.3407	Cost: 12.47s
Train Epoch: 1958 	Average Loss: -11.2949
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -6.6802

Learning rate: 9.083509945933975e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1959 [0/90000 (0%)]	Loss: -6.5294	Cost: 31.99s
Train Epoch: 1959 [20480/90000 (23%)]	Loss: -11.1470	Cost: 10.81s
Train Epoch: 1959 [40960/90000 (45%)]	Loss: -11.1870	Cost: 9.31s
Train Epoch: 1959 [61440/90000 (68%)]	Loss: -11.7679	Cost: 7.52s
Train Epoch: 1959 [81920/90000 (91%)]	Loss: -11.6126	Cost: 13.67s
Train Epoch: 1959 	Average Loss: -10.9940
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1757

Learning rate: 9.082603301228332e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1960 [0/90000 (0%)]	Loss: -6.7799	Cost: 39.13s
Train Epoch: 1960 [20480/90000 (23%)]	Loss: -11.6571	Cost: 8.93s
Train Epoch: 1960 [40960/90000 (45%)]	Loss: -11.7679	Cost: 17.85s
Train Epoch: 1960 [61440/90000 (68%)]	Loss: -11.9199	Cost: 12.22s
Train Epoch: 1960 [81920/90000 (91%)]	Loss: -11.9309	Cost: 12.04s
Train Epoch: 1960 	Average Loss: -11.3911
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1530

Learning rate: 9.081696253585899e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1961 [0/90000 (0%)]	Loss: -6.4853	Cost: 34.33s
Train Epoch: 1961 [20480/90000 (23%)]	Loss: -11.4517	Cost: 7.50s
Train Epoch: 1961 [40960/90000 (45%)]	Loss: -11.7970	Cost: 12.62s
Train Epoch: 1961 [61440/90000 (68%)]	Loss: -11.1680	Cost: 8.79s
Train Epoch: 1961 [81920/90000 (91%)]	Loss: -11.5574	Cost: 11.80s
Train Epoch: 1961 	Average Loss: -11.0202
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1445

Learning rate: 9.080788803096196e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1962 [0/90000 (0%)]	Loss: -6.7688	Cost: 31.13s
Train Epoch: 1962 [20480/90000 (23%)]	Loss: -11.1575	Cost: 10.36s
Train Epoch: 1962 [40960/90000 (45%)]	Loss: -11.2560	Cost: 17.54s
Train Epoch: 1962 [61440/90000 (68%)]	Loss: -11.3720	Cost: 12.46s
Train Epoch: 1962 [81920/90000 (91%)]	Loss: -11.6643	Cost: 11.90s
Train Epoch: 1962 	Average Loss: -10.9963
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1128

Learning rate: 9.079880949848785e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1963 [0/90000 (0%)]	Loss: -6.6349	Cost: 36.15s
Train Epoch: 1963 [20480/90000 (23%)]	Loss: -11.3089	Cost: 12.19s
Train Epoch: 1963 [40960/90000 (45%)]	Loss: -11.6783	Cost: 7.11s
Train Epoch: 1963 [61440/90000 (68%)]	Loss: -11.9121	Cost: 6.43s
Train Epoch: 1963 [81920/90000 (91%)]	Loss: -12.1122	Cost: 13.59s
Train Epoch: 1963 	Average Loss: -11.3665
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2440

Learning rate: 9.078972693933266e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1964 [0/90000 (0%)]	Loss: -7.4430	Cost: 35.11s
Train Epoch: 1964 [20480/90000 (23%)]	Loss: -11.9068	Cost: 9.80s
Train Epoch: 1964 [40960/90000 (45%)]	Loss: -11.9984	Cost: 20.97s
Train Epoch: 1964 [61440/90000 (68%)]	Loss: -12.1760	Cost: 12.05s
Train Epoch: 1964 [81920/90000 (91%)]	Loss: -12.1747	Cost: 11.71s
Train Epoch: 1964 	Average Loss: -11.6484
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4289

Saving model as e1964_model.pt & e1964_waveforms_supplementary.hdf5
Learning rate: 9.078064035439282e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1965 [0/90000 (0%)]	Loss: -7.1360	Cost: 37.90s
Train Epoch: 1965 [20480/90000 (23%)]	Loss: -11.9912	Cost: 11.83s
Train Epoch: 1965 [40960/90000 (45%)]	Loss: -12.0746	Cost: 6.63s
Train Epoch: 1965 [61440/90000 (68%)]	Loss: -12.3603	Cost: 6.15s
Train Epoch: 1965 [81920/90000 (91%)]	Loss: -12.4755	Cost: 11.80s
Train Epoch: 1965 	Average Loss: -11.8731
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6158

Saving model as e1965_model.pt & e1965_waveforms_supplementary.hdf5
Learning rate: 9.077154974456515e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1966 [0/90000 (0%)]	Loss: -7.2715	Cost: 28.28s
Train Epoch: 1966 [20480/90000 (23%)]	Loss: -12.2489	Cost: 9.33s
Train Epoch: 1966 [40960/90000 (45%)]	Loss: -12.2378	Cost: 25.54s
Train Epoch: 1966 [61440/90000 (68%)]	Loss: -12.1915	Cost: 12.89s
Train Epoch: 1966 [81920/90000 (91%)]	Loss: -11.8680	Cost: 12.07s
Train Epoch: 1966 	Average Loss: -11.7112
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1902

Learning rate: 9.076245511074684e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1967 [0/90000 (0%)]	Loss: -6.8793	Cost: 42.94s
Train Epoch: 1967 [20480/90000 (23%)]	Loss: -11.7703	Cost: 12.18s
Train Epoch: 1967 [40960/90000 (45%)]	Loss: -11.8726	Cost: 8.61s
Train Epoch: 1967 [61440/90000 (68%)]	Loss: -12.2150	Cost: 6.73s
Train Epoch: 1967 [81920/90000 (91%)]	Loss: -12.1000	Cost: 14.53s
Train Epoch: 1967 	Average Loss: -11.5663
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5136

Learning rate: 9.07533564538355e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1968 [0/90000 (0%)]	Loss: -7.0380	Cost: 30.17s
Train Epoch: 1968 [20480/90000 (23%)]	Loss: -12.0476	Cost: 9.48s
Train Epoch: 1968 [40960/90000 (45%)]	Loss: -12.0324	Cost: 16.46s
Train Epoch: 1968 [61440/90000 (68%)]	Loss: -12.1324	Cost: 13.84s
Train Epoch: 1968 [81920/90000 (91%)]	Loss: -12.1072	Cost: 12.10s
Train Epoch: 1968 	Average Loss: -11.6764
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3150

Learning rate: 9.074425377472912e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1969 [0/90000 (0%)]	Loss: -6.9044	Cost: 53.96s
Train Epoch: 1969 [20480/90000 (23%)]	Loss: -12.0436	Cost: 11.50s
Train Epoch: 1969 [40960/90000 (45%)]	Loss: -12.0421	Cost: 7.78s
Train Epoch: 1969 [61440/90000 (68%)]	Loss: -12.4229	Cost: 6.41s
Train Epoch: 1969 [81920/90000 (91%)]	Loss: -12.1632	Cost: 13.04s
Train Epoch: 1969 	Average Loss: -11.6914
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2906

Learning rate: 9.073514707432611e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1970 [0/90000 (0%)]	Loss: -6.8514	Cost: 27.25s
Train Epoch: 1970 [20480/90000 (23%)]	Loss: -12.0245	Cost: 6.84s
Train Epoch: 1970 [40960/90000 (45%)]	Loss: -12.0273	Cost: 17.32s
Train Epoch: 1970 [61440/90000 (68%)]	Loss: -12.4186	Cost: 12.98s
Train Epoch: 1970 [81920/90000 (91%)]	Loss: -12.2456	Cost: 12.33s
Train Epoch: 1970 	Average Loss: -11.7864
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4326

Learning rate: 9.072603635352528e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1971 [0/90000 (0%)]	Loss: -7.3647	Cost: 40.18s
Train Epoch: 1971 [20480/90000 (23%)]	Loss: -11.7858	Cost: 11.99s
Train Epoch: 1971 [40960/90000 (45%)]	Loss: -11.9437	Cost: 9.50s
Train Epoch: 1971 [61440/90000 (68%)]	Loss: -12.2160	Cost: 9.16s
Train Epoch: 1971 [81920/90000 (91%)]	Loss: -12.1126	Cost: 12.08s
Train Epoch: 1971 	Average Loss: -11.6314
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3167

Learning rate: 9.071692161322579e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1972 [0/90000 (0%)]	Loss: -5.9705	Cost: 34.63s
Train Epoch: 1972 [20480/90000 (23%)]	Loss: -11.8117	Cost: 9.89s
Train Epoch: 1972 [40960/90000 (45%)]	Loss: -11.9086	Cost: 18.40s
Train Epoch: 1972 [61440/90000 (68%)]	Loss: -12.2259	Cost: 12.30s
Train Epoch: 1972 [81920/90000 (91%)]	Loss: -12.0837	Cost: 12.20s
Train Epoch: 1972 	Average Loss: -11.5707
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3691

Learning rate: 9.070780285432725e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1973 [0/90000 (0%)]	Loss: -7.7079	Cost: 39.42s
Train Epoch: 1973 [20480/90000 (23%)]	Loss: -11.9484	Cost: 9.50s
Train Epoch: 1973 [40960/90000 (45%)]	Loss: -11.9937	Cost: 8.01s
Train Epoch: 1973 [61440/90000 (68%)]	Loss: -12.2665	Cost: 8.02s
Train Epoch: 1973 [81920/90000 (91%)]	Loss: -12.3582	Cost: 12.80s
Train Epoch: 1973 	Average Loss: -11.7435
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4008

Learning rate: 9.069868007772965e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1974 [0/90000 (0%)]	Loss: -7.2444	Cost: 35.39s
Train Epoch: 1974 [20480/90000 (23%)]	Loss: -12.2368	Cost: 7.20s
Train Epoch: 1974 [40960/90000 (45%)]	Loss: -12.2124	Cost: 17.01s
Train Epoch: 1974 [61440/90000 (68%)]	Loss: -12.5740	Cost: 12.11s
Train Epoch: 1974 [81920/90000 (91%)]	Loss: -12.3048	Cost: 11.92s
Train Epoch: 1974 	Average Loss: -11.8992
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.3187

Learning rate: 9.068955328433336e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1975 [0/90000 (0%)]	Loss: -7.3375	Cost: 32.15s
Train Epoch: 1975 [20480/90000 (23%)]	Loss: -12.2012	Cost: 9.29s
Train Epoch: 1975 [40960/90000 (45%)]	Loss: -12.1978	Cost: 8.34s
Train Epoch: 1975 [61440/90000 (68%)]	Loss: -12.2111	Cost: 7.71s
Train Epoch: 1975 [81920/90000 (91%)]	Loss: -11.9119	Cost: 14.33s
Train Epoch: 1975 	Average Loss: -11.8039
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1681

Learning rate: 9.068042247503917e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1976 [0/90000 (0%)]	Loss: -6.7602	Cost: 36.57s
Train Epoch: 1976 [20480/90000 (23%)]	Loss: -11.7940	Cost: 10.48s
Train Epoch: 1976 [40960/90000 (45%)]	Loss: -11.6512	Cost: 18.29s
Train Epoch: 1976 [61440/90000 (68%)]	Loss: -11.9579	Cost: 12.57s
Train Epoch: 1976 [81920/90000 (91%)]	Loss: -11.9350	Cost: 11.83s
Train Epoch: 1976 	Average Loss: -11.4719
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2930

Learning rate: 9.067128765074822e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1977 [0/90000 (0%)]	Loss: -6.5422	Cost: 41.34s
Train Epoch: 1977 [20480/90000 (23%)]	Loss: -11.6851	Cost: 6.71s
Train Epoch: 1977 [40960/90000 (45%)]	Loss: -11.9714	Cost: 13.55s
Train Epoch: 1977 [61440/90000 (68%)]	Loss: -11.9873	Cost: 8.51s
Train Epoch: 1977 [81920/90000 (91%)]	Loss: -11.8996	Cost: 8.84s
Train Epoch: 1977 	Average Loss: -11.4941
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1398

Learning rate: 9.066214881236213e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1978 [0/90000 (0%)]	Loss: -6.8516	Cost: 29.44s
Train Epoch: 1978 [20480/90000 (23%)]	Loss: -11.4777	Cost: 7.46s
Train Epoch: 1978 [40960/90000 (45%)]	Loss: -11.7004	Cost: 18.87s
Train Epoch: 1978 [61440/90000 (68%)]	Loss: -11.9356	Cost: 12.16s
Train Epoch: 1978 [81920/90000 (91%)]	Loss: -12.0487	Cost: 12.03s
Train Epoch: 1978 	Average Loss: -11.3688
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4253

Learning rate: 9.065300596078284e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1979 [0/90000 (0%)]	Loss: -6.7306	Cost: 43.31s
Train Epoch: 1979 [20480/90000 (23%)]	Loss: -11.8479	Cost: 11.96s
Train Epoch: 1979 [40960/90000 (45%)]	Loss: -12.2000	Cost: 11.90s
Train Epoch: 1979 [61440/90000 (68%)]	Loss: -12.4773	Cost: 5.98s
Train Epoch: 1979 [81920/90000 (91%)]	Loss: -12.2476	Cost: 6.16s
Train Epoch: 1979 	Average Loss: -11.7420
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5397

Learning rate: 9.064385909691271e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1980 [0/90000 (0%)]	Loss: -7.0920	Cost: 29.22s
Train Epoch: 1980 [20480/90000 (23%)]	Loss: -12.0104	Cost: 6.65s
Train Epoch: 1980 [40960/90000 (45%)]	Loss: -11.8230	Cost: 20.26s
Train Epoch: 1980 [61440/90000 (68%)]	Loss: -12.0453	Cost: 14.79s
Train Epoch: 1980 [81920/90000 (91%)]	Loss: -11.9807	Cost: 13.35s
Train Epoch: 1980 	Average Loss: -11.5967
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.4210

Learning rate: 9.06347082216545e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1981 [0/90000 (0%)]	Loss: -7.2340	Cost: 34.57s
Train Epoch: 1981 [20480/90000 (23%)]	Loss: -12.1333	Cost: 13.26s
Train Epoch: 1981 [40960/90000 (45%)]	Loss: -12.2569	Cost: 13.11s
Train Epoch: 1981 [61440/90000 (68%)]	Loss: -12.4333	Cost: 7.25s
Train Epoch: 1981 [81920/90000 (91%)]	Loss: -12.4533	Cost: 7.01s
Train Epoch: 1981 	Average Loss: -11.8886
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7409

Saving model as e1981_model.pt & e1981_waveforms_supplementary.hdf5
Learning rate: 9.062555333591139e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1982 [0/90000 (0%)]	Loss: -7.4933	Cost: 31.40s
Train Epoch: 1982 [20480/90000 (23%)]	Loss: -12.2111	Cost: 8.58s
Train Epoch: 1982 [40960/90000 (45%)]	Loss: -12.2509	Cost: 12.87s
Train Epoch: 1982 [61440/90000 (68%)]	Loss: -12.4065	Cost: 7.26s
Train Epoch: 1982 [81920/90000 (91%)]	Loss: -12.2957	Cost: 18.30s
Train Epoch: 1982 	Average Loss: -11.8852
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5045

Learning rate: 9.06163944405869e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1983 [0/90000 (0%)]	Loss: -6.2074	Cost: 39.28s
Train Epoch: 1983 [20480/90000 (23%)]	Loss: -12.1244	Cost: 12.76s
Train Epoch: 1983 [40960/90000 (45%)]	Loss: -12.2273	Cost: 12.21s
Train Epoch: 1983 [61440/90000 (68%)]	Loss: -12.3089	Cost: 9.81s
Train Epoch: 1983 [81920/90000 (91%)]	Loss: -11.8167	Cost: 6.59s
Train Epoch: 1983 	Average Loss: -11.6937
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.1410

Learning rate: 9.0607231536585e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1984 [0/90000 (0%)]	Loss: -5.9402	Cost: 31.68s
Train Epoch: 1984 [20480/90000 (23%)]	Loss: -11.6671	Cost: 9.16s
Train Epoch: 1984 [40960/90000 (45%)]	Loss: -11.8051	Cost: 11.61s
Train Epoch: 1984 [61440/90000 (68%)]	Loss: -11.8250	Cost: 8.64s
Train Epoch: 1984 [81920/90000 (91%)]	Loss: -11.7815	Cost: 8.99s
Train Epoch: 1984 	Average Loss: -11.3749
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.2030

Learning rate: 9.059806462481002e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1985 [0/90000 (0%)]	Loss: -6.4947	Cost: 32.27s
Train Epoch: 1985 [20480/90000 (23%)]	Loss: -11.8060	Cost: 6.89s
Train Epoch: 1985 [40960/90000 (45%)]	Loss: -11.7233	Cost: 18.24s
Train Epoch: 1985 [61440/90000 (68%)]	Loss: -12.2415	Cost: 12.06s
Train Epoch: 1985 [81920/90000 (91%)]	Loss: -12.2712	Cost: 11.89s
Train Epoch: 1985 	Average Loss: -11.5927
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5092

Learning rate: 9.05888937061667e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1986 [0/90000 (0%)]	Loss: -7.1286	Cost: 31.00s
Train Epoch: 1986 [20480/90000 (23%)]	Loss: -12.2520	Cost: 11.78s
Train Epoch: 1986 [40960/90000 (45%)]	Loss: -12.2679	Cost: 8.74s
Train Epoch: 1986 [61440/90000 (68%)]	Loss: -12.5649	Cost: 6.82s
Train Epoch: 1986 [81920/90000 (91%)]	Loss: -12.3559	Cost: 13.48s
Train Epoch: 1986 	Average Loss: -11.8767
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7398

Learning rate: 9.057971878156017e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1987 [0/90000 (0%)]	Loss: -6.7747	Cost: 30.62s
Train Epoch: 1987 [20480/90000 (23%)]	Loss: -12.1481	Cost: 10.30s
Train Epoch: 1987 [40960/90000 (45%)]	Loss: -12.0711	Cost: 20.04s
Train Epoch: 1987 [61440/90000 (68%)]	Loss: -12.3878	Cost: 12.36s
Train Epoch: 1987 [81920/90000 (91%)]	Loss: -12.2705	Cost: 11.76s
Train Epoch: 1987 	Average Loss: -11.8815
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5598

Learning rate: 9.057053985189597e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1988 [0/90000 (0%)]	Loss: -7.7159	Cost: 42.90s
Train Epoch: 1988 [20480/90000 (23%)]	Loss: -12.1706	Cost: 10.20s
Train Epoch: 1988 [40960/90000 (45%)]	Loss: -12.2683	Cost: 9.86s
Train Epoch: 1988 [61440/90000 (68%)]	Loss: -12.4617	Cost: 6.40s
Train Epoch: 1988 [81920/90000 (91%)]	Loss: -12.2534	Cost: 12.85s
Train Epoch: 1988 	Average Loss: -11.8931
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.5599

Learning rate: 9.056135691808e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1989 [0/90000 (0%)]	Loss: -6.3847	Cost: 28.58s
Train Epoch: 1989 [20480/90000 (23%)]	Loss: -11.9989	Cost: 8.91s
Train Epoch: 1989 [40960/90000 (45%)]	Loss: -12.2246	Cost: 18.49s
Train Epoch: 1989 [61440/90000 (68%)]	Loss: -12.5329	Cost: 12.03s
Train Epoch: 1989 [81920/90000 (91%)]	Loss: -12.5006	Cost: 12.12s
Train Epoch: 1989 	Average Loss: -11.8367
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7215

Learning rate: 9.05521699810186e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1990 [0/90000 (0%)]	Loss: -7.4079	Cost: 34.91s
Train Epoch: 1990 [20480/90000 (23%)]	Loss: -12.1225	Cost: 11.95s
Train Epoch: 1990 [40960/90000 (45%)]	Loss: -12.3977	Cost: 11.14s
Train Epoch: 1990 [61440/90000 (68%)]	Loss: -12.6552	Cost: 6.57s
Train Epoch: 1990 [81920/90000 (91%)]	Loss: -12.4774	Cost: 7.79s
Train Epoch: 1990 	Average Loss: -12.0354
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.7744

Saving model as e1990_model.pt & e1990_waveforms_supplementary.hdf5
Learning rate: 9.054297904161849e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1991 [0/90000 (0%)]	Loss: -7.3425	Cost: 24.97s
Train Epoch: 1991 [20480/90000 (23%)]	Loss: -12.4009	Cost: 8.34s
Train Epoch: 1991 [40960/90000 (45%)]	Loss: -12.4617	Cost: 14.94s
Train Epoch: 1991 [61440/90000 (68%)]	Loss: -12.6442	Cost: 12.39s
Train Epoch: 1991 [81920/90000 (91%)]	Loss: -12.2870	Cost: 12.97s
Train Epoch: 1991 	Average Loss: -12.0426
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Test set: Average loss: -7.6536

Learning rate: 9.053378410078676e-05
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
Train Epoch: 1992 [0/90000 (0%)]	Loss: -6.6210	Cost: 42.16s
Train Epoch: 1992 [20480/90000 (23%)]	Loss: -12.0245	Cost: 14.54s
Train Epoch: 1992 [40960/90000 (45%)]	Loss: -12.0543	Cost: 12.24s
Train Epoch: 1992 [61440/90000 (68%)]	Loss: -12.1380	Cost: 9.96s
Train Epoch: 1992 [81920/90000 (91%)]	Loss: -12.2456	Cost: 6.08s
Train Epoch: 1992 	Average Loss: -11.6983
Re-generating waveforms for posterior prior.
Setting extrinsic parameters to fiducial values.
